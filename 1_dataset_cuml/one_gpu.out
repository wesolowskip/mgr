pwesolowski@eden:~/praca-mgr/pipelines-repo/1_dataset_cuml$ cat slurm-690720.out.1-gpu-8cpu
+ CONTAINER=/home2/faculty/pwesolowski/containers/cuml-prod.sif
+ CONTAINER_RC_FILE=/home2/faculty/pwesolowski/containers/singularity_rc
+ SCRIPT=/home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/run_no_gds.sh
+ MP_FORCE_HOST_READ=--mp-force-host-read
+ for FILES in "California.json"
+ for PROTOCOL in tcp ucx
+ for ENABLE_IB in "--enable-infiniband" ""
+ for ENABLE_NVLINK in "--enable-nvlink" ""
+ for RMM_POOL_SIZE in ""
+ for MP_BLOCKSIZE in "256MiB" "1GiB" "4GiB"
+ for MP_PINNED_READ in "" "--mp-pinned-read"
+ [[ tcp == ucx ]]
+ [[ --enable-infiniband == '' ]]
+ for MP_PINNED_READ in "" "--mp-pinned-read"
+ [[ tcp == ucx ]]
+ [[ --enable-infiniband == '' ]]
+ for MP_BLOCKSIZE in "256MiB" "1GiB" "4GiB"
+ for MP_PINNED_READ in "" "--mp-pinned-read"
+ [[ tcp == ucx ]]
+ [[ --enable-infiniband == '' ]]
+ for MP_PINNED_READ in "" "--mp-pinned-read"
+ [[ tcp == ucx ]]
+ [[ --enable-infiniband == '' ]]
+ for MP_BLOCKSIZE in "256MiB" "1GiB" "4GiB"
+ for MP_PINNED_READ in "" "--mp-pinned-read"
+ [[ tcp == ucx ]]
+ [[ --enable-infiniband == '' ]]
+ for MP_PINNED_READ in "" "--mp-pinned-read"
+ [[ tcp == ucx ]]
+ [[ --enable-infiniband == '' ]]
+ for ENABLE_NVLINK in "--enable-nvlink" ""
+ for RMM_POOL_SIZE in ""
+ for MP_BLOCKSIZE in "256MiB" "1GiB" "4GiB"
+ for MP_PINNED_READ in "" "--mp-pinned-read"
+ [[ tcp == ucx ]]
+ [[ --enable-infiniband == '' ]]
+ for MP_PINNED_READ in "" "--mp-pinned-read"
+ [[ tcp == ucx ]]
+ [[ --enable-infiniband == '' ]]
+ for MP_BLOCKSIZE in "256MiB" "1GiB" "4GiB"
+ for MP_PINNED_READ in "" "--mp-pinned-read"
+ [[ tcp == ucx ]]
+ [[ --enable-infiniband == '' ]]
+ for MP_PINNED_READ in "" "--mp-pinned-read"
+ [[ tcp == ucx ]]
+ [[ --enable-infiniband == '' ]]
+ for MP_BLOCKSIZE in "256MiB" "1GiB" "4GiB"
+ for MP_PINNED_READ in "" "--mp-pinned-read"
+ [[ tcp == ucx ]]
+ [[ --enable-infiniband == '' ]]
+ for MP_PINNED_READ in "" "--mp-pinned-read"
+ [[ tcp == ucx ]]
+ [[ --enable-infiniband == '' ]]
+ for ENABLE_IB in "--enable-infiniband" ""
+ for ENABLE_NVLINK in "--enable-nvlink" ""
+ for RMM_POOL_SIZE in ""
+ for MP_BLOCKSIZE in "256MiB" "1GiB" "4GiB"
+ for MP_PINNED_READ in "" "--mp-pinned-read"
+ [[ tcp == ucx ]]
+ [[ '' == '' ]]
+ [[ --enable-nvlink == '' ]]
+ for MP_PINNED_READ in "" "--mp-pinned-read"
+ [[ tcp == ucx ]]
+ [[ '' == '' ]]
+ [[ --enable-nvlink == '' ]]
+ for MP_BLOCKSIZE in "256MiB" "1GiB" "4GiB"
+ for MP_PINNED_READ in "" "--mp-pinned-read"
+ [[ tcp == ucx ]]
+ [[ '' == '' ]]
+ [[ --enable-nvlink == '' ]]
+ for MP_PINNED_READ in "" "--mp-pinned-read"
+ [[ tcp == ucx ]]
+ [[ '' == '' ]]
+ [[ --enable-nvlink == '' ]]
+ for MP_BLOCKSIZE in "256MiB" "1GiB" "4GiB"
+ for MP_PINNED_READ in "" "--mp-pinned-read"
+ [[ tcp == ucx ]]
+ [[ '' == '' ]]
+ [[ --enable-nvlink == '' ]]
+ for MP_PINNED_READ in "" "--mp-pinned-read"
+ [[ tcp == ucx ]]
+ [[ '' == '' ]]
+ [[ --enable-nvlink == '' ]]
+ for ENABLE_NVLINK in "--enable-nvlink" ""
+ for RMM_POOL_SIZE in ""
+ for MP_BLOCKSIZE in "256MiB" "1GiB" "4GiB"
+ for MP_PINNED_READ in "" "--mp-pinned-read"
+ [[ tcp == ucx ]]
+ [[ '' == '' ]]
+ [[ '' == '' ]]
+ FILES=California.json
+ PROTOCOL=tcp
+ ENABLE_IB=
+ ENABLE_NVLINK=
+ RMM_POOL_SIZE=
+ MP_BLOCKSIZE=256MiB
+ MP_PINNED_READ=
+ MP_FORCE_HOST_READ=--mp-force-host-read
+ singularity run --nv -B /scratch/shared/pwesolowski /home2/faculty/pwesolowski/containers/cuml-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/run_no_gds.sh
[WARN  tini (3218815)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
+ cd /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/
+ python -u cuml_single_node.py --files California.json --reps 5 --protocol tcp --mp-blocksize 256MiB --mp-force-host-read
<Managed Device 0>
args=Namespace(data_dir='/scratch/shared/pwesolowski/mgr-pipeline/joined-cuml', files=['California.json'], reps=5, protocol='tcp', enable_infiniband=False, enable_nvlink=False, rmm_pool_size=None, jit_unspill=False, mp_blocksize='256MiB', mp_force_host_read=True, mp_pinned_read=False, mp_force_gpu_preprocess=False)
2023-07-07 09:38:18,616 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-07 09:38:18,616 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
Code block 'ddf-preprocessing' took: 41396.42401 ms
Code block 'ddf-preprocessing' took: 15395.19691 ms
Code block 'ddf-preprocessing' took: 14966.40719 ms
Code block 'ddf-preprocessing' took: 14987.17677 ms
Code block 'ddf-preprocessing' took: 14885.01025 ms
Code block 'ddf-scaler-fit' took: 14893.27185 ms
Code block 'ddf-scaler-fit' took: 14807.76980 ms
Code block 'ddf-scaler-fit' took: 15109.77206 ms
Code block 'ddf-scaler-fit' took: 15831.57348 ms
Code block 'ddf-scaler-fit' took: 16185.41961 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 46850.25969 ms
Code block 'ddf-kmeans-score' took: 15799.22379 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 42649.45352 ms
Code block 'ddf-kmeans-score' took: 15672.68396 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 42644.57383 ms
Code block 'ddf-kmeans-score' took: 17287.88676 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 42535.63238 ms
Code block 'ddf-kmeans-score' took: 16026.20160 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 42694.19140 ms
Code block 'ddf-kmeans-score' took: 15640.40912 ms
scores=[array(-4847342.78125)]
client.get_worker_logs()={'tcp://127.0.0.1:44431': (('INFO', "2023-07-07 09:46:42,231 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 09:46:14,932 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 09:45:42,478 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 09:45:15,176 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 09:44:41,610 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 09:44:14,301 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 09:43:42,093 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 09:43:14,800 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 09:42:42,598 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 09:42:11,225 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', '2023-07-07 09:38:24,485 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 09:38:24,485 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:44623'), ('INFO', '2023-07-07 09:38:24,435 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 09:38:19,698 - distributed.worker - INFO - Starting Worker plugin PreImport-d1044783-1913-4c9a-bab9-c6d87c452ced'), ('INFO', '2023-07-07 09:38:19,698 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ff3cfdc7-f210-4695-9bae-cb2be8bdbcbd'), ('INFO', '2023-07-07 09:38:19,698 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d5a94cb9-af32-4a52-adf1-e83395483c1d'), ('INFO', '2023-07-07 09:38:19,698 - distributed.worker - INFO -       Local Directory: /scratch/shared/pwesolowski/mgr-pipeline/joined-cuml/tmp/dask-worker-space/worker-5m4qafq8'), ('INFO', '2023-07-07 09:38:19,698 - distributed.worker - INFO -                Memory:                  50.00 GiB'), ('INFO', '2023-07-07 09:38:19,698 - distributed.worker - INFO -               Threads:                          2'), ('INFO', '2023-07-07 09:38:19,698 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 09:38:19,698 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:44623'), ('INFO', '2023-07-07 09:38:19,698 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46595'), ('INFO', '2023-07-07 09:38:19,698 - distributed.worker - INFO -           Worker name:                          0'), ('INFO', '2023-07-07 09:38:19,698 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44431'), ('INFO', '2023-07-07 09:38:19,698 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44431'))}
2023-07-07 09:47:02,558 - distributed.nanny - WARNING - Worker process still alive after 3.1999990844726565 seconds, killing
+ sleep 1
+ for MP_PINNED_READ in "" "--mp-pinned-read"
+ [[ tcp == ucx ]]
+ [[ '' == '' ]]
+ [[ '' == '' ]]
+ FILES=California.json
+ PROTOCOL=tcp
+ ENABLE_IB=
+ ENABLE_NVLINK=
+ RMM_POOL_SIZE=
+ MP_BLOCKSIZE=256MiB
+ MP_PINNED_READ=--mp-pinned-read
+ MP_FORCE_HOST_READ=--mp-force-host-read
+ singularity run --nv -B /scratch/shared/pwesolowski /home2/faculty/pwesolowski/containers/cuml-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/run_no_gds.sh
[WARN  tini (3230140)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
+ cd /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/
+ python -u cuml_single_node.py --files California.json --reps 5 --protocol tcp --mp-blocksize 256MiB --mp-force-host-read --mp-pinned-read
<Managed Device 0>
args=Namespace(data_dir='/scratch/shared/pwesolowski/mgr-pipeline/joined-cuml', files=['California.json'], reps=5, protocol='tcp', enable_infiniband=False, enable_nvlink=False, rmm_pool_size=None, jit_unspill=False, mp_blocksize='256MiB', mp_force_host_read=True, mp_pinned_read=True, mp_force_gpu_preprocess=False)
2023-07-07 09:47:43,109 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-07 09:47:43,109 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
Code block 'ddf-preprocessing' took: 38127.31664 ms
Code block 'ddf-preprocessing' took: 14913.95126 ms
Code block 'ddf-preprocessing' took: 14952.50962 ms
Code block 'ddf-preprocessing' took: 14892.53382 ms
Code block 'ddf-preprocessing' took: 15010.87911 ms
Code block 'ddf-scaler-fit' took: 18002.89028 ms
Code block 'ddf-scaler-fit' took: 17705.81758 ms
Code block 'ddf-scaler-fit' took: 17690.58190 ms
Code block 'ddf-scaler-fit' took: 18557.56808 ms
Code block 'ddf-scaler-fit' took: 20070.54128 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 49861.21464 ms
Code block 'ddf-kmeans-score' took: 18811.20506 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 45416.82150 ms
Code block 'ddf-kmeans-score' took: 18528.34985 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 45573.38234 ms
Code block 'ddf-kmeans-score' took: 18675.97946 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 45728.93597 ms
Code block 'ddf-kmeans-score' took: 18775.78014 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 45549.60484 ms
Code block 'ddf-kmeans-score' took: 19060.01610 ms
scores=[array(-4846416.25)]
client.get_worker_logs()={'tcp://127.0.0.1:44451': (('INFO', "2023-07-07 09:56:17,681 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 09:55:50,351 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 09:55:12,316 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 09:54:44,974 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 09:54:06,857 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 09:53:39,590 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 09:53:01,541 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 09:52:34,283 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 09:51:56,201 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 09:51:24,680 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', '2023-07-07 09:47:47,725 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 09:47:47,725 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:33347'), ('INFO', '2023-07-07 09:47:47,678 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 09:47:44,195 - distributed.worker - INFO - Starting Worker plugin PreImport-d886d256-3889-41af-9dd9-e6ac92f9e62f'), ('INFO', '2023-07-07 09:47:44,195 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-1063b53e-8446-4c56-822f-ae564e1f879d'), ('INFO', '2023-07-07 09:47:44,195 - distributed.worker - INFO - Starting Worker plugin RMMSetup-06f5d6e5-40d0-48da-a345-bad06d8030d5'), ('INFO', '2023-07-07 09:47:44,195 - distributed.worker - INFO -       Local Directory: /scratch/shared/pwesolowski/mgr-pipeline/joined-cuml/tmp/dask-worker-space/worker-de__luqg'), ('INFO', '2023-07-07 09:47:44,195 - distributed.worker - INFO -                Memory:                  50.00 GiB'), ('INFO', '2023-07-07 09:47:44,195 - distributed.worker - INFO -               Threads:                          2'), ('INFO', '2023-07-07 09:47:44,195 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 09:47:44,195 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:33347'), ('INFO', '2023-07-07 09:47:44,195 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33115'), ('INFO', '2023-07-07 09:47:44,195 - distributed.worker - INFO -           Worker name:                          0'), ('INFO', '2023-07-07 09:47:44,195 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44451'), ('INFO', '2023-07-07 09:47:44,195 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44451'))}
2023-07-07 09:56:41,391 - distributed.nanny - WARNING - Worker process still alive after 3.1999989318847657 seconds, killing
+ sleep 1
+ for MP_BLOCKSIZE in "256MiB" "1GiB" "4GiB"
+ for MP_PINNED_READ in "" "--mp-pinned-read"
+ [[ tcp == ucx ]]
+ [[ '' == '' ]]
+ [[ '' == '' ]]
+ FILES=California.json
+ PROTOCOL=tcp
+ ENABLE_IB=
+ ENABLE_NVLINK=
+ RMM_POOL_SIZE=
+ MP_BLOCKSIZE=1GiB
+ MP_PINNED_READ=
+ MP_FORCE_HOST_READ=--mp-force-host-read
+ singularity run --nv -B /scratch/shared/pwesolowski /home2/faculty/pwesolowski/containers/cuml-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/run_no_gds.sh
[WARN  tini (3241265)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
+ cd /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/
+ python -u cuml_single_node.py --files California.json --reps 5 --protocol tcp --mp-blocksize 1GiB --mp-force-host-read
<Managed Device 0>
args=Namespace(data_dir='/scratch/shared/pwesolowski/mgr-pipeline/joined-cuml', files=['California.json'], reps=5, protocol='tcp', enable_infiniband=False, enable_nvlink=False, rmm_pool_size=None, jit_unspill=False, mp_blocksize='1GiB', mp_force_host_read=True, mp_pinned_read=False, mp_force_gpu_preprocess=False)
2023-07-07 09:57:06,562 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-07 09:57:06,562 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
Code block 'ddf-preprocessing' took: 36895.31931 ms
Code block 'ddf-preprocessing' took: 14822.76523 ms
Code block 'ddf-preprocessing' took: 14733.88714 ms
Code block 'ddf-preprocessing' took: 14866.05743 ms
Code block 'ddf-preprocessing' took: 14755.49057 ms
Code block 'ddf-scaler-fit' took: 13101.94911 ms
Code block 'ddf-scaler-fit' took: 12392.92515 ms
Code block 'ddf-scaler-fit' took: 12464.13972 ms
Code block 'ddf-scaler-fit' took: 13289.79666 ms
Code block 'ddf-scaler-fit' took: 13390.79271 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 44819.63587 ms
Code block 'ddf-kmeans-score' took: 13011.37088 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 39811.44818 ms
Code block 'ddf-kmeans-score' took: 13180.46760 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 40163.25091 ms
Code block 'ddf-kmeans-score' took: 13384.43715 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 40289.17105 ms
Code block 'ddf-kmeans-score' took: 13243.65705 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 40240.34110 ms
Code block 'ddf-kmeans-score' took: 13301.12277 ms
scores=[array(-4836194.96875)]
client.get_worker_logs()={'tcp://127.0.0.1:42017': (('INFO', "2023-07-07 10:04:21,968 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 10:03:54,749 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 10:03:27,492 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 10:03:00,192 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 10:02:32,840 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 10:02:05,590 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 10:01:38,369 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 10:01:11,055 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 10:00:44,364 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 10:00:13,160 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', '2023-07-07 09:57:11,009 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 09:57:11,009 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:41171'), ('INFO', '2023-07-07 09:57:10,966 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 09:57:07,550 - distributed.worker - INFO - Starting Worker plugin PreImport-7f7af064-3f94-4247-a31c-41ff2f3abaaa'), ('INFO', '2023-07-07 09:57:07,550 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-230a5749-cec6-4f4a-944a-28e8491e686d'), ('INFO', '2023-07-07 09:57:07,550 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0fc99fd7-3dcc-4466-a80b-a449941fd95b'), ('INFO', '2023-07-07 09:57:07,550 - distributed.worker - INFO -       Local Directory: /scratch/shared/pwesolowski/mgr-pipeline/joined-cuml/tmp/dask-worker-space/worker-fkozfnjw'), ('INFO', '2023-07-07 09:57:07,549 - distributed.worker - INFO -                Memory:                  50.00 GiB'), ('INFO', '2023-07-07 09:57:07,549 - distributed.worker - INFO -               Threads:                          2'), ('INFO', '2023-07-07 09:57:07,549 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 09:57:07,549 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:41171'), ('INFO', '2023-07-07 09:57:07,549 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39347'), ('INFO', '2023-07-07 09:57:07,549 - distributed.worker - INFO -           Worker name:                          0'), ('INFO', '2023-07-07 09:57:07,549 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42017'), ('INFO', '2023-07-07 09:57:07,549 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42017'))}
+ sleep 1
+ for MP_PINNED_READ in "" "--mp-pinned-read"
+ [[ tcp == ucx ]]
+ [[ '' == '' ]]
+ [[ '' == '' ]]
+ FILES=California.json
+ PROTOCOL=tcp
+ ENABLE_IB=
+ ENABLE_NVLINK=
+ RMM_POOL_SIZE=
+ MP_BLOCKSIZE=1GiB
+ MP_PINNED_READ=--mp-pinned-read
+ MP_FORCE_HOST_READ=--mp-force-host-read
+ singularity run --nv -B /scratch/shared/pwesolowski /home2/faculty/pwesolowski/containers/cuml-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/run_no_gds.sh
[WARN  tini (3249820)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
+ cd /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/
+ python -u cuml_single_node.py --files California.json --reps 5 --protocol tcp --mp-blocksize 1GiB --mp-force-host-read --mp-pinned-read
<Managed Device 0>
args=Namespace(data_dir='/scratch/shared/pwesolowski/mgr-pipeline/joined-cuml', files=['California.json'], reps=5, protocol='tcp', enable_infiniband=False, enable_nvlink=False, rmm_pool_size=None, jit_unspill=False, mp_blocksize='1GiB', mp_force_host_read=True, mp_pinned_read=True, mp_force_gpu_preprocess=False)
2023-07-07 10:05:05,178 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-07 10:05:05,178 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
Code block 'ddf-preprocessing' took: 36853.49158 ms
Code block 'ddf-preprocessing' took: 14792.48264 ms
Code block 'ddf-preprocessing' took: 14885.15869 ms
Code block 'ddf-preprocessing' took: 14916.37519 ms
Code block 'ddf-preprocessing' took: 14679.68339 ms
Code block 'ddf-scaler-fit' took: 16351.22752 ms
Code block 'ddf-scaler-fit' took: 15687.22426 ms
Code block 'ddf-scaler-fit' took: 15457.90862 ms
Code block 'ddf-scaler-fit' took: 15751.94594 ms
Code block 'ddf-scaler-fit' took: 15744.85168 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 47472.04038 ms
Code block 'ddf-kmeans-score' took: 16002.90727 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 42888.13604 ms
Code block 'ddf-kmeans-score' took: 16040.20894 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 43600.95902 ms
Code block 'ddf-kmeans-score' took: 16970.49315 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 43071.04218 ms
Code block 'ddf-kmeans-score' took: 16062.71540 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 43236.71382 ms
Code block 'ddf-kmeans-score' took: 16190.98459 ms
scores=[array(-4848274.625)]
client.get_worker_logs()={'tcp://127.0.0.1:46573': (('INFO', "2023-07-07 10:13:03,171 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 10:12:35,922 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 10:12:02,878 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 10:11:35,633 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 10:11:01,850 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 10:10:34,642 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 10:10:01,190 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 10:09:33,969 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 10:09:01,125 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 10:08:29,782 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', '2023-07-07 10:05:09,874 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 10:05:09,874 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:45493'), ('INFO', '2023-07-07 10:05:09,841 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 10:05:06,397 - distributed.worker - INFO - Starting Worker plugin PreImport-ed96e17b-09fd-46b8-b98d-e4036b94b63a'), ('INFO', '2023-07-07 10:05:06,397 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ad6da3a0-421e-487d-89a9-244574d74614'), ('INFO', '2023-07-07 10:05:06,397 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ad537861-7edb-40b1-896a-e8801e2a1883'), ('INFO', '2023-07-07 10:05:06,397 - distributed.worker - INFO -       Local Directory: /scratch/shared/pwesolowski/mgr-pipeline/joined-cuml/tmp/dask-worker-space/worker-2wgy58kz'), ('INFO', '2023-07-07 10:05:06,397 - distributed.worker - INFO -                Memory:                  50.00 GiB'), ('INFO', '2023-07-07 10:05:06,397 - distributed.worker - INFO -               Threads:                          2'), ('INFO', '2023-07-07 10:05:06,396 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 10:05:06,396 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:45493'), ('INFO', '2023-07-07 10:05:06,396 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35485'), ('INFO', '2023-07-07 10:05:06,396 - distributed.worker - INFO -           Worker name:                          0'), ('INFO', '2023-07-07 10:05:06,396 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46573'), ('INFO', '2023-07-07 10:05:06,396 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46573'))}
2023-07-07 10:13:24,127 - distributed.nanny - WARNING - Worker process still alive after 3.1999990844726565 seconds, killing
+ sleep 1
+ for MP_BLOCKSIZE in "256MiB" "1GiB" "4GiB"
+ for MP_PINNED_READ in "" "--mp-pinned-read"
+ [[ tcp == ucx ]]
+ [[ '' == '' ]]
+ [[ '' == '' ]]
+ FILES=California.json
+ PROTOCOL=tcp
+ ENABLE_IB=
+ ENABLE_NVLINK=
+ RMM_POOL_SIZE=
+ MP_BLOCKSIZE=4GiB
+ MP_PINNED_READ=
+ MP_FORCE_HOST_READ=--mp-force-host-read
+ singularity run --nv -B /scratch/shared/pwesolowski /home2/faculty/pwesolowski/containers/cuml-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/run_no_gds.sh
[WARN  tini (3259485)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
+ cd /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/
+ python -u cuml_single_node.py --files California.json --reps 5 --protocol tcp --mp-blocksize 4GiB --mp-force-host-read
<Managed Device 0>
args=Namespace(data_dir='/scratch/shared/pwesolowski/mgr-pipeline/joined-cuml', files=['California.json'], reps=5, protocol='tcp', enable_infiniband=False, enable_nvlink=False, rmm_pool_size=None, jit_unspill=False, mp_blocksize='4GiB', mp_force_host_read=True, mp_pinned_read=False, mp_force_gpu_preprocess=False)
2023-07-07 10:13:46,028 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-07 10:13:46,028 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
Code block 'ddf-preprocessing' took: 37553.72878 ms
Code block 'ddf-preprocessing' took: 14705.48265 ms
Code block 'ddf-preprocessing' took: 14583.68196 ms
Code block 'ddf-preprocessing' took: 14701.98140 ms
Code block 'ddf-preprocessing' took: 14596.73329 ms
Code block 'ddf-scaler-fit' took: 12805.92492 ms
Code block 'ddf-scaler-fit' took: 11920.80112 ms
Code block 'ddf-scaler-fit' took: 12053.19062 ms
Code block 'ddf-scaler-fit' took: 11779.63762 ms
Code block 'ddf-scaler-fit' took: 12325.31050 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 45303.25582 ms
Code block 'ddf-kmeans-score' took: 12966.17797 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 41819.91947 ms
Code block 'ddf-kmeans-score' took: 12673.37625 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 42343.45006 ms
Code block 'ddf-kmeans-score' took: 12649.22712 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 41377.50454 ms
Code block 'ddf-kmeans-score' took: 12697.53686 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 41172.99741 ms
Code block 'ddf-kmeans-score' took: 12672.39944 ms
scores=[array(-9703555.5)]
client.get_worker_logs()={'tcp://127.0.0.1:35379': (('INFO', "2023-07-07 10:21:03,861 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 10:20:34,720 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 10:20:09,000 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 10:19:39,900 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 10:19:13,891 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 10:18:44,732 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 10:18:17,888 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 10:17:48,798 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 10:17:21,782 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 10:16:48,704 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', '2023-07-07 10:13:50,458 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 10:13:50,458 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:44951'), ('INFO', '2023-07-07 10:13:50,416 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 10:13:50,416 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6e859ee6-5907-413c-b13f-396cd91542f3'), ('INFO', '2023-07-07 10:13:50,416 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-06004cbf-eb00-4312-8261-e4f2d609c1b5'), ('INFO', '2023-07-07 10:13:47,260 - distributed.worker - INFO - Starting Worker plugin PreImport-4022a23e-16a1-4b66-8dba-ff7a52f7c073'), ('INFO', '2023-07-07 10:13:47,260 - distributed.worker - INFO -       Local Directory: /scratch/shared/pwesolowski/mgr-pipeline/joined-cuml/tmp/dask-worker-space/worker-m8e77gog'), ('INFO', '2023-07-07 10:13:47,260 - distributed.worker - INFO -                Memory:                  50.00 GiB'), ('INFO', '2023-07-07 10:13:47,260 - distributed.worker - INFO -               Threads:                          2'), ('INFO', '2023-07-07 10:13:47,260 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 10:13:47,260 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:44951'), ('INFO', '2023-07-07 10:13:47,260 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46791'), ('INFO', '2023-07-07 10:13:47,260 - distributed.worker - INFO -           Worker name:                          0'), ('INFO', '2023-07-07 10:13:47,260 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35379'), ('INFO', '2023-07-07 10:13:47,260 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35379'))}
2023-07-07 10:21:21,112 - distributed.nanny - WARNING - Worker process still alive after 3.199999694824219 seconds, killing
+ sleep 1
+ for MP_PINNED_READ in "" "--mp-pinned-read"
+ [[ tcp == ucx ]]
+ [[ '' == '' ]]
+ [[ '' == '' ]]
+ FILES=California.json
+ PROTOCOL=tcp
+ ENABLE_IB=
+ ENABLE_NVLINK=
+ RMM_POOL_SIZE=
+ MP_BLOCKSIZE=4GiB
+ MP_PINNED_READ=--mp-pinned-read
+ MP_FORCE_HOST_READ=--mp-force-host-read
+ singularity run --nv -B /scratch/shared/pwesolowski /home2/faculty/pwesolowski/containers/cuml-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/run_no_gds.sh
[WARN  tini (3268476)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
+ cd /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/
+ python -u cuml_single_node.py --files California.json --reps 5 --protocol tcp --mp-blocksize 4GiB --mp-force-host-read --mp-pinned-read
<Managed Device 0>
args=Namespace(data_dir='/scratch/shared/pwesolowski/mgr-pipeline/joined-cuml', files=['California.json'], reps=5, protocol='tcp', enable_infiniband=False, enable_nvlink=False, rmm_pool_size=None, jit_unspill=False, mp_blocksize='4GiB', mp_force_host_read=True, mp_pinned_read=True, mp_force_gpu_preprocess=False)
2023-07-07 10:21:43,330 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-07 10:21:43,330 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
Code block 'ddf-preprocessing' took: 37806.17313 ms
Code block 'ddf-preprocessing' took: 14743.81383 ms
Code block 'ddf-preprocessing' took: 14608.70410 ms
Code block 'ddf-preprocessing' took: 14799.70686 ms
Code block 'ddf-preprocessing' took: 14720.01069 ms
Code block 'ddf-scaler-fit' took: 15359.39242 ms
Code block 'ddf-scaler-fit' took: 14351.65725 ms
Code block 'ddf-scaler-fit' took: 14504.22782 ms
Code block 'ddf-scaler-fit' took: 14447.53221 ms
Code block 'ddf-scaler-fit' took: 14459.61955 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 47954.88078 ms
Code block 'ddf-kmeans-score' took: 15098.75756 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 44612.85381 ms
Code block 'ddf-kmeans-score' took: 15167.44314 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 44144.54277 ms
Code block 'ddf-kmeans-score' took: 14963.67888 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 44652.38459 ms
Code block 'ddf-kmeans-score' took: 15454.98771 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 47678.63970 ms
Code block 'ddf-kmeans-score' took: 15564.76908 ms
scores=[array(-19106068.75)]
client.get_worker_logs()={'tcp://127.0.0.1:41767': (('INFO', "2023-07-07 10:29:40,168 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 10:29:10,666 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 10:28:36,043 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 10:28:06,903 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 10:27:35,382 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 10:27:06,234 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 10:26:35,071 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 10:26:05,874 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 10:25:33,976 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 10:25:00,902 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', '2023-07-07 10:21:47,984 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 10:21:47,984 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:42501'), ('INFO', '2023-07-07 10:21:47,951 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 10:21:47,950 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-de763d77-2a2f-4a64-b992-cac486627ab7'), ('INFO', '2023-07-07 10:21:44,406 - distributed.worker - INFO - Starting Worker plugin PreImport-9de8a02a-6674-40f4-809d-5616824f7cf0'), ('INFO', '2023-07-07 10:21:44,406 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3652c368-6d78-4f07-9633-e5b4ac5fd0c0'), ('INFO', '2023-07-07 10:21:44,406 - distributed.worker - INFO -       Local Directory: /scratch/shared/pwesolowski/mgr-pipeline/joined-cuml/tmp/dask-worker-space/worker-6tuh41wb'), ('INFO', '2023-07-07 10:21:44,406 - distributed.worker - INFO -                Memory:                  50.00 GiB'), ('INFO', '2023-07-07 10:21:44,406 - distributed.worker - INFO -               Threads:                          2'), ('INFO', '2023-07-07 10:21:44,406 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 10:21:44,406 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:42501'), ('INFO', '2023-07-07 10:21:44,406 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44119'), ('INFO', '2023-07-07 10:21:44,406 - distributed.worker - INFO -           Worker name:                          0'), ('INFO', '2023-07-07 10:21:44,406 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41767'), ('INFO', '2023-07-07 10:21:44,406 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41767'))}
+ sleep 1
+ for PROTOCOL in tcp ucx
+ for ENABLE_IB in "--enable-infiniband" ""
+ for ENABLE_NVLINK in "--enable-nvlink" ""
+ for RMM_POOL_SIZE in ""
+ for MP_BLOCKSIZE in "256MiB" "1GiB" "4GiB"
+ for MP_PINNED_READ in "" "--mp-pinned-read"
+ [[ ucx == ucx ]]
+ FILES=California.json
+ PROTOCOL=ucx
+ ENABLE_IB=--enable-infiniband
+ ENABLE_NVLINK=--enable-nvlink
+ RMM_POOL_SIZE=
+ MP_BLOCKSIZE=256MiB
+ MP_PINNED_READ=
+ MP_FORCE_HOST_READ=--mp-force-host-read
+ singularity run --nv -B /scratch/shared/pwesolowski /home2/faculty/pwesolowski/containers/cuml-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/run_no_gds.sh
[WARN  tini (3278161)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
+ cd /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/
+ python -u cuml_single_node.py --files California.json --reps 5 --protocol ucx --enable-infiniband --enable-nvlink --mp-blocksize 256MiB --mp-force-host-read
<Managed Device 0>
args=Namespace(data_dir='/scratch/shared/pwesolowski/mgr-pipeline/joined-cuml', files=['California.json'], reps=5, protocol='ucx', enable_infiniband=True, enable_nvlink=True, rmm_pool_size=None, jit_unspill=False, mp_blocksize='256MiB', mp_force_host_read=True, mp_pinned_read=False, mp_force_gpu_preprocess=False)
/opt/conda/envs/rapids/lib/python3.10/site-packages/dask_cuda-23.2.0-py3.10.egg/dask_cuda/local_cuda_cluster.py:266: UserWarning: When using NVLink we recommend setting a `rmm_pool_size`. Please see: https://dask-cuda.readthedocs.io/en/latest/ucx.html#important-notes for more details
2023-07-07 10:30:22,744 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-07 10:30:22,744 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
Code block 'ddf-preprocessing' took: 38067.38436 ms
Code block 'ddf-preprocessing' took: 15035.68590 ms
Code block 'ddf-preprocessing' took: 15222.53611 ms
Code block 'ddf-preprocessing' took: 15267.64246 ms
Code block 'ddf-preprocessing' took: 14961.60876 ms
Code block 'ddf-scaler-fit' took: 15330.10534 ms
Code block 'ddf-scaler-fit' took: 14787.27854 ms
Code block 'ddf-scaler-fit' took: 15650.07826 ms
Code block 'ddf-scaler-fit' took: 16100.90541 ms
Code block 'ddf-scaler-fit' took: 16793.67175 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 47237.22009 ms
Code block 'ddf-kmeans-score' took: 16125.14434 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 43034.94805 ms
Code block 'ddf-kmeans-score' took: 16295.37543 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 43186.68429 ms
Code block 'ddf-kmeans-score' took: 16252.41074 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 42895.06972 ms
Code block 'ddf-kmeans-score' took: 16778.93417 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 42860.76669 ms
Code block 'ddf-kmeans-score' took: 16454.71651 ms
scores=[array(-4834778.984375)]
client.get_worker_logs()={'ucx://127.0.0.1:43411': (('INFO', "2023-07-07 10:38:22,330 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 10:37:55,029 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 10:37:21,563 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 10:36:54,230 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 10:36:21,332 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 10:35:54,052 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 10:35:20,753 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 10:34:53,391 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 10:34:20,443 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 10:33:48,971 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', '2023-07-07 10:30:26,755 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 10:30:26,755 - distributed.worker - INFO -         Registered to:      ucx://127.0.0.1:44033'), ('INFO', '2023-07-07 10:30:26,683 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 10:30:26,683 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-32873b41-ca16-475a-ace8-61eb21b8a9d1'), ('INFO', '2023-07-07 10:30:23,232 - distributed.worker - INFO - Starting Worker plugin PreImport-1694b472-ba5a-43f9-a785-ba4f60277c95'), ('INFO', '2023-07-07 10:30:23,232 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3f31c5fc-2c2c-4efe-a027-f4894458df52'), ('INFO', '2023-07-07 10:30:23,232 - distributed.worker - INFO -       Local Directory: /scratch/shared/pwesolowski/mgr-pipeline/joined-cuml/tmp/dask-worker-space/worker-26fy92qq'), ('INFO', '2023-07-07 10:30:23,232 - distributed.worker - INFO -                Memory:                  50.00 GiB'), ('INFO', '2023-07-07 10:30:23,232 - distributed.worker - INFO -               Threads:                          2'), ('INFO', '2023-07-07 10:30:23,232 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 10:30:23,232 - distributed.worker - INFO - Waiting to connect to:      ucx://127.0.0.1:44033'), ('INFO', '2023-07-07 10:30:23,232 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34813'), ('INFO', '2023-07-07 10:30:23,232 - distributed.worker - INFO -           Worker name:                          0'), ('INFO', '2023-07-07 10:30:23,232 - distributed.worker - INFO -          Listening to:      ucx://127.0.0.1:43411'), ('INFO', '2023-07-07 10:30:23,232 - distributed.worker - INFO -       Start worker at:      ucx://127.0.0.1:43411'))}
2023-07-07 10:38:43,771 - distributed.nanny - WARNING - Worker process still alive after 3.1999995422363288 seconds, killing
+ sleep 1
+ for MP_PINNED_READ in "" "--mp-pinned-read"
+ [[ ucx == ucx ]]
+ FILES=California.json
+ PROTOCOL=ucx
+ ENABLE_IB=--enable-infiniband
+ ENABLE_NVLINK=--enable-nvlink
+ RMM_POOL_SIZE=
+ MP_BLOCKSIZE=256MiB
+ MP_PINNED_READ=--mp-pinned-read
+ MP_FORCE_HOST_READ=--mp-force-host-read
+ singularity run --nv -B /scratch/shared/pwesolowski /home2/faculty/pwesolowski/containers/cuml-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/run_no_gds.sh
[WARN  tini (3287950)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
+ cd /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/
+ python -u cuml_single_node.py --files California.json --reps 5 --protocol ucx --enable-infiniband --enable-nvlink --mp-blocksize 256MiB --mp-force-host-read --mp-pinned-read
<Managed Device 0>
args=Namespace(data_dir='/scratch/shared/pwesolowski/mgr-pipeline/joined-cuml', files=['California.json'], reps=5, protocol='ucx', enable_infiniband=True, enable_nvlink=True, rmm_pool_size=None, jit_unspill=False, mp_blocksize='256MiB', mp_force_host_read=True, mp_pinned_read=True, mp_force_gpu_preprocess=False)
/opt/conda/envs/rapids/lib/python3.10/site-packages/dask_cuda-23.2.0-py3.10.egg/dask_cuda/local_cuda_cluster.py:266: UserWarning: When using NVLink we recommend setting a `rmm_pool_size`. Please see: https://dask-cuda.readthedocs.io/en/latest/ucx.html#important-notes for more details
2023-07-07 10:39:07,381 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-07 10:39:07,381 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
Code block 'ddf-preprocessing' took: 40356.28278 ms
Code block 'ddf-preprocessing' took: 14990.63472 ms
Code block 'ddf-preprocessing' took: 15203.38386 ms
Code block 'ddf-preprocessing' took: 15141.23110 ms
Code block 'ddf-preprocessing' took: 15135.32465 ms
Code block 'ddf-scaler-fit' took: 19277.99727 ms
Code block 'ddf-scaler-fit' took: 18759.48096 ms
Code block 'ddf-scaler-fit' took: 18435.79428 ms
Code block 'ddf-scaler-fit' took: 19897.31335 ms
Code block 'ddf-scaler-fit' took: 19663.70449 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 49880.76611 ms
Code block 'ddf-kmeans-score' took: 18920.22482 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 46249.92449 ms
Code block 'ddf-kmeans-score' took: 20042.00357 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 45865.68589 ms
Code block 'ddf-kmeans-score' took: 19233.94716 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 45980.24649 ms
Code block 'ddf-kmeans-score' took: 19043.34905 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 46066.96514 ms
Code block 'ddf-kmeans-score' took: 19404.10452 ms
scores=[array(-4834427.84375)]
client.get_worker_logs()={'ucx://127.0.0.1:35753': (('INFO', "2023-07-07 10:47:53,538 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 10:47:26,276 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 10:46:47,341 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 10:46:20,080 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 10:45:40,918 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 10:45:13,639 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 10:44:33,882 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 10:44:06,677 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 10:43:27,598 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 10:42:56,301 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', '2023-07-07 10:39:11,373 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 10:39:11,373 - distributed.worker - INFO -         Registered to:      ucx://127.0.0.1:47189'), ('INFO', '2023-07-07 10:39:11,295 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 10:39:11,295 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ebe6414c-ce7a-42ee-85d0-7358432ded41'), ('INFO', '2023-07-07 10:39:07,852 - distributed.worker - INFO - Starting Worker plugin PreImport-6b3f732f-96df-4c6d-81ac-d2004f817378'), ('INFO', '2023-07-07 10:39:07,852 - distributed.worker - INFO - Starting Worker plugin RMMSetup-95332e86-718e-46a2-af4e-dcbad0a37dd0'), ('INFO', '2023-07-07 10:39:07,852 - distributed.worker - INFO -       Local Directory: /scratch/shared/pwesolowski/mgr-pipeline/joined-cuml/tmp/dask-worker-space/worker-he_uqfg7'), ('INFO', '2023-07-07 10:39:07,852 - distributed.worker - INFO -                Memory:                  50.00 GiB'), ('INFO', '2023-07-07 10:39:07,852 - distributed.worker - INFO -               Threads:                          2'), ('INFO', '2023-07-07 10:39:07,852 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 10:39:07,852 - distributed.worker - INFO - Waiting to connect to:      ucx://127.0.0.1:47189'), ('INFO', '2023-07-07 10:39:07,852 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39723'), ('INFO', '2023-07-07 10:39:07,852 - distributed.worker - INFO -           Worker name:                          0'), ('INFO', '2023-07-07 10:39:07,852 - distributed.worker - INFO -          Listening to:      ucx://127.0.0.1:35753'), ('INFO', '2023-07-07 10:39:07,852 - distributed.worker - INFO -       Start worker at:      ucx://127.0.0.1:35753'))}
2023-07-07 10:48:17,901 - distributed.nanny - WARNING - Worker process still alive after 3.1999990844726565 seconds, killing
+ sleep 1
+ for MP_BLOCKSIZE in "256MiB" "1GiB" "4GiB"
+ for MP_PINNED_READ in "" "--mp-pinned-read"
+ [[ ucx == ucx ]]
+ FILES=California.json
+ PROTOCOL=ucx
+ ENABLE_IB=--enable-infiniband
+ ENABLE_NVLINK=--enable-nvlink
+ RMM_POOL_SIZE=
+ MP_BLOCKSIZE=1GiB
+ MP_PINNED_READ=
+ MP_FORCE_HOST_READ=--mp-force-host-read
+ singularity run --nv -B /scratch/shared/pwesolowski /home2/faculty/pwesolowski/containers/cuml-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/run_no_gds.sh
[WARN  tini (3302137)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
+ cd /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/
+ python -u cuml_single_node.py --files California.json --reps 5 --protocol ucx --enable-infiniband --enable-nvlink --mp-blocksize 1GiB --mp-force-host-read
<Managed Device 0>
args=Namespace(data_dir='/scratch/shared/pwesolowski/mgr-pipeline/joined-cuml', files=['California.json'], reps=5, protocol='ucx', enable_infiniband=True, enable_nvlink=True, rmm_pool_size=None, jit_unspill=False, mp_blocksize='1GiB', mp_force_host_read=True, mp_pinned_read=False, mp_force_gpu_preprocess=False)
/opt/conda/envs/rapids/lib/python3.10/site-packages/dask_cuda-23.2.0-py3.10.egg/dask_cuda/local_cuda_cluster.py:266: UserWarning: When using NVLink we recommend setting a `rmm_pool_size`. Please see: https://dask-cuda.readthedocs.io/en/latest/ucx.html#important-notes for more details
2023-07-07 10:48:42,847 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-07 10:48:42,847 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
Code block 'ddf-preprocessing' took: 37977.34005 ms
Code block 'ddf-preprocessing' took: 14736.67768 ms
Code block 'ddf-preprocessing' took: 14729.00450 ms
Code block 'ddf-preprocessing' took: 14837.33971 ms
Code block 'ddf-preprocessing' took: 14796.23702 ms
Code block 'ddf-scaler-fit' took: 14008.55178 ms
Code block 'ddf-scaler-fit' took: 12991.92550 ms
Code block 'ddf-scaler-fit' took: 13643.44426 ms
Code block 'ddf-scaler-fit' took: 13994.81772 ms
Code block 'ddf-scaler-fit' took: 13552.04281 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 45358.89978 ms
Code block 'ddf-kmeans-score' took: 13646.94681 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 40916.64355 ms
Code block 'ddf-kmeans-score' took: 13753.39578 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 40457.30694 ms
Code block 'ddf-kmeans-score' took: 13636.25514 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 40973.53548 ms
Code block 'ddf-kmeans-score' took: 13640.32543 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 40820.21058 ms
Code block 'ddf-kmeans-score' took: 13662.26328 ms
scores=[array(-4847245.96875)]
client.get_worker_logs()={'ucx://127.0.0.1:48467': (('INFO', "2023-07-07 10:56:09,007 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 10:55:41,705 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 10:55:13,460 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 10:54:46,183 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 10:54:17,811 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 10:53:50,491 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 10:53:22,555 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 10:52:55,233 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 10:52:26,737 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 10:51:55,077 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', '2023-07-07 10:48:47,555 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 10:48:47,555 - distributed.worker - INFO -         Registered to:      ucx://127.0.0.1:37389'), ('INFO', '2023-07-07 10:48:47,473 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 10:48:47,473 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0b8630ee-7785-4c2f-870f-1d198cc503fe'), ('INFO', '2023-07-07 10:48:43,328 - distributed.worker - INFO - Starting Worker plugin PreImport-05a8f547-006e-461b-8255-39be8884e33f'), ('INFO', '2023-07-07 10:48:43,328 - distributed.worker - INFO - Starting Worker plugin RMMSetup-030c8efa-984f-44e2-b80b-b5372c91370b'), ('INFO', '2023-07-07 10:48:43,327 - distributed.worker - INFO -       Local Directory: /scratch/shared/pwesolowski/mgr-pipeline/joined-cuml/tmp/dask-worker-space/worker-cb2v75yc'), ('INFO', '2023-07-07 10:48:43,327 - distributed.worker - INFO -                Memory:                  50.00 GiB'), ('INFO', '2023-07-07 10:48:43,327 - distributed.worker - INFO -               Threads:                          2'), ('INFO', '2023-07-07 10:48:43,327 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 10:48:43,327 - distributed.worker - INFO - Waiting to connect to:      ucx://127.0.0.1:37389'), ('INFO', '2023-07-07 10:48:43,327 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37997'), ('INFO', '2023-07-07 10:48:43,327 - distributed.worker - INFO -           Worker name:                          0'), ('INFO', '2023-07-07 10:48:43,327 - distributed.worker - INFO -          Listening to:      ucx://127.0.0.1:48467'), ('INFO', '2023-07-07 10:48:43,327 - distributed.worker - INFO -       Start worker at:      ucx://127.0.0.1:48467'))}
2023-07-07 10:56:27,533 - distributed.nanny - WARNING - Worker process still alive after 3.1999989318847657 seconds, killing
+ sleep 1
+ for MP_PINNED_READ in "" "--mp-pinned-read"
+ [[ ucx == ucx ]]
+ FILES=California.json
+ PROTOCOL=ucx
+ ENABLE_IB=--enable-infiniband
+ ENABLE_NVLINK=--enable-nvlink
+ RMM_POOL_SIZE=
+ MP_BLOCKSIZE=1GiB
+ MP_PINNED_READ=--mp-pinned-read
+ MP_FORCE_HOST_READ=--mp-force-host-read
+ singularity run --nv -B /scratch/shared/pwesolowski /home2/faculty/pwesolowski/containers/cuml-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/run_no_gds.sh
[WARN  tini (3313728)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
+ cd /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/
+ python -u cuml_single_node.py --files California.json --reps 5 --protocol ucx --enable-infiniband --enable-nvlink --mp-blocksize 1GiB --mp-force-host-read --mp-pinned-read
<Managed Device 0>
args=Namespace(data_dir='/scratch/shared/pwesolowski/mgr-pipeline/joined-cuml', files=['California.json'], reps=5, protocol='ucx', enable_infiniband=True, enable_nvlink=True, rmm_pool_size=None, jit_unspill=False, mp_blocksize='1GiB', mp_force_host_read=True, mp_pinned_read=True, mp_force_gpu_preprocess=False)
/opt/conda/envs/rapids/lib/python3.10/site-packages/dask_cuda-23.2.0-py3.10.egg/dask_cuda/local_cuda_cluster.py:266: UserWarning: When using NVLink we recommend setting a `rmm_pool_size`. Please see: https://dask-cuda.readthedocs.io/en/latest/ucx.html#important-notes for more details
2023-07-07 10:57:05,460 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-07 10:57:05,460 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
Code block 'ddf-preprocessing' took: 38704.02070 ms
Code block 'ddf-preprocessing' took: 14824.96548 ms
Code block 'ddf-preprocessing' took: 14716.70233 ms
Code block 'ddf-preprocessing' took: 14903.35962 ms
Code block 'ddf-preprocessing' took: 14618.63692 ms
Code block 'ddf-scaler-fit' took: 17877.05709 ms
Code block 'ddf-scaler-fit' took: 15208.53091 ms
Code block 'ddf-scaler-fit' took: 15310.18167 ms
Code block 'ddf-scaler-fit' took: 15523.50867 ms
Code block 'ddf-scaler-fit' took: 16275.09167 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 48039.79339 ms
Code block 'ddf-kmeans-score' took: 16311.88407 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 44390.62373 ms
Code block 'ddf-kmeans-score' took: 15969.55821 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 43148.24464 ms
Code block 'ddf-kmeans-score' took: 16073.50288 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 43365.36915 ms
Code block 'ddf-kmeans-score' took: 16280.89107 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 43293.94836 ms
Code block 'ddf-kmeans-score' took: 16720.86573 ms
scores=[array(-4848727.75)]
client.get_worker_logs()={'ucx://127.0.0.1:48607': (('INFO', "2023-07-07 11:05:08,216 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 11:04:40,889 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 11:04:07,596 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 11:03:40,270 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 11:03:07,102 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 11:02:39,789 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 11:02:06,951 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 11:01:39,640 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 11:01:05,016 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 11:00:33,786 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', '2023-07-07 10:57:10,047 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 10:57:10,047 - distributed.worker - INFO -         Registered to:      ucx://127.0.0.1:49077'), ('INFO', '2023-07-07 10:57:09,956 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 10:57:09,956 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-02a4ee80-fd13-4c82-9bcb-6acf9471ae0a'), ('INFO', '2023-07-07 10:57:05,952 - distributed.worker - INFO - Starting Worker plugin PreImport-40e1c59b-bf8c-49f0-977a-1301ed218c50'), ('INFO', '2023-07-07 10:57:05,952 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4bb3d4b8-384c-4770-993f-0ab4c796b83c'), ('INFO', '2023-07-07 10:57:05,952 - distributed.worker - INFO -       Local Directory: /scratch/shared/pwesolowski/mgr-pipeline/joined-cuml/tmp/dask-worker-space/worker-wgqkd_6n'), ('INFO', '2023-07-07 10:57:05,952 - distributed.worker - INFO -                Memory:                  50.00 GiB'), ('INFO', '2023-07-07 10:57:05,952 - distributed.worker - INFO -               Threads:                          2'), ('INFO', '2023-07-07 10:57:05,952 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 10:57:05,952 - distributed.worker - INFO - Waiting to connect to:      ucx://127.0.0.1:49077'), ('INFO', '2023-07-07 10:57:05,952 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44697'), ('INFO', '2023-07-07 10:57:05,952 - distributed.worker - INFO -           Worker name:                          0'), ('INFO', '2023-07-07 10:57:05,952 - distributed.worker - INFO -          Listening to:      ucx://127.0.0.1:48607'), ('INFO', '2023-07-07 10:57:05,952 - distributed.worker - INFO -       Start worker at:      ucx://127.0.0.1:48607'))}
2023-07-07 11:05:29,781 - distributed.nanny - WARNING - Worker process still alive after 3.1999989318847657 seconds, killing
+ sleep 1
+ for MP_BLOCKSIZE in "256MiB" "1GiB" "4GiB"
+ for MP_PINNED_READ in "" "--mp-pinned-read"
+ [[ ucx == ucx ]]
+ FILES=California.json
+ PROTOCOL=ucx
+ ENABLE_IB=--enable-infiniband
+ ENABLE_NVLINK=--enable-nvlink
+ RMM_POOL_SIZE=
+ MP_BLOCKSIZE=4GiB
+ MP_PINNED_READ=
+ MP_FORCE_HOST_READ=--mp-force-host-read
+ singularity run --nv -B /scratch/shared/pwesolowski /home2/faculty/pwesolowski/containers/cuml-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/run_no_gds.sh
[WARN  tini (3326466)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
+ cd /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/
+ python -u cuml_single_node.py --files California.json --reps 5 --protocol ucx --enable-infiniband --enable-nvlink --mp-blocksize 4GiB --mp-force-host-read
<Managed Device 0>
args=Namespace(data_dir='/scratch/shared/pwesolowski/mgr-pipeline/joined-cuml', files=['California.json'], reps=5, protocol='ucx', enable_infiniband=True, enable_nvlink=True, rmm_pool_size=None, jit_unspill=False, mp_blocksize='4GiB', mp_force_host_read=True, mp_pinned_read=False, mp_force_gpu_preprocess=False)
/opt/conda/envs/rapids/lib/python3.10/site-packages/dask_cuda-23.2.0-py3.10.egg/dask_cuda/local_cuda_cluster.py:266: UserWarning: When using NVLink we recommend setting a `rmm_pool_size`. Please see: https://dask-cuda.readthedocs.io/en/latest/ucx.html#important-notes for more details
2023-07-07 11:05:55,943 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-07 11:05:55,943 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
Code block 'ddf-preprocessing' took: 37202.68177 ms
Code block 'ddf-preprocessing' took: 14631.69606 ms
Code block 'ddf-preprocessing' took: 14890.22323 ms
Code block 'ddf-preprocessing' took: 14766.97399 ms
Code block 'ddf-preprocessing' took: 14843.81498 ms
Code block 'ddf-scaler-fit' took: 13223.03035 ms
Code block 'ddf-scaler-fit' took: 12284.51331 ms
Code block 'ddf-scaler-fit' took: 11936.91495 ms
Code block 'ddf-scaler-fit' took: 11922.93811 ms
Code block 'ddf-scaler-fit' took: 12080.13102 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 44855.04184 ms
Code block 'ddf-kmeans-score' took: 12192.58509 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 41512.89862 ms
Code block 'ddf-kmeans-score' took: 12656.62559 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 41831.36680 ms
Code block 'ddf-kmeans-score' took: 12622.57801 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 41839.92482 ms
Code block 'ddf-kmeans-score' took: 13792.68848 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 42080.81414 ms
Code block 'ddf-kmeans-score' took: 12894.64691 ms
scores=[array(-32218148.)]
client.get_worker_logs()={'ucx://127.0.0.1:41199': (('INFO', "2023-07-07 11:13:15,238 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 11:12:46,116 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 11:12:18,193 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 11:11:49,044 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 11:11:22,666 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 11:10:53,554 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 11:10:27,112 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 11:09:57,912 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 11:09:32,035 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 11:08:59,110 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', '2023-07-07 11:06:00,300 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 11:06:00,299 - distributed.worker - INFO -         Registered to:      ucx://127.0.0.1:58973'), ('INFO', '2023-07-07 11:06:00,200 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 11:06:00,200 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-66e667cc-2809-45f3-b629-523870fed2e3'), ('INFO', '2023-07-07 11:05:56,435 - distributed.worker - INFO - Starting Worker plugin PreImport-dc9f007d-b776-40ec-9aee-66a5e5cd0cc5'), ('INFO', '2023-07-07 11:05:56,435 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9f13186c-e368-491b-a6a1-9e97128f55a2'), ('INFO', '2023-07-07 11:05:56,435 - distributed.worker - INFO -       Local Directory: /scratch/shared/pwesolowski/mgr-pipeline/joined-cuml/tmp/dask-worker-space/worker-pb1ngoh7'), ('INFO', '2023-07-07 11:05:56,435 - distributed.worker - INFO -                Memory:                  50.00 GiB'), ('INFO', '2023-07-07 11:05:56,435 - distributed.worker - INFO -               Threads:                          2'), ('INFO', '2023-07-07 11:05:56,435 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 11:05:56,435 - distributed.worker - INFO - Waiting to connect to:      ucx://127.0.0.1:58973'), ('INFO', '2023-07-07 11:05:56,435 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41627'), ('INFO', '2023-07-07 11:05:56,435 - distributed.worker - INFO -           Worker name:                          0'), ('INFO', '2023-07-07 11:05:56,435 - distributed.worker - INFO -          Listening to:      ucx://127.0.0.1:41199'), ('INFO', '2023-07-07 11:05:56,435 - distributed.worker - INFO -       Start worker at:      ucx://127.0.0.1:41199'))}
2023-07-07 11:13:32,858 - distributed.nanny - WARNING - Worker process still alive after 3.1999990844726565 seconds, killing
+ sleep 1
+ for MP_PINNED_READ in "" "--mp-pinned-read"
+ [[ ucx == ucx ]]
+ FILES=California.json
+ PROTOCOL=ucx
+ ENABLE_IB=--enable-infiniband
+ ENABLE_NVLINK=--enable-nvlink
+ RMM_POOL_SIZE=
+ MP_BLOCKSIZE=4GiB
+ MP_PINNED_READ=--mp-pinned-read
+ MP_FORCE_HOST_READ=--mp-force-host-read
+ singularity run --nv -B /scratch/shared/pwesolowski /home2/faculty/pwesolowski/containers/cuml-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/run_no_gds.sh
[WARN  tini (3335281)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
+ cd /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/
+ python -u cuml_single_node.py --files California.json --reps 5 --protocol ucx --enable-infiniband --enable-nvlink --mp-blocksize 4GiB --mp-force-host-read --mp-pinned-read
<Managed Device 0>
args=Namespace(data_dir='/scratch/shared/pwesolowski/mgr-pipeline/joined-cuml', files=['California.json'], reps=5, protocol='ucx', enable_infiniband=True, enable_nvlink=True, rmm_pool_size=None, jit_unspill=False, mp_blocksize='4GiB', mp_force_host_read=True, mp_pinned_read=True, mp_force_gpu_preprocess=False)
/opt/conda/envs/rapids/lib/python3.10/site-packages/dask_cuda-23.2.0-py3.10.egg/dask_cuda/local_cuda_cluster.py:266: UserWarning: When using NVLink we recommend setting a `rmm_pool_size`. Please see: https://dask-cuda.readthedocs.io/en/latest/ucx.html#important-notes for more details
2023-07-07 11:13:59,726 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-07 11:13:59,726 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
Code block 'ddf-preprocessing' took: 38283.56002 ms
Code block 'ddf-preprocessing' took: 14742.45350 ms
Code block 'ddf-preprocessing' took: 14660.89985 ms
Code block 'ddf-preprocessing' took: 14554.73922 ms
Code block 'ddf-preprocessing' took: 14721.62880 ms
Code block 'ddf-scaler-fit' took: 15234.62854 ms
Code block 'ddf-scaler-fit' took: 14918.10076 ms
Code block 'ddf-scaler-fit' took: 14887.04700 ms
Code block 'ddf-scaler-fit' took: 14573.87409 ms
Code block 'ddf-scaler-fit' took: 14832.03598 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 47732.56550 ms
Code block 'ddf-kmeans-score' took: 15140.91587 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 44825.26233 ms
Code block 'ddf-kmeans-score' took: 15031.92004 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 44948.10275 ms
Code block 'ddf-kmeans-score' took: 14735.32791 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 44647.87986 ms
Code block 'ddf-kmeans-score' took: 15473.92654 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 45104.59670 ms
Code block 'ddf-kmeans-score' took: 15862.44042 ms
scores=[array(-50893343.)]
client.get_worker_logs()={'ucx://127.0.0.1:59377': (('INFO', "2023-07-07 11:21:56,069 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 11:21:26,915 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 11:20:54,478 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 11:20:25,317 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 11:19:54,087 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 11:19:24,968 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 11:18:53,079 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 11:18:23,956 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 11:17:51,707 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 11:17:18,464 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', '2023-07-07 11:14:03,916 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 11:14:03,916 - distributed.worker - INFO -         Registered to:      ucx://127.0.0.1:38533'), ('INFO', '2023-07-07 11:14:03,836 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 11:14:03,836 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-4632b3f9-7344-4858-9d7a-1ebda6381977'), ('INFO', '2023-07-07 11:14:00,445 - distributed.worker - INFO - Starting Worker plugin PreImport-fe2bd9f1-b142-4e06-9111-0a1599f072f9'), ('INFO', '2023-07-07 11:14:00,445 - distributed.worker - INFO - Starting Worker plugin RMMSetup-75ea72fc-9fb7-46fd-8643-3a221e8d62b4'), ('INFO', '2023-07-07 11:14:00,445 - distributed.worker - INFO -       Local Directory: /scratch/shared/pwesolowski/mgr-pipeline/joined-cuml/tmp/dask-worker-space/worker-v0q8fq3g'), ('INFO', '2023-07-07 11:14:00,445 - distributed.worker - INFO -                Memory:                  50.00 GiB'), ('INFO', '2023-07-07 11:14:00,445 - distributed.worker - INFO -               Threads:                          2'), ('INFO', '2023-07-07 11:14:00,445 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 11:14:00,444 - distributed.worker - INFO - Waiting to connect to:      ucx://127.0.0.1:38533'), ('INFO', '2023-07-07 11:14:00,444 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34171'), ('INFO', '2023-07-07 11:14:00,444 - distributed.worker - INFO -           Worker name:                          0'), ('INFO', '2023-07-07 11:14:00,444 - distributed.worker - INFO -          Listening to:      ucx://127.0.0.1:59377'), ('INFO', '2023-07-07 11:14:00,444 - distributed.worker - INFO -       Start worker at:      ucx://127.0.0.1:59377'))}
2023-07-07 11:22:16,581 - distributed.nanny - WARNING - Worker process still alive after 3.199999389648438 seconds, killing
+ sleep 1
+ for ENABLE_NVLINK in "--enable-nvlink" ""
+ for RMM_POOL_SIZE in ""
+ for MP_BLOCKSIZE in "256MiB" "1GiB" "4GiB"
+ for MP_PINNED_READ in "" "--mp-pinned-read"
+ [[ ucx == ucx ]]
+ FILES=California.json
+ PROTOCOL=ucx
+ ENABLE_IB=--enable-infiniband
+ ENABLE_NVLINK=
+ RMM_POOL_SIZE=
+ MP_BLOCKSIZE=256MiB
+ MP_PINNED_READ=
+ MP_FORCE_HOST_READ=--mp-force-host-read
+ singularity run --nv -B /scratch/shared/pwesolowski /home2/faculty/pwesolowski/containers/cuml-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/run_no_gds.sh
[WARN  tini (3345144)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
+ cd /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/
+ python -u cuml_single_node.py --files California.json --reps 5 --protocol ucx --enable-infiniband --mp-blocksize 256MiB --mp-force-host-read
<Managed Device 0>
args=Namespace(data_dir='/scratch/shared/pwesolowski/mgr-pipeline/joined-cuml', files=['California.json'], reps=5, protocol='ucx', enable_infiniband=True, enable_nvlink=False, rmm_pool_size=None, jit_unspill=False, mp_blocksize='256MiB', mp_force_host_read=True, mp_pinned_read=False, mp_force_gpu_preprocess=False)
2023-07-07 11:22:40,936 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-07 11:22:40,939 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
Code block 'ddf-preprocessing' took: 38273.82373 ms
Code block 'ddf-preprocessing' took: 14989.30107 ms
Code block 'ddf-preprocessing' took: 15004.37019 ms
Code block 'ddf-preprocessing' took: 14942.71001 ms
Code block 'ddf-preprocessing' took: 15186.54328 ms
Code block 'ddf-scaler-fit' took: 15313.69907 ms
Code block 'ddf-scaler-fit' took: 15066.42748 ms
Code block 'ddf-scaler-fit' took: 15921.16915 ms
Code block 'ddf-scaler-fit' took: 17721.43233 ms
Code block 'ddf-scaler-fit' took: 17571.35288 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 47332.01097 ms
Code block 'ddf-kmeans-score' took: 15942.69698 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 43087.69391 ms
Code block 'ddf-kmeans-score' took: 16496.33555 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 42968.25905 ms
Code block 'ddf-kmeans-score' took: 16264.94656 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 43005.93184 ms
Code block 'ddf-kmeans-score' took: 16337.18951 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 43633.16881 ms
Code block 'ddf-kmeans-score' took: 16214.64323 ms
scores=[array(-4834734.4140625)]
client.get_worker_logs()={'ucx://127.0.0.1:37743': (('INFO', "2023-07-07 11:30:43,302 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 11:30:16,052 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 11:29:42,207 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 11:29:14,972 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 11:28:41,830 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 11:28:14,576 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 11:27:41,282 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 11:27:13,907 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 11:26:41,124 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 11:26:09,922 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', '2023-07-07 11:22:44,869 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 11:22:44,868 - distributed.worker - INFO -         Registered to:      ucx://127.0.0.1:49247'), ('INFO', '2023-07-07 11:22:44,794 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 11:22:44,794 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9e8240d3-ec9b-44cf-af9b-cec3fdd2d150'), ('INFO', '2023-07-07 11:22:41,451 - distributed.worker - INFO - Starting Worker plugin PreImport-672cda54-94df-4361-b71b-7a8d4b470c49'), ('INFO', '2023-07-07 11:22:41,451 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6c3ec6d3-5b6c-4375-8c71-5678f8be2cf9'), ('INFO', '2023-07-07 11:22:41,451 - distributed.worker - INFO -       Local Directory: /scratch/shared/pwesolowski/mgr-pipeline/joined-cuml/tmp/dask-worker-space/worker-ql0vf8mj'), ('INFO', '2023-07-07 11:22:41,451 - distributed.worker - INFO -                Memory:                  50.00 GiB'), ('INFO', '2023-07-07 11:22:41,451 - distributed.worker - INFO -               Threads:                          2'), ('INFO', '2023-07-07 11:22:41,451 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 11:22:41,451 - distributed.worker - INFO - Waiting to connect to:      ucx://127.0.0.1:49247'), ('INFO', '2023-07-07 11:22:41,451 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34751'), ('INFO', '2023-07-07 11:22:41,451 - distributed.worker - INFO -           Worker name:                          0'), ('INFO', '2023-07-07 11:22:41,451 - distributed.worker - INFO -          Listening to:      ucx://127.0.0.1:37743'), ('INFO', '2023-07-07 11:22:41,451 - distributed.worker - INFO -       Start worker at:      ucx://127.0.0.1:37743'))}
2023-07-07 11:31:04,227 - distributed.nanny - WARNING - Worker process still alive after 3.1999995422363288 seconds, killing
+ sleep 1
+ for MP_PINNED_READ in "" "--mp-pinned-read"
+ [[ ucx == ucx ]]
+ FILES=California.json
+ PROTOCOL=ucx
+ ENABLE_IB=--enable-infiniband
+ ENABLE_NVLINK=
+ RMM_POOL_SIZE=
+ MP_BLOCKSIZE=256MiB
+ MP_PINNED_READ=--mp-pinned-read
+ MP_FORCE_HOST_READ=--mp-force-host-read
+ singularity run --nv -B /scratch/shared/pwesolowski /home2/faculty/pwesolowski/containers/cuml-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/run_no_gds.sh
[WARN  tini (3355018)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
+ cd /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/
+ python -u cuml_single_node.py --files California.json --reps 5 --protocol ucx --enable-infiniband --mp-blocksize 256MiB --mp-force-host-read --mp-pinned-read
<Managed Device 0>
args=Namespace(data_dir='/scratch/shared/pwesolowski/mgr-pipeline/joined-cuml', files=['California.json'], reps=5, protocol='ucx', enable_infiniband=True, enable_nvlink=False, rmm_pool_size=None, jit_unspill=False, mp_blocksize='256MiB', mp_force_host_read=True, mp_pinned_read=True, mp_force_gpu_preprocess=False)
2023-07-07 11:31:27,157 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-07 11:31:27,157 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
Code block 'ddf-preprocessing' took: 37255.48120 ms
Code block 'ddf-preprocessing' took: 14882.16666 ms
Code block 'ddf-preprocessing' took: 14886.87823 ms
Code block 'ddf-preprocessing' took: 14993.34417 ms
Code block 'ddf-preprocessing' took: 14895.80435 ms
Code block 'ddf-scaler-fit' took: 18980.46151 ms
Code block 'ddf-scaler-fit' took: 18912.96969 ms
Code block 'ddf-scaler-fit' took: 19500.00679 ms
Code block 'ddf-scaler-fit' took: 19781.77692 ms
Code block 'ddf-scaler-fit' took: 20268.66338 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 50638.33799 ms
Code block 'ddf-kmeans-score' took: 19052.22661 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 45774.76833 ms
Code block 'ddf-kmeans-score' took: 19279.46824 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 46156.33173 ms
Code block 'ddf-kmeans-score' took: 19382.37498 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 46691.39191 ms
Code block 'ddf-kmeans-score' took: 18830.37690 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 46188.26158 ms
Code block 'ddf-kmeans-score' took: 19417.96853 ms
scores=[array(-4846546.8984375)]
client.get_worker_logs()={'ucx://127.0.0.1:58817': (('INFO', "2023-07-07 11:40:11,166 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 11:39:43,803 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 11:39:04,918 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 11:38:37,571 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 11:37:57,429 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 11:37:30,082 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 11:36:50,793 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 11:36:23,518 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 11:35:44,803 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 11:35:13,489 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', '2023-07-07 11:31:30,963 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 11:31:30,963 - distributed.worker - INFO -         Registered to:      ucx://127.0.0.1:34381'), ('INFO', '2023-07-07 11:31:30,890 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 11:31:30,890 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b682e669-7aee-47cf-8b31-21c275e427cc'), ('INFO', '2023-07-07 11:31:27,606 - distributed.worker - INFO - Starting Worker plugin PreImport-1f60ba8f-58bb-4528-84a4-350728424976'), ('INFO', '2023-07-07 11:31:27,606 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e2fcc655-c5b4-41c8-8cd2-588b36b3e840'), ('INFO', '2023-07-07 11:31:27,606 - distributed.worker - INFO -       Local Directory: /scratch/shared/pwesolowski/mgr-pipeline/joined-cuml/tmp/dask-worker-space/worker-2ifc9vcb'), ('INFO', '2023-07-07 11:31:27,606 - distributed.worker - INFO -                Memory:                  50.00 GiB'), ('INFO', '2023-07-07 11:31:27,606 - distributed.worker - INFO -               Threads:                          2'), ('INFO', '2023-07-07 11:31:27,606 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 11:31:27,606 - distributed.worker - INFO - Waiting to connect to:      ucx://127.0.0.1:34381'), ('INFO', '2023-07-07 11:31:27,606 - distributed.worker - INFO -          dashboard at:            127.0.0.1:32835'), ('INFO', '2023-07-07 11:31:27,606 - distributed.worker - INFO -           Worker name:                          0'), ('INFO', '2023-07-07 11:31:27,606 - distributed.worker - INFO -          Listening to:      ucx://127.0.0.1:58817'), ('INFO', '2023-07-07 11:31:27,606 - distributed.worker - INFO -       Start worker at:      ucx://127.0.0.1:58817'))}
2023-07-07 11:40:35,733 - distributed.nanny - WARNING - Worker process still alive after 3.1999987792968754 seconds, killing
+ sleep 1
+ for MP_BLOCKSIZE in "256MiB" "1GiB" "4GiB"
+ for MP_PINNED_READ in "" "--mp-pinned-read"
+ [[ ucx == ucx ]]
+ FILES=California.json
+ PROTOCOL=ucx
+ ENABLE_IB=--enable-infiniband
+ ENABLE_NVLINK=
+ RMM_POOL_SIZE=
+ MP_BLOCKSIZE=1GiB
+ MP_PINNED_READ=
+ MP_FORCE_HOST_READ=--mp-force-host-read
+ singularity run --nv -B /scratch/shared/pwesolowski /home2/faculty/pwesolowski/containers/cuml-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/run_no_gds.sh
[WARN  tini (3365158)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
+ cd /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/
+ python -u cuml_single_node.py --files California.json --reps 5 --protocol ucx --enable-infiniband --mp-blocksize 1GiB --mp-force-host-read
<Managed Device 0>
args=Namespace(data_dir='/scratch/shared/pwesolowski/mgr-pipeline/joined-cuml', files=['California.json'], reps=5, protocol='ucx', enable_infiniband=True, enable_nvlink=False, rmm_pool_size=None, jit_unspill=False, mp_blocksize='1GiB', mp_force_host_read=True, mp_pinned_read=False, mp_force_gpu_preprocess=False)
2023-07-07 11:40:58,640 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-07 11:40:58,640 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
Code block 'ddf-preprocessing' took: 38698.85497 ms
Code block 'ddf-preprocessing' took: 14811.69875 ms
Code block 'ddf-preprocessing' took: 14699.03723 ms
Code block 'ddf-preprocessing' took: 14790.70760 ms
Code block 'ddf-preprocessing' took: 14663.43759 ms
Code block 'ddf-scaler-fit' took: 13406.97173 ms
Code block 'ddf-scaler-fit' took: 12469.34901 ms
Code block 'ddf-scaler-fit' took: 12947.95788 ms
Code block 'ddf-scaler-fit' took: 13583.21128 ms
Code block 'ddf-scaler-fit' took: 13193.54005 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 44564.45123 ms
Code block 'ddf-kmeans-score' took: 14160.77842 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 40203.77590 ms
Code block 'ddf-kmeans-score' took: 13784.51158 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 40352.71934 ms
Code block 'ddf-kmeans-score' took: 13716.37698 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 40369.66511 ms
Code block 'ddf-kmeans-score' took: 13529.54357 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 40109.63717 ms
Code block 'ddf-kmeans-score' took: 13084.26870 ms
scores=[array(-4845801.84375)]
client.get_worker_logs()={'ucx://127.0.0.1:48941': (('INFO', "2023-07-07 11:48:19,987 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 11:47:52,712 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 11:47:25,308 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 11:46:58,013 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 11:46:30,194 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 11:46:03,041 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 11:45:35,011 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 11:45:07,819 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 11:44:39,272 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 11:44:08,181 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', '2023-07-07 11:41:02,719 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 11:41:02,718 - distributed.worker - INFO -         Registered to:      ucx://127.0.0.1:54315'), ('INFO', '2023-07-07 11:41:02,646 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 11:41:02,646 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d1d9b498-2bb5-41e2-beee-ca080546dc65'), ('INFO', '2023-07-07 11:40:59,251 - distributed.worker - INFO - Starting Worker plugin PreImport-95e264e4-bc56-4018-9956-84a22abc76a7'), ('INFO', '2023-07-07 11:40:59,251 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0173a315-6d65-4e1b-9f99-564b49f074f8'), ('INFO', '2023-07-07 11:40:59,251 - distributed.worker - INFO -       Local Directory: /scratch/shared/pwesolowski/mgr-pipeline/joined-cuml/tmp/dask-worker-space/worker-78978t9d'), ('INFO', '2023-07-07 11:40:59,251 - distributed.worker - INFO -                Memory:                  50.00 GiB'), ('INFO', '2023-07-07 11:40:59,251 - distributed.worker - INFO -               Threads:                          2'), ('INFO', '2023-07-07 11:40:59,251 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 11:40:59,251 - distributed.worker - INFO - Waiting to connect to:      ucx://127.0.0.1:54315'), ('INFO', '2023-07-07 11:40:59,251 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38283'), ('INFO', '2023-07-07 11:40:59,251 - distributed.worker - INFO -           Worker name:                          0'), ('INFO', '2023-07-07 11:40:59,251 - distributed.worker - INFO -          Listening to:      ucx://127.0.0.1:48941'), ('INFO', '2023-07-07 11:40:59,251 - distributed.worker - INFO -       Start worker at:      ucx://127.0.0.1:48941'))}
+ sleep 1
+ for MP_PINNED_READ in "" "--mp-pinned-read"
+ [[ ucx == ucx ]]
+ FILES=California.json
+ PROTOCOL=ucx
+ ENABLE_IB=--enable-infiniband
+ ENABLE_NVLINK=
+ RMM_POOL_SIZE=
+ MP_BLOCKSIZE=1GiB
+ MP_PINNED_READ=--mp-pinned-read
+ MP_FORCE_HOST_READ=--mp-force-host-read
+ singularity run --nv -B /scratch/shared/pwesolowski /home2/faculty/pwesolowski/containers/cuml-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/run_no_gds.sh
[WARN  tini (3373533)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
+ cd /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/
+ python -u cuml_single_node.py --files California.json --reps 5 --protocol ucx --enable-infiniband --mp-blocksize 1GiB --mp-force-host-read --mp-pinned-read
<Managed Device 0>
args=Namespace(data_dir='/scratch/shared/pwesolowski/mgr-pipeline/joined-cuml', files=['California.json'], reps=5, protocol='ucx', enable_infiniband=True, enable_nvlink=False, rmm_pool_size=None, jit_unspill=False, mp_blocksize='1GiB', mp_force_host_read=True, mp_pinned_read=True, mp_force_gpu_preprocess=False)
2023-07-07 11:49:00,051 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-07 11:49:00,051 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
Code block 'ddf-preprocessing' took: 38000.02256 ms
Code block 'ddf-preprocessing' took: 14886.65286 ms
Code block 'ddf-preprocessing' took: 14875.57258 ms
Code block 'ddf-preprocessing' took: 14924.81682 ms
Code block 'ddf-preprocessing' took: 14724.80793 ms
Code block 'ddf-scaler-fit' took: 16384.03841 ms
Code block 'ddf-scaler-fit' took: 15428.42625 ms
Code block 'ddf-scaler-fit' took: 15835.06936 ms
Code block 'ddf-scaler-fit' took: 15874.63208 ms
Code block 'ddf-scaler-fit' took: 16278.10009 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 47605.84706 ms
Code block 'ddf-kmeans-score' took: 16059.27392 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 43026.38286 ms
Code block 'ddf-kmeans-score' took: 15887.30555 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 43029.74198 ms
Code block 'ddf-kmeans-score' took: 15882.46110 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 42896.95375 ms
Code block 'ddf-kmeans-score' took: 15946.96199 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 42931.61498 ms
Code block 'ddf-kmeans-score' took: 15946.03031 ms
scores=[array(-4847737.90625)]
client.get_worker_logs()={'ucx://127.0.0.1:41929': (('INFO', "2023-07-07 11:56:57,589 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 11:56:30,293 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 11:55:57,664 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 11:55:30,336 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 11:54:57,779 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 11:54:30,452 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 11:53:57,811 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 11:53:30,474 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 11:52:57,437 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 11:52:26,014 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', '2023-07-07 11:49:03,972 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 11:49:03,972 - distributed.worker - INFO -         Registered to:      ucx://127.0.0.1:38025'), ('INFO', '2023-07-07 11:49:03,896 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 11:49:03,896 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8b4029f0-3bb2-48af-a021-7ddcef8efb1f'), ('INFO', '2023-07-07 11:49:00,532 - distributed.worker - INFO - Starting Worker plugin PreImport-f17df6be-37d0-4605-847c-1b48f9708ede'), ('INFO', '2023-07-07 11:49:00,532 - distributed.worker - INFO - Starting Worker plugin RMMSetup-476bd1cd-8d6c-48bc-a9c7-3f0b7700c123'), ('INFO', '2023-07-07 11:49:00,532 - distributed.worker - INFO -       Local Directory: /scratch/shared/pwesolowski/mgr-pipeline/joined-cuml/tmp/dask-worker-space/worker-0ab3dhj3'), ('INFO', '2023-07-07 11:49:00,532 - distributed.worker - INFO -                Memory:                  50.00 GiB'), ('INFO', '2023-07-07 11:49:00,532 - distributed.worker - INFO -               Threads:                          2'), ('INFO', '2023-07-07 11:49:00,532 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 11:49:00,532 - distributed.worker - INFO - Waiting to connect to:      ucx://127.0.0.1:38025'), ('INFO', '2023-07-07 11:49:00,532 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34859'), ('INFO', '2023-07-07 11:49:00,532 - distributed.worker - INFO -           Worker name:                          0'), ('INFO', '2023-07-07 11:49:00,532 - distributed.worker - INFO -          Listening to:      ucx://127.0.0.1:41929'), ('INFO', '2023-07-07 11:49:00,532 - distributed.worker - INFO -       Start worker at:      ucx://127.0.0.1:41929'))}
2023-07-07 11:57:18,304 - distributed.nanny - WARNING - Worker process still alive after 3.1999987792968754 seconds, killing
+ sleep 1
+ for MP_BLOCKSIZE in "256MiB" "1GiB" "4GiB"
+ for MP_PINNED_READ in "" "--mp-pinned-read"
+ [[ ucx == ucx ]]
+ FILES=California.json
+ PROTOCOL=ucx
+ ENABLE_IB=--enable-infiniband
+ ENABLE_NVLINK=
+ RMM_POOL_SIZE=
+ MP_BLOCKSIZE=4GiB
+ MP_PINNED_READ=
+ MP_FORCE_HOST_READ=--mp-force-host-read
+ singularity run --nv -B /scratch/shared/pwesolowski /home2/faculty/pwesolowski/containers/cuml-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/run_no_gds.sh
[WARN  tini (3384002)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
+ cd /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/
+ python -u cuml_single_node.py --files California.json --reps 5 --protocol ucx --enable-infiniband --mp-blocksize 4GiB --mp-force-host-read
<Managed Device 0>
args=Namespace(data_dir='/scratch/shared/pwesolowski/mgr-pipeline/joined-cuml', files=['California.json'], reps=5, protocol='ucx', enable_infiniband=True, enable_nvlink=False, rmm_pool_size=None, jit_unspill=False, mp_blocksize='4GiB', mp_force_host_read=True, mp_pinned_read=False, mp_force_gpu_preprocess=False)
2023-07-07 11:57:41,406 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-07 11:57:41,406 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
Code block 'ddf-preprocessing' took: 37184.63479 ms
Code block 'ddf-preprocessing' took: 14610.00653 ms
Code block 'ddf-preprocessing' took: 14649.37181 ms
Code block 'ddf-preprocessing' took: 14690.64967 ms
Code block 'ddf-preprocessing' took: 14660.91650 ms
Code block 'ddf-scaler-fit' took: 12756.08009 ms
Code block 'ddf-scaler-fit' took: 11754.90151 ms
Code block 'ddf-scaler-fit' took: 12309.79537 ms
Code block 'ddf-scaler-fit' took: 11758.76783 ms
Code block 'ddf-scaler-fit' took: 12583.20945 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 45911.04718 ms
Code block 'ddf-kmeans-score' took: 12850.64857 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 41735.01055 ms
Code block 'ddf-kmeans-score' took: 12589.01212 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 42054.60413 ms
Code block 'ddf-kmeans-score' took: 12271.44777 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 42280.37364 ms
Code block 'ddf-kmeans-score' took: 12954.62788 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 41673.21610 ms
Code block 'ddf-kmeans-score' took: 13088.45162 ms
scores=[array(-9703893.5)]
client.get_worker_logs()={'ucx://127.0.0.1:47031': (('INFO', "2023-07-07 12:04:59,742 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 12:04:30,620 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 12:04:04,106 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 12:03:34,918 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 12:03:08,534 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 12:02:39,332 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 12:02:12,874 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 12:01:43,744 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 12:01:16,766 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 12:00:43,653 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', '2023-07-07 11:57:45,552 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 11:57:45,551 - distributed.worker - INFO -         Registered to:      ucx://127.0.0.1:44065'), ('INFO', '2023-07-07 11:57:45,476 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 11:57:45,476 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2ded0e24-740c-43c2-ab30-417162794b87'), ('INFO', '2023-07-07 11:57:41,867 - distributed.worker - INFO - Starting Worker plugin PreImport-1e1e0427-f7c6-4f07-b9be-c9f1f3c31eae'), ('INFO', '2023-07-07 11:57:41,867 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1a487a11-15a3-46f9-973e-1196935f3357'), ('INFO', '2023-07-07 11:57:41,867 - distributed.worker - INFO -       Local Directory: /scratch/shared/pwesolowski/mgr-pipeline/joined-cuml/tmp/dask-worker-space/worker-uvoj480_'), ('INFO', '2023-07-07 11:57:41,867 - distributed.worker - INFO -                Memory:                  50.00 GiB'), ('INFO', '2023-07-07 11:57:41,867 - distributed.worker - INFO -               Threads:                          2'), ('INFO', '2023-07-07 11:57:41,867 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 11:57:41,867 - distributed.worker - INFO - Waiting to connect to:      ucx://127.0.0.1:44065'), ('INFO', '2023-07-07 11:57:41,867 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35605'), ('INFO', '2023-07-07 11:57:41,867 - distributed.worker - INFO -           Worker name:                          0'), ('INFO', '2023-07-07 11:57:41,867 - distributed.worker - INFO -          Listening to:      ucx://127.0.0.1:47031'), ('INFO', '2023-07-07 11:57:41,867 - distributed.worker - INFO -       Start worker at:      ucx://127.0.0.1:47031'))}
2023-07-07 12:05:17,551 - distributed.nanny - WARNING - Worker process still alive after 3.199999389648438 seconds, killing
+ sleep 1
+ for MP_PINNED_READ in "" "--mp-pinned-read"
+ [[ ucx == ucx ]]
+ FILES=California.json
+ PROTOCOL=ucx
+ ENABLE_IB=--enable-infiniband
+ ENABLE_NVLINK=
+ RMM_POOL_SIZE=
+ MP_BLOCKSIZE=4GiB
+ MP_PINNED_READ=--mp-pinned-read
+ MP_FORCE_HOST_READ=--mp-force-host-read
+ singularity run --nv -B /scratch/shared/pwesolowski /home2/faculty/pwesolowski/containers/cuml-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/run_no_gds.sh
[WARN  tini (3394513)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
+ cd /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/
+ python -u cuml_single_node.py --files California.json --reps 5 --protocol ucx --enable-infiniband --mp-blocksize 4GiB --mp-force-host-read --mp-pinned-read
<Managed Device 0>
args=Namespace(data_dir='/scratch/shared/pwesolowski/mgr-pipeline/joined-cuml', files=['California.json'], reps=5, protocol='ucx', enable_infiniband=True, enable_nvlink=False, rmm_pool_size=None, jit_unspill=False, mp_blocksize='4GiB', mp_force_host_read=True, mp_pinned_read=True, mp_force_gpu_preprocess=False)
2023-07-07 12:05:44,411 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-07 12:05:44,412 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
Code block 'ddf-preprocessing' took: 37367.44148 ms
Code block 'ddf-preprocessing' took: 14676.78652 ms
Code block 'ddf-preprocessing' took: 14788.67134 ms
Code block 'ddf-preprocessing' took: 14660.80602 ms
Code block 'ddf-preprocessing' took: 14764.88996 ms
Code block 'ddf-scaler-fit' took: 15488.57903 ms
Code block 'ddf-scaler-fit' took: 14626.65962 ms
Code block 'ddf-scaler-fit' took: 14811.41467 ms
Code block 'ddf-scaler-fit' took: 14690.14814 ms
Code block 'ddf-scaler-fit' took: 14755.79018 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 47846.59384 ms
Code block 'ddf-kmeans-score' took: 15468.40290 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 44556.85108 ms
Code block 'ddf-kmeans-score' took: 14651.53219 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 45020.04067 ms
Code block 'ddf-kmeans-score' took: 15141.12129 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 45153.11430 ms
Code block 'ddf-kmeans-score' took: 15466.76622 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 44744.52118 ms
Code block 'ddf-kmeans-score' took: 16439.75917 ms
scores=[array(-9703555.5)]
client.get_worker_logs()={'ucx://127.0.0.1:45971': (('INFO', "2023-07-07 12:13:41,038 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 12:13:11,912 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 12:12:39,818 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 12:12:10,772 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 12:11:38,498 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 12:11:09,361 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 12:10:37,830 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 12:10:08,779 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 12:09:36,717 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 12:09:03,499 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', '2023-07-07 12:05:48,651 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 12:05:48,651 - distributed.worker - INFO -         Registered to:      ucx://127.0.0.1:44561'), ('INFO', '2023-07-07 12:05:48,580 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 12:05:48,579 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ff50bd8d-313d-46c2-80fa-77cd9baae0d6'), ('INFO', '2023-07-07 12:05:44,890 - distributed.worker - INFO - Starting Worker plugin PreImport-f0d64f7d-1754-4610-86ea-7354afdde494'), ('INFO', '2023-07-07 12:05:44,890 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a88eef89-11ff-4c05-9d92-e1ba27193725'), ('INFO', '2023-07-07 12:05:44,889 - distributed.worker - INFO -       Local Directory: /scratch/shared/pwesolowski/mgr-pipeline/joined-cuml/tmp/dask-worker-space/worker-hmn816n2'), ('INFO', '2023-07-07 12:05:44,889 - distributed.worker - INFO -                Memory:                  50.00 GiB'), ('INFO', '2023-07-07 12:05:44,889 - distributed.worker - INFO -               Threads:                          2'), ('INFO', '2023-07-07 12:05:44,889 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 12:05:44,889 - distributed.worker - INFO - Waiting to connect to:      ucx://127.0.0.1:44561'), ('INFO', '2023-07-07 12:05:44,889 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44667'), ('INFO', '2023-07-07 12:05:44,889 - distributed.worker - INFO -           Worker name:                          0'), ('INFO', '2023-07-07 12:05:44,889 - distributed.worker - INFO -          Listening to:      ucx://127.0.0.1:45971'), ('INFO', '2023-07-07 12:05:44,889 - distributed.worker - INFO -       Start worker at:      ucx://127.0.0.1:45971'))}
2023-07-07 12:14:02,480 - distributed.nanny - WARNING - Worker process still alive after 3.1999987792968754 seconds, killing
+ sleep 1
+ for ENABLE_IB in "--enable-infiniband" ""
+ for ENABLE_NVLINK in "--enable-nvlink" ""
+ for RMM_POOL_SIZE in ""
+ for MP_BLOCKSIZE in "256MiB" "1GiB" "4GiB"
+ for MP_PINNED_READ in "" "--mp-pinned-read"
+ [[ ucx == ucx ]]
+ FILES=California.json
+ PROTOCOL=ucx
+ ENABLE_IB=
+ ENABLE_NVLINK=--enable-nvlink
+ RMM_POOL_SIZE=
+ MP_BLOCKSIZE=256MiB
+ MP_PINNED_READ=
+ MP_FORCE_HOST_READ=--mp-force-host-read
+ singularity run --nv -B /scratch/shared/pwesolowski /home2/faculty/pwesolowski/containers/cuml-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/run_no_gds.sh
[WARN  tini (3404759)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
+ cd /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/
+ python -u cuml_single_node.py --files California.json --reps 5 --protocol ucx --enable-nvlink --mp-blocksize 256MiB --mp-force-host-read
<Managed Device 0>
args=Namespace(data_dir='/scratch/shared/pwesolowski/mgr-pipeline/joined-cuml', files=['California.json'], reps=5, protocol='ucx', enable_infiniband=False, enable_nvlink=True, rmm_pool_size=None, jit_unspill=False, mp_blocksize='256MiB', mp_force_host_read=True, mp_pinned_read=False, mp_force_gpu_preprocess=False)
/opt/conda/envs/rapids/lib/python3.10/site-packages/dask_cuda-23.2.0-py3.10.egg/dask_cuda/local_cuda_cluster.py:266: UserWarning: When using NVLink we recommend setting a `rmm_pool_size`. Please see: https://dask-cuda.readthedocs.io/en/latest/ucx.html#important-notes for more details
2023-07-07 12:14:54,616 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-07 12:14:54,618 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
Code block 'ddf-preprocessing' took: 38090.01188 ms
Code block 'ddf-preprocessing' took: 15061.29261 ms
Code block 'ddf-preprocessing' took: 15350.72359 ms
Code block 'ddf-preprocessing' took: 14930.61166 ms
Code block 'ddf-preprocessing' took: 15038.73615 ms
Code block 'ddf-scaler-fit' took: 15402.06112 ms
Code block 'ddf-scaler-fit' took: 14872.60728 ms
Code block 'ddf-scaler-fit' took: 15479.09799 ms
Code block 'ddf-scaler-fit' took: 16138.37950 ms
Code block 'ddf-scaler-fit' took: 16479.87379 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 47604.33473 ms
Code block 'ddf-kmeans-score' took: 15911.09891 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 42667.41584 ms
Code block 'ddf-kmeans-score' took: 16393.70904 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 43416.56791 ms
Code block 'ddf-kmeans-score' took: 16421.82731 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 43176.17791 ms
Code block 'ddf-kmeans-score' took: 16340.35452 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 43539.78257 ms
Code block 'ddf-kmeans-score' took: 16063.45083 ms
scores=[array(-4835394.703125)]
client.get_worker_logs()={'ucx://127.0.0.1:40905': (('INFO', "2023-07-07 12:23:02,751 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 12:22:35,514 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 12:22:01,796 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 12:21:34,548 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 12:21:01,088 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 12:20:33,758 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 12:20:00,166 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 12:19:32,880 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 12:19:00,302 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 12:18:28,699 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', '2023-07-07 12:14:59,601 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 12:14:59,601 - distributed.worker - INFO -         Registered to:      ucx://127.0.0.1:36171'), ('INFO', '2023-07-07 12:14:59,519 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 12:14:59,519 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0274392f-daea-4844-8a13-3b6fdce59317'), ('INFO', '2023-07-07 12:14:55,062 - distributed.worker - INFO - Starting Worker plugin PreImport-c4ec901e-eaa7-4296-b9b9-4fb19c985ea3'), ('INFO', '2023-07-07 12:14:55,062 - distributed.worker - INFO - Starting Worker plugin RMMSetup-08b3e17e-aabc-4f1a-8c57-4cf766525865'), ('INFO', '2023-07-07 12:14:55,062 - distributed.worker - INFO -       Local Directory: /scratch/shared/pwesolowski/mgr-pipeline/joined-cuml/tmp/dask-worker-space/worker-sbp8s_90'), ('INFO', '2023-07-07 12:14:55,062 - distributed.worker - INFO -                Memory:                  50.00 GiB'), ('INFO', '2023-07-07 12:14:55,062 - distributed.worker - INFO -               Threads:                          2'), ('INFO', '2023-07-07 12:14:55,062 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 12:14:55,062 - distributed.worker - INFO - Waiting to connect to:      ucx://127.0.0.1:36171'), ('INFO', '2023-07-07 12:14:55,062 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37329'), ('INFO', '2023-07-07 12:14:55,062 - distributed.worker - INFO -           Worker name:                          0'), ('INFO', '2023-07-07 12:14:55,062 - distributed.worker - INFO -          Listening to:      ucx://127.0.0.1:40905'), ('INFO', '2023-07-07 12:14:55,062 - distributed.worker - INFO -       Start worker at:      ucx://127.0.0.1:40905'))}
2023-07-07 12:23:23,675 - distributed.nanny - WARNING - Worker process still alive after 3.199999694824219 seconds, killing
+ sleep 1
+ for MP_PINNED_READ in "" "--mp-pinned-read"
+ [[ ucx == ucx ]]
+ FILES=California.json
+ PROTOCOL=ucx
+ ENABLE_IB=
+ ENABLE_NVLINK=--enable-nvlink
+ RMM_POOL_SIZE=
+ MP_BLOCKSIZE=256MiB
+ MP_PINNED_READ=--mp-pinned-read
+ MP_FORCE_HOST_READ=--mp-force-host-read
+ singularity run --nv -B /scratch/shared/pwesolowski /home2/faculty/pwesolowski/containers/cuml-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/run_no_gds.sh
[WARN  tini (3416934)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
+ cd /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/
+ python -u cuml_single_node.py --files California.json --reps 5 --protocol ucx --enable-nvlink --mp-blocksize 256MiB --mp-force-host-read --mp-pinned-read
<Managed Device 0>
args=Namespace(data_dir='/scratch/shared/pwesolowski/mgr-pipeline/joined-cuml', files=['California.json'], reps=5, protocol='ucx', enable_infiniband=False, enable_nvlink=True, rmm_pool_size=None, jit_unspill=False, mp_blocksize='256MiB', mp_force_host_read=True, mp_pinned_read=True, mp_force_gpu_preprocess=False)
/opt/conda/envs/rapids/lib/python3.10/site-packages/dask_cuda-23.2.0-py3.10.egg/dask_cuda/local_cuda_cluster.py:266: UserWarning: When using NVLink we recommend setting a `rmm_pool_size`. Please see: https://dask-cuda.readthedocs.io/en/latest/ucx.html#important-notes for more details
2023-07-07 12:23:48,803 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-07 12:23:48,804 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
Code block 'ddf-preprocessing' took: 37930.15853 ms
Code block 'ddf-preprocessing' took: 14984.18568 ms
Code block 'ddf-preprocessing' took: 14925.46101 ms
Code block 'ddf-preprocessing' took: 15004.89688 ms
Code block 'ddf-preprocessing' took: 14876.54844 ms
Code block 'ddf-scaler-fit' took: 18490.37102 ms
Code block 'ddf-scaler-fit' took: 17743.41604 ms
Code block 'ddf-scaler-fit' took: 18397.62645 ms
Code block 'ddf-scaler-fit' took: 19185.65011 ms
Code block 'ddf-scaler-fit' took: 19372.26360 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 49996.51979 ms
Code block 'ddf-kmeans-score' took: 18549.10205 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 46034.13846 ms
Code block 'ddf-kmeans-score' took: 18964.49451 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 49046.30160 ms
Code block 'ddf-kmeans-score' took: 19111.47685 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 46796.89105 ms
Code block 'ddf-kmeans-score' took: 18865.58713 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 45632.05001 ms
Code block 'ddf-kmeans-score' took: 19159.00973 ms
scores=[array(-4846125.6484375)]
client.get_worker_logs()={'ucx://127.0.0.1:50491': (('INFO', "2023-07-07 12:32:29,202 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 12:32:01,822 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 12:31:23,595 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 12:30:56,254 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 12:30:16,581 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 12:29:49,246 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 12:29:07,463 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 12:28:40,212 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 12:28:01,737 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 12:27:30,342 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', '2023-07-07 12:23:52,586 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 12:23:52,586 - distributed.worker - INFO -         Registered to:      ucx://127.0.0.1:56013'), ('INFO', '2023-07-07 12:23:52,516 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 12:23:49,209 - distributed.worker - INFO - Starting Worker plugin PreImport-dd81125b-d192-49b7-b340-2d4f1310efa8'), ('INFO', '2023-07-07 12:23:49,209 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5d6ce018-b4cf-4553-b1fb-48c747c67f78'), ('INFO', '2023-07-07 12:23:49,209 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ddcdce19-f720-493b-9ac0-aa0452354f1a'), ('INFO', '2023-07-07 12:23:49,208 - distributed.worker - INFO -       Local Directory: /scratch/shared/pwesolowski/mgr-pipeline/joined-cuml/tmp/dask-worker-space/worker-d6andib9'), ('INFO', '2023-07-07 12:23:49,208 - distributed.worker - INFO -                Memory:                  50.00 GiB'), ('INFO', '2023-07-07 12:23:49,208 - distributed.worker - INFO -               Threads:                          2'), ('INFO', '2023-07-07 12:23:49,208 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 12:23:49,208 - distributed.worker - INFO - Waiting to connect to:      ucx://127.0.0.1:56013'), ('INFO', '2023-07-07 12:23:49,208 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36541'), ('INFO', '2023-07-07 12:23:49,208 - distributed.worker - INFO -           Worker name:                          0'), ('INFO', '2023-07-07 12:23:49,208 - distributed.worker - INFO -          Listening to:      ucx://127.0.0.1:50491'), ('INFO', '2023-07-07 12:23:49,208 - distributed.worker - INFO -       Start worker at:      ucx://127.0.0.1:50491'))}
+ sleep 1
+ for MP_BLOCKSIZE in "256MiB" "1GiB" "4GiB"
+ for MP_PINNED_READ in "" "--mp-pinned-read"
+ [[ ucx == ucx ]]
+ FILES=California.json
+ PROTOCOL=ucx
+ ENABLE_IB=
+ ENABLE_NVLINK=--enable-nvlink
+ RMM_POOL_SIZE=
+ MP_BLOCKSIZE=1GiB
+ MP_PINNED_READ=
+ MP_FORCE_HOST_READ=--mp-force-host-read
+ singularity run --nv -B /scratch/shared/pwesolowski /home2/faculty/pwesolowski/containers/cuml-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/run_no_gds.sh
[WARN  tini (3426931)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
+ cd /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/
+ python -u cuml_single_node.py --files California.json --reps 5 --protocol ucx --enable-nvlink --mp-blocksize 1GiB --mp-force-host-read
<Managed Device 0>
args=Namespace(data_dir='/scratch/shared/pwesolowski/mgr-pipeline/joined-cuml', files=['California.json'], reps=5, protocol='ucx', enable_infiniband=False, enable_nvlink=True, rmm_pool_size=None, jit_unspill=False, mp_blocksize='1GiB', mp_force_host_read=True, mp_pinned_read=False, mp_force_gpu_preprocess=False)
/opt/conda/envs/rapids/lib/python3.10/site-packages/dask_cuda-23.2.0-py3.10.egg/dask_cuda/local_cuda_cluster.py:266: UserWarning: When using NVLink we recommend setting a `rmm_pool_size`. Please see: https://dask-cuda.readthedocs.io/en/latest/ucx.html#important-notes for more details
2023-07-07 12:33:15,506 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-07 12:33:15,507 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
Code block 'ddf-preprocessing' took: 37191.01019 ms
Code block 'ddf-preprocessing' took: 14798.37621 ms
Code block 'ddf-preprocessing' took: 14687.87944 ms
Code block 'ddf-preprocessing' took: 14694.99794 ms
Code block 'ddf-preprocessing' took: 14910.97987 ms
Code block 'ddf-scaler-fit' took: 13315.35240 ms
Code block 'ddf-scaler-fit' took: 12956.56026 ms
Code block 'ddf-scaler-fit' took: 12889.96699 ms
Code block 'ddf-scaler-fit' took: 13253.41153 ms
Code block 'ddf-scaler-fit' took: 13537.09582 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 44434.95142 ms
Code block 'ddf-kmeans-score' took: 13500.28892 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 40253.09692 ms
Code block 'ddf-kmeans-score' took: 13530.14836 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 40827.15718 ms
Code block 'ddf-kmeans-score' took: 13462.75895 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 40202.99855 ms
Code block 'ddf-kmeans-score' took: 13263.21957 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 40307.58469 ms
Code block 'ddf-kmeans-score' took: 13510.92517 ms
scores=[array(-4834532.21875)]
client.get_worker_logs()={'ucx://127.0.0.1:32971': (('INFO', "2023-07-07 12:40:34,557 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 12:40:07,340 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 12:39:39,967 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 12:39:12,772 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 12:38:45,264 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 12:38:18,027 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 12:37:49,756 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 12:37:22,523 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 12:36:54,740 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 12:36:23,444 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', '2023-07-07 12:33:19,365 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 12:33:19,365 - distributed.worker - INFO -         Registered to:      ucx://127.0.0.1:42587'), ('INFO', '2023-07-07 12:33:19,297 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 12:33:19,297 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0aa5e2ad-d9f1-492e-a28f-0b8162e9589f'), ('INFO', '2023-07-07 12:33:15,964 - distributed.worker - INFO - Starting Worker plugin PreImport-690ac19b-46eb-4fd7-8d9f-abb20931580c'), ('INFO', '2023-07-07 12:33:15,964 - distributed.worker - INFO - Starting Worker plugin RMMSetup-594856ff-6f64-4e45-a708-7930d0ae7005'), ('INFO', '2023-07-07 12:33:15,964 - distributed.worker - INFO -       Local Directory: /scratch/shared/pwesolowski/mgr-pipeline/joined-cuml/tmp/dask-worker-space/worker-lrokq10z'), ('INFO', '2023-07-07 12:33:15,964 - distributed.worker - INFO -                Memory:                  50.00 GiB'), ('INFO', '2023-07-07 12:33:15,964 - distributed.worker - INFO -               Threads:                          2'), ('INFO', '2023-07-07 12:33:15,964 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 12:33:15,964 - distributed.worker - INFO - Waiting to connect to:      ucx://127.0.0.1:42587'), ('INFO', '2023-07-07 12:33:15,964 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43881'), ('INFO', '2023-07-07 12:33:15,964 - distributed.worker - INFO -           Worker name:                          0'), ('INFO', '2023-07-07 12:33:15,964 - distributed.worker - INFO -          Listening to:      ucx://127.0.0.1:32971'), ('INFO', '2023-07-07 12:33:15,964 - distributed.worker - INFO -       Start worker at:      ucx://127.0.0.1:32971'))}
2023-07-07 12:40:52,693 - distributed.nanny - WARNING - Worker process still alive after 3.1999986267089846 seconds, killing
+ sleep 1
+ for MP_PINNED_READ in "" "--mp-pinned-read"
+ [[ ucx == ucx ]]
+ FILES=California.json
+ PROTOCOL=ucx
+ ENABLE_IB=
+ ENABLE_NVLINK=--enable-nvlink
+ RMM_POOL_SIZE=
+ MP_BLOCKSIZE=1GiB
+ MP_PINNED_READ=--mp-pinned-read
+ MP_FORCE_HOST_READ=--mp-force-host-read
+ singularity run --nv -B /scratch/shared/pwesolowski /home2/faculty/pwesolowski/containers/cuml-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/run_no_gds.sh
[WARN  tini (3436219)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
+ cd /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/
+ python -u cuml_single_node.py --files California.json --reps 5 --protocol ucx --enable-nvlink --mp-blocksize 1GiB --mp-force-host-read --mp-pinned-read
<Managed Device 0>
args=Namespace(data_dir='/scratch/shared/pwesolowski/mgr-pipeline/joined-cuml', files=['California.json'], reps=5, protocol='ucx', enable_infiniband=False, enable_nvlink=True, rmm_pool_size=None, jit_unspill=False, mp_blocksize='1GiB', mp_force_host_read=True, mp_pinned_read=True, mp_force_gpu_preprocess=False)
/opt/conda/envs/rapids/lib/python3.10/site-packages/dask_cuda-23.2.0-py3.10.egg/dask_cuda/local_cuda_cluster.py:266: UserWarning: When using NVLink we recommend setting a `rmm_pool_size`. Please see: https://dask-cuda.readthedocs.io/en/latest/ucx.html#important-notes for more details
2023-07-07 12:41:15,554 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-07 12:41:15,554 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
Code block 'ddf-preprocessing' took: 37526.70242 ms
Code block 'ddf-preprocessing' took: 14778.58796 ms
Code block 'ddf-preprocessing' took: 14700.93764 ms
Code block 'ddf-preprocessing' took: 14908.98598 ms
Code block 'ddf-preprocessing' took: 14872.57631 ms
Code block 'ddf-scaler-fit' took: 15780.90489 ms
Code block 'ddf-scaler-fit' took: 15035.63920 ms
Code block 'ddf-scaler-fit' took: 15307.14128 ms
Code block 'ddf-scaler-fit' took: 15909.11614 ms
Code block 'ddf-scaler-fit' took: 15726.28622 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 47310.44705 ms
Code block 'ddf-kmeans-score' took: 15602.66353 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 42734.62378 ms
Code block 'ddf-kmeans-score' took: 16339.94409 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 42658.02117 ms
Code block 'ddf-kmeans-score' took: 15624.34463 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 42913.44976 ms
Code block 'ddf-kmeans-score' took: 15802.37807 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 42661.27716 ms
Code block 'ddf-kmeans-score' took: 16435.71651 ms
scores=[array(-4834318.3125)]
client.get_worker_logs()={'ucx://127.0.0.1:46475': (('INFO', "2023-07-07 12:49:09,281 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 12:48:42,068 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 12:48:09,785 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 12:47:42,620 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 12:47:10,198 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 12:46:43,003 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 12:46:10,160 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 12:45:42,902 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 12:45:10,575 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 12:44:39,255 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', '2023-07-07 12:41:19,667 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 12:41:19,666 - distributed.worker - INFO -         Registered to:      ucx://127.0.0.1:58177'), ('INFO', '2023-07-07 12:41:19,598 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 12:41:19,598 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-230bec22-cf19-49de-96b3-a27c84ed3e50'), ('INFO', '2023-07-07 12:41:15,997 - distributed.worker - INFO - Starting Worker plugin PreImport-4b9e057d-cc63-4286-81df-2eb082a75995'), ('INFO', '2023-07-07 12:41:15,997 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7664a00c-24d6-4354-8548-f99ce805755b'), ('INFO', '2023-07-07 12:41:15,997 - distributed.worker - INFO -       Local Directory: /scratch/shared/pwesolowski/mgr-pipeline/joined-cuml/tmp/dask-worker-space/worker-5iexyutf'), ('INFO', '2023-07-07 12:41:15,997 - distributed.worker - INFO -                Memory:                  50.00 GiB'), ('INFO', '2023-07-07 12:41:15,997 - distributed.worker - INFO -               Threads:                          2'), ('INFO', '2023-07-07 12:41:15,997 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 12:41:15,997 - distributed.worker - INFO - Waiting to connect to:      ucx://127.0.0.1:58177'), ('INFO', '2023-07-07 12:41:15,997 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42653'), ('INFO', '2023-07-07 12:41:15,997 - distributed.worker - INFO -           Worker name:                          0'), ('INFO', '2023-07-07 12:41:15,997 - distributed.worker - INFO -          Listening to:      ucx://127.0.0.1:46475'), ('INFO', '2023-07-07 12:41:15,997 - distributed.worker - INFO -       Start worker at:      ucx://127.0.0.1:46475'))}
2023-07-07 12:49:30,416 - distributed.nanny - WARNING - Worker process still alive after 3.1999983215332035 seconds, killing
+ sleep 1
+ for MP_BLOCKSIZE in "256MiB" "1GiB" "4GiB"
+ for MP_PINNED_READ in "" "--mp-pinned-read"
+ [[ ucx == ucx ]]
+ FILES=California.json
+ PROTOCOL=ucx
+ ENABLE_IB=
+ ENABLE_NVLINK=--enable-nvlink
+ RMM_POOL_SIZE=
+ MP_BLOCKSIZE=4GiB
+ MP_PINNED_READ=
+ MP_FORCE_HOST_READ=--mp-force-host-read
+ singularity run --nv -B /scratch/shared/pwesolowski /home2/faculty/pwesolowski/containers/cuml-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/run_no_gds.sh
[WARN  tini (3445404)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
+ cd /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/
+ python -u cuml_single_node.py --files California.json --reps 5 --protocol ucx --enable-nvlink --mp-blocksize 4GiB --mp-force-host-read
<Managed Device 0>
args=Namespace(data_dir='/scratch/shared/pwesolowski/mgr-pipeline/joined-cuml', files=['California.json'], reps=5, protocol='ucx', enable_infiniband=False, enable_nvlink=True, rmm_pool_size=None, jit_unspill=False, mp_blocksize='4GiB', mp_force_host_read=True, mp_pinned_read=False, mp_force_gpu_preprocess=False)
/opt/conda/envs/rapids/lib/python3.10/site-packages/dask_cuda-23.2.0-py3.10.egg/dask_cuda/local_cuda_cluster.py:266: UserWarning: When using NVLink we recommend setting a `rmm_pool_size`. Please see: https://dask-cuda.readthedocs.io/en/latest/ucx.html#important-notes for more details
2023-07-07 12:49:54,587 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-07 12:49:54,587 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
Code block 'ddf-preprocessing' took: 38349.50966 ms
Code block 'ddf-preprocessing' took: 14804.28509 ms
Code block 'ddf-preprocessing' took: 14875.15096 ms
Code block 'ddf-preprocessing' took: 14792.92326 ms
Code block 'ddf-preprocessing' took: 14791.29058 ms
Code block 'ddf-scaler-fit' took: 13777.10000 ms
Code block 'ddf-scaler-fit' took: 12616.91598 ms
Code block 'ddf-scaler-fit' took: 12393.35884 ms
Code block 'ddf-scaler-fit' took: 11927.64909 ms
Code block 'ddf-scaler-fit' took: 12457.86591 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 46856.35878 ms
Code block 'ddf-kmeans-score' took: 13085.95848 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 42202.77482 ms
Code block 'ddf-kmeans-score' took: 12691.36339 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 42719.91836 ms
Code block 'ddf-kmeans-score' took: 12157.24605 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 42120.53074 ms
Code block 'ddf-kmeans-score' took: 12158.48105 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 42215.87843 ms
Code block 'ddf-kmeans-score' took: 12212.17686 ms
scores=[array(-9703544.625)]
client.get_worker_logs()={'ucx://127.0.0.1:50909': (('INFO', "2023-07-07 12:57:18,573 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 12:56:49,404 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 12:56:23,209 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 12:55:54,130 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 12:55:27,912 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 12:54:58,827 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 12:54:31,485 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 12:54:02,360 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 12:53:34,942 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 12:53:01,497 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', '2023-07-07 12:49:58,895 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 12:49:58,895 - distributed.worker - INFO -         Registered to:      ucx://127.0.0.1:40835'), ('INFO', '2023-07-07 12:49:58,825 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 12:49:58,825 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3a5babba-0cfb-4242-9c3f-7eecd94cafa2'), ('INFO', '2023-07-07 12:49:58,825 - distributed.worker - INFO - Starting Worker plugin RMMSetup-fbb2dac6-890c-4ae6-99da-721646835c72'), ('INFO', '2023-07-07 12:49:55,008 - distributed.worker - INFO - Starting Worker plugin PreImport-560e2f7a-6ee2-4fdc-83a1-68402077d883'), ('INFO', '2023-07-07 12:49:55,008 - distributed.worker - INFO -       Local Directory: /scratch/shared/pwesolowski/mgr-pipeline/joined-cuml/tmp/dask-worker-space/worker-qdtquq23'), ('INFO', '2023-07-07 12:49:55,008 - distributed.worker - INFO -                Memory:                  50.00 GiB'), ('INFO', '2023-07-07 12:49:55,008 - distributed.worker - INFO -               Threads:                          2'), ('INFO', '2023-07-07 12:49:55,008 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 12:49:55,008 - distributed.worker - INFO - Waiting to connect to:      ucx://127.0.0.1:40835'), ('INFO', '2023-07-07 12:49:55,007 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42559'), ('INFO', '2023-07-07 12:49:55,007 - distributed.worker - INFO -           Worker name:                          0'), ('INFO', '2023-07-07 12:49:55,007 - distributed.worker - INFO -          Listening to:      ucx://127.0.0.1:50909'), ('INFO', '2023-07-07 12:49:55,007 - distributed.worker - INFO -       Start worker at:      ucx://127.0.0.1:50909'))}
2023-07-07 12:57:35,364 - distributed.nanny - WARNING - Worker process still alive after 3.1999992370605472 seconds, killing
+ sleep 1
+ for MP_PINNED_READ in "" "--mp-pinned-read"
+ [[ ucx == ucx ]]
+ FILES=California.json
+ PROTOCOL=ucx
+ ENABLE_IB=
+ ENABLE_NVLINK=--enable-nvlink
+ RMM_POOL_SIZE=
+ MP_BLOCKSIZE=4GiB
+ MP_PINNED_READ=--mp-pinned-read
+ MP_FORCE_HOST_READ=--mp-force-host-read
+ singularity run --nv -B /scratch/shared/pwesolowski /home2/faculty/pwesolowski/containers/cuml-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/run_no_gds.sh
[WARN  tini (3455158)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
+ cd /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/
+ python -u cuml_single_node.py --files California.json --reps 5 --protocol ucx --enable-nvlink --mp-blocksize 4GiB --mp-force-host-read --mp-pinned-read
<Managed Device 0>
args=Namespace(data_dir='/scratch/shared/pwesolowski/mgr-pipeline/joined-cuml', files=['California.json'], reps=5, protocol='ucx', enable_infiniband=False, enable_nvlink=True, rmm_pool_size=None, jit_unspill=False, mp_blocksize='4GiB', mp_force_host_read=True, mp_pinned_read=True, mp_force_gpu_preprocess=False)
/opt/conda/envs/rapids/lib/python3.10/site-packages/dask_cuda-23.2.0-py3.10.egg/dask_cuda/local_cuda_cluster.py:266: UserWarning: When using NVLink we recommend setting a `rmm_pool_size`. Please see: https://dask-cuda.readthedocs.io/en/latest/ucx.html#important-notes for more details
2023-07-07 12:57:58,640 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-07 12:57:58,640 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
Code block 'ddf-preprocessing' took: 37430.03354 ms
Code block 'ddf-preprocessing' took: 14665.20190 ms
Code block 'ddf-preprocessing' took: 14560.74919 ms
Code block 'ddf-preprocessing' took: 14703.82062 ms
Code block 'ddf-preprocessing' took: 14613.28360 ms
Code block 'ddf-scaler-fit' took: 15864.32431 ms
Code block 'ddf-scaler-fit' took: 14667.30889 ms
Code block 'ddf-scaler-fit' took: 14652.29234 ms
Code block 'ddf-scaler-fit' took: 14459.66677 ms
Code block 'ddf-scaler-fit' took: 14615.56328 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 47780.85703 ms
Code block 'ddf-kmeans-score' took: 15885.74201 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 44009.41247 ms
Code block 'ddf-kmeans-score' took: 15553.33313 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 44749.28123 ms
Code block 'ddf-kmeans-score' took: 15959.31014 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 44519.74951 ms
Code block 'ddf-kmeans-score' took: 15596.80080 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 44290.93566 ms
Code block 'ddf-kmeans-score' took: 15086.80318 ms
scores=[array(-28281310.5)]
client.get_worker_logs()={'ucx://127.0.0.1:36959': (('INFO', "2023-07-07 13:05:54,067 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 13:05:24,976 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 13:04:53,161 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 13:04:24,051 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 13:03:51,682 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 13:03:22,619 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 13:02:50,371 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 13:02:21,293 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 13:01:49,168 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 13:01:15,975 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', '2023-07-07 12:58:02,961 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 12:58:02,961 - distributed.worker - INFO -         Registered to:      ucx://127.0.0.1:58505'), ('INFO', '2023-07-07 12:58:02,892 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 12:58:02,892 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e19a63a5-1333-4880-ae79-1fdbf30724b3'), ('INFO', '2023-07-07 12:58:02,891 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2cd070c4-be89-4243-a2b9-5a16a82d89ca'), ('INFO', '2023-07-07 12:57:59,203 - distributed.worker - INFO - Starting Worker plugin PreImport-c3a6a5cf-15e4-447a-a965-93029db4ff02'), ('INFO', '2023-07-07 12:57:59,203 - distributed.worker - INFO -       Local Directory: /scratch/shared/pwesolowski/mgr-pipeline/joined-cuml/tmp/dask-worker-space/worker-ern1q9oo'), ('INFO', '2023-07-07 12:57:59,203 - distributed.worker - INFO -                Memory:                  50.00 GiB'), ('INFO', '2023-07-07 12:57:59,203 - distributed.worker - INFO -               Threads:                          2'), ('INFO', '2023-07-07 12:57:59,203 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 12:57:59,203 - distributed.worker - INFO - Waiting to connect to:      ucx://127.0.0.1:58505'), ('INFO', '2023-07-07 12:57:59,203 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35833'), ('INFO', '2023-07-07 12:57:59,203 - distributed.worker - INFO -           Worker name:                          0'), ('INFO', '2023-07-07 12:57:59,203 - distributed.worker - INFO -          Listening to:      ucx://127.0.0.1:36959'), ('INFO', '2023-07-07 12:57:59,203 - distributed.worker - INFO -       Start worker at:      ucx://127.0.0.1:36959'))}
2023-07-07 13:06:13,795 - distributed.nanny - WARNING - Worker process still alive after 3.1999986267089846 seconds, killing
+ sleep 1
+ for ENABLE_NVLINK in "--enable-nvlink" ""
+ for RMM_POOL_SIZE in ""
+ for MP_BLOCKSIZE in "256MiB" "1GiB" "4GiB"
+ for MP_PINNED_READ in "" "--mp-pinned-read"
+ [[ ucx == ucx ]]
+ FILES=California.json
+ PROTOCOL=ucx
+ ENABLE_IB=
+ ENABLE_NVLINK=
+ RMM_POOL_SIZE=
+ MP_BLOCKSIZE=256MiB
+ MP_PINNED_READ=
+ MP_FORCE_HOST_READ=--mp-force-host-read
+ singularity run --nv -B /scratch/shared/pwesolowski /home2/faculty/pwesolowski/containers/cuml-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/run_no_gds.sh
[WARN  tini (3465206)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
+ cd /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/
+ python -u cuml_single_node.py --files California.json --reps 5 --protocol ucx --mp-blocksize 256MiB --mp-force-host-read
<Managed Device 0>
args=Namespace(data_dir='/scratch/shared/pwesolowski/mgr-pipeline/joined-cuml', files=['California.json'], reps=5, protocol='ucx', enable_infiniband=False, enable_nvlink=False, rmm_pool_size=None, jit_unspill=False, mp_blocksize='256MiB', mp_force_host_read=True, mp_pinned_read=False, mp_force_gpu_preprocess=False)
2023-07-07 13:06:37,894 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-07 13:06:37,895 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
Code block 'ddf-preprocessing' took: 37297.75259 ms
Code block 'ddf-preprocessing' took: 15046.81760 ms
Code block 'ddf-preprocessing' took: 15085.26530 ms
Code block 'ddf-preprocessing' took: 15072.66079 ms
Code block 'ddf-preprocessing' took: 14862.66936 ms
Code block 'ddf-scaler-fit' took: 14911.61557 ms
Code block 'ddf-scaler-fit' took: 15262.34208 ms
Code block 'ddf-scaler-fit' took: 16391.79158 ms
Code block 'ddf-scaler-fit' took: 16214.92918 ms
Code block 'ddf-scaler-fit' took: 16426.71325 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 47189.21388 ms
Code block 'ddf-kmeans-score' took: 16004.06123 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 43472.67473 ms
Code block 'ddf-kmeans-score' took: 16357.08929 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 43344.94395 ms
Code block 'ddf-kmeans-score' took: 16200.40915 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 43309.25183 ms
Code block 'ddf-kmeans-score' took: 16418.07725 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 43153.46070 ms
Code block 'ddf-kmeans-score' took: 16058.46105 ms
scores=[array(-4848319.6953125)]
client.get_worker_logs()={'ucx://127.0.0.1:58523': (('INFO', "2023-07-07 13:14:38,525 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 13:14:11,207 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 13:13:37,857 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 13:13:10,534 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 13:12:37,211 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 13:12:09,895 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 13:11:36,328 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 13:11:08,994 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 13:10:35,627 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 13:10:04,369 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', '2023-07-07 13:06:42,133 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 13:06:42,133 - distributed.worker - INFO -         Registered to:      ucx://127.0.0.1:59945'), ('INFO', '2023-07-07 13:06:42,040 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 13:06:42,040 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-bc8e70fa-448a-4b73-b5e0-efaebb0f5ebf'), ('INFO', '2023-07-07 13:06:38,327 - distributed.worker - INFO - Starting Worker plugin PreImport-748039ae-c221-43cd-85f4-a075302b64c3'), ('INFO', '2023-07-07 13:06:38,327 - distributed.worker - INFO - Starting Worker plugin RMMSetup-86695bc9-f491-4bc7-93fb-2cc8a9448cec'), ('INFO', '2023-07-07 13:06:38,327 - distributed.worker - INFO -       Local Directory: /scratch/shared/pwesolowski/mgr-pipeline/joined-cuml/tmp/dask-worker-space/worker-d2thpn1k'), ('INFO', '2023-07-07 13:06:38,327 - distributed.worker - INFO -                Memory:                  50.00 GiB'), ('INFO', '2023-07-07 13:06:38,327 - distributed.worker - INFO -               Threads:                          2'), ('INFO', '2023-07-07 13:06:38,327 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 13:06:38,327 - distributed.worker - INFO - Waiting to connect to:      ucx://127.0.0.1:59945'), ('INFO', '2023-07-07 13:06:38,327 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37891'), ('INFO', '2023-07-07 13:06:38,327 - distributed.worker - INFO -           Worker name:                          0'), ('INFO', '2023-07-07 13:06:38,327 - distributed.worker - INFO -          Listening to:      ucx://127.0.0.1:58523'), ('INFO', '2023-07-07 13:06:38,327 - distributed.worker - INFO -       Start worker at:      ucx://127.0.0.1:58523'))}
2023-07-07 13:14:59,486 - distributed.nanny - WARNING - Worker process still alive after 3.199999389648438 seconds, killing
+ sleep 1
+ for MP_PINNED_READ in "" "--mp-pinned-read"
+ [[ ucx == ucx ]]
+ FILES=California.json
+ PROTOCOL=ucx
+ ENABLE_IB=
+ ENABLE_NVLINK=
+ RMM_POOL_SIZE=
+ MP_BLOCKSIZE=256MiB
+ MP_PINNED_READ=--mp-pinned-read
+ MP_FORCE_HOST_READ=--mp-force-host-read
+ singularity run --nv -B /scratch/shared/pwesolowski /home2/faculty/pwesolowski/containers/cuml-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/run_no_gds.sh
[WARN  tini (3475799)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
+ cd /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/
+ python -u cuml_single_node.py --files California.json --reps 5 --protocol ucx --mp-blocksize 256MiB --mp-force-host-read --mp-pinned-read
<Managed Device 0>
args=Namespace(data_dir='/scratch/shared/pwesolowski/mgr-pipeline/joined-cuml', files=['California.json'], reps=5, protocol='ucx', enable_infiniband=False, enable_nvlink=False, rmm_pool_size=None, jit_unspill=False, mp_blocksize='256MiB', mp_force_host_read=True, mp_pinned_read=True, mp_force_gpu_preprocess=False)
2023-07-07 13:15:24,598 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-07 13:15:24,598 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
Code block 'ddf-preprocessing' took: 40846.76321 ms
Code block 'ddf-preprocessing' took: 15166.71010 ms
Code block 'ddf-preprocessing' took: 15139.90700 ms
Code block 'ddf-preprocessing' took: 14889.05801 ms
Code block 'ddf-preprocessing' took: 15010.21899 ms
Code block 'ddf-scaler-fit' took: 18185.79752 ms
Code block 'ddf-scaler-fit' took: 17875.54109 ms
Code block 'ddf-scaler-fit' took: 18316.85483 ms
Code block 'ddf-scaler-fit' took: 18696.56742 ms
Code block 'ddf-scaler-fit' took: 19204.77554 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 50156.72468 ms
Code block 'ddf-kmeans-score' took: 19603.24257 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 46166.37862 ms
Code block 'ddf-kmeans-score' took: 18986.41245 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 45997.46404 ms
Code block 'ddf-kmeans-score' took: 19120.71780 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 46561.68613 ms
Code block 'ddf-kmeans-score' took: 18717.53828 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 45597.82748 ms
Code block 'ddf-kmeans-score' took: 19834.39652 ms
scores=[array(-4845067.5234375)]
client.get_worker_logs()={'ucx://127.0.0.1:40999': (('INFO', "2023-07-07 13:24:06,778 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 13:23:39,481 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 13:23:01,389 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 13:22:34,055 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 13:21:54,620 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 13:21:27,304 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 13:20:48,553 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 13:20:21,072 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 13:19:41,464 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 13:19:10,100 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', '2023-07-07 13:15:29,203 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 13:15:29,202 - distributed.worker - INFO -         Registered to:      ucx://127.0.0.1:60529'), ('INFO', '2023-07-07 13:15:29,133 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 13:15:29,132 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-11bce3a4-3aac-49f2-afdd-d9612b76aaa9'), ('INFO', '2023-07-07 13:15:24,987 - distributed.worker - INFO - Starting Worker plugin PreImport-eadfdd6b-9146-4700-8ff9-09cacd9c182d'), ('INFO', '2023-07-07 13:15:24,987 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ecd9b188-ec89-43c6-bc45-1e890b10ae00'), ('INFO', '2023-07-07 13:15:24,986 - distributed.worker - INFO -       Local Directory: /scratch/shared/pwesolowski/mgr-pipeline/joined-cuml/tmp/dask-worker-space/worker-cwfvc_0h'), ('INFO', '2023-07-07 13:15:24,986 - distributed.worker - INFO -                Memory:                  50.00 GiB'), ('INFO', '2023-07-07 13:15:24,986 - distributed.worker - INFO -               Threads:                          2'), ('INFO', '2023-07-07 13:15:24,986 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 13:15:24,986 - distributed.worker - INFO - Waiting to connect to:      ucx://127.0.0.1:60529'), ('INFO', '2023-07-07 13:15:24,986 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35287'), ('INFO', '2023-07-07 13:15:24,986 - distributed.worker - INFO -           Worker name:                          0'), ('INFO', '2023-07-07 13:15:24,986 - distributed.worker - INFO -          Listening to:      ucx://127.0.0.1:40999'), ('INFO', '2023-07-07 13:15:24,986 - distributed.worker - INFO -       Start worker at:      ucx://127.0.0.1:40999'))}
2023-07-07 13:24:31,776 - distributed.nanny - WARNING - Worker process still alive after 3.1999990844726565 seconds, killing
+ sleep 1
+ for MP_BLOCKSIZE in "256MiB" "1GiB" "4GiB"
+ for MP_PINNED_READ in "" "--mp-pinned-read"
+ [[ ucx == ucx ]]
+ FILES=California.json
+ PROTOCOL=ucx
+ ENABLE_IB=
+ ENABLE_NVLINK=
+ RMM_POOL_SIZE=
+ MP_BLOCKSIZE=1GiB
+ MP_PINNED_READ=
+ MP_FORCE_HOST_READ=--mp-force-host-read
+ singularity run --nv -B /scratch/shared/pwesolowski /home2/faculty/pwesolowski/containers/cuml-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/run_no_gds.sh
[WARN  tini (3485669)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
+ cd /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/
+ python -u cuml_single_node.py --files California.json --reps 5 --protocol ucx --mp-blocksize 1GiB --mp-force-host-read
<Managed Device 0>
args=Namespace(data_dir='/scratch/shared/pwesolowski/mgr-pipeline/joined-cuml', files=['California.json'], reps=5, protocol='ucx', enable_infiniband=False, enable_nvlink=False, rmm_pool_size=None, jit_unspill=False, mp_blocksize='1GiB', mp_force_host_read=True, mp_pinned_read=False, mp_force_gpu_preprocess=False)
2023-07-07 13:24:56,529 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-07 13:24:56,530 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
Code block 'ddf-preprocessing' took: 38117.71486 ms
Code block 'ddf-preprocessing' took: 14706.87426 ms
Code block 'ddf-preprocessing' took: 14676.72895 ms
Code block 'ddf-preprocessing' took: 14776.09776 ms
Code block 'ddf-preprocessing' took: 14672.83328 ms
Code block 'ddf-scaler-fit' took: 13337.65826 ms
Code block 'ddf-scaler-fit' took: 12451.52537 ms
Code block 'ddf-scaler-fit' took: 13032.03521 ms
Code block 'ddf-scaler-fit' took: 13021.01429 ms
Code block 'ddf-scaler-fit' took: 13320.46683 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 44353.83037 ms
Code block 'ddf-kmeans-score' took: 12950.74429 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 40095.91744 ms
Code block 'ddf-kmeans-score' took: 13199.78172 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 42890.69199 ms
Code block 'ddf-kmeans-score' took: 13326.68201 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 40322.49966 ms
Code block 'ddf-kmeans-score' took: 13552.23411 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 40204.83937 ms
Code block 'ddf-kmeans-score' took: 13554.41224 ms
scores=[array(-4834237.15625)]
client.get_worker_logs()={'ucx://127.0.0.1:48753': (('INFO', "2023-07-07 13:32:17,007 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 13:31:49,758 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 13:31:22,198 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 13:30:54,978 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 13:30:27,504 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 13:30:00,306 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 13:29:30,349 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 13:29:03,133 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 13:28:36,009 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 13:28:04,812 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', '2023-07-07 13:25:00,937 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 13:25:00,937 - distributed.worker - INFO -         Registered to:      ucx://127.0.0.1:45605'), ('INFO', '2023-07-07 13:25:00,867 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 13:24:56,979 - distributed.worker - INFO - Starting Worker plugin PreImport-110d5bb3-e3c4-4dae-a8b3-d25f866aba4e'), ('INFO', '2023-07-07 13:24:56,979 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0ab33e18-97ed-45aa-b3dc-7fc08d345666'), ('INFO', '2023-07-07 13:24:56,979 - distributed.worker - INFO - Starting Worker plugin RMMSetup-decf3925-136f-46ce-9917-53587b5b14b1'), ('INFO', '2023-07-07 13:24:56,979 - distributed.worker - INFO -       Local Directory: /scratch/shared/pwesolowski/mgr-pipeline/joined-cuml/tmp/dask-worker-space/worker-560djqeq'), ('INFO', '2023-07-07 13:24:56,979 - distributed.worker - INFO -                Memory:                  50.00 GiB'), ('INFO', '2023-07-07 13:24:56,979 - distributed.worker - INFO -               Threads:                          2'), ('INFO', '2023-07-07 13:24:56,979 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 13:24:56,979 - distributed.worker - INFO - Waiting to connect to:      ucx://127.0.0.1:45605'), ('INFO', '2023-07-07 13:24:56,979 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39825'), ('INFO', '2023-07-07 13:24:56,979 - distributed.worker - INFO -           Worker name:                          0'), ('INFO', '2023-07-07 13:24:56,979 - distributed.worker - INFO -          Listening to:      ucx://127.0.0.1:48753'), ('INFO', '2023-07-07 13:24:56,979 - distributed.worker - INFO -       Start worker at:      ucx://127.0.0.1:48753'))}
2023-07-07 13:32:35,232 - distributed.nanny - WARNING - Worker process still alive after 3.1999992370605472 seconds, killing
+ sleep 1
+ for MP_PINNED_READ in "" "--mp-pinned-read"
+ [[ ucx == ucx ]]
+ FILES=California.json
+ PROTOCOL=ucx
+ ENABLE_IB=
+ ENABLE_NVLINK=
+ RMM_POOL_SIZE=
+ MP_BLOCKSIZE=1GiB
+ MP_PINNED_READ=--mp-pinned-read
+ MP_FORCE_HOST_READ=--mp-force-host-read
+ singularity run --nv -B /scratch/shared/pwesolowski /home2/faculty/pwesolowski/containers/cuml-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/run_no_gds.sh
[WARN  tini (3495542)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
+ cd /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/
+ python -u cuml_single_node.py --files California.json --reps 5 --protocol ucx --mp-blocksize 1GiB --mp-force-host-read --mp-pinned-read
<Managed Device 0>
args=Namespace(data_dir='/scratch/shared/pwesolowski/mgr-pipeline/joined-cuml', files=['California.json'], reps=5, protocol='ucx', enable_infiniband=False, enable_nvlink=False, rmm_pool_size=None, jit_unspill=False, mp_blocksize='1GiB', mp_force_host_read=True, mp_pinned_read=True, mp_force_gpu_preprocess=False)
2023-07-07 13:33:00,596 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-07 13:33:00,597 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
Code block 'ddf-preprocessing' took: 40024.03528 ms
Code block 'ddf-preprocessing' took: 14930.29503 ms
Code block 'ddf-preprocessing' took: 14813.15032 ms
Code block 'ddf-preprocessing' took: 14715.64214 ms
Code block 'ddf-preprocessing' took: 14837.14778 ms
Code block 'ddf-scaler-fit' took: 16073.13416 ms
Code block 'ddf-scaler-fit' took: 14972.05952 ms
Code block 'ddf-scaler-fit' took: 16212.02381 ms
Code block 'ddf-scaler-fit' took: 15903.94866 ms
Code block 'ddf-scaler-fit' took: 16538.67819 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 47351.74034 ms
Code block 'ddf-kmeans-score' took: 15969.65994 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 43357.95781 ms
Code block 'ddf-kmeans-score' took: 16728.73035 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 43332.73058 ms
Code block 'ddf-kmeans-score' took: 16235.57328 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 43275.65071 ms
Code block 'ddf-kmeans-score' took: 16416.42422 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 43015.01253 ms
Code block 'ddf-kmeans-score' took: 16498.93482 ms
scores=[array(-4846522.09375)]
client.get_worker_logs()={'ucx://127.0.0.1:49339': (('INFO', "2023-07-07 13:41:02,718 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 13:40:35,436 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 13:40:02,235 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 13:39:34,924 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 13:39:01,682 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 13:38:34,376 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 13:38:00,554 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 13:37:33,288 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 13:36:59,864 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 13:36:28,490 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', '2023-07-07 13:33:04,879 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 13:33:04,878 - distributed.worker - INFO -         Registered to:      ucx://127.0.0.1:33593'), ('INFO', '2023-07-07 13:33:04,804 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 13:33:04,804 - distributed.worker - INFO - Starting Worker plugin RMMSetup-577e0cba-0bb4-48ac-bbf8-7c79685a99b5'), ('INFO', '2023-07-07 13:33:00,983 - distributed.worker - INFO - Starting Worker plugin PreImport-33dcf191-6206-4a23-b3f7-287f9c5bb0cb'), ('INFO', '2023-07-07 13:33:00,983 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-af70aeb9-c04a-4a01-a7fb-6a3ddae7b0fb'), ('INFO', '2023-07-07 13:33:00,983 - distributed.worker - INFO -       Local Directory: /scratch/shared/pwesolowski/mgr-pipeline/joined-cuml/tmp/dask-worker-space/worker-c06tpc29'), ('INFO', '2023-07-07 13:33:00,983 - distributed.worker - INFO -                Memory:                  50.00 GiB'), ('INFO', '2023-07-07 13:33:00,983 - distributed.worker - INFO -               Threads:                          2'), ('INFO', '2023-07-07 13:33:00,983 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 13:33:00,983 - distributed.worker - INFO - Waiting to connect to:      ucx://127.0.0.1:33593'), ('INFO', '2023-07-07 13:33:00,983 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34663'), ('INFO', '2023-07-07 13:33:00,983 - distributed.worker - INFO -           Worker name:                          0'), ('INFO', '2023-07-07 13:33:00,983 - distributed.worker - INFO -          Listening to:      ucx://127.0.0.1:49339'), ('INFO', '2023-07-07 13:33:00,983 - distributed.worker - INFO -       Start worker at:      ucx://127.0.0.1:49339'))}
2023-07-07 13:41:23,851 - distributed.nanny - WARNING - Worker process still alive after 3.1999987792968754 seconds, killing
+ sleep 1
+ for MP_BLOCKSIZE in "256MiB" "1GiB" "4GiB"
+ for MP_PINNED_READ in "" "--mp-pinned-read"
+ [[ ucx == ucx ]]
+ FILES=California.json
+ PROTOCOL=ucx
+ ENABLE_IB=
+ ENABLE_NVLINK=
+ RMM_POOL_SIZE=
+ MP_BLOCKSIZE=4GiB
+ MP_PINNED_READ=
+ MP_FORCE_HOST_READ=--mp-force-host-read
+ singularity run --nv -B /scratch/shared/pwesolowski /home2/faculty/pwesolowski/containers/cuml-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/run_no_gds.sh
[WARN  tini (3506008)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
+ cd /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/
+ python -u cuml_single_node.py --files California.json --reps 5 --protocol ucx --mp-blocksize 4GiB --mp-force-host-read
<Managed Device 0>
args=Namespace(data_dir='/scratch/shared/pwesolowski/mgr-pipeline/joined-cuml', files=['California.json'], reps=5, protocol='ucx', enable_infiniband=False, enable_nvlink=False, rmm_pool_size=None, jit_unspill=False, mp_blocksize='4GiB', mp_force_host_read=True, mp_pinned_read=False, mp_force_gpu_preprocess=False)
2023-07-07 13:41:48,183 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-07 13:41:48,183 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
Code block 'ddf-preprocessing' took: 38690.53411 ms
Code block 'ddf-preprocessing' took: 14587.98832 ms
Code block 'ddf-preprocessing' took: 14731.37354 ms
Code block 'ddf-preprocessing' took: 14602.87904 ms
Code block 'ddf-preprocessing' took: 14763.53398 ms
Code block 'ddf-scaler-fit' took: 13248.49803 ms
Code block 'ddf-scaler-fit' took: 12727.40143 ms
Code block 'ddf-scaler-fit' took: 12684.78951 ms
Code block 'ddf-scaler-fit' took: 12755.13568 ms
Code block 'ddf-scaler-fit' took: 12289.17253 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 46023.77928 ms
Code block 'ddf-kmeans-score' took: 13121.81500 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 41957.34729 ms
Code block 'ddf-kmeans-score' took: 12896.88323 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 42140.67550 ms
Code block 'ddf-kmeans-score' took: 13146.34193 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 42001.17902 ms
Code block 'ddf-kmeans-score' took: 13379.61416 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 42306.49161 ms
Code block 'ddf-kmeans-score' took: 13385.28672 ms
scores=[array(-27881408.5)]
client.get_worker_logs()={'ucx://127.0.0.1:52353': (('INFO', "2023-07-07 13:49:13,389 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 13:48:44,300 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 13:48:16,676 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 13:47:47,628 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 13:47:20,459 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 13:46:51,483 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 13:46:24,345 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 13:45:55,203 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 13:45:27,906 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 13:44:54,643 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', '2023-07-07 13:41:52,156 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 13:41:52,155 - distributed.worker - INFO -         Registered to:      ucx://127.0.0.1:56311'), ('INFO', '2023-07-07 13:41:52,088 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 13:41:52,087 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f36c2422-0262-43db-851d-9c78ff0f188d'), ('INFO', '2023-07-07 13:41:48,565 - distributed.worker - INFO - Starting Worker plugin PreImport-e4a267e0-9bc1-4f7a-8807-d05c944d514b'), ('INFO', '2023-07-07 13:41:48,565 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f0601573-4d10-45a7-9434-308c1e73947a'), ('INFO', '2023-07-07 13:41:48,565 - distributed.worker - INFO -       Local Directory: /scratch/shared/pwesolowski/mgr-pipeline/joined-cuml/tmp/dask-worker-space/worker-vah23fop'), ('INFO', '2023-07-07 13:41:48,565 - distributed.worker - INFO -                Memory:                  50.00 GiB'), ('INFO', '2023-07-07 13:41:48,565 - distributed.worker - INFO -               Threads:                          2'), ('INFO', '2023-07-07 13:41:48,565 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 13:41:48,565 - distributed.worker - INFO - Waiting to connect to:      ucx://127.0.0.1:56311'), ('INFO', '2023-07-07 13:41:48,565 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45219'), ('INFO', '2023-07-07 13:41:48,565 - distributed.worker - INFO -           Worker name:                          0'), ('INFO', '2023-07-07 13:41:48,565 - distributed.worker - INFO -          Listening to:      ucx://127.0.0.1:52353'), ('INFO', '2023-07-07 13:41:48,565 - distributed.worker - INFO -       Start worker at:      ucx://127.0.0.1:52353'))}
2023-07-07 13:49:31,513 - distributed.nanny - WARNING - Worker process still alive after 3.199999389648438 seconds, killing
+ sleep 1
+ for MP_PINNED_READ in "" "--mp-pinned-read"
+ [[ ucx == ucx ]]
+ FILES=California.json
+ PROTOCOL=ucx
+ ENABLE_IB=
+ ENABLE_NVLINK=
+ RMM_POOL_SIZE=
+ MP_BLOCKSIZE=4GiB
+ MP_PINNED_READ=--mp-pinned-read
+ MP_FORCE_HOST_READ=--mp-force-host-read
+ singularity run --nv -B /scratch/shared/pwesolowski /home2/faculty/pwesolowski/containers/cuml-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/run_no_gds.sh
[WARN  tini (3516895)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
+ cd /home2/faculty/pwesolowski/praca-mgr/pipelines-repo/1_dataset_cuml/
+ python -u cuml_single_node.py --files California.json --reps 5 --protocol ucx --mp-blocksize 4GiB --mp-force-host-read --mp-pinned-read
<Managed Device 0>
args=Namespace(data_dir='/scratch/shared/pwesolowski/mgr-pipeline/joined-cuml', files=['California.json'], reps=5, protocol='ucx', enable_infiniband=False, enable_nvlink=False, rmm_pool_size=None, jit_unspill=False, mp_blocksize='4GiB', mp_force_host_read=True, mp_pinned_read=True, mp_force_gpu_preprocess=False)
2023-07-07 13:50:22,092 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-07-07 13:50:22,092 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
Code block 'ddf-preprocessing' took: 37188.97236 ms
Code block 'ddf-preprocessing' took: 14942.99822 ms
Code block 'ddf-preprocessing' took: 15077.21141 ms
Code block 'ddf-preprocessing' took: 14914.72741 ms
Code block 'ddf-preprocessing' took: 15022.73029 ms
Code block 'ddf-scaler-fit' took: 18544.81931 ms
Code block 'ddf-scaler-fit' took: 17312.35058 ms
Code block 'ddf-scaler-fit' took: 17021.70444 ms
Code block 'ddf-scaler-fit' took: 17294.53873 ms
Code block 'ddf-scaler-fit' took: 15489.78783 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 49243.52068 ms
Code block 'ddf-kmeans-score' took: 14960.59801 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 44099.84793 ms
Code block 'ddf-kmeans-score' took: 15401.21790 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 44784.03228 ms
Code block 'ddf-kmeans-score' took: 15208.34628 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 44238.56205 ms
Code block 'ddf-kmeans-score' took: 14527.33525 ms
Fitting kmeans with 8 clusters
Code block 'ddf-kmeans-fit' took: 45199.83295 ms
Code block 'ddf-kmeans-score' took: 14641.31477 ms
scores=[array(-2036092.625)]
client.get_worker_logs()={'ucx://127.0.0.1:44139': (('INFO', "2023-07-07 13:58:31,675 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 13:58:02,557 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 13:57:30,886 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 13:57:01,740 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 13:56:30,365 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 13:56:01,202 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 13:55:29,140 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 13:55:00,042 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', "2023-07-07 13:54:28,635 - distributed.worker - INFO - Run out-of-band function '_func_destroy_all'"), ('INFO', "2023-07-07 13:53:55,269 - distributed.worker - INFO - Run out-of-band function '_func_init_all'"), ('INFO', '2023-07-07 13:50:27,424 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 13:50:27,424 - distributed.worker - INFO -         Registered to:      ucx://127.0.0.1:58939'), ('INFO', '2023-07-07 13:50:27,356 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 13:50:27,356 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f3dd292a-e639-46f0-8d94-876a3c7e78ae'), ('INFO', '2023-07-07 13:50:22,476 - distributed.worker - INFO - Starting Worker plugin PreImport-4ebabbe4-c432-4cc5-8e95-fd7672fab7e5'), ('INFO', '2023-07-07 13:50:22,475 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3482a632-4c24-4634-954d-ac87d0a15b0d'), ('INFO', '2023-07-07 13:50:22,475 - distributed.worker - INFO -       Local Directory: /scratch/shared/pwesolowski/mgr-pipeline/joined-cuml/tmp/dask-worker-space/worker-gr5en_uo'), ('INFO', '2023-07-07 13:50:22,475 - distributed.worker - INFO -                Memory:                  50.00 GiB'), ('INFO', '2023-07-07 13:50:22,475 - distributed.worker - INFO -               Threads:                          2'), ('INFO', '2023-07-07 13:50:22,475 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2023-07-07 13:50:22,475 - distributed.worker - INFO - Waiting to connect to:      ucx://127.0.0.1:58939'), ('INFO', '2023-07-07 13:50:22,475 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45909'), ('INFO', '2023-07-07 13:50:22,475 - distributed.worker - INFO -           Worker name:                          0'), ('INFO', '2023-07-07 13:50:22,475 - distributed.worker - INFO -          Listening to:      ucx://127.0.0.1:44139'), ('INFO', '2023-07-07 13:50:22,475 - distributed.worker - INFO -       Start worker at:      ucx://127.0.0.1:44139'))}
2023-07-07 13:58:50,951 - distributed.nanny - WARNING - Worker process still alive after 3.199998474121094 seconds, killing
+ sleep 1
