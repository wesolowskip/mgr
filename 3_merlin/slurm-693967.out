+ export WORKFLOW_DIR=/scratch/shared/pwesolowski/mgr-pipeline/merlin/
+ WORKFLOW_DIR=/scratch/shared/pwesolowski/mgr-pipeline/merlin/
+ export DATA_DIR=/scratch/shared/pwesolowski/mgr-pipeline/joined-recommender
+ DATA_DIR=/scratch/shared/pwesolowski/mgr-pipeline/joined-recommender
+ for BATCH_SIZE in 8192 16384 32768
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --force-host-read --batch-size 8192 --epochs 5'
[WARN  tini (1124988)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-18 23:39:12.454271: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-18 23:39:15.563336: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-18 23:39:43.812328: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-18 23:43:39.918745: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-18 23:43:40.530652: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f510c3e0380 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-18 23:43:40.530718: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-18 23:43:40.749215: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-18 23:43:41.938040: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-18 23:43:42.295524: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.985287
Step #4000	Loss: 0.296180
Step #8000	Loss: 0.331134
Step #12000	Loss: 0.316810
Step #16000	Loss: 0.335975
Step #20000	Loss: 0.323002
Step #24000	Loss: 0.418471
Step #28000	Loss: 0.414035
Step #32000	Loss: 0.435792
Step #36000	Loss: 0.381189
Step #40000	Loss: 0.334524
Step #44000	Loss: 0.342416
Step #48000	Loss: 0.328260
Step #52000	Loss: 0.330611
Step #56000	Loss: 0.347511
Step #60000	Loss: 0.387307
Step #64000	Loss: 0.313489
Step #68000	Loss: 0.341181
Step #72000	Loss: 0.385252
Step #76000	Loss: 0.364255
Step #80000	Loss: 0.370687
Step #84000	Loss: 0.358541
Step #88000	Loss: 0.361606
Step #92000	Loss: 0.374690
Step #96000	Loss: 0.323133
Step #100000	Loss: 0.440150
Step #104000	Loss: 0.325449
Step #108000	Loss: 0.338661
Step #112000	Loss: 0.336268
Step #116000	Loss: 0.382837
Step #120000	Loss: 0.318125
Step #124000	Loss: 0.336950
Step #128000	Loss: 0.375456
Step #132000	Loss: 0.343169
Step #136000	Loss: 0.427895
Step #140000	Loss: 0.420145
Step #144000	Loss: 0.428458
Step #148000	Loss: 0.326352
Step #152000	Loss: 0.424098
Step #156000	Loss: 0.311547
Step #160000	Loss: 0.338870
Step #164000	Loss: 0.303892
Step #168000	Loss: 0.425097
Step #172000	Loss: 0.407437
Step #176000	Loss: 0.299634
Step #180000	Loss: 0.339696
Step #184000	Loss: 0.314360
Step #188000	Loss: 0.475728
Step #192000	Loss: 0.439799
Step #196000	Loss: 0.456811
Step #200000	Loss: 0.331268
Step #204000	Loss: 0.296051
Step #208000	Loss: 0.335800
Step #212000	Loss: 0.341996
Step #216000	Loss: 0.390549
Step #220000	Loss: 0.423300
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 1765249.85758 ms
train loss 0.3610624074935913
Code block 'val epoch=0' took: 104705.68296 ms
validation loss 0.5985057950019836
Step #0	Loss: 0.680932
Step #4000	Loss: 0.287918
Step #8000	Loss: 0.312796
Step #12000	Loss: 0.299737
Step #16000	Loss: 0.314703
Step #20000	Loss: 0.310917
Step #24000	Loss: 0.362225
Step #28000	Loss: 0.351910
Step #32000	Loss: 0.369960
Step #36000	Loss: 0.339087
Step #40000	Loss: 0.326379
Step #44000	Loss: 0.313567
Step #48000	Loss: 0.315979
Step #52000	Loss: 0.327504
Step #56000	Loss: 0.308868
Step #60000	Loss: 0.326382
Step #64000	Loss: 0.301139
Step #68000	Loss: 0.327206
Step #72000	Loss: 0.343508
Step #76000	Loss: 0.335622
Step #80000	Loss: 0.325114
Step #84000	Loss: 0.334086
Step #88000	Loss: 0.317084
Step #92000	Loss: 0.334078
Step #96000	Loss: 0.297632
Step #100000	Loss: 0.360634
Step #104000	Loss: 0.317845
Step #108000	Loss: 0.328790
Step #112000	Loss: 0.305717
Step #116000	Loss: 0.335020
Step #120000	Loss: 0.312996
Step #124000	Loss: 0.290175
Step #128000	Loss: 0.327532
Step #132000	Loss: 0.327150
Step #136000	Loss: 0.359774
Step #140000	Loss: 0.383106
Step #144000	Loss: 0.346467
Step #148000	Loss: 0.301890
Step #152000	Loss: 0.350676
Step #156000	Loss: 0.315206
Step #160000	Loss: 0.302945
Step #164000	Loss: 0.301516
Step #168000	Loss: 0.349604
Step #172000	Loss: 0.348572
Step #176000	Loss: 0.280095
Step #180000	Loss: 0.313343
Step #184000	Loss: 0.295708
Step #188000	Loss: 0.379442
Step #192000	Loss: 0.352302
Step #196000	Loss: 0.378077
Step #200000	Loss: 0.314591
Step #204000	Loss: 0.287216
Step #208000	Loss: 0.320107
Step #212000	Loss: 0.326346
Step #216000	Loss: 0.342364
Step #220000	Loss: 0.343507
Code block 'train epoch=1' took: 1736627.08904 ms
train loss 0.32614508271217346
Code block 'val epoch=1' took: 104833.97370 ms
validation loss 0.6903324127197266
Step #0	Loss: 0.696725
Step #4000	Loss: 0.268700
Step #8000	Loss: 0.299955
Step #12000	Loss: 0.306963
Step #16000	Loss: 0.292681
Step #20000	Loss: 0.313192
Step #24000	Loss: 0.318381
Step #28000	Loss: 0.321581
Step #32000	Loss: 0.318088
Step #36000	Loss: 0.310622
Step #40000	Loss: 0.319860
Step #44000	Loss: 0.310937
Step #48000	Loss: 0.306385
Step #52000	Loss: 0.299793
Step #56000	Loss: 0.308007
Step #60000	Loss: 0.308090
Step #64000	Loss: 0.282895
Step #68000	Loss: 0.311247
Step #72000	Loss: 0.316321
Step #76000	Loss: 0.311241
Step #80000	Loss: 0.309171
Step #84000	Loss: 0.319935
Step #88000	Loss: 0.317746
Step #92000	Loss: 0.319343
Step #96000	Loss: 0.300095
Step #100000	Loss: 0.330423
Step #104000	Loss: 0.300789
Step #108000	Loss: 0.316528
Step #112000	Loss: 0.302350
Step #116000	Loss: 0.319002
Step #120000	Loss: 0.290524
Step #124000	Loss: 0.278632
Step #128000	Loss: 0.316479
Step #132000	Loss: 0.309951
Step #136000	Loss: 0.329388
Step #140000	Loss: 0.329636
Step #144000	Loss: 0.327484
Step #148000	Loss: 0.297244
Step #152000	Loss: 0.326500
Step #156000	Loss: 0.299920
Step #160000	Loss: 0.289603
Step #164000	Loss: 0.296029
Step #168000	Loss: 0.321165
Step #172000	Loss: 0.328163
Step #176000	Loss: 0.278811
Step #180000	Loss: 0.294758
Step #184000	Loss: 0.291649
Step #188000	Loss: 0.350216
Step #192000	Loss: 0.330468
Step #196000	Loss: 0.343359
Step #200000	Loss: 0.309461
Step #204000	Loss: 0.290617
Step #208000	Loss: 0.304452
Step #212000	Loss: 0.306325
Step #216000	Loss: 0.325116
Step #220000	Loss: 0.320409
Code block 'train epoch=2' took: 1734705.21661 ms
train loss 0.3116849362850189
Code block 'val epoch=2' took: 103840.68429 ms
validation loss 0.7442466616630554
Step #0	Loss: 0.608784
Step #4000	Loss: 0.271242
Step #8000	Loss: 0.294030
Step #12000	Loss: 0.308105
Step #16000	Loss: 0.294566
Step #20000	Loss: 0.296972
Step #24000	Loss: 0.313033
Step #28000	Loss: 0.308208
Step #32000	Loss: 0.308676
Step #36000	Loss: 0.303275
Step #40000	Loss: 0.309850
Step #44000	Loss: 0.285336
Step #48000	Loss: 0.293202
Step #52000	Loss: 0.292730
Step #56000	Loss: 0.303667
Step #60000	Loss: 0.305115
Step #64000	Loss: 0.288383
Step #68000	Loss: 0.306471
Step #72000	Loss: 0.313242
Step #76000	Loss: 0.297123
Step #80000	Loss: 0.305247
Step #84000	Loss: 0.320778
Step #88000	Loss: 0.299843
Step #92000	Loss: 0.309765
Step #96000	Loss: 0.303185
Step #100000	Loss: 0.332664
Step #104000	Loss: 0.302629
Step #108000	Loss: 0.317011
Step #112000	Loss: 0.292597
Step #116000	Loss: 0.305237
Step #120000	Loss: 0.290382
Step #124000	Loss: 0.293889
Step #128000	Loss: 0.312896
Step #132000	Loss: 0.323269
Step #136000	Loss: 0.323394
Step #140000	Loss: 0.320527
Step #144000	Loss: 0.309838
Step #148000	Loss: 0.290031
Step #152000	Loss: 0.306033
Step #156000	Loss: 0.300773
Step #160000	Loss: 0.289080
Step #164000	Loss: 0.299750
Step #168000	Loss: 0.318486
Step #172000	Loss: 0.314340
Step #176000	Loss: 0.273122
Step #180000	Loss: 0.288101
Step #184000	Loss: 0.287731
Step #188000	Loss: 0.313902
Step #192000	Loss: 0.309892
Step #196000	Loss: 0.325675
Step #200000	Loss: 0.304979
Step #204000	Loss: 0.286844
Step #208000	Loss: 0.299655
Step #212000	Loss: 0.300037
Step #216000	Loss: 0.316886
Step #220000	Loss: 0.320815
Code block 'train epoch=3' took: 1736299.92449 ms
train loss 0.3056027889251709
Code block 'val epoch=3' took: 103644.34173 ms
validation loss 0.7750786542892456
Step #0	Loss: 0.536579
Step #4000	Loss: 0.279548
Step #8000	Loss: 0.283653
Step #12000	Loss: 0.287797
Step #16000	Loss: 0.304114
Step #20000	Loss: 0.303028
Step #24000	Loss: 0.301080
Step #28000	Loss: 0.305212
Step #32000	Loss: 0.296239
Step #36000	Loss: 0.300850
Step #40000	Loss: 0.313936
Step #44000	Loss: 0.291150
Step #48000	Loss: 0.294877
Step #52000	Loss: 0.295189
Step #56000	Loss: 0.301856
Step #60000	Loss: 0.287175
Step #64000	Loss: 0.288709
Step #68000	Loss: 0.313769
Step #72000	Loss: 0.312888
Step #76000	Loss: 0.291707
Step #80000	Loss: 0.299822
Step #84000	Loss: 0.303252
Step #88000	Loss: 0.296551
Step #92000	Loss: 0.306209
Step #96000	Loss: 0.284892
Step #100000	Loss: 0.316810
Step #104000	Loss: 0.315585
Step #108000	Loss: 0.310666
Step #112000	Loss: 0.297342
Step #116000	Loss: 0.298422
Step #120000	Loss: 0.281594
Step #124000	Loss: 0.285266
Step #128000	Loss: 0.312536
Step #132000	Loss: 0.305102
Step #136000	Loss: 0.325500
Step #140000	Loss: 0.320451
Step #144000	Loss: 0.311750
Step #148000	Loss: 0.305367
Step #152000	Loss: 0.316421
Step #156000	Loss: 0.303509
Step #160000	Loss: 0.279541
Step #164000	Loss: 0.284656
Step #168000	Loss: 0.312644
Step #172000	Loss: 0.310925
Step #176000	Loss: 0.265009
Step #180000	Loss: 0.297380
Step #184000	Loss: 0.291036
Step #188000	Loss: 0.319418
Step #192000	Loss: 0.318216
Step #196000	Loss: 0.307963
Step #200000	Loss: 0.293881
Step #204000	Loss: 0.279120
Step #208000	Loss: 0.308214
Step #212000	Loss: 0.298419
Step #216000	Loss: 0.314407
Step #220000	Loss: 0.301669
Code block 'train epoch=4' took: 1734598.38838 ms
train loss 0.30255407094955444
Code block 'val epoch=4' took: 102211.53332 ms
validation loss 0.7940730452537537
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --force-host-read --batch-size 8192 --epochs 5'
[WARN  tini (1241931)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-19 02:17:24.162653: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-19 02:17:27.932293: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-19 02:17:57.842673: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-19 02:21:55.635176: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-19 02:21:56.295014: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f5d60bf9a80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-19 02:21:56.295106: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-19 02:21:56.474190: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-19 02:21:57.678895: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-19 02:21:58.065883: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 3.873241
Step #4000	Loss: 0.308122
Step #8000	Loss: 0.316732
Step #12000	Loss: 0.333555
Step #16000	Loss: 0.316473
Step #20000	Loss: 0.328354
Step #24000	Loss: 0.446615
Step #28000	Loss: 0.421327
Step #32000	Loss: 0.431022
Step #36000	Loss: 0.415895
Step #40000	Loss: 0.340141
Step #44000	Loss: 0.363687
Step #48000	Loss: 0.360557
Step #52000	Loss: 0.369358
Step #56000	Loss: 0.392428
Step #60000	Loss: 0.438975
Step #64000	Loss: 0.338022
Step #68000	Loss: 0.375316
Step #72000	Loss: 0.345920
Step #76000	Loss: 0.322374
Step #80000	Loss: 0.328128
Step #84000	Loss: 0.353791
Step #88000	Loss: 0.399399
Step #92000	Loss: 0.393473
Step #96000	Loss: 0.321355
Step #100000	Loss: 0.429719
Step #104000	Loss: 0.364104
Step #108000	Loss: 0.366306
Step #112000	Loss: 0.311506
Step #116000	Loss: 0.334513
Step #120000	Loss: 0.319661
Step #124000	Loss: 0.381473
Step #128000	Loss: 0.393058
Step #132000	Loss: 0.327332
Step #136000	Loss: 0.443684
Step #140000	Loss: 0.424370
Step #144000	Loss: 0.331406
Step #148000	Loss: 0.350810
Step #152000	Loss: 0.442294
Step #156000	Loss: 0.327232
Step #160000	Loss: 0.397191
Step #164000	Loss: 0.298967
Step #168000	Loss: 0.442996
Step #172000	Loss: 0.323409
Step #176000	Loss: 0.351950
Step #180000	Loss: 0.370085
Step #184000	Loss: 0.309617
Step #188000	Loss: 0.472320
Step #192000	Loss: 0.444868
Step #196000	Loss: 0.464916
Step #200000	Loss: 0.325773
Step #204000	Loss: 0.314361
Step #208000	Loss: 0.311011
Step #212000	Loss: 0.334441
Step #216000	Loss: 0.416010
Step #220000	Loss: 0.340096
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 1756754.06169 ms
train loss 0.3593406677246094
Code block 'val epoch=0' took: 102707.20823 ms
validation loss 0.6738625168800354
Step #0	Loss: 0.457023
Step #4000	Loss: 0.284274
Step #8000	Loss: 0.291724
Step #12000	Loss: 0.314222
Step #16000	Loss: 0.308294
Step #20000	Loss: 0.324306
Step #24000	Loss: 0.363053
Step #28000	Loss: 0.358590
Step #32000	Loss: 0.350943
Step #36000	Loss: 0.342086
Step #40000	Loss: 0.325795
Step #44000	Loss: 0.307142
Step #48000	Loss: 0.319440
Step #52000	Loss: 0.318470
Step #56000	Loss: 0.341872
Step #60000	Loss: 0.350392
Step #64000	Loss: 0.306236
Step #68000	Loss: 0.331766
Step #72000	Loss: 0.314369
Step #76000	Loss: 0.309588
Step #80000	Loss: 0.309873
Step #84000	Loss: 0.333301
Step #88000	Loss: 0.330593
Step #92000	Loss: 0.348607
Step #96000	Loss: 0.305336
Step #100000	Loss: 0.356916
Step #104000	Loss: 0.326247
Step #108000	Loss: 0.329523
Step #112000	Loss: 0.309977
Step #116000	Loss: 0.316919
Step #120000	Loss: 0.299028
Step #124000	Loss: 0.315250
Step #128000	Loss: 0.335871
Step #132000	Loss: 0.315114
Step #136000	Loss: 0.358346
Step #140000	Loss: 0.352703
Step #144000	Loss: 0.314703
Step #148000	Loss: 0.319787
Step #152000	Loss: 0.363368
Step #156000	Loss: 0.310994
Step #160000	Loss: 0.323583
Step #164000	Loss: 0.296093
Step #168000	Loss: 0.379486
Step #172000	Loss: 0.307140
Step #176000	Loss: 0.301790
Step #180000	Loss: 0.326092
Step #184000	Loss: 0.311783
Step #188000	Loss: 0.372430
Step #192000	Loss: 0.358816
Step #196000	Loss: 0.372796
Step #200000	Loss: 0.312390
Step #204000	Loss: 0.295911
Step #208000	Loss: 0.288343
Step #212000	Loss: 0.310442
Step #216000	Loss: 0.344816
Step #220000	Loss: 0.316260
Code block 'train epoch=1' took: 1729904.78878 ms
train loss 0.3232980966567993
Code block 'val epoch=1' took: 102257.48272 ms
validation loss 0.6783626079559326
Step #0	Loss: 0.339969
Step #4000	Loss: 0.290258
Step #8000	Loss: 0.308839
Step #12000	Loss: 0.296802
Step #16000	Loss: 0.313632
Step #20000	Loss: 0.300573
Step #24000	Loss: 0.314865
Step #28000	Loss: 0.313596
Step #32000	Loss: 0.319236
Step #36000	Loss: 0.307484
Step #40000	Loss: 0.321745
Step #44000	Loss: 0.295653
Step #48000	Loss: 0.302804
Step #52000	Loss: 0.312407
Step #56000	Loss: 0.315674
Step #60000	Loss: 0.326407
Step #64000	Loss: 0.292136
Step #68000	Loss: 0.324889
Step #72000	Loss: 0.312970
Step #76000	Loss: 0.294437
Step #80000	Loss: 0.304337
Step #84000	Loss: 0.324257
Step #88000	Loss: 0.307047
Step #92000	Loss: 0.318313
Step #96000	Loss: 0.300595
Step #100000	Loss: 0.313256
Step #104000	Loss: 0.311742
Step #108000	Loss: 0.316975
Step #112000	Loss: 0.309387
Step #116000	Loss: 0.308094
Step #120000	Loss: 0.304828
Step #124000	Loss: 0.291331
Step #128000	Loss: 0.318197
Step #132000	Loss: 0.309269
Step #136000	Loss: 0.344315
Step #140000	Loss: 0.337703
Step #144000	Loss: 0.301756
Step #148000	Loss: 0.306668
Step #152000	Loss: 0.332859
Step #156000	Loss: 0.302071
Step #160000	Loss: 0.298043
Step #164000	Loss: 0.290809
Step #168000	Loss: 0.336427
Step #172000	Loss: 0.297547
Step #176000	Loss: 0.286869
Step #180000	Loss: 0.300161
Step #184000	Loss: 0.300082
Step #188000	Loss: 0.329562
Step #192000	Loss: 0.335555
Step #196000	Loss: 0.331489
Step #200000	Loss: 0.306891
Step #204000	Loss: 0.287549
Step #208000	Loss: 0.292433
Step #212000	Loss: 0.307099
Step #216000	Loss: 0.325564
Step #220000	Loss: 0.315325
Code block 'train epoch=2' took: 1728777.73672 ms
train loss 0.3102010488510132
Code block 'val epoch=2' took: 104274.10531 ms
validation loss 0.6755568385124207
Step #0	Loss: 0.322495
Step #4000	Loss: 0.290106
Step #8000	Loss: 0.289952
Step #12000	Loss: 0.309893
Step #16000	Loss: 0.295813
Step #20000	Loss: 0.306800
Step #24000	Loss: 0.316956
Step #28000	Loss: 0.316202
Step #32000	Loss: 0.293373
Step #36000	Loss: 0.298281
Step #40000	Loss: 0.321390
Step #44000	Loss: 0.294840
Step #48000	Loss: 0.306839
Step #52000	Loss: 0.307671
Step #56000	Loss: 0.317424
Step #60000	Loss: 0.310077
Step #64000	Loss: 0.289570
Step #68000	Loss: 0.315381
Step #72000	Loss: 0.304194
Step #76000	Loss: 0.289090
Step #80000	Loss: 0.295595
Step #84000	Loss: 0.317111
Step #88000	Loss: 0.300062
Step #92000	Loss: 0.303355
Step #96000	Loss: 0.296156
Step #100000	Loss: 0.301858
Step #104000	Loss: 0.319220
Step #108000	Loss: 0.309670
Step #112000	Loss: 0.299294
Step #116000	Loss: 0.305739
Step #120000	Loss: 0.301384
Step #124000	Loss: 0.291332
Step #128000	Loss: 0.313354
Step #132000	Loss: 0.312058
Step #136000	Loss: 0.322537
Step #140000	Loss: 0.315556
Step #144000	Loss: 0.295725
Step #148000	Loss: 0.301290
Step #152000	Loss: 0.318174
Step #156000	Loss: 0.312289
Step #160000	Loss: 0.305649
Step #164000	Loss: 0.293223
Step #168000	Loss: 0.316467
Step #172000	Loss: 0.292399
Step #176000	Loss: 0.285737
Step #180000	Loss: 0.303168
Step #184000	Loss: 0.300136
Step #188000	Loss: 0.317222
Step #192000	Loss: 0.323371
Step #196000	Loss: 0.313459
Step #200000	Loss: 0.311491
Step #204000	Loss: 0.289367
Step #208000	Loss: 0.296096
Step #212000	Loss: 0.306217
Step #216000	Loss: 0.305750
Step #220000	Loss: 0.304534
Code block 'train epoch=3' took: 1727629.21913 ms
train loss 0.30469220876693726
Code block 'val epoch=3' took: 102882.90718 ms
validation loss 0.720996618270874
Step #0	Loss: 0.301737
Step #4000	Loss: 0.286630
Step #8000	Loss: 0.291772
Step #12000	Loss: 0.295545
Step #16000	Loss: 0.303440
Step #20000	Loss: 0.301108
Step #24000	Loss: 0.314944
Step #28000	Loss: 0.310416
Step #32000	Loss: 0.306053
Step #36000	Loss: 0.300507
Step #40000	Loss: 0.312520
Step #44000	Loss: 0.284485
Step #48000	Loss: 0.290674
Step #52000	Loss: 0.297654
Step #56000	Loss: 0.306047
Step #60000	Loss: 0.291543
Step #64000	Loss: 0.285605
Step #68000	Loss: 0.320311
Step #72000	Loss: 0.302209
Step #76000	Loss: 0.294374
Step #80000	Loss: 0.297779
Step #84000	Loss: 0.312005
Step #88000	Loss: 0.307037
Step #92000	Loss: 0.308128
Step #96000	Loss: 0.299078
Step #100000	Loss: 0.304365
Step #104000	Loss: 0.309679
Step #108000	Loss: 0.306676
Step #112000	Loss: 0.282211
Step #116000	Loss: 0.295016
Step #120000	Loss: 0.292229
Step #124000	Loss: 0.280840
Step #128000	Loss: 0.314398
Step #132000	Loss: 0.305719
Step #136000	Loss: 0.316217
Step #140000	Loss: 0.310285
Step #144000	Loss: 0.295194
Step #148000	Loss: 0.286919
Step #152000	Loss: 0.307645
Step #156000	Loss: 0.308035
Step #160000	Loss: 0.300655
Step #164000	Loss: 0.290252
Step #168000	Loss: 0.313645
Step #172000	Loss: 0.285180
Step #176000	Loss: 0.278399
Step #180000	Loss: 0.286588
Step #184000	Loss: 0.284607
Step #188000	Loss: 0.324284
Step #192000	Loss: 0.314888
Step #196000	Loss: 0.311821
Step #200000	Loss: 0.309420
Step #204000	Loss: 0.277012
Step #208000	Loss: 0.291254
Step #212000	Loss: 0.293161
Step #216000	Loss: 0.309205
Step #220000	Loss: 0.290223
Code block 'train epoch=4' took: 1727072.36758 ms
train loss 0.30195745825767517
Code block 'val epoch=4' took: 103361.54484 ms
validation loss 0.7107621431350708
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --force-host-read --batch-size 8192 --epochs 5'
[WARN  tini (1358143)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-19 04:54:55.100187: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-19 04:54:58.438792: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-19 04:55:26.266813: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-19 04:59:25.383893: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-19 04:59:26.058280: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fb845fde270 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-19 04:59:26.059793: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-19 04:59:26.223628: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-19 04:59:27.395308: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-19 04:59:27.765217: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.741949
Step #4000	Loss: 0.314013
Step #8000	Loss: 0.357884
Step #12000	Loss: 0.331879
Step #16000	Loss: 0.329365
Step #20000	Loss: 0.325343
Step #24000	Loss: 0.374567
Step #28000	Loss: 0.317878
Step #32000	Loss: 0.419320
Step #36000	Loss: 0.356294
Step #40000	Loss: 0.326282
Step #44000	Loss: 0.295611
Step #48000	Loss: 0.381430
Step #52000	Loss: 0.327199
Step #56000	Loss: 0.345783
Step #60000	Loss: 0.422720
Step #64000	Loss: 0.318102
Step #68000	Loss: 0.334652
Step #72000	Loss: 0.350261
Step #76000	Loss: 0.347768
Step #80000	Loss: 0.339031
Step #84000	Loss: 0.415291
Step #88000	Loss: 0.336614
Step #92000	Loss: 0.417137
Step #96000	Loss: 0.329452
Step #100000	Loss: 0.368795
Step #104000	Loss: 0.312296
Step #108000	Loss: 0.370919
Step #112000	Loss: 0.311504
Step #116000	Loss: 0.314745
Step #120000	Loss: 0.352921
Step #124000	Loss: 0.336233
Step #128000	Loss: 0.337466
Step #132000	Loss: 0.338011
Step #136000	Loss: 0.443646
Step #140000	Loss: 0.364975
Step #144000	Loss: 0.444005
Step #148000	Loss: 0.359590
Step #152000	Loss: 0.468856
Step #156000	Loss: 0.371516
Step #160000	Loss: 0.332885
Step #164000	Loss: 0.327822
Step #168000	Loss: 0.432717
Step #172000	Loss: 0.324260
Step #176000	Loss: 0.334518
Step #180000	Loss: 0.326274
Step #184000	Loss: 0.327580
Step #188000	Loss: 0.480001
Step #192000	Loss: 0.373210
Step #196000	Loss: 0.351938
Step #200000	Loss: 0.324611
Step #204000	Loss: 0.363495
Step #208000	Loss: 0.397304
Step #212000	Loss: 0.335719
Step #216000	Loss: 0.425376
Step #220000	Loss: 0.323727
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 1753946.60487 ms
train loss 0.35922959446907043
Code block 'val epoch=0' took: 103951.07527 ms
validation loss 0.6089650392532349
Step #0	Loss: 0.464302
Step #4000	Loss: 0.287555
Step #8000	Loss: 0.310147
Step #12000	Loss: 0.323420
Step #16000	Loss: 0.323597
Step #20000	Loss: 0.307709
Step #24000	Loss: 0.332060
Step #28000	Loss: 0.311602
Step #32000	Loss: 0.347597
Step #36000	Loss: 0.323770
Step #40000	Loss: 0.304102
Step #44000	Loss: 0.287980
Step #48000	Loss: 0.329131
Step #52000	Loss: 0.330423
Step #56000	Loss: 0.309314
Step #60000	Loss: 0.357466
Step #64000	Loss: 0.311127
Step #68000	Loss: 0.301465
Step #72000	Loss: 0.317955
Step #76000	Loss: 0.306293
Step #80000	Loss: 0.319309
Step #84000	Loss: 0.364808
Step #88000	Loss: 0.312786
Step #92000	Loss: 0.351432
Step #96000	Loss: 0.298984
Step #100000	Loss: 0.325107
Step #104000	Loss: 0.313460
Step #108000	Loss: 0.322214
Step #112000	Loss: 0.304863
Step #116000	Loss: 0.297779
Step #120000	Loss: 0.310830
Step #124000	Loss: 0.305158
Step #128000	Loss: 0.324945
Step #132000	Loss: 0.316487
Step #136000	Loss: 0.364308
Step #140000	Loss: 0.327867
Step #144000	Loss: 0.369833
Step #148000	Loss: 0.323050
Step #152000	Loss: 0.380096
Step #156000	Loss: 0.330213
Step #160000	Loss: 0.320446
Step #164000	Loss: 0.301744
Step #168000	Loss: 0.366283
Step #172000	Loss: 0.299335
Step #176000	Loss: 0.301894
Step #180000	Loss: 0.309758
Step #184000	Loss: 0.303369
Step #188000	Loss: 0.382288
Step #192000	Loss: 0.317912
Step #196000	Loss: 0.326996
Step #200000	Loss: 0.303839
Step #204000	Loss: 0.317940
Step #208000	Loss: 0.343831
Step #212000	Loss: 0.313889
Step #216000	Loss: 0.357369
Step #220000	Loss: 0.299025
Code block 'train epoch=1' took: 1725618.30819 ms
train loss 0.323161780834198
Code block 'val epoch=1' took: 103126.28199 ms
validation loss 0.6794114708900452
Step #0	Loss: 0.351584
Step #4000	Loss: 0.300688
Step #8000	Loss: 0.297724
Step #12000	Loss: 0.317137
Step #16000	Loss: 0.314768
Step #20000	Loss: 0.306905
Step #24000	Loss: 0.315588
Step #28000	Loss: 0.319380
Step #32000	Loss: 0.314526
Step #36000	Loss: 0.313242
Step #40000	Loss: 0.308676
Step #44000	Loss: 0.273875
Step #48000	Loss: 0.303643
Step #52000	Loss: 0.299577
Step #56000	Loss: 0.310625
Step #60000	Loss: 0.327050
Step #64000	Loss: 0.290380
Step #68000	Loss: 0.315964
Step #72000	Loss: 0.303503
Step #76000	Loss: 0.297439
Step #80000	Loss: 0.306488
Step #84000	Loss: 0.337305
Step #88000	Loss: 0.307407
Step #92000	Loss: 0.330216
Step #96000	Loss: 0.305300
Step #100000	Loss: 0.308947
Step #104000	Loss: 0.297952
Step #108000	Loss: 0.315403
Step #112000	Loss: 0.301406
Step #116000	Loss: 0.295887
Step #120000	Loss: 0.299409
Step #124000	Loss: 0.296709
Step #128000	Loss: 0.316033
Step #132000	Loss: 0.316387
Step #136000	Loss: 0.335432
Step #140000	Loss: 0.324310
Step #144000	Loss: 0.321808
Step #148000	Loss: 0.324939
Step #152000	Loss: 0.328302
Step #156000	Loss: 0.308135
Step #160000	Loss: 0.312638
Step #164000	Loss: 0.305944
Step #168000	Loss: 0.330237
Step #172000	Loss: 0.291692
Step #176000	Loss: 0.289124
Step #180000	Loss: 0.317029
Step #184000	Loss: 0.302263
Step #188000	Loss: 0.346458
Step #192000	Loss: 0.323588
Step #196000	Loss: 0.318961
Step #200000	Loss: 0.301537
Step #204000	Loss: 0.294815
Step #208000	Loss: 0.318545
Step #212000	Loss: 0.300064
Step #216000	Loss: 0.338350
Step #220000	Loss: 0.291042
Code block 'train epoch=2' took: 1726139.23478 ms
train loss 0.31049463152885437
Code block 'val epoch=2' took: 103406.53804 ms
validation loss 0.6981711387634277
Step #0	Loss: 0.336078
Step #4000	Loss: 0.292738
Step #8000	Loss: 0.290618
Step #12000	Loss: 0.315960
Step #16000	Loss: 0.308532
Step #20000	Loss: 0.307207
Step #24000	Loss: 0.300361
Step #28000	Loss: 0.305023
Step #32000	Loss: 0.296532
Step #36000	Loss: 0.300005
Step #40000	Loss: 0.304510
Step #44000	Loss: 0.286041
Step #48000	Loss: 0.287016
Step #52000	Loss: 0.291542
Step #56000	Loss: 0.297335
Step #60000	Loss: 0.310456
Step #64000	Loss: 0.295578
Step #68000	Loss: 0.304684
Step #72000	Loss: 0.297519
Step #76000	Loss: 0.310879
Step #80000	Loss: 0.304241
Step #84000	Loss: 0.332327
Step #88000	Loss: 0.302103
Step #92000	Loss: 0.318923
Step #96000	Loss: 0.293525
Step #100000	Loss: 0.313843
Step #104000	Loss: 0.295624
Step #108000	Loss: 0.304725
Step #112000	Loss: 0.290823
Step #116000	Loss: 0.284401
Step #120000	Loss: 0.299569
Step #124000	Loss: 0.295172
Step #128000	Loss: 0.301215
Step #132000	Loss: 0.306677
Step #136000	Loss: 0.327109
Step #140000	Loss: 0.313786
Step #144000	Loss: 0.304825
Step #148000	Loss: 0.300404
Step #152000	Loss: 0.329998
Step #156000	Loss: 0.301838
Step #160000	Loss: 0.321081
Step #164000	Loss: 0.293792
Step #168000	Loss: 0.322899
Step #172000	Loss: 0.289362
Step #176000	Loss: 0.282641
Step #180000	Loss: 0.297548
Step #184000	Loss: 0.304641
Step #188000	Loss: 0.325977
Step #192000	Loss: 0.310847
Step #196000	Loss: 0.314654
Step #200000	Loss: 0.311001
Step #204000	Loss: 0.291818
Step #208000	Loss: 0.306257
Step #212000	Loss: 0.300088
Step #216000	Loss: 0.324882
Step #220000	Loss: 0.294528
Code block 'train epoch=3' took: 1726044.43320 ms
train loss 0.3048398196697235
Code block 'val epoch=3' took: 103516.17010 ms
validation loss 0.7615790963172913
Step #0	Loss: 0.315524
Step #4000	Loss: 0.286296
Step #8000	Loss: 0.288278
Step #12000	Loss: 0.324547
Step #16000	Loss: 0.306195
Step #20000	Loss: 0.295265
Step #24000	Loss: 0.290545
Step #28000	Loss: 0.293253
Step #32000	Loss: 0.292899
Step #36000	Loss: 0.303185
Step #40000	Loss: 0.295999
Step #44000	Loss: 0.272737
Step #48000	Loss: 0.291940
Step #52000	Loss: 0.290967
Step #56000	Loss: 0.314189
Step #60000	Loss: 0.297107
Step #64000	Loss: 0.293027
Step #68000	Loss: 0.311488
Step #72000	Loss: 0.295568
Step #76000	Loss: 0.298477
Step #80000	Loss: 0.304346
Step #84000	Loss: 0.324109
Step #88000	Loss: 0.294630
Step #92000	Loss: 0.305226
Step #96000	Loss: 0.309879
Step #100000	Loss: 0.293031
Step #104000	Loss: 0.303512
Step #108000	Loss: 0.303332
Step #112000	Loss: 0.291122
Step #116000	Loss: 0.293655
Step #120000	Loss: 0.291133
Step #124000	Loss: 0.288075
Step #128000	Loss: 0.313769
Step #132000	Loss: 0.307025
Step #136000	Loss: 0.318078
Step #140000	Loss: 0.318807
Step #144000	Loss: 0.307537
Step #148000	Loss: 0.292310
Step #152000	Loss: 0.307150
Step #156000	Loss: 0.295633
Step #160000	Loss: 0.312119
Step #164000	Loss: 0.297391
Step #168000	Loss: 0.318116
Step #172000	Loss: 0.295068
Step #176000	Loss: 0.283869
Step #180000	Loss: 0.302329
Step #184000	Loss: 0.308803
Step #188000	Loss: 0.320726
Step #192000	Loss: 0.302718
Step #196000	Loss: 0.313541
Step #200000	Loss: 0.307061
Step #204000	Loss: 0.287800
Step #208000	Loss: 0.307628
Step #212000	Loss: 0.307977
Step #216000	Loss: 0.317183
Step #220000	Loss: 0.278665
Code block 'train epoch=4' took: 1726092.39359 ms
train loss 0.3019494414329529
Code block 'val epoch=4' took: 103092.84294 ms
validation loss 0.8017175793647766
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --force-host-read --batch-size 8192 --epochs 5'
[WARN  tini (1478429)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-19 07:32:14.246756: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-19 07:32:17.913839: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-19 07:32:48.078467: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-19 07:36:34.774208: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-19 07:36:35.377043: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f64f90f4b30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-19 07:36:35.385709: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-19 07:36:35.573077: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-19 07:36:36.728007: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-19 07:36:37.069041: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.500254
Step #4000	Loss: 0.326603
Step #8000	Loss: 0.343413
Step #12000	Loss: 0.324761
Step #16000	Loss: 0.314267
Step #20000	Loss: 0.317775
Step #24000	Loss: 0.439822
Step #28000	Loss: 0.435469
Step #32000	Loss: 0.424713
Step #36000	Loss: 0.410353
Step #40000	Loss: 0.351868
Step #44000	Loss: 0.365997
Step #48000	Loss: 0.358416
Step #52000	Loss: 0.364098
Step #56000	Loss: 0.397671
Step #60000	Loss: 0.414840
Step #64000	Loss: 0.335451
Step #68000	Loss: 0.368619
Step #72000	Loss: 0.363485
Step #76000	Loss: 0.388099
Step #80000	Loss: 0.405883
Step #84000	Loss: 0.415681
Step #88000	Loss: 0.389821
Step #92000	Loss: 0.370661
Step #96000	Loss: 0.357318
Step #100000	Loss: 0.344999
Step #104000	Loss: 0.306620
Step #108000	Loss: 0.341437
Step #112000	Loss: 0.345466
Step #116000	Loss: 0.421845
Step #120000	Loss: 0.318876
Step #124000	Loss: 0.377981
Step #128000	Loss: 0.394210
Step #132000	Loss: 0.312159
Step #136000	Loss: 0.447063
Step #140000	Loss: 0.415486
Step #144000	Loss: 0.343569
Step #148000	Loss: 0.347540
Step #152000	Loss: 0.358861
Step #156000	Loss: 0.358450
Step #160000	Loss: 0.377308
Step #164000	Loss: 0.320507
Step #168000	Loss: 0.366035
Step #172000	Loss: 0.325118
Step #176000	Loss: 0.357684
Step #180000	Loss: 0.385849
Step #184000	Loss: 0.320078
Step #188000	Loss: 0.464268
Step #192000	Loss: 0.447015
Step #196000	Loss: 0.443901
Step #200000	Loss: 0.321971
Step #204000	Loss: 0.343780
Step #208000	Loss: 0.311956
Step #212000	Loss: 0.332412
Step #216000	Loss: 0.406563
Step #220000	Loss: 0.434196
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 1739306.35803 ms
train loss 0.35963115096092224
Code block 'val epoch=0' took: 102934.53151 ms
validation loss 0.6039828658103943
Step #0	Loss: 0.481598
Step #4000	Loss: 0.312072
Step #8000	Loss: 0.311568
Step #12000	Loss: 0.321773
Step #16000	Loss: 0.306887
Step #20000	Loss: 0.319916
Step #24000	Loss: 0.358198
Step #28000	Loss: 0.362165
Step #32000	Loss: 0.349386
Step #36000	Loss: 0.343141
Step #40000	Loss: 0.320796
Step #44000	Loss: 0.311602
Step #48000	Loss: 0.324660
Step #52000	Loss: 0.333338
Step #56000	Loss: 0.336552
Step #60000	Loss: 0.341264
Step #64000	Loss: 0.295433
Step #68000	Loss: 0.338252
Step #72000	Loss: 0.326780
Step #76000	Loss: 0.335912
Step #80000	Loss: 0.348783
Step #84000	Loss: 0.357734
Step #88000	Loss: 0.331365
Step #92000	Loss: 0.332971
Step #96000	Loss: 0.353977
Step #100000	Loss: 0.310165
Step #104000	Loss: 0.301105
Step #108000	Loss: 0.322704
Step #112000	Loss: 0.318873
Step #116000	Loss: 0.348644
Step #120000	Loss: 0.296798
Step #124000	Loss: 0.314236
Step #128000	Loss: 0.332092
Step #132000	Loss: 0.317266
Step #136000	Loss: 0.375598
Step #140000	Loss: 0.372358
Step #144000	Loss: 0.313674
Step #148000	Loss: 0.302867
Step #152000	Loss: 0.318553
Step #156000	Loss: 0.326824
Step #160000	Loss: 0.311467
Step #164000	Loss: 0.309582
Step #168000	Loss: 0.316865
Step #172000	Loss: 0.294206
Step #176000	Loss: 0.308491
Step #180000	Loss: 0.328969
Step #184000	Loss: 0.299729
Step #188000	Loss: 0.370946
Step #192000	Loss: 0.366828
Step #196000	Loss: 0.368819
Step #200000	Loss: 0.314633
Step #204000	Loss: 0.290425
Step #208000	Loss: 0.296522
Step #212000	Loss: 0.306192
Step #216000	Loss: 0.343190
Step #220000	Loss: 0.358622
Code block 'train epoch=1' took: 1711156.71688 ms
train loss 0.3235411047935486
Code block 'val epoch=1' took: 101592.59753 ms
validation loss 0.6548215746879578
Step #0	Loss: 0.345030
Step #4000	Loss: 0.300678
Step #8000	Loss: 0.300237
Step #12000	Loss: 0.305456
Step #16000	Loss: 0.303632
Step #20000	Loss: 0.303571
Step #24000	Loss: 0.330017
Step #28000	Loss: 0.324412
Step #32000	Loss: 0.307010
Step #36000	Loss: 0.320744
Step #40000	Loss: 0.318525
Step #44000	Loss: 0.280561
Step #48000	Loss: 0.298421
Step #52000	Loss: 0.313122
Step #56000	Loss: 0.314376
Step #60000	Loss: 0.315515
Step #64000	Loss: 0.302689
Step #68000	Loss: 0.314753
Step #72000	Loss: 0.312550
Step #76000	Loss: 0.317542
Step #80000	Loss: 0.319981
Step #84000	Loss: 0.331681
Step #88000	Loss: 0.316442
Step #92000	Loss: 0.316392
Step #96000	Loss: 0.319235
Step #100000	Loss: 0.309256
Step #104000	Loss: 0.307884
Step #108000	Loss: 0.314776
Step #112000	Loss: 0.301370
Step #116000	Loss: 0.322838
Step #120000	Loss: 0.301657
Step #124000	Loss: 0.306840
Step #128000	Loss: 0.329513
Step #132000	Loss: 0.318452
Step #136000	Loss: 0.339098
Step #140000	Loss: 0.341222
Step #144000	Loss: 0.316073
Step #148000	Loss: 0.306840
Step #152000	Loss: 0.302472
Step #156000	Loss: 0.309270
Step #160000	Loss: 0.303151
Step #164000	Loss: 0.291063
Step #168000	Loss: 0.315614
Step #172000	Loss: 0.288807
Step #176000	Loss: 0.292298
Step #180000	Loss: 0.303749
Step #184000	Loss: 0.295112
Step #188000	Loss: 0.331875
Step #192000	Loss: 0.338948
Step #196000	Loss: 0.335289
Step #200000	Loss: 0.304444
Step #204000	Loss: 0.295762
Step #208000	Loss: 0.299473
Step #212000	Loss: 0.304909
Step #216000	Loss: 0.336225
Step #220000	Loss: 0.315416
Code block 'train epoch=2' took: 1712561.83837 ms
train loss 0.3106183707714081
Code block 'val epoch=2' took: 102459.59444 ms
validation loss 0.6955806612968445
Step #0	Loss: 0.328165
Step #4000	Loss: 0.285499
Step #8000	Loss: 0.296121
Step #12000	Loss: 0.288818
Step #16000	Loss: 0.295470
Step #20000	Loss: 0.304759
Step #24000	Loss: 0.301824
Step #28000	Loss: 0.306859
Step #32000	Loss: 0.304753
Step #36000	Loss: 0.308110
Step #40000	Loss: 0.313282
Step #44000	Loss: 0.284320
Step #48000	Loss: 0.295119
Step #52000	Loss: 0.297928
Step #56000	Loss: 0.306553
Step #60000	Loss: 0.313485
Step #64000	Loss: 0.283772
Step #68000	Loss: 0.315284
Step #72000	Loss: 0.301464
Step #76000	Loss: 0.301683
Step #80000	Loss: 0.308395
Step #84000	Loss: 0.335450
Step #88000	Loss: 0.302189
Step #92000	Loss: 0.318421
Step #96000	Loss: 0.306094
Step #100000	Loss: 0.305078
Step #104000	Loss: 0.290581
Step #108000	Loss: 0.313213
Step #112000	Loss: 0.303337
Step #116000	Loss: 0.319979
Step #120000	Loss: 0.293654
Step #124000	Loss: 0.293041
Step #128000	Loss: 0.323222
Step #132000	Loss: 0.305767
Step #136000	Loss: 0.325307
Step #140000	Loss: 0.321879
Step #144000	Loss: 0.310055
Step #148000	Loss: 0.304281
Step #152000	Loss: 0.304382
Step #156000	Loss: 0.309570
Step #160000	Loss: 0.286634
Step #164000	Loss: 0.305971
Step #168000	Loss: 0.306773
Step #172000	Loss: 0.298340
Step #176000	Loss: 0.292956
Step #180000	Loss: 0.300422
Step #184000	Loss: 0.295453
Step #188000	Loss: 0.328880
Step #192000	Loss: 0.314519
Step #196000	Loss: 0.319222
Step #200000	Loss: 0.299866
Step #204000	Loss: 0.289585
Step #208000	Loss: 0.294952
Step #212000	Loss: 0.303191
Step #216000	Loss: 0.325515
Step #220000	Loss: 0.323609
Code block 'train epoch=3' took: 1714692.43684 ms
train loss 0.3048403263092041
Code block 'val epoch=3' took: 100551.80561 ms
validation loss 0.740669846534729
Step #0	Loss: 0.315606
Step #4000	Loss: 0.289526
Step #8000	Loss: 0.291231
Step #12000	Loss: 0.285688
Step #16000	Loss: 0.293236
Step #20000	Loss: 0.304329
Step #24000	Loss: 0.303084
Step #28000	Loss: 0.311559
Step #32000	Loss: 0.294545
Step #36000	Loss: 0.309370
Step #40000	Loss: 0.314658
Step #44000	Loss: 0.276532
Step #48000	Loss: 0.284920
Step #52000	Loss: 0.301103
Step #56000	Loss: 0.304653
Step #60000	Loss: 0.299991
Step #64000	Loss: 0.298797
Step #68000	Loss: 0.308715
Step #72000	Loss: 0.292719
Step #76000	Loss: 0.300032
Step #80000	Loss: 0.294924
Step #84000	Loss: 0.320873
Step #88000	Loss: 0.306304
Step #92000	Loss: 0.314209
Step #96000	Loss: 0.298538
Step #100000	Loss: 0.295679
Step #104000	Loss: 0.293482
Step #108000	Loss: 0.323408
Step #112000	Loss: 0.301535
Step #116000	Loss: 0.300162
Step #120000	Loss: 0.293980
Step #124000	Loss: 0.297098
Step #128000	Loss: 0.310556
Step #132000	Loss: 0.311067
Step #136000	Loss: 0.326026
Step #140000	Loss: 0.315043
Step #144000	Loss: 0.306673
Step #148000	Loss: 0.296969
Step #152000	Loss: 0.293844
Step #156000	Loss: 0.291781
Step #160000	Loss: 0.294315
Step #164000	Loss: 0.298512
Step #168000	Loss: 0.298491
Step #172000	Loss: 0.301107
Step #176000	Loss: 0.287193
Step #180000	Loss: 0.310293
Step #184000	Loss: 0.294435
Step #188000	Loss: 0.324530
Step #192000	Loss: 0.314493
Step #196000	Loss: 0.316404
Step #200000	Loss: 0.299928
Step #204000	Loss: 0.296707
Step #208000	Loss: 0.304126
Step #212000	Loss: 0.308189
Step #216000	Loss: 0.315037
Step #220000	Loss: 0.308167
Code block 'train epoch=4' took: 1714548.91329 ms
train loss 0.30205202102661133
Code block 'val epoch=4' took: 99843.73816 ms
validation loss 0.7798807621002197
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --force-host-read --batch-size 8192 --epochs 5'
[WARN  tini (1593957)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-19 10:08:14.398109: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-19 10:08:18.343371: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-19 10:08:49.064048: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-19 10:12:41.241394: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-19 10:12:41.786445: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f30af454860 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-19 10:12:41.786507: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-19 10:12:41.955962: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-19 10:12:43.102256: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-19 10:12:43.486707: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.533070
Step #4000	Loss: 0.336201
Step #8000	Loss: 0.323972
Step #12000	Loss: 0.346331
Step #16000	Loss: 0.357657
Step #20000	Loss: 0.362145
Step #24000	Loss: 0.338838
Step #28000	Loss: 0.343934
Step #32000	Loss: 0.330472
Step #36000	Loss: 0.330746
Step #40000	Loss: 0.319135
Step #44000	Loss: 0.304342
Step #48000	Loss: 0.324485
Step #52000	Loss: 0.323469
Step #56000	Loss: 0.337698
Step #60000	Loss: 0.330353
Step #64000	Loss: 0.316513
Step #68000	Loss: 0.343728
Step #72000	Loss: 0.395604
Step #76000	Loss: 0.330264
Step #80000	Loss: 0.345803
Step #84000	Loss: 0.345106
Step #88000	Loss: 0.424684
Step #92000	Loss: 0.410338
Step #96000	Loss: 0.403574
Step #100000	Loss: 0.350384
Step #104000	Loss: 0.359724
Step #108000	Loss: 0.348339
Step #112000	Loss: 0.320224
Step #116000	Loss: 0.434708
Step #120000	Loss: 0.317993
Step #124000	Loss: 0.332159
Step #128000	Loss: 0.342841
Step #132000	Loss: 0.330204
Step #136000	Loss: 0.458798
Step #140000	Loss: 0.404377
Step #144000	Loss: 0.376813
Step #148000	Loss: 0.357360
Step #152000	Loss: 0.323554
Step #156000	Loss: 0.345751
Step #160000	Loss: 0.406244
Step #164000	Loss: 0.328546
Step #168000	Loss: 0.332939
Step #172000	Loss: 0.381539
Step #176000	Loss: 0.405398
Step #180000	Loss: 0.372595
Step #184000	Loss: 0.337700
Step #188000	Loss: 0.355487
Step #192000	Loss: 0.364534
Step #196000	Loss: 0.363270
Step #200000	Loss: 0.371201
Step #204000	Loss: 0.332451
Step #208000	Loss: 0.353732
Step #212000	Loss: 0.352931
Step #216000	Loss: 0.349057
Step #220000	Loss: 0.427463
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 1735992.10532 ms
train loss 0.35916629433631897
Code block 'val epoch=0' took: 102460.45861 ms
validation loss 0.7184599041938782
Step #0	Loss: 0.511129
Step #4000	Loss: 0.309149
Step #8000	Loss: 0.303966
Step #12000	Loss: 0.326139
Step #16000	Loss: 0.318488
Step #20000	Loss: 0.324489
Step #24000	Loss: 0.317587
Step #28000	Loss: 0.314836
Step #32000	Loss: 0.307545
Step #36000	Loss: 0.301554
Step #40000	Loss: 0.308735
Step #44000	Loss: 0.286785
Step #48000	Loss: 0.306149
Step #52000	Loss: 0.308161
Step #56000	Loss: 0.315224
Step #60000	Loss: 0.308136
Step #64000	Loss: 0.299749
Step #68000	Loss: 0.316411
Step #72000	Loss: 0.334813
Step #76000	Loss: 0.301170
Step #80000	Loss: 0.319187
Step #84000	Loss: 0.332395
Step #88000	Loss: 0.344123
Step #92000	Loss: 0.341680
Step #96000	Loss: 0.344531
Step #100000	Loss: 0.319163
Step #104000	Loss: 0.315280
Step #108000	Loss: 0.315411
Step #112000	Loss: 0.310002
Step #116000	Loss: 0.357042
Step #120000	Loss: 0.304731
Step #124000	Loss: 0.308181
Step #128000	Loss: 0.319099
Step #132000	Loss: 0.313811
Step #136000	Loss: 0.376938
Step #140000	Loss: 0.334018
Step #144000	Loss: 0.330174
Step #148000	Loss: 0.323369
Step #152000	Loss: 0.312294
Step #156000	Loss: 0.318230
Step #160000	Loss: 0.328894
Step #164000	Loss: 0.295497
Step #168000	Loss: 0.312643
Step #172000	Loss: 0.320549
Step #176000	Loss: 0.334147
Step #180000	Loss: 0.331236
Step #184000	Loss: 0.322322
Step #188000	Loss: 0.337531
Step #192000	Loss: 0.327124
Step #196000	Loss: 0.325939
Step #200000	Loss: 0.323977
Step #204000	Loss: 0.302798
Step #208000	Loss: 0.307824
Step #212000	Loss: 0.321698
Step #216000	Loss: 0.318954
Step #220000	Loss: 0.352655
Code block 'train epoch=1' took: 1710230.98298 ms
train loss 0.32249966263771057
Code block 'val epoch=1' took: 104205.96858 ms
validation loss 0.7321688532829285
Step #0	Loss: 0.368353
Step #4000	Loss: 0.297542
Step #8000	Loss: 0.297039
Step #12000	Loss: 0.303965
Step #16000	Loss: 0.306975
Step #20000	Loss: 0.312291
Step #24000	Loss: 0.313457
Step #28000	Loss: 0.319157
Step #32000	Loss: 0.293826
Step #36000	Loss: 0.305923
Step #40000	Loss: 0.299636
Step #44000	Loss: 0.281873
Step #48000	Loss: 0.296902
Step #52000	Loss: 0.292430
Step #56000	Loss: 0.305185
Step #60000	Loss: 0.298835
Step #64000	Loss: 0.292365
Step #68000	Loss: 0.314043
Step #72000	Loss: 0.308002
Step #76000	Loss: 0.296541
Step #80000	Loss: 0.309364
Step #84000	Loss: 0.325374
Step #88000	Loss: 0.323891
Step #92000	Loss: 0.317002
Step #96000	Loss: 0.324417
Step #100000	Loss: 0.302682
Step #104000	Loss: 0.307855
Step #108000	Loss: 0.314576
Step #112000	Loss: 0.289572
Step #116000	Loss: 0.318922
Step #120000	Loss: 0.307098
Step #124000	Loss: 0.308215
Step #128000	Loss: 0.310151
Step #132000	Loss: 0.322303
Step #136000	Loss: 0.340811
Step #140000	Loss: 0.297955
Step #144000	Loss: 0.304077
Step #148000	Loss: 0.318486
Step #152000	Loss: 0.305905
Step #156000	Loss: 0.317662
Step #160000	Loss: 0.313290
Step #164000	Loss: 0.300338
Step #168000	Loss: 0.309723
Step #172000	Loss: 0.304287
Step #176000	Loss: 0.303259
Step #180000	Loss: 0.309049
Step #184000	Loss: 0.311336
Step #188000	Loss: 0.318118
Step #192000	Loss: 0.315908
Step #196000	Loss: 0.321342
Step #200000	Loss: 0.317747
Step #204000	Loss: 0.294858
Step #208000	Loss: 0.313253
Step #212000	Loss: 0.311479
Step #216000	Loss: 0.316361
Step #220000	Loss: 0.313787
Code block 'train epoch=2' took: 1711590.17030 ms
train loss 0.3099646270275116
Code block 'val epoch=2' took: 102326.50810 ms
validation loss 0.7355049848556519
Step #0	Loss: 0.349511
Step #4000	Loss: 0.287083
Step #8000	Loss: 0.302764
Step #12000	Loss: 0.298526
Step #16000	Loss: 0.298717
Step #20000	Loss: 0.311628
Step #24000	Loss: 0.311251
Step #28000	Loss: 0.307674
Step #32000	Loss: 0.296740
Step #36000	Loss: 0.297954
Step #40000	Loss: 0.299008
Step #44000	Loss: 0.289293
Step #48000	Loss: 0.292645
Step #52000	Loss: 0.306085
Step #56000	Loss: 0.299007
Step #60000	Loss: 0.297617
Step #64000	Loss: 0.283172
Step #68000	Loss: 0.298065
Step #72000	Loss: 0.294913
Step #76000	Loss: 0.295144
Step #80000	Loss: 0.301153
Step #84000	Loss: 0.314905
Step #88000	Loss: 0.301581
Step #92000	Loss: 0.317381
Step #96000	Loss: 0.315871
Step #100000	Loss: 0.303565
Step #104000	Loss: 0.302051
Step #108000	Loss: 0.322727
Step #112000	Loss: 0.296841
Step #116000	Loss: 0.312415
Step #120000	Loss: 0.309621
Step #124000	Loss: 0.294990
Step #128000	Loss: 0.307565
Step #132000	Loss: 0.309528
Step #136000	Loss: 0.322791
Step #140000	Loss: 0.305049
Step #144000	Loss: 0.301688
Step #148000	Loss: 0.298764
Step #152000	Loss: 0.306482
Step #156000	Loss: 0.311052
Step #160000	Loss: 0.304661
Step #164000	Loss: 0.287848
Step #168000	Loss: 0.313426
Step #172000	Loss: 0.291402
Step #176000	Loss: 0.302390
Step #180000	Loss: 0.287932
Step #184000	Loss: 0.301453
Step #188000	Loss: 0.304344
Step #192000	Loss: 0.316379
Step #196000	Loss: 0.308336
Step #200000	Loss: 0.307213
Step #204000	Loss: 0.288445
Step #208000	Loss: 0.302707
Step #212000	Loss: 0.311293
Step #216000	Loss: 0.302580
Step #220000	Loss: 0.306937
Code block 'train epoch=3' took: 1712146.23953 ms
train loss 0.3045342266559601
Code block 'val epoch=3' took: 101498.50233 ms
validation loss 0.7577281594276428
Step #0	Loss: 0.339267
Step #4000	Loss: 0.291422
Step #8000	Loss: 0.291716
Step #12000	Loss: 0.296272
Step #16000	Loss: 0.303977
Step #20000	Loss: 0.302089
Step #24000	Loss: 0.303004
Step #28000	Loss: 0.306643
Step #32000	Loss: 0.292296
Step #36000	Loss: 0.294603
Step #40000	Loss: 0.307663
Step #44000	Loss: 0.278893
Step #48000	Loss: 0.290624
Step #52000	Loss: 0.292633
Step #56000	Loss: 0.299636
Step #60000	Loss: 0.290791
Step #64000	Loss: 0.296708
Step #68000	Loss: 0.301976
Step #72000	Loss: 0.296922
Step #76000	Loss: 0.294031
Step #80000	Loss: 0.311690
Step #84000	Loss: 0.307957
Step #88000	Loss: 0.299664
Step #92000	Loss: 0.302555
Step #96000	Loss: 0.315015
Step #100000	Loss: 0.306285
Step #104000	Loss: 0.295559
Step #108000	Loss: 0.311612
Step #112000	Loss: 0.284973
Step #116000	Loss: 0.302070
Step #120000	Loss: 0.305050
Step #124000	Loss: 0.296543
Step #128000	Loss: 0.301623
Step #132000	Loss: 0.314388
Step #136000	Loss: 0.318105
Step #140000	Loss: 0.288367
Step #144000	Loss: 0.301480
Step #148000	Loss: 0.301020
Step #152000	Loss: 0.288383
Step #156000	Loss: 0.304448
Step #160000	Loss: 0.287089
Step #164000	Loss: 0.302501
Step #168000	Loss: 0.299177
Step #172000	Loss: 0.297159
Step #176000	Loss: 0.304084
Step #180000	Loss: 0.295416
Step #184000	Loss: 0.305033
Step #188000	Loss: 0.309970
Step #192000	Loss: 0.322773
Step #196000	Loss: 0.319427
Step #200000	Loss: 0.305688
Step #204000	Loss: 0.281021
Step #208000	Loss: 0.323491
Step #212000	Loss: 0.303282
Step #216000	Loss: 0.312271
Step #220000	Loss: 0.295925
Code block 'train epoch=4' took: 1711553.94711 ms
train loss 0.3019660413265228
Code block 'val epoch=4' took: 102089.06522 ms
validation loss 0.7868340015411377
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --force-host-read --batch-size 8192 --epochs 5'
[WARN  tini (1710947)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-19 12:44:13.166497: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-19 12:44:16.847583: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-19 12:44:52.323147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-19 12:48:56.530991: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-19 12:48:57.313833: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fb9b79f03b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-19 12:48:57.315021: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-19 12:48:57.486519: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-19 12:48:58.781916: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-19 12:48:59.183516: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 1.481164
Step #4000	Loss: 0.404881
Step #8000	Loss: 0.317014
Step #12000	Loss: 0.325720
Step #16000	Loss: 0.336174
Step #20000	Loss: 0.381538
Step #24000	Loss: 0.455576
Step #28000	Loss: 0.343325
Step #32000	Loss: 0.342278
Step #36000	Loss: 0.433415
Step #40000	Loss: 0.323011
Step #44000	Loss: 0.394035
Step #48000	Loss: 0.303881
Step #52000	Loss: 0.344419
Step #56000	Loss: 0.419576
Step #60000	Loss: 0.329225
Step #64000	Loss: 0.344033
Step #68000	Loss: 0.421777
Step #72000	Loss: 0.398726
Step #76000	Loss: 0.428890
Step #80000	Loss: 0.324031
Step #84000	Loss: 0.349229
Step #88000	Loss: 0.359107
Step #92000	Loss: 0.415794
Step #96000	Loss: 0.373993
Step #100000	Loss: 0.384522
Step #104000	Loss: 0.315953
Step #108000	Loss: 0.339711
Step #112000	Loss: 0.333218
Step #116000	Loss: 0.346862
Step #120000	Loss: 0.342315
Step #124000	Loss: 0.333417
Step #128000	Loss: 0.362879
Step #132000	Loss: 0.374790
Step #136000	Loss: 0.446625
Step #140000	Loss: 0.348129
Step #144000	Loss: 0.331316
Step #148000	Loss: 0.364451
Step #152000	Loss: 0.415596
Step #156000	Loss: 0.340077
Step #160000	Loss: 0.333047
Step #164000	Loss: 0.317102
Step #168000	Loss: 0.355672
Step #172000	Loss: 0.359715
Step #176000	Loss: 0.349180
Step #180000	Loss: 0.330693
Step #184000	Loss: 0.358417
Step #188000	Loss: 0.480768
Step #192000	Loss: 0.350293
Step #196000	Loss: 0.386902
Step #200000	Loss: 0.342830
Step #204000	Loss: 0.319535
Step #208000	Loss: 0.316141
Step #212000	Loss: 0.333443
Step #216000	Loss: 0.360288
Step #220000	Loss: 0.343271
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 1743330.40269 ms
train loss 0.358175128698349
Code block 'val epoch=0' took: 102048.10881 ms
validation loss 0.6463301777839661
Step #0	Loss: 0.487785
Step #4000	Loss: 0.335248
Step #8000	Loss: 0.297009
Step #12000	Loss: 0.310238
Step #16000	Loss: 0.319936
Step #20000	Loss: 0.333685
Step #24000	Loss: 0.346228
Step #28000	Loss: 0.318175
Step #32000	Loss: 0.303906
Step #36000	Loss: 0.352657
Step #40000	Loss: 0.314905
Step #44000	Loss: 0.332296
Step #48000	Loss: 0.297966
Step #52000	Loss: 0.309291
Step #56000	Loss: 0.340066
Step #60000	Loss: 0.308881
Step #64000	Loss: 0.305224
Step #68000	Loss: 0.339894
Step #72000	Loss: 0.333264
Step #76000	Loss: 0.337502
Step #80000	Loss: 0.307224
Step #84000	Loss: 0.331361
Step #88000	Loss: 0.328608
Step #92000	Loss: 0.359418
Step #96000	Loss: 0.328504
Step #100000	Loss: 0.321529
Step #104000	Loss: 0.310765
Step #108000	Loss: 0.336157
Step #112000	Loss: 0.320657
Step #116000	Loss: 0.318638
Step #120000	Loss: 0.321228
Step #124000	Loss: 0.320534
Step #128000	Loss: 0.329075
Step #132000	Loss: 0.332462
Step #136000	Loss: 0.355069
Step #140000	Loss: 0.332280
Step #144000	Loss: 0.315598
Step #148000	Loss: 0.310048
Step #152000	Loss: 0.332789
Step #156000	Loss: 0.306818
Step #160000	Loss: 0.324733
Step #164000	Loss: 0.295204
Step #168000	Loss: 0.322383
Step #172000	Loss: 0.321413
Step #176000	Loss: 0.303490
Step #180000	Loss: 0.309862
Step #184000	Loss: 0.312764
Step #188000	Loss: 0.362791
Step #192000	Loss: 0.331003
Step #196000	Loss: 0.336590
Step #200000	Loss: 0.311958
Step #204000	Loss: 0.310511
Step #208000	Loss: 0.313988
Step #212000	Loss: 0.323103
Step #216000	Loss: 0.324502
Step #220000	Loss: 0.315145
Code block 'train epoch=1' took: 1715125.93170 ms
train loss 0.3208099603652954
Code block 'val epoch=1' took: 101374.86989 ms
validation loss 0.6696241497993469
Step #0	Loss: 0.423953
Step #4000	Loss: 0.313597
Step #8000	Loss: 0.307144
Step #12000	Loss: 0.310372
Step #16000	Loss: 0.305767
Step #20000	Loss: 0.314216
Step #24000	Loss: 0.327424
Step #28000	Loss: 0.316548
Step #32000	Loss: 0.301224
Step #36000	Loss: 0.322855
Step #40000	Loss: 0.305025
Step #44000	Loss: 0.305028
Step #48000	Loss: 0.297910
Step #52000	Loss: 0.307144
Step #56000	Loss: 0.318967
Step #60000	Loss: 0.300576
Step #64000	Loss: 0.299550
Step #68000	Loss: 0.334831
Step #72000	Loss: 0.311631
Step #76000	Loss: 0.319589
Step #80000	Loss: 0.306068
Step #84000	Loss: 0.315289
Step #88000	Loss: 0.313621
Step #92000	Loss: 0.327907
Step #96000	Loss: 0.316207
Step #100000	Loss: 0.306631
Step #104000	Loss: 0.314778
Step #108000	Loss: 0.313796
Step #112000	Loss: 0.314383
Step #116000	Loss: 0.302910
Step #120000	Loss: 0.307968
Step #124000	Loss: 0.293141
Step #128000	Loss: 0.322373
Step #132000	Loss: 0.330909
Step #136000	Loss: 0.338736
Step #140000	Loss: 0.322205
Step #144000	Loss: 0.302886
Step #148000	Loss: 0.299481
Step #152000	Loss: 0.323456
Step #156000	Loss: 0.312351
Step #160000	Loss: 0.307711
Step #164000	Loss: 0.296306
Step #168000	Loss: 0.315108
Step #172000	Loss: 0.299752
Step #176000	Loss: 0.298568
Step #180000	Loss: 0.308877
Step #184000	Loss: 0.318415
Step #188000	Loss: 0.328295
Step #192000	Loss: 0.325939
Step #196000	Loss: 0.325416
Step #200000	Loss: 0.304476
Step #204000	Loss: 0.297560
Step #208000	Loss: 0.311719
Step #212000	Loss: 0.307840
Step #216000	Loss: 0.317854
Step #220000	Loss: 0.309838
Code block 'train epoch=2' took: 1714209.40956 ms
train loss 0.30894097685813904
Code block 'val epoch=2' took: 102336.99329 ms
validation loss 0.7570713758468628
Step #0	Loss: 0.363141
Step #4000	Loss: 0.296551
Step #8000	Loss: 0.296251
Step #12000	Loss: 0.312435
Step #16000	Loss: 0.289425
Step #20000	Loss: 0.309133
Step #24000	Loss: 0.312005
Step #28000	Loss: 0.298631
Step #32000	Loss: 0.302600
Step #36000	Loss: 0.312834
Step #40000	Loss: 0.315828
Step #44000	Loss: 0.307279
Step #48000	Loss: 0.282387
Step #52000	Loss: 0.291521
Step #56000	Loss: 0.300557
Step #60000	Loss: 0.298816
Step #64000	Loss: 0.288313
Step #68000	Loss: 0.310566
Step #72000	Loss: 0.295886
Step #76000	Loss: 0.311306
Step #80000	Loss: 0.308508
Step #84000	Loss: 0.314849
Step #88000	Loss: 0.314925
Step #92000	Loss: 0.308641
Step #96000	Loss: 0.320728
Step #100000	Loss: 0.300989
Step #104000	Loss: 0.307002
Step #108000	Loss: 0.308303
Step #112000	Loss: 0.303206
Step #116000	Loss: 0.302538
Step #120000	Loss: 0.290612
Step #124000	Loss: 0.308328
Step #128000	Loss: 0.310469
Step #132000	Loss: 0.322130
Step #136000	Loss: 0.322993
Step #140000	Loss: 0.318346
Step #144000	Loss: 0.289489
Step #148000	Loss: 0.300353
Step #152000	Loss: 0.301263
Step #156000	Loss: 0.312948
Step #160000	Loss: 0.302662
Step #164000	Loss: 0.293383
Step #168000	Loss: 0.302486
Step #172000	Loss: 0.290007
Step #176000	Loss: 0.295363
Step #180000	Loss: 0.288704
Step #184000	Loss: 0.311958
Step #188000	Loss: 0.320619
Step #192000	Loss: 0.320287
Step #196000	Loss: 0.319268
Step #200000	Loss: 0.308985
Step #204000	Loss: 0.286000
Step #208000	Loss: 0.287987
Step #212000	Loss: 0.310620
Step #216000	Loss: 0.313650
Step #220000	Loss: 0.293740
Code block 'train epoch=3' took: 1720251.88953 ms
train loss 0.3046098053455353
Code block 'val epoch=3' took: 103956.67135 ms
validation loss 0.8078529834747314
Step #0	Loss: 0.339880
Step #4000	Loss: 0.295784
Step #8000	Loss: 0.289591
Step #12000	Loss: 0.300040
Step #16000	Loss: 0.299229
Step #20000	Loss: 0.308394
Step #24000	Loss: 0.308776
Step #28000	Loss: 0.304539
Step #32000	Loss: 0.278125
Step #36000	Loss: 0.315461
Step #40000	Loss: 0.310908
Step #44000	Loss: 0.294937
Step #48000	Loss: 0.296310
Step #52000	Loss: 0.298733
Step #56000	Loss: 0.297356
Step #60000	Loss: 0.295345
Step #64000	Loss: 0.294171
Step #68000	Loss: 0.311627
Step #72000	Loss: 0.305777
Step #76000	Loss: 0.321371
Step #80000	Loss: 0.299974
Step #84000	Loss: 0.316184
Step #88000	Loss: 0.311382
Step #92000	Loss: 0.318087
Step #96000	Loss: 0.306327
Step #100000	Loss: 0.304126
Step #104000	Loss: 0.288028
Step #108000	Loss: 0.309387
Step #112000	Loss: 0.306813
Step #116000	Loss: 0.292868
Step #120000	Loss: 0.302891
Step #124000	Loss: 0.298422
Step #128000	Loss: 0.306840
Step #132000	Loss: 0.301387
Step #136000	Loss: 0.313110
Step #140000	Loss: 0.314037
Step #144000	Loss: 0.292445
Step #148000	Loss: 0.307545
Step #152000	Loss: 0.309134
Step #156000	Loss: 0.300266
Step #160000	Loss: 0.301856
Step #164000	Loss: 0.292524
Step #168000	Loss: 0.306716
Step #172000	Loss: 0.294715
Step #176000	Loss: 0.280990
Step #180000	Loss: 0.295495
Step #184000	Loss: 0.312556
Step #188000	Loss: 0.323303
Step #192000	Loss: 0.316577
Step #196000	Loss: 0.318338
Step #200000	Loss: 0.297830
Step #204000	Loss: 0.288336
Step #208000	Loss: 0.295558
Step #212000	Loss: 0.302345
Step #216000	Loss: 0.312592
Step #220000	Loss: 0.299918
Code block 'train epoch=4' took: 1724564.57010 ms
train loss 0.30230075120925903
Code block 'val epoch=4' took: 103984.79529 ms
validation loss 0.8838920593261719
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --force-host-read --batch-size 8192 --epochs 5'
[WARN  tini (1963235)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-19 15:21:00.397529: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-19 15:21:04.440365: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-19 15:21:36.881614: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-19 15:25:25.877612: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-19 15:25:26.396192: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fcd9c0caad0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-19 15:25:26.416870: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-19 15:25:26.601865: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-19 15:25:27.645055: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-19 15:25:27.989577: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 1.202895
Step #4000	Loss: 0.388554
Step #8000	Loss: 0.381535
terminate called after throwing an instance of 'rmm::out_of_memory'
  what():  std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp
[dgx-2:1963262] *** Process received signal ***
[dgx-2:1963262] Signal: Aborted (6)
[dgx-2:1963262] Signal code:  (-6)
[dgx-2:1963262] [ 0] /lib/x86_64-linux-gnu/libc.so.6(+0x42520)[0x7fd716b7d520]
[dgx-2:1963262] [ 1] /lib/x86_64-linux-gnu/libc.so.6(pthread_kill+0x12c)[0x7fd716bd1a7c]
[dgx-2:1963262] [ 2] /lib/x86_64-linux-gnu/libc.so.6(raise+0x16)[0x7fd716b7d476]
[dgx-2:1963262] [ 3] /lib/x86_64-linux-gnu/libc.so.6(abort+0xd3)[0x7fd716b637f3]
[dgx-2:1963262] [ 4] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(_ZN9__gnu_cxx27__verbose_terminate_handlerEv+0xc0)[0x7fd713ceb026]
[dgx-2:1963262] [ 5] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(+0xb0514)[0x7fd713ce9514]
[dgx-2:1963262] [ 6] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(+0xb0566)[0x7fd713ce9566]
[dgx-2:1963262] [ 7] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(__cxa_rethrow+0x0)[0x7fd713ce9758]
[dgx-2:1963262] [ 8] /opt/conda/envs/rapids/lib/python3.10/site-packages/rmm/_lib/device_buffer.cpython-310-x86_64-linux-gnu.so(+0x4b67d)[0x7fd5f42e267d]
[dgx-2:1963262] [ 9] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf6columnC2ERKS0_N3rmm16cuda_stream_viewEPNS3_2mr22device_memory_resourceE+0x6d)[0x7fd4d3ad6add]
[dgx-2:1963262] [10] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf6columnC2ERKS0_N3rmm16cuda_stream_viewEPNS3_2mr22device_memory_resourceE+0x20c)[0x7fd4d3ad6c7c]
[dgx-2:1963262] [11] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf5tableC1ERKS0_+0x263)[0x7fd4d5210ec3]
[dgx-2:1963262] [12] /home2/faculty/pwesolowski/praca-mgr/parser-repo/build/libmeta-cudf-parser-1.so(_Z25generate_example_metadataPKcmmi11end_of_linebb+0x87d)[0x7fcf4092b27d]
[dgx-2:1963262] [13] /home2/faculty/pwesolowski/praca-mgr/parser-repo/python_binding/metajsonparser/_lib/json_cudf.cpython-310-x86_64-linux-gnu.so(+0x4b344)[0x7fd45e0e3344]
[dgx-2:1963262] [14] python(+0x13fb27)[0x55a6e8bf3b27]
[dgx-2:1963262] [15] python(PyObject_Call+0x209)[0x55a6e8c00139]
[dgx-2:1963262] [16] python(_PyEval_EvalFrameDefault+0x5d8c)[0x55a6e8be9b7c]
[dgx-2:1963262] [17] python(_PyFunction_Vectorcall+0x6f)[0x55a6e8bf3f8f]
[dgx-2:1963262] [18] python(_PyEval_EvalFrameDefault+0x2ec2)[0x55a6e8be6cb2]
[dgx-2:1963262] [19] python(_PyFunction_Vectorcall+0x6f)[0x55a6e8bf3f8f]
[dgx-2:1963262] [20] python(_PyEval_EvalFrameDefault+0x332)[0x55a6e8be4122]
[dgx-2:1963262] [21] python(_PyFunction_Vectorcall+0x6f)[0x55a6e8bf3f8f]
[dgx-2:1963262] [22] python(_PyEval_EvalFrameDefault+0x2ec2)[0x55a6e8be6cb2]
[dgx-2:1963262] [23] python(_PyFunction_Vectorcall+0x6f)[0x55a6e8bf3f8f]
[dgx-2:1963262] [24] python(_PyEval_EvalFrameDefault+0x332)[0x55a6e8be4122]
[dgx-2:1963262] [25] python(_PyFunction_Vectorcall+0x6f)[0x55a6e8bf3f8f]
[dgx-2:1963262] [26] python(_PyEval_EvalFrameDefault+0x2ec2)[0x55a6e8be6cb2]
[dgx-2:1963262] [27] python(+0x14b641)[0x55a6e8bff641]
[dgx-2:1963262] [28] python(_PyEval_EvalFrameDefault+0x332)[0x55a6e8be4122]
[dgx-2:1963262] [29] python(_PyFunction_Vectorcall+0x6f)[0x55a6e8bf3f8f]
[dgx-2:1963262] *** End of error message ***
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --force-host-read --batch-size 8192 --epochs 5'
[WARN  tini (1968873)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-19 15:27:04.535516: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-19 15:27:08.485637: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-19 15:27:37.899053: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
Failed to transform operator <nvtabular.ops.categorify.Categorify object at 0x7f3e03ff7af0>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1780, in _encode
    ).sort_values("order")["labels"]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 2214, in sort_values
    out = self._gather(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-19 15:31:32.520493: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-19 15:31:33.104117: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f3913b28a60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-19 15:31:33.104188: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-19 15:31:33.278476: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-19 15:31:34.460220: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-19 15:31:34.829893: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.864635
Code block 'train epoch=0' took: 61069.90359 ms
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 332, in _get_next_batch
    batch = next(self._batch_itr)
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home2/faculty/pwesolowski/praca-mgr/pipelines-repo/2_merlin/run_merlin.py", line 155, in <module>
    for batch, (examples, labels) in enumerate(train_tf_ds):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/tensorflow.py", line 97, in __next__
    converted_batch = self.convert_batch(super().__next__())
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 261, in __next__
    return self._get_next_batch()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 344, in _get_next_batch
    batch = next(self._batch_itr)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 369, in make_tensors
    tensors_by_name = self._convert_df_to_tensors(gdf)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 520, in _convert_df_to_tensors
    tensors_by_name[column_name] = self._to_tensor(gdf_i[[column_name]])
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 450, in _to_tensor
    tensor = df_or_series.to_cupy()
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/single_column_frame.py", line 131, in to_cupy
    return super().to_cupy(dtype, copy, na_value).flatten()
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 533, in to_cupy
    return self._to_array(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 498, in _to_array
    matrix[:, i] = get_column_values_na(col)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 477, in get_column_values_na
    return get_column_values(col)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 534, in <lambda>
    (lambda col: col.values.copy())
  File "cupy/_core/core.pyx", line 590, in cupy._core.core._ndarray_base.copy
  File "cupy/_core/core.pyx", line 616, in cupy._core.core._ndarray_base.copy
  File "cupy/_core/core.pyx", line 575, in cupy._core.core._ndarray_base.astype
  File "cupy/_core/core.pyx", line 136, in cupy._core.core.ndarray.__new__
  File "cupy/_core/core.pyx", line 224, in cupy._core.core._ndarray_base._init
  File "cupy/cuda/memory.pyx", line 742, in cupy.cuda.memory.alloc
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/rmm/rmm.py", line 230, in rmm_cupy_allocator
    buf = librmm.device_buffer.DeviceBuffer(size=nbytes, stream=stream)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --force-host-read --batch-size 8192 --epochs 5'
[WARN  tini (1973996)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-19 15:32:25.236377: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-19 15:32:29.338259: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-19 15:32:58.260106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
Failed to transform operator <nvtabular.ops.categorify.Categorify object at 0x7efe62c6bb80>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1780, in _encode
    ).sort_values("order")["labels"]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 2214, in sort_values
    out = self._gather(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-19 15:36:52.553825: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-19 15:36:53.007248: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7ef5d78d0a30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-19 15:36:53.007308: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-19 15:36:53.169408: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-19 15:36:54.319261: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-19 15:36:54.666358: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.563906
Step #4000	Loss: 0.348257
Code block 'train epoch=0' took: 87524.22444 ms
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1780, in _encode
    ).sort_values("order")["labels"]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 2214, in sort_values
    out = self._gather(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home2/faculty/pwesolowski/praca-mgr/pipelines-repo/2_merlin/run_merlin.py", line 155, in <module>
    for batch, (examples, labels) in enumerate(train_tf_ds):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/tensorflow.py", line 97, in __next__
    converted_batch = self.convert_batch(super().__next__())
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 261, in __next__
    return self._get_next_batch()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 343, in _get_next_batch
    self._fetch_chunk()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 277, in _fetch_chunk
    raise chunks
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 791, in load_chunks
    self.chunk_logic(itr)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 759, in chunk_logic
    for chunks in self.batch(itr):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 745, in batch
    value = next(itr)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/io/dataframe_iter.py", line 44, in __iter__
    yield part.compute(scheduler="synchronous")
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/base.py", line 314, in compute
    (result,) = compute(self, traverse=False, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/base.py", line 599, in compute
    results = schedule(dsk, keys, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 557, in get_sync
    return get_async(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 500, in get_async
    for key, res_info, failed in queue_get(queue).result():
  File "/opt/conda/envs/rapids/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/opt/conda/envs/rapids/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 542, in submit
    fut.set_result(fn(*args, **kwargs))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 238, in batch_execute_tasks
    return [execute_task(*a) for a in it]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 238, in <listcomp>
    return [execute_task(*a) for a in it]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 229, in execute_task
    result = pack_exception(e, dumps)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 224, in execute_task
    result = _execute_task(task, data)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/optimization.py", line 990, in __call__
    return core.get(self.dsk, self.outkey, dict(zip(self.inkeys, args)))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 149, in get
    result = _execute_task(task, cache)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in <genexpr>
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/utils.py", line 72, in apply
    return func(*args, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 87, in transform
    transformed_data = self._execute_node(node, transformable, capture_dtypes, strict)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 101, in _execute_node
    upstream_outputs = self._run_upstream_transforms(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 114, in _run_upstream_transforms
    node_output = self._execute_node(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 107, in _execute_node
    transform_output = self._run_node_transform(node, transform_input, capture_dtypes, strict)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 227, in _run_node_transform
    raise exc
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
+ for BATCH_SIZE in 8192 16384 32768
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --force-host-read --batch-size 16384 --epochs 5'
[WARN  tini (1979542)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-19 15:38:08.375726: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-19 15:38:11.826977: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-19 15:38:39.119759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-19 15:42:34.274798: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-19 15:42:34.745884: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f55fc3f4110 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-19 15:42:34.747445: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-19 15:42:34.915700: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-19 15:42:36.064809: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-19 15:42:36.431714: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 2.394728
Step #4000	Loss: 0.323016
Step #8000	Loss: 0.337734
Step #12000	Loss: 0.430271
Step #16000	Loss: 0.426828
Step #20000	Loss: 0.327808
Step #24000	Loss: 0.326056
Step #28000	Loss: 0.350535
Step #32000	Loss: 0.303994
Step #36000	Loss: 0.361071
Step #40000	Loss: 0.377881
Step #44000	Loss: 0.368143
Step #48000	Loss: 0.309968
Step #52000	Loss: 0.340513
Step #56000	Loss: 0.333489
Step #60000	Loss: 0.325147
Step #64000	Loss: 0.375619
Step #68000	Loss: 0.439157
Step #72000	Loss: 0.433827
Step #76000	Loss: 0.435014
Step #80000	Loss: 0.344465
Step #84000	Loss: 0.418154
Step #88000	Loss: 0.305241
Step #92000	Loss: 0.316409
Step #96000	Loss: 0.429912
Step #100000	Loss: 0.332194
Step #104000	Loss: 0.334808
Step #108000	Loss: 0.381753
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 1044396.75372 ms
train loss 0.3620978593826294
Code block 'val epoch=0' took: 81140.22099 ms
validation loss 0.627262532711029
Step #0	Loss: 0.436751
Step #4000	Loss: 0.299331
Step #8000	Loss: 0.317636
Step #12000	Loss: 0.357668
Step #16000	Loss: 0.362082
Step #20000	Loss: 0.322158
Step #24000	Loss: 0.296684
Step #28000	Loss: 0.314011
Step #32000	Loss: 0.305930
Step #36000	Loss: 0.322385
Step #40000	Loss: 0.323630
Step #44000	Loss: 0.328952
Step #48000	Loss: 0.301723
Step #52000	Loss: 0.321198
Step #56000	Loss: 0.320754
Step #60000	Loss: 0.309473
Step #64000	Loss: 0.336615
Step #68000	Loss: 0.362298
Step #72000	Loss: 0.356654
Step #76000	Loss: 0.360503
Step #80000	Loss: 0.301463
Step #84000	Loss: 0.352438
Step #88000	Loss: 0.285930
Step #92000	Loss: 0.300143
Step #96000	Loss: 0.351528
Step #100000	Loss: 0.320205
Step #104000	Loss: 0.313078
Step #108000	Loss: 0.341465
Code block 'train epoch=1' took: 1016825.75302 ms
train loss 0.32507559657096863
Code block 'val epoch=1' took: 81512.23662 ms
validation loss 0.6687442064285278
Step #0	Loss: 0.331401
Step #4000	Loss: 0.294059
Step #8000	Loss: 0.309432
Step #12000	Loss: 0.329028
Step #16000	Loss: 0.317350
Step #20000	Loss: 0.318835
Step #24000	Loss: 0.291369
Step #28000	Loss: 0.311499
Step #32000	Loss: 0.284203
Step #36000	Loss: 0.292273
Step #40000	Loss: 0.310142
Step #44000	Loss: 0.308116
Step #48000	Loss: 0.292035
Step #52000	Loss: 0.315735
Step #56000	Loss: 0.306706
Step #60000	Loss: 0.299057
Step #64000	Loss: 0.314159
Step #68000	Loss: 0.331688
Step #72000	Loss: 0.324711
Step #76000	Loss: 0.334389
Step #80000	Loss: 0.295862
Step #84000	Loss: 0.324224
Step #88000	Loss: 0.283205
Step #92000	Loss: 0.302685
Step #96000	Loss: 0.321770
Step #100000	Loss: 0.312164
Step #104000	Loss: 0.306352
Step #108000	Loss: 0.323724
Code block 'train epoch=2' took: 1013289.36892 ms
train loss 0.3108891248703003
Code block 'val epoch=2' took: 80560.85535 ms
validation loss 0.7112212181091309
Step #0	Loss: 0.295289
Step #4000	Loss: 0.297214
Step #8000	Loss: 0.303572
Step #12000	Loss: 0.312752
Step #16000	Loss: 0.307111
Step #20000	Loss: 0.312841
Step #24000	Loss: 0.288548
Step #28000	Loss: 0.301529
Step #32000	Loss: 0.291309
Step #36000	Loss: 0.295811
Step #40000	Loss: 0.304688
Step #44000	Loss: 0.305681
Step #48000	Loss: 0.297191
Step #52000	Loss: 0.312172
Step #56000	Loss: 0.297021
Step #60000	Loss: 0.293979
Step #64000	Loss: 0.313236
Step #68000	Loss: 0.322508
Step #72000	Loss: 0.309260
Step #76000	Loss: 0.311469
Step #80000	Loss: 0.287232
Step #84000	Loss: 0.314750
Step #88000	Loss: 0.280671
Step #92000	Loss: 0.286532
Step #96000	Loss: 0.314221
Step #100000	Loss: 0.305956
Step #104000	Loss: 0.301380
Step #108000	Loss: 0.325845
Code block 'train epoch=3' took: 1015512.76824 ms
train loss 0.305115669965744
Code block 'val epoch=3' took: 81584.33171 ms
validation loss 0.7565086483955383
Step #0	Loss: 0.294282
Step #4000	Loss: 0.291584
Step #8000	Loss: 0.295762
Step #12000	Loss: 0.306771
Step #16000	Loss: 0.294997
Step #20000	Loss: 0.320979
Step #24000	Loss: 0.289090
Step #28000	Loss: 0.297098
Step #32000	Loss: 0.293404
Step #36000	Loss: 0.295595
Step #40000	Loss: 0.300213
Step #44000	Loss: 0.300812
Step #48000	Loss: 0.293154
Step #52000	Loss: 0.307236
Step #56000	Loss: 0.301808
Step #60000	Loss: 0.297618
Step #64000	Loss: 0.302122
Step #68000	Loss: 0.317458
Step #72000	Loss: 0.308997
Step #76000	Loss: 0.311573
Step #80000	Loss: 0.278206
Step #84000	Loss: 0.312178
Step #88000	Loss: 0.277096
Step #92000	Loss: 0.294210
Step #96000	Loss: 0.316058
Step #100000	Loss: 0.310590
Step #104000	Loss: 0.301096
Step #108000	Loss: 0.315323
Code block 'train epoch=4' took: 1017231.91438 ms
train loss 0.30229470133781433
Code block 'val epoch=4' took: 81419.08253 ms
validation loss 0.8293925523757935
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --force-host-read --batch-size 16384 --epochs 5'
[WARN  tini (2050889)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-19 17:14:26.366722: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-19 17:14:30.492841: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-19 17:15:00.989885: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-19 17:18:58.523981: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-19 17:18:59.177578: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f44330541f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-19 17:18:59.179288: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-19 17:18:59.356556: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-19 17:19:00.530783: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-19 17:19:00.876302: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.510507
Step #4000	Loss: 0.313442
Step #8000	Loss: 0.320991
Step #12000	Loss: 0.443471
Step #16000	Loss: 0.435137
Step #20000	Loss: 0.350365
Step #24000	Loss: 0.366531
Step #28000	Loss: 0.390394
Step #32000	Loss: 0.329634
Step #36000	Loss: 0.343861
Step #40000	Loss: 0.336693
Step #44000	Loss: 0.392255
Step #48000	Loss: 0.319984
Step #52000	Loss: 0.357047
Step #56000	Loss: 0.317803
Step #60000	Loss: 0.324390
Step #64000	Loss: 0.411600
Step #68000	Loss: 0.443935
Step #72000	Loss: 0.339051
Step #76000	Loss: 0.452164
Step #80000	Loss: 0.378658
Step #84000	Loss: 0.452580
Step #88000	Loss: 0.351232
Step #92000	Loss: 0.313464
Step #96000	Loss: 0.447146
Step #100000	Loss: 0.328703
Step #104000	Loss: 0.312634
Step #108000	Loss: 0.412812
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 1036625.87633 ms
train loss 0.36081454157829285
Code block 'val epoch=0' took: 80744.36645 ms
validation loss 0.6634195446968079
Step #0	Loss: 0.460740
Step #4000	Loss: 0.310125
Step #8000	Loss: 0.316634
Step #12000	Loss: 0.356111
Step #16000	Loss: 0.356337
Step #20000	Loss: 0.326462
Step #24000	Loss: 0.314039
Step #28000	Loss: 0.328225
Step #32000	Loss: 0.298547
Step #36000	Loss: 0.326068
Step #40000	Loss: 0.308130
Step #44000	Loss: 0.325657
Step #48000	Loss: 0.310026
Step #52000	Loss: 0.327014
Step #56000	Loss: 0.301025
Step #60000	Loss: 0.311124
Step #64000	Loss: 0.331501
Step #68000	Loss: 0.364899
Step #72000	Loss: 0.321734
Step #76000	Loss: 0.354318
Step #80000	Loss: 0.310130
Step #84000	Loss: 0.372885
Step #88000	Loss: 0.311619
Step #92000	Loss: 0.303249
Step #96000	Loss: 0.362667
Step #100000	Loss: 0.321075
Step #104000	Loss: 0.305627
Step #108000	Loss: 0.347544
Code block 'train epoch=1' took: 1008583.40109 ms
train loss 0.32343655824661255
Code block 'val epoch=1' took: 80439.19137 ms
validation loss 0.7107799053192139
Step #0	Loss: 0.345653
Step #4000	Loss: 0.302240
Step #8000	Loss: 0.298834
Step #12000	Loss: 0.323282
Step #16000	Loss: 0.317894
Step #20000	Loss: 0.324239
Step #24000	Loss: 0.300947
Step #28000	Loss: 0.309211
Step #32000	Loss: 0.294615
Step #36000	Loss: 0.310944
Step #40000	Loss: 0.303638
Step #44000	Loss: 0.312785
Step #48000	Loss: 0.310339
Step #52000	Loss: 0.310174
Step #56000	Loss: 0.297724
Step #60000	Loss: 0.299230
Step #64000	Loss: 0.328621
Step #68000	Loss: 0.343399
Step #72000	Loss: 0.303644
Step #76000	Loss: 0.327051
Step #80000	Loss: 0.297951
Step #84000	Loss: 0.333589
Step #88000	Loss: 0.296985
Step #92000	Loss: 0.304357
Step #96000	Loss: 0.328967
Step #100000	Loss: 0.308173
Step #104000	Loss: 0.300068
Step #108000	Loss: 0.321857
Code block 'train epoch=2' took: 1008476.86614 ms
train loss 0.3104521930217743
Code block 'val epoch=2' took: 80175.43038 ms
validation loss 0.7401033639907837
Step #0	Loss: 0.324548
Step #4000	Loss: 0.298724
Step #8000	Loss: 0.298284
Step #12000	Loss: 0.309057
Step #16000	Loss: 0.300301
Step #20000	Loss: 0.314182
Step #24000	Loss: 0.304584
Step #28000	Loss: 0.297263
Step #32000	Loss: 0.300787
Step #36000	Loss: 0.304459
Step #40000	Loss: 0.303290
Step #44000	Loss: 0.303176
Step #48000	Loss: 0.300048
Step #52000	Loss: 0.300167
Step #56000	Loss: 0.299503
Step #60000	Loss: 0.307527
Step #64000	Loss: 0.322737
Step #68000	Loss: 0.335105
Step #72000	Loss: 0.301040
Step #76000	Loss: 0.308095
Step #80000	Loss: 0.291894
Step #84000	Loss: 0.321176
Step #88000	Loss: 0.291242
Step #92000	Loss: 0.296058
Step #96000	Loss: 0.318050
Step #100000	Loss: 0.310658
Step #104000	Loss: 0.296576
Step #108000	Loss: 0.314169
Code block 'train epoch=3' took: 1006278.84433 ms
train loss 0.3051955997943878
Code block 'val epoch=3' took: 80663.24300 ms
validation loss 0.7529704570770264
Step #0	Loss: 0.324394
Step #4000	Loss: 0.287194
Step #8000	Loss: 0.297285
Step #12000	Loss: 0.309163
Step #16000	Loss: 0.297457
Step #20000	Loss: 0.309368
Step #24000	Loss: 0.300030
Step #28000	Loss: 0.304009
Step #32000	Loss: 0.291172
Step #36000	Loss: 0.296022
Step #40000	Loss: 0.298949
Step #44000	Loss: 0.308456
Step #48000	Loss: 0.291739
Step #52000	Loss: 0.308039
Step #56000	Loss: 0.295796
Step #60000	Loss: 0.297511
Step #64000	Loss: 0.308291
Step #68000	Loss: 0.321889
Step #72000	Loss: 0.306678
Step #76000	Loss: 0.310848
Step #80000	Loss: 0.288226
Step #84000	Loss: 0.312678
Step #88000	Loss: 0.283828
Step #92000	Loss: 0.296485
Step #96000	Loss: 0.321035
Step #100000	Loss: 0.309341
Step #104000	Loss: 0.290095
Step #108000	Loss: 0.306434
Code block 'train epoch=4' took: 1008633.32595 ms
train loss 0.30264711380004883
Code block 'val epoch=4' took: 80108.02323 ms
validation loss 0.7961490154266357
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --force-host-read --batch-size 16384 --epochs 5'
[WARN  tini (2127284)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-19 18:50:05.212308: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-19 18:50:09.669392: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-19 18:50:40.027290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-19 18:54:38.266937: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-19 18:54:38.725078: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f8e10944de0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-19 18:54:38.726517: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-19 18:54:38.890629: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-19 18:54:39.923363: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-19 18:54:40.233200: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.523826
Step #4000	Loss: 0.375639
Step #8000	Loss: 0.337046
Step #12000	Loss: 0.373038
Step #16000	Loss: 0.432589
Step #20000	Loss: 0.318955
Step #24000	Loss: 0.382810
Step #28000	Loss: 0.320095
Step #32000	Loss: 0.329581
Step #36000	Loss: 0.342004
Step #40000	Loss: 0.334325
Step #44000	Loss: 0.328787
Step #48000	Loss: 0.324142
Step #52000	Loss: 0.313956
Step #56000	Loss: 0.321885
Step #60000	Loss: 0.344540
Step #64000	Loss: 0.331206
Step #68000	Loss: 0.443382
Step #72000	Loss: 0.446586
Step #76000	Loss: 0.463891
Step #80000	Loss: 0.340871
Step #84000	Loss: 0.445511
Step #88000	Loss: 0.334954
Step #92000	Loss: 0.323473
Step #96000	Loss: 0.382428
Step #100000	Loss: 0.325919
Step #104000	Loss: 0.405512
Step #108000	Loss: 0.420545
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 1033915.39751 ms
train loss 0.3595663607120514
Code block 'val epoch=0' took: 80783.89168 ms
validation loss 0.6765369772911072
Step #0	Loss: 0.480310
Step #4000	Loss: 0.314654
Step #8000	Loss: 0.314261
Step #12000	Loss: 0.325748
Step #16000	Loss: 0.340902
Step #20000	Loss: 0.304636
Step #24000	Loss: 0.336800
Step #28000	Loss: 0.302479
Step #32000	Loss: 0.295328
Step #36000	Loss: 0.318391
Step #40000	Loss: 0.314486
Step #44000	Loss: 0.302630
Step #48000	Loss: 0.308828
Step #52000	Loss: 0.303067
Step #56000	Loss: 0.306276
Step #60000	Loss: 0.302230
Step #64000	Loss: 0.313162
Step #68000	Loss: 0.379695
Step #72000	Loss: 0.348950
Step #76000	Loss: 0.367840
Step #80000	Loss: 0.325210
Step #84000	Loss: 0.367116
Step #88000	Loss: 0.297123
Step #92000	Loss: 0.312369
Step #96000	Loss: 0.337819
Step #100000	Loss: 0.317020
Step #104000	Loss: 0.335950
Step #108000	Loss: 0.357205
Code block 'train epoch=1' took: 1005142.25012 ms
train loss 0.322581022977829
Code block 'val epoch=1' took: 80444.23768 ms
validation loss 0.7133705019950867
Step #0	Loss: 0.359812
Step #4000	Loss: 0.298355
Step #8000	Loss: 0.306074
Step #12000	Loss: 0.318764
Step #16000	Loss: 0.314891
Step #20000	Loss: 0.305470
Step #24000	Loss: 0.296920
Step #28000	Loss: 0.300478
Step #32000	Loss: 0.285348
Step #36000	Loss: 0.301784
Step #40000	Loss: 0.303989
Step #44000	Loss: 0.307101
Step #48000	Loss: 0.303487
Step #52000	Loss: 0.302025
Step #56000	Loss: 0.292562
Step #60000	Loss: 0.302096
Step #64000	Loss: 0.319224
Step #68000	Loss: 0.341334
Step #72000	Loss: 0.320238
Step #76000	Loss: 0.337305
Step #80000	Loss: 0.323327
Step #84000	Loss: 0.332449
Step #88000	Loss: 0.295914
Step #92000	Loss: 0.291954
Step #96000	Loss: 0.321139
Step #100000	Loss: 0.310146
Step #104000	Loss: 0.319111
Step #108000	Loss: 0.324068
Code block 'train epoch=2' took: 1004498.21134 ms
train loss 0.309932142496109
Code block 'val epoch=2' took: 80431.28695 ms
validation loss 0.7971677184104919
Step #0	Loss: 0.334348
Step #4000	Loss: 0.289092
Step #8000	Loss: 0.302982
Step #12000	Loss: 0.302448
Step #16000	Loss: 0.288811
Step #20000	Loss: 0.303036
Step #24000	Loss: 0.292944
Step #28000	Loss: 0.306486
Step #32000	Loss: 0.289639
Step #36000	Loss: 0.298858
Step #40000	Loss: 0.303153
Step #44000	Loss: 0.305576
Step #48000	Loss: 0.301642
Step #52000	Loss: 0.296678
Step #56000	Loss: 0.292502
Step #60000	Loss: 0.293179
Step #64000	Loss: 0.308722
Step #68000	Loss: 0.329903
Step #72000	Loss: 0.312587
Step #76000	Loss: 0.315998
Step #80000	Loss: 0.308566
Step #84000	Loss: 0.321714
Step #88000	Loss: 0.286358
Step #92000	Loss: 0.283602
Step #96000	Loss: 0.318849
Step #100000	Loss: 0.308978
Step #104000	Loss: 0.313187
Step #108000	Loss: 0.323257
Code block 'train epoch=3' took: 1006360.08179 ms
train loss 0.30472925305366516
Code block 'val epoch=3' took: 80157.20633 ms
validation loss 0.8304387331008911
Step #0	Loss: 0.315008
Step #4000	Loss: 0.295878
Step #8000	Loss: 0.297610
Step #12000	Loss: 0.307859
Step #16000	Loss: 0.292866
Step #20000	Loss: 0.301032
Step #24000	Loss: 0.291146
Step #28000	Loss: 0.294168
Step #32000	Loss: 0.283814
Step #36000	Loss: 0.293335
Step #40000	Loss: 0.294684
Step #44000	Loss: 0.304304
Step #48000	Loss: 0.296997
Step #52000	Loss: 0.298793
Step #56000	Loss: 0.295203
Step #60000	Loss: 0.290947
Step #64000	Loss: 0.309727
Step #68000	Loss: 0.325566
Step #72000	Loss: 0.304969
Step #76000	Loss: 0.307212
Step #80000	Loss: 0.310870
Step #84000	Loss: 0.310069
Step #88000	Loss: 0.286554
Step #92000	Loss: 0.295937
Step #96000	Loss: 0.311644
Step #100000	Loss: 0.308644
Step #104000	Loss: 0.310792
Step #108000	Loss: 0.313697
Code block 'train epoch=4' took: 1005867.73281 ms
train loss 0.30203890800476074
Code block 'val epoch=4' took: 79761.58610 ms
validation loss 0.9018481373786926
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --force-host-read --batch-size 16384 --epochs 5'
[WARN  tini (2199255)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-19 20:25:27.591775: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-19 20:25:31.319504: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-19 20:25:59.509552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-19 20:29:47.119886: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-19 20:29:47.565285: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fbc01ef3810 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-19 20:29:47.566470: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-19 20:29:47.713823: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-19 20:29:48.756358: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-19 20:29:49.085719: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 3.112525
Step #4000	Loss: 0.358630
Step #8000	Loss: 0.316032
Step #12000	Loss: 0.438593
Step #16000	Loss: 0.437246
Step #20000	Loss: 0.352264
Step #24000	Loss: 0.356371
Step #28000	Loss: 0.394863
Step #32000	Loss: 0.341999
Step #36000	Loss: 0.373857
Step #40000	Loss: 0.410643
Step #44000	Loss: 0.391861
Step #48000	Loss: 0.365181
Step #52000	Loss: 0.325436
Step #56000	Loss: 0.331102
Step #60000	Loss: 0.315193
Step #64000	Loss: 0.385949
Step #68000	Loss: 0.455745
Step #72000	Loss: 0.341718
Step #76000	Loss: 0.341995
Step #80000	Loss: 0.388085
Step #84000	Loss: 0.350217
Step #88000	Loss: 0.346589
Step #92000	Loss: 0.308030
Step #96000	Loss: 0.440638
Step #100000	Loss: 0.326486
Step #104000	Loss: 0.316709
Step #108000	Loss: 0.411157
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 1020952.72182 ms
train loss 0.3603445291519165
Code block 'val epoch=0' took: 77496.39938 ms
validation loss 0.5926899313926697
Step #0	Loss: 0.465525
Step #4000	Loss: 0.314106
Step #8000	Loss: 0.308091
Step #12000	Loss: 0.359519
Step #16000	Loss: 0.361062
Step #20000	Loss: 0.323929
Step #24000	Loss: 0.322293
Step #28000	Loss: 0.343335
Step #32000	Loss: 0.300476
Step #36000	Loss: 0.329661
Step #40000	Loss: 0.336631
Step #44000	Loss: 0.331944
Step #48000	Loss: 0.321527
Step #52000	Loss: 0.305786
Step #56000	Loss: 0.308574
Step #60000	Loss: 0.304111
Step #64000	Loss: 0.337367
Step #68000	Loss: 0.362405
Step #72000	Loss: 0.318960
Step #76000	Loss: 0.314479
Step #80000	Loss: 0.324453
Step #84000	Loss: 0.321990
Step #88000	Loss: 0.309707
Step #92000	Loss: 0.299538
Step #96000	Loss: 0.367774
Step #100000	Loss: 0.315465
Step #104000	Loss: 0.297622
Step #108000	Loss: 0.344509
Code block 'train epoch=1' took: 993991.11199 ms
train loss 0.3233778774738312
Code block 'val epoch=1' took: 77915.53767 ms
validation loss 0.6539854407310486
Step #0	Loss: 0.330968
Step #4000	Loss: 0.303830
Step #8000	Loss: 0.310358
Step #12000	Loss: 0.320936
Step #16000	Loss: 0.320797
Step #20000	Loss: 0.321976
Step #24000	Loss: 0.298270
Step #28000	Loss: 0.315183
Step #32000	Loss: 0.291418
Step #36000	Loss: 0.320198
Step #40000	Loss: 0.320174
Step #44000	Loss: 0.313348
Step #48000	Loss: 0.314846
Step #52000	Loss: 0.295987
Step #56000	Loss: 0.302959
Step #60000	Loss: 0.298311
Step #64000	Loss: 0.319908
Step #68000	Loss: 0.345905
Step #72000	Loss: 0.300924
Step #76000	Loss: 0.306508
Step #80000	Loss: 0.303510
Step #84000	Loss: 0.311927
Step #88000	Loss: 0.295820
Step #92000	Loss: 0.292527
Step #96000	Loss: 0.337475
Step #100000	Loss: 0.311802
Step #104000	Loss: 0.311069
Step #108000	Loss: 0.322934
Code block 'train epoch=2' took: 993689.02928 ms
train loss 0.3103683292865753
Code block 'val epoch=2' took: 77862.20576 ms
validation loss 0.7433866262435913
Step #0	Loss: 0.311806
Step #4000	Loss: 0.293058
Step #8000	Loss: 0.299997
Step #12000	Loss: 0.307116
Step #16000	Loss: 0.303791
Step #20000	Loss: 0.313290
Step #24000	Loss: 0.301191
Step #28000	Loss: 0.303623
Step #32000	Loss: 0.288495
Step #36000	Loss: 0.298943
Step #40000	Loss: 0.302367
Step #44000	Loss: 0.307960
Step #48000	Loss: 0.315139
Step #52000	Loss: 0.294710
Step #56000	Loss: 0.300468
Step #60000	Loss: 0.299010
Step #64000	Loss: 0.313672
Step #68000	Loss: 0.335108
Step #72000	Loss: 0.295948
Step #76000	Loss: 0.303963
Step #80000	Loss: 0.296609
Step #84000	Loss: 0.310076
Step #88000	Loss: 0.292820
Step #92000	Loss: 0.297813
Step #96000	Loss: 0.312737
Step #100000	Loss: 0.306992
Step #104000	Loss: 0.288929
Step #108000	Loss: 0.318369
Code block 'train epoch=3' took: 992579.70214 ms
train loss 0.3047265112400055
Code block 'val epoch=3' took: 76923.64864 ms
validation loss 0.7522380352020264
Step #0	Loss: 0.320256
Step #4000	Loss: 0.288384
Step #8000	Loss: 0.292231
Step #12000	Loss: 0.310134
Step #16000	Loss: 0.292691
Step #20000	Loss: 0.305023
Step #24000	Loss: 0.294044
Step #28000	Loss: 0.304048
Step #32000	Loss: 0.295280
Step #36000	Loss: 0.290547
Step #40000	Loss: 0.298596
Step #44000	Loss: 0.301462
Step #48000	Loss: 0.309191
Step #52000	Loss: 0.292742
Step #56000	Loss: 0.296205
Step #60000	Loss: 0.296520
Step #64000	Loss: 0.300951
Step #68000	Loss: 0.320828
Step #72000	Loss: 0.302052
Step #76000	Loss: 0.304991
Step #80000	Loss: 0.298365
Step #84000	Loss: 0.304149
Step #88000	Loss: 0.290708
Step #92000	Loss: 0.290197
Step #96000	Loss: 0.305843
Step #100000	Loss: 0.294997
Step #104000	Loss: 0.290569
Step #108000	Loss: 0.317265
Code block 'train epoch=4' took: 993874.92439 ms
train loss 0.30209338665008545
Code block 'val epoch=4' took: 78553.95319 ms
validation loss 0.8116544485092163
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --force-host-read --batch-size 16384 --epochs 5'
[WARN  tini (2268659)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-19 21:59:29.803611: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-19 21:59:33.483013: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-19 22:00:02.577277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-19 22:03:52.413507: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-19 22:03:52.962549: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fe47274b3c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-19 22:03:52.964094: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-19 22:03:53.138176: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-19 22:03:54.142505: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-19 22:03:54.474714: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 2.247911
Step #4000	Loss: 2.974644
Step #8000	Loss: 2.804319
Step #12000	Loss: 3.075164
Step #16000	Loss: 2.758712
Step #20000	Loss: 3.125424
Step #24000	Loss: 2.753128
Step #28000	Loss: 3.122632
Step #32000	Loss: 2.736375
Step #36000	Loss: 2.667500
Step #40000	Loss: 3.162653
Step #44000	Loss: 3.225944
Step #48000	Loss: 3.016527
Step #52000	Loss: 3.041657
Step #56000	Loss: 2.993259
Step #60000	Loss: 2.977436
Step #64000	Loss: 3.014666
Step #68000	Loss: 3.072371
Step #72000	Loss: 3.121701
Step #76000	Loss: 2.989536
Step #80000	Loss: 2.844340
Step #84000	Loss: 3.114255
Step #88000	Loss: 3.094709
Step #92000	Loss: 2.717760
Step #96000	Loss: 3.199883
Step #100000	Loss: 3.102155
Step #104000	Loss: 2.954168
Step #108000	Loss: 3.133801
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 1014358.60441 ms
train loss 3.012582778930664
Code block 'val epoch=0' took: 78250.79493 ms
validation loss 3.013411521911621
Step #0	Loss: 3.218498
Step #4000	Loss: 2.996982
Step #8000	Loss: 2.761505
Step #12000	Loss: 2.932761
Step #16000	Loss: 2.804318
Step #20000	Loss: 2.987674
Step #24000	Loss: 2.799665
Step #28000	Loss: 3.097502
Step #32000	Loss: 2.795942
Step #36000	Loss: 2.653539
Step #40000	Loss: 3.140316
Step #44000	Loss: 3.188714
Step #48000	Loss: 3.075164
Step #52000	Loss: 2.996051
Step #56000	Loss: 2.916938
Step #60000	Loss: 2.982090
Step #64000	Loss: 2.959752
Step #68000	Loss: 3.100294
Step #72000	Loss: 3.056549
Step #76000	Loss: 2.933691
Step #80000	Loss: 2.831310
Step #84000	Loss: 3.143108
Step #88000	Loss: 2.983951
Step #92000	Loss: 2.687046
Step #96000	Loss: 3.228736
Step #100000	Loss: 3.108670
Step #104000	Loss: 2.956960
Step #108000	Loss: 3.144039
Code block 'train epoch=1' took: 988925.54195 ms
train loss 3.0126168727874756
Code block 'val epoch=1' took: 77897.60341 ms
validation loss 3.013411521911621
Step #0	Loss: 3.267827
Step #4000	Loss: 2.981159
Step #8000	Loss: 2.846202
Step #12000	Loss: 3.143108
Step #16000	Loss: 2.819211
Step #20000	Loss: 3.053757
Step #24000	Loss: 2.871332
Step #28000	Loss: 3.103086
Step #32000	Loss: 2.817349
Step #36000	Loss: 2.670292
Step #40000	Loss: 3.131008
Step #44000	Loss: 3.247351
Step #48000	Loss: 3.010012
Step #52000	Loss: 2.989536
Step #56000	Loss: 2.923453
Step #60000	Loss: 3.022111
Step #64000	Loss: 2.968129
Step #68000	Loss: 3.172892
Step #72000	Loss: 3.140316
Step #76000	Loss: 2.919730
Step #80000	Loss: 2.893670
Step #84000	Loss: 3.162653
Step #88000	Loss: 3.094709
Step #92000	Loss: 2.720552
Step #96000	Loss: 3.181268
Step #100000	Loss: 3.147762
Step #104000	Loss: 2.935553
Step #108000	Loss: 3.060272
Code block 'train epoch=2' took: 990304.24626 ms
train loss 3.012596368789673
Code block 'val epoch=2' took: 77734.43396 ms
validation loss 3.013411521911621
Step #0	Loss: 3.305057
Step #4000	Loss: 2.948583
Step #8000	Loss: 2.777327
Step #12000	Loss: 2.987674
Step #16000	Loss: 2.807111
Step #20000	Loss: 3.024904
Step #24000	Loss: 2.754059
Step #28000	Loss: 3.110532
Step #32000	Loss: 2.781981
Step #36000	Loss: 2.672153
Step #40000	Loss: 3.184991
Step #44000	Loss: 3.114255
Step #48000	Loss: 3.071441
Step #52000	Loss: 2.987674
Step #56000	Loss: 2.951375
Step #60000	Loss: 3.025835
Step #64000	Loss: 2.954168
Step #68000	Loss: 3.093779
Step #72000	Loss: 3.070510
Step #76000	Loss: 2.929968
Step #80000	Loss: 2.848063
Step #84000	Loss: 3.145900
Step #88000	Loss: 3.063995
Step #92000	Loss: 2.656331
Step #96000	Loss: 3.223151
Step #100000	Loss: 3.170099
Step #104000	Loss: 2.845271
Step #108000	Loss: 3.083540
Code block 'train epoch=3' took: 989431.25399 ms
train loss 3.0125792026519775
Code block 'val epoch=3' took: 76616.25804 ms
validation loss 3.013411521911621
Step #0	Loss: 3.287372
Step #4000	Loss: 2.926245
Step #8000	Loss: 2.687046
Step #12000	Loss: 2.992328
Step #16000	Loss: 2.744751
Step #20000	Loss: 3.074233
Step #24000	Loss: 2.843410
Step #28000	Loss: 3.116117
Step #32000	Loss: 2.778258
Step #36000	Loss: 2.624686
Step #40000	Loss: 3.152415
Step #44000	Loss: 3.125424
Step #48000	Loss: 3.030488
Step #52000	Loss: 2.983021
Step #56000	Loss: 2.947652
Step #60000	Loss: 2.980228
Step #64000	Loss: 2.942999
Step #68000	Loss: 3.124493
Step #72000	Loss: 3.019320
Step #76000	Loss: 3.029558
Step #80000	Loss: 2.819211
Step #84000	Loss: 3.130077
Step #88000	Loss: 3.034211
Step #92000	Loss: 2.663777
Step #96000	Loss: 3.305057
Step #100000	Loss: 3.066787
Step #104000	Loss: 2.971852
Step #108000	Loss: 3.080748
Code block 'train epoch=4' took: 991843.15605 ms
train loss 3.012596845626831
Code block 'val epoch=4' took: 78444.09843 ms
validation loss 3.013411521911621
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --force-host-read --batch-size 16384 --epochs 5'
[WARN  tini (2338363)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-19 23:33:12.202054: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-19 23:33:15.648655: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-19 23:33:43.191257: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-19 23:37:39.386776: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-19 23:37:40.016978: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fc7a391d920 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-19 23:37:40.017154: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-19 23:37:40.175066: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-19 23:37:41.249437: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-19 23:37:41.597121: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.939859
Step #4000	Loss: 0.307514
Step #8000	Loss: 0.329007
Step #12000	Loss: 0.440314
Step #16000	Loss: 0.345796
Step #20000	Loss: 0.321278
Step #24000	Loss: 0.306203
Step #28000	Loss: 0.438936
Step #32000	Loss: 0.342240
Step #36000	Loss: 0.395762
Step #40000	Loss: 0.337353
Step #44000	Loss: 0.367059
Step #48000	Loss: 0.377284
Step #52000	Loss: 0.315430
Step #56000	Loss: 0.342403
Step #60000	Loss: 0.347223
Step #64000	Loss: 0.360383
Step #68000	Loss: 0.450671
Step #72000	Loss: 0.334430
Step #76000	Loss: 0.410397
Step #80000	Loss: 0.346276
Step #84000	Loss: 0.352140
Step #88000	Loss: 0.331741
Step #92000	Loss: 0.353776
Step #96000	Loss: 0.342471
Step #100000	Loss: 0.331914
Step #104000	Loss: 0.316331
Step #108000	Loss: 0.358729
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 1023999.00436 ms
train loss 0.35911333560943604
Code block 'val epoch=0' took: 78228.47043 ms
validation loss 0.6253565549850464
Step #0	Loss: 0.479240
Step #4000	Loss: 0.302749
Step #8000	Loss: 0.314760
Step #12000	Loss: 0.351376
Step #16000	Loss: 0.310216
Step #20000	Loss: 0.315806
Step #24000	Loss: 0.290334
Step #28000	Loss: 0.349955
Step #32000	Loss: 0.312013
Step #36000	Loss: 0.326038
Step #40000	Loss: 0.313774
Step #44000	Loss: 0.316184
Step #48000	Loss: 0.333871
Step #52000	Loss: 0.302809
Step #56000	Loss: 0.313051
Step #60000	Loss: 0.322175
Step #64000	Loss: 0.332484
Step #68000	Loss: 0.361614
Step #72000	Loss: 0.302112
Step #76000	Loss: 0.333775
Step #80000	Loss: 0.315355
Step #84000	Loss: 0.322272
Step #88000	Loss: 0.301102
Step #92000	Loss: 0.324047
Step #96000	Loss: 0.332229
Step #100000	Loss: 0.314403
Step #104000	Loss: 0.301340
Step #108000	Loss: 0.324513
Code block 'train epoch=1' took: 997178.05827 ms
train loss 0.320678174495697
Code block 'val epoch=1' took: 77038.37593 ms
validation loss 0.6633208394050598
Step #0	Loss: 0.375773
Step #4000	Loss: 0.301528
Step #8000	Loss: 0.303874
Step #12000	Loss: 0.317325
Step #16000	Loss: 0.307979
Step #20000	Loss: 0.302649
Step #24000	Loss: 0.293688
Step #28000	Loss: 0.311903
Step #32000	Loss: 0.303823
Step #36000	Loss: 0.303381
Step #40000	Loss: 0.308198
Step #44000	Loss: 0.309040
Step #48000	Loss: 0.318507
Step #52000	Loss: 0.303537
Step #56000	Loss: 0.310309
Step #60000	Loss: 0.309760
Step #64000	Loss: 0.320698
Step #68000	Loss: 0.341838
Step #72000	Loss: 0.297888
Step #76000	Loss: 0.314800
Step #80000	Loss: 0.316413
Step #84000	Loss: 0.315189
Step #88000	Loss: 0.290881
Step #92000	Loss: 0.314138
Step #96000	Loss: 0.321418
Step #100000	Loss: 0.309350
Step #104000	Loss: 0.294776
Step #108000	Loss: 0.311651
Code block 'train epoch=2' took: 997281.65883 ms
train loss 0.30887851119041443
Code block 'val epoch=2' took: 77205.19556 ms
validation loss 0.7159980535507202
Step #0	Loss: 0.357513
Step #4000	Loss: 0.296362
Step #8000	Loss: 0.291432
Step #12000	Loss: 0.308724
Step #16000	Loss: 0.291064
Step #20000	Loss: 0.309619
Step #24000	Loss: 0.288167
Step #28000	Loss: 0.312099
Step #32000	Loss: 0.289245
Step #36000	Loss: 0.296088
Step #40000	Loss: 0.304312
Step #44000	Loss: 0.305908
Step #48000	Loss: 0.311407
Step #52000	Loss: 0.306095
Step #56000	Loss: 0.303141
Step #60000	Loss: 0.304531
Step #64000	Loss: 0.309131
Step #68000	Loss: 0.323010
Step #72000	Loss: 0.296202
Step #76000	Loss: 0.310485
Step #80000	Loss: 0.308073
Step #84000	Loss: 0.305625
Step #88000	Loss: 0.293414
Step #92000	Loss: 0.304826
Step #96000	Loss: 0.319326
Step #100000	Loss: 0.309977
Step #104000	Loss: 0.292281
Step #108000	Loss: 0.309493
Code block 'train epoch=3' took: 997352.28534 ms
train loss 0.3042120337486267
Code block 'val epoch=3' took: 77215.28046 ms
validation loss 0.7272120118141174
Step #0	Loss: 0.337991
Step #4000	Loss: 0.282602
Step #8000	Loss: 0.293213
Step #12000	Loss: 0.301383
Step #16000	Loss: 0.286524
Step #20000	Loss: 0.298813
Step #24000	Loss: 0.285910
Step #28000	Loss: 0.293478
Step #32000	Loss: 0.290341
Step #36000	Loss: 0.285176
Step #40000	Loss: 0.300908
Step #44000	Loss: 0.307653
Step #48000	Loss: 0.310940
Step #52000	Loss: 0.306755
Step #56000	Loss: 0.300282
Step #60000	Loss: 0.296700
Step #64000	Loss: 0.311111
Step #68000	Loss: 0.317595
Step #72000	Loss: 0.289107
Step #76000	Loss: 0.308334
Step #80000	Loss: 0.310387
Step #84000	Loss: 0.305262
Step #88000	Loss: 0.290474
Step #92000	Loss: 0.294275
Step #96000	Loss: 0.315350
Step #100000	Loss: 0.312601
Step #104000	Loss: 0.300117
Step #108000	Loss: 0.305129
Code block 'train epoch=4' took: 997439.57497 ms
train loss 0.3017154633998871
Code block 'val epoch=4' took: 77139.99978 ms
validation loss 0.7821038961410522
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --force-host-read --batch-size 16384 --epochs 5'
[WARN  tini (2408730)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-20 01:07:28.094888: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-20 01:07:31.391853: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-20 01:07:58.881277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-20 01:11:50.263015: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-20 01:11:50.764550: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f46fb486ae0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-20 01:11:50.766004: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-20 01:11:50.948791: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-20 01:11:51.988926: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-20 01:11:52.316856: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.532197
Step #4000	Loss: 0.378369
terminate called after throwing an instance of 'rmm::out_of_memory'
  what():  std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp
[dgx-2:2408753] *** Process received signal ***
[dgx-2:2408753] Signal: Aborted (6)
[dgx-2:2408753] Signal code:  (-6)
[dgx-2:2408753] [ 0] /lib/x86_64-linux-gnu/libc.so.6(+0x42520)[0x7f50d6922520]
[dgx-2:2408753] [ 1] /lib/x86_64-linux-gnu/libc.so.6(pthread_kill+0x12c)[0x7f50d6976a7c]
[dgx-2:2408753] [ 2] /lib/x86_64-linux-gnu/libc.so.6(raise+0x16)[0x7f50d6922476]
[dgx-2:2408753] [ 3] /lib/x86_64-linux-gnu/libc.so.6(abort+0xd3)[0x7f50d69087f3]
[dgx-2:2408753] [ 4] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(_ZN9__gnu_cxx27__verbose_terminate_handlerEv+0xc0)[0x7f50d3a90026]
[dgx-2:2408753] [ 5] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(+0xb0514)[0x7f50d3a8e514]
[dgx-2:2408753] [ 6] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(+0xb0566)[0x7f50d3a8e566]
[dgx-2:2408753] [ 7] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(__cxa_rethrow+0x0)[0x7f50d3a8e758]
[dgx-2:2408753] [ 8] /opt/conda/envs/rapids/lib/python3.10/site-packages/rmm/_lib/device_buffer.cpython-310-x86_64-linux-gnu.so(+0x4b67d)[0x7f4fac08167d]
[dgx-2:2408753] [ 9] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf19make_numeric_columnENS_9data_typeEiNS_10mask_stateEN3rmm16cuda_stream_viewEPNS2_2mr22device_memory_resourceE+0x126)[0x7f4ea3ae20c6]
[dgx-2:2408753] [10] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf7strings6detail25create_chars_child_columnEiN3rmm16cuda_stream_viewEPNS2_2mr22device_memory_resourceE+0x19)[0x7f4ea51ffa29]
[dgx-2:2408753] [11] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf7strings6detail19make_strings_columnIPKN6thrust4pairIPKciEEEESt10unique_ptrINS_6columnESt14default_deleteISB_EET_SF_N3rmm16cuda_stream_viewEPNSG_2mr22device_memory_resourceE+0x47a)[0x7f4ea51f937a]
[dgx-2:2408753] [12] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf19make_strings_columnENS_11device_spanIKN6thrust4pairIPKciEELm18446744073709551615EEEN3rmm16cuda_stream_viewEPNS8_2mr22device_memory_resourceE+0x83)[0x7f4ea51f4603]
[dgx-2:2408753] [13] /home2/faculty/pwesolowski/praca-mgr/parser-repo/build/libmeta-cudf-parser-1.so(_ZNK18ParserOutputDeviceI5JDictIN5boost4mp117mp_listIJNS3_IJNS3_IJSt17integral_constantIiLi117EES4_IiLi115EES4_IiLi101EES4_IiLi114EES4_IiLi95EES4_IiLi105EES4_IiLi100EEEEE17JStringStaticCopyIS4_IiLi21EESC_NS3_IJEEEEEEENS3_IJNS3_IJS4_IiLi103EES4_IiLi109EES4_IiLi97EES4_IiLi112EES9_SA_SB_EEESD_IS4_IiLi37EESM_SF_EEEENS3_IJNS3_IJS8_SK_S4_IiLi116EESA_S4_IiLi110EESI_EEE7JNumberIhSS_SF_EEEENS3_IJNS3_IJS4_IiLi99EESK_SQ_S7_SI_S4_IiLi111EES8_S4_IiLi121EEEEESD_IS4_IiLi470EESZ_SF_EEEENS3_IJNS3_IJS4_IiLi108EESK_SQ_SA_SQ_S5_SB_S7_EEE11JRealNumberIfS14_SF_EEEENS3_IJNS3_IJS13_SX_SR_SI_SA_SQ_S5_SB_S7_EEES15_IfS18_SF_EEEEEEESF_EE6ToCudfEN3rmm16cuda_stream_viewEPNS1E_2mr22device_memory_resourceE+0x505)[0x7f4901c643a5]
[dgx-2:2408753] [14] /home2/faculty/pwesolowski/praca-mgr/parser-repo/build/libmeta-cudf-parser-1.so(_Z25generate_example_metadataPKcmmi11end_of_linebb+0x1cf)[0x7f4901c5bbcf]
[dgx-2:2408753] [15] /home2/faculty/pwesolowski/praca-mgr/parser-repo/python_binding/metajsonparser/_lib/json_cudf.cpython-310-x86_64-linux-gnu.so(+0x4b344)[0x7f4901d33344]
[dgx-2:2408753] [16] python(+0x13fb27)[0x5600e2a57b27]
[dgx-2:2408753] [17] python(PyObject_Call+0x209)[0x5600e2a64139]
[dgx-2:2408753] [18] python(_PyEval_EvalFrameDefault+0x5d8c)[0x5600e2a4db7c]
[dgx-2:2408753] [19] python(_PyFunction_Vectorcall+0x6f)[0x5600e2a57f8f]
[dgx-2:2408753] [20] python(_PyEval_EvalFrameDefault+0x2ec2)[0x5600e2a4acb2]
[dgx-2:2408753] [21] python(_PyFunction_Vectorcall+0x6f)[0x5600e2a57f8f]
[dgx-2:2408753] [22] python(_PyEval_EvalFrameDefault+0x332)[0x5600e2a48122]
[dgx-2:2408753] [23] python(_PyFunction_Vectorcall+0x6f)[0x5600e2a57f8f]
[dgx-2:2408753] [24] python(_PyEval_EvalFrameDefault+0x2ec2)[0x5600e2a4acb2]
[dgx-2:2408753] [25] python(_PyFunction_Vectorcall+0x6f)[0x5600e2a57f8f]
[dgx-2:2408753] [26] python(_PyEval_EvalFrameDefault+0x332)[0x5600e2a48122]
[dgx-2:2408753] [27] python(_PyFunction_Vectorcall+0x6f)[0x5600e2a57f8f]
[dgx-2:2408753] [28] python(_PyEval_EvalFrameDefault+0x2ec2)[0x5600e2a4acb2]
[dgx-2:2408753] [29] python(+0x14b641)[0x5600e2a63641]
[dgx-2:2408753] *** End of error message ***
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --force-host-read --batch-size 16384 --epochs 5'
[WARN  tini (2413914)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-20 01:12:55.035250: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-20 01:12:58.712901: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-20 01:13:27.880685: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
Failed to transform operator <nvtabular.ops.categorify.Categorify object at 0x7faea698faf0>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1778, in _encode
    labels = codes.merge(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/dataframe.py", line 4004, in merge
    ).perform_merge()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/join/join.py", line 203, in perform_merge
    self.rhs._gather(gather_map=right_rows, **gather_kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-20 01:17:24.443548: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-20 01:17:25.078163: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7faa96aadb20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-20 01:17:25.079698: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-20 01:17:25.286194: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-20 01:17:26.532173: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-20 01:17:26.945319: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.817349
Code block 'train epoch=0' took: 51952.36965 ms
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 332, in _get_next_batch
    batch = next(self._batch_itr)
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home2/faculty/pwesolowski/praca-mgr/pipelines-repo/2_merlin/run_merlin.py", line 155, in <module>
    for batch, (examples, labels) in enumerate(train_tf_ds):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/tensorflow.py", line 97, in __next__
    converted_batch = self.convert_batch(super().__next__())
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 261, in __next__
    return self._get_next_batch()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 344, in _get_next_batch
    batch = next(self._batch_itr)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 369, in make_tensors
    tensors_by_name = self._convert_df_to_tensors(gdf)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 520, in _convert_df_to_tensors
    tensors_by_name[column_name] = self._to_tensor(gdf_i[[column_name]])
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 450, in _to_tensor
    tensor = df_or_series.to_cupy()
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/single_column_frame.py", line 131, in to_cupy
    return super().to_cupy(dtype, copy, na_value).flatten()
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 533, in to_cupy
    return self._to_array(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 498, in _to_array
    matrix[:, i] = get_column_values_na(col)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 477, in get_column_values_na
    return get_column_values(col)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 534, in <lambda>
    (lambda col: col.values.copy())
  File "cupy/_core/core.pyx", line 590, in cupy._core.core._ndarray_base.copy
  File "cupy/_core/core.pyx", line 616, in cupy._core.core._ndarray_base.copy
  File "cupy/_core/core.pyx", line 575, in cupy._core.core._ndarray_base.astype
  File "cupy/_core/core.pyx", line 136, in cupy._core.core.ndarray.__new__
  File "cupy/_core/core.pyx", line 224, in cupy._core.core._ndarray_base._init
  File "cupy/cuda/memory.pyx", line 742, in cupy.cuda.memory.alloc
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/rmm/rmm.py", line 230, in rmm_cupy_allocator
    buf = librmm.device_buffer.DeviceBuffer(size=nbytes, stream=stream)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --force-host-read --batch-size 16384 --epochs 5'
[WARN  tini (2418980)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-20 01:18:04.682611: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-20 01:18:08.386348: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-20 01:18:37.796729: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
Failed to transform operator <nvtabular.ops.categorify.Categorify object at 0x7f281fa83b20>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1778, in _encode
    labels = codes.merge(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/dataframe.py", line 4004, in merge
    ).perform_merge()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/join/join.py", line 203, in perform_merge
    self.rhs._gather(gather_map=right_rows, **gather_kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-20 01:22:35.721250: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-20 01:22:36.378718: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f2606115120 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-20 01:22:36.380267: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-20 01:22:36.559747: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-20 01:22:37.712208: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-20 01:22:38.060427: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 1.501281
Code block 'train epoch=0' took: 65331.51176 ms
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1778, in _encode
    labels = codes.merge(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/dataframe.py", line 4004, in merge
    ).perform_merge()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/join/join.py", line 203, in perform_merge
    self.rhs._gather(gather_map=right_rows, **gather_kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home2/faculty/pwesolowski/praca-mgr/pipelines-repo/2_merlin/run_merlin.py", line 155, in <module>
    for batch, (examples, labels) in enumerate(train_tf_ds):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/tensorflow.py", line 97, in __next__
    converted_batch = self.convert_batch(super().__next__())
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 261, in __next__
    return self._get_next_batch()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 343, in _get_next_batch
    self._fetch_chunk()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 277, in _fetch_chunk
    raise chunks
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 791, in load_chunks
    self.chunk_logic(itr)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 759, in chunk_logic
    for chunks in self.batch(itr):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 745, in batch
    value = next(itr)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/io/dataframe_iter.py", line 44, in __iter__
    yield part.compute(scheduler="synchronous")
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/base.py", line 314, in compute
    (result,) = compute(self, traverse=False, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/base.py", line 599, in compute
    results = schedule(dsk, keys, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 557, in get_sync
    return get_async(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 500, in get_async
    for key, res_info, failed in queue_get(queue).result():
  File "/opt/conda/envs/rapids/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/opt/conda/envs/rapids/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 542, in submit
    fut.set_result(fn(*args, **kwargs))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 238, in batch_execute_tasks
    return [execute_task(*a) for a in it]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 238, in <listcomp>
    return [execute_task(*a) for a in it]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 229, in execute_task
    result = pack_exception(e, dumps)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 224, in execute_task
    result = _execute_task(task, data)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/optimization.py", line 990, in __call__
    return core.get(self.dsk, self.outkey, dict(zip(self.inkeys, args)))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 149, in get
    result = _execute_task(task, cache)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in <genexpr>
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/utils.py", line 72, in apply
    return func(*args, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 87, in transform
    transformed_data = self._execute_node(node, transformable, capture_dtypes, strict)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 101, in _execute_node
    upstream_outputs = self._run_upstream_transforms(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 114, in _run_upstream_transforms
    node_output = self._execute_node(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 107, in _execute_node
    transform_output = self._run_node_transform(node, transform_input, capture_dtypes, strict)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 227, in _run_node_transform
    raise exc
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
+ for BATCH_SIZE in 8192 16384 32768
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --force-host-read --batch-size 32768 --epochs 5'
[WARN  tini (2424160)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-20 01:23:28.343187: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-20 01:23:31.671388: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-20 01:23:59.753520: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-20 01:27:54.516289: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-20 01:27:54.997557: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fed54a04d40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-20 01:27:54.997673: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-20 01:27:55.163948: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-20 01:27:56.199941: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-20 01:27:56.532920: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.854032
Step #4000	Loss: 0.339201
Step #8000	Loss: 0.438903
Step #12000	Loss: 0.330588
Step #16000	Loss: 0.306794
Step #20000	Loss: 0.372050
Step #24000	Loss: 0.317733
Step #28000	Loss: 0.329911
Step #32000	Loss: 0.378132
Step #36000	Loss: 0.427035
Step #40000	Loss: 0.349862
Step #44000	Loss: 0.307818
Step #48000	Loss: 0.437836
Step #52000	Loss: 0.347497
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 689218.03338 ms
train loss 0.36546993255615234
Code block 'val epoch=0' took: 70366.51928 ms
validation loss 0.5776280760765076
Step #0	Loss: 0.470323
Step #4000	Loss: 0.314682
Step #8000	Loss: 0.358206
Step #12000	Loss: 0.301811
Step #16000	Loss: 0.301213
Step #20000	Loss: 0.323388
Step #24000	Loss: 0.302280
Step #28000	Loss: 0.311220
Step #32000	Loss: 0.328877
Step #36000	Loss: 0.338348
Step #40000	Loss: 0.305168
Step #44000	Loss: 0.280313
Step #48000	Loss: 0.362714
Step #52000	Loss: 0.321741
Code block 'train epoch=1' took: 662171.76561 ms
train loss 0.32507145404815674
Code block 'val epoch=1' took: 70387.86450 ms
validation loss 0.639861524105072
Step #0	Loss: 0.319155
Step #4000	Loss: 0.303481
Step #8000	Loss: 0.319092
Step #12000	Loss: 0.300340
Step #16000	Loss: 0.293480
Step #20000	Loss: 0.312071
Step #24000	Loss: 0.299032
Step #28000	Loss: 0.305056
Step #32000	Loss: 0.316421
Step #36000	Loss: 0.314078
Step #40000	Loss: 0.289462
Step #44000	Loss: 0.275861
Step #48000	Loss: 0.324487
Step #52000	Loss: 0.312607
Code block 'train epoch=2' took: 655757.40364 ms
train loss 0.3103289008140564
Code block 'val epoch=2' took: 70098.74539 ms
validation loss 0.696405291557312
Step #0	Loss: 0.299831
Step #4000	Loss: 0.298008
Step #8000	Loss: 0.302356
Step #12000	Loss: 0.290058
Step #16000	Loss: 0.288247
Step #20000	Loss: 0.301335
Step #24000	Loss: 0.299120
Step #28000	Loss: 0.297651
Step #32000	Loss: 0.308844
Step #36000	Loss: 0.301644
Step #40000	Loss: 0.289192
Step #44000	Loss: 0.278682
Step #48000	Loss: 0.318223
Step #52000	Loss: 0.306718
Code block 'train epoch=3' took: 655435.53738 ms
train loss 0.30475226044654846
Code block 'val epoch=3' took: 69382.69432 ms
validation loss 0.7417599558830261
Step #0	Loss: 0.300053
Step #4000	Loss: 0.295956
Step #8000	Loss: 0.293694
Step #12000	Loss: 0.296421
Step #16000	Loss: 0.289716
Step #20000	Loss: 0.297533
Step #24000	Loss: 0.292935
Step #28000	Loss: 0.300172
Step #32000	Loss: 0.306061
Step #36000	Loss: 0.299195
Step #40000	Loss: 0.280925
Step #44000	Loss: 0.276170
Step #48000	Loss: 0.309059
Step #52000	Loss: 0.301329
Code block 'train epoch=4' took: 655561.02574 ms
train loss 0.3020739257335663
Code block 'val epoch=4' took: 69715.10829 ms
validation loss 0.7923415899276733
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --force-host-read --batch-size 32768 --epochs 5'
[WARN  tini (2480029)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-20 02:29:01.921970: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-20 02:29:05.560298: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-20 02:29:33.159804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-20 02:33:32.664451: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-20 02:33:33.191337: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f5f96f44110 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-20 02:33:33.192744: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-20 02:33:33.374075: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-20 02:33:34.516843: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-20 02:33:34.924759: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.894335
Step #4000	Loss: 0.323311
Step #8000	Loss: 0.435119
Step #12000	Loss: 0.367541
Step #16000	Loss: 0.340065
Step #20000	Loss: 0.335989
Step #24000	Loss: 0.322178
Step #28000	Loss: 0.314984
Step #32000	Loss: 0.393509
Step #36000	Loss: 0.339189
Step #40000	Loss: 0.391422
Step #44000	Loss: 0.351347
Step #48000	Loss: 0.450346
Step #52000	Loss: 0.315020
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 681988.35984 ms
train loss 0.36206284165382385
Code block 'val epoch=0' took: 67883.62327 ms
validation loss 0.5714302659034729
Step #0	Loss: 0.455586
Step #4000	Loss: 0.311595
Step #8000	Loss: 0.358747
Step #12000	Loss: 0.316167
Step #16000	Loss: 0.302773
Step #20000	Loss: 0.315014
Step #24000	Loss: 0.306083
Step #28000	Loss: 0.307468
Step #32000	Loss: 0.331380
Step #36000	Loss: 0.313217
Step #40000	Loss: 0.314983
Step #44000	Loss: 0.310268
Step #48000	Loss: 0.360720
Step #52000	Loss: 0.300003
Code block 'train epoch=1' took: 652813.21301 ms
train loss 0.32255619764328003
Code block 'val epoch=1' took: 69559.11697 ms
validation loss 0.6425379514694214
Step #0	Loss: 0.334488
Step #4000	Loss: 0.305598
Step #8000	Loss: 0.318165
Step #12000	Loss: 0.302413
Step #16000	Loss: 0.292389
Step #20000	Loss: 0.310401
Step #24000	Loss: 0.298996
Step #28000	Loss: 0.298292
Step #32000	Loss: 0.317470
Step #36000	Loss: 0.299312
Step #40000	Loss: 0.296994
Step #44000	Loss: 0.293102
Step #48000	Loss: 0.327415
Step #52000	Loss: 0.300174
Code block 'train epoch=2' took: 650353.03723 ms
train loss 0.3095114827156067
Code block 'val epoch=2' took: 69414.99447 ms
validation loss 0.6910873055458069
Step #0	Loss: 0.311876
Step #4000	Loss: 0.293224
Step #8000	Loss: 0.302213
Step #12000	Loss: 0.296035
Step #16000	Loss: 0.286539
Step #20000	Loss: 0.304916
Step #24000	Loss: 0.297638
Step #28000	Loss: 0.295269
Step #32000	Loss: 0.311914
Step #36000	Loss: 0.298724
Step #40000	Loss: 0.295146
Step #44000	Loss: 0.285279
Step #48000	Loss: 0.315402
Step #52000	Loss: 0.295971
Code block 'train epoch=3' took: 649325.91421 ms
train loss 0.3044168949127197
Code block 'val epoch=3' took: 69505.10906 ms
validation loss 0.7348774671554565
Step #0	Loss: 0.313744
Step #4000	Loss: 0.294697
Step #8000	Loss: 0.296336
Step #12000	Loss: 0.296058
Step #16000	Loss: 0.293086
Step #20000	Loss: 0.295370
Step #24000	Loss: 0.292873
Step #28000	Loss: 0.297715
Step #32000	Loss: 0.310455
Step #36000	Loss: 0.299038
Step #40000	Loss: 0.290170
Step #44000	Loss: 0.282193
Step #48000	Loss: 0.312520
Step #52000	Loss: 0.292947
Code block 'train epoch=4' took: 647434.18438 ms
train loss 0.30187690258026123
Code block 'val epoch=4' took: 69859.94295 ms
validation loss 0.7597072124481201
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --force-host-read --batch-size 32768 --epochs 5'
[WARN  tini (2529578)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-20 03:33:54.554051: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-20 03:33:58.026758: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-20 03:34:27.575923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-20 03:38:27.595006: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-20 03:38:28.056903: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f236f45d720 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-20 03:38:28.058244: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-20 03:38:28.242933: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-20 03:38:29.321217: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-20 03:38:29.662657: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.552713
Step #4000	Loss: 0.337821
Step #8000	Loss: 0.436542
Step #12000	Loss: 0.384777
Step #16000	Loss: 0.332922
Step #20000	Loss: 0.340406
Step #24000	Loss: 0.329444
Step #28000	Loss: 0.318265
Step #32000	Loss: 0.331791
Step #36000	Loss: 0.463741
Step #40000	Loss: 0.345875
Step #44000	Loss: 0.339571
Step #48000	Loss: 0.379764
Step #52000	Loss: 0.414497
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 677809.09288 ms
train loss 0.36348193883895874
Code block 'val epoch=0' took: 69430.30905 ms
validation loss 0.5927637815475464
Step #0	Loss: 0.470867
Step #4000	Loss: 0.320485
Step #8000	Loss: 0.338649
Step #12000	Loss: 0.323602
Step #16000	Loss: 0.303743
Step #20000	Loss: 0.314464
Step #24000	Loss: 0.310400
Step #28000	Loss: 0.300057
Step #32000	Loss: 0.320322
Step #36000	Loss: 0.352412
Step #40000	Loss: 0.325548
Step #44000	Loss: 0.299792
Step #48000	Loss: 0.328990
Step #52000	Loss: 0.338800
Code block 'train epoch=1' took: 647083.55385 ms
train loss 0.32348114252090454
Code block 'val epoch=1' took: 67770.77611 ms
validation loss 0.6368563771247864
Step #0	Loss: 0.343975
Step #4000	Loss: 0.305722
Step #8000	Loss: 0.310574
Step #12000	Loss: 0.301424
Step #16000	Loss: 0.295286
Step #20000	Loss: 0.307150
Step #24000	Loss: 0.304408
Step #28000	Loss: 0.297644
Step #32000	Loss: 0.314072
Step #36000	Loss: 0.320960
Step #40000	Loss: 0.318770
Step #44000	Loss: 0.295201
Step #48000	Loss: 0.321025
Step #52000	Loss: 0.322552
Code block 'train epoch=2' took: 646175.72976 ms
train loss 0.310273140668869
Code block 'val epoch=2' took: 68883.68498 ms
validation loss 0.6864697933197021
Step #0	Loss: 0.321022
Step #4000	Loss: 0.300811
Step #8000	Loss: 0.290588
Step #12000	Loss: 0.297112
Step #16000	Loss: 0.290740
Step #20000	Loss: 0.304695
Step #24000	Loss: 0.300603
Step #28000	Loss: 0.296783
Step #32000	Loss: 0.306095
Step #36000	Loss: 0.307987
Step #40000	Loss: 0.308030
Step #44000	Loss: 0.285359
Step #48000	Loss: 0.313534
Step #52000	Loss: 0.314378
Code block 'train epoch=3' took: 648661.91820 ms
train loss 0.3053194582462311
Code block 'val epoch=3' took: 68920.33261 ms
validation loss 0.7432793378829956
Step #0	Loss: 0.320451
Step #4000	Loss: 0.299107
Step #8000	Loss: 0.290849
Step #12000	Loss: 0.297383
Step #16000	Loss: 0.288382
Step #20000	Loss: 0.301918
Step #24000	Loss: 0.297491
Step #28000	Loss: 0.298084
Step #32000	Loss: 0.311237
Step #36000	Loss: 0.298371
Step #40000	Loss: 0.308362
Step #44000	Loss: 0.293800
Step #48000	Loss: 0.310524
Step #52000	Loss: 0.310726
Code block 'train epoch=4' took: 649121.63374 ms
train loss 0.30215203762054443
Code block 'val epoch=4' took: 68198.83454 ms
validation loss 0.7969700694084167
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --force-host-read --batch-size 32768 --epochs 5'
[WARN  tini (2579923)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-20 04:38:32.761557: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-20 04:38:36.300907: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-20 04:39:05.196131: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-20 04:42:57.497540: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-20 04:42:57.951172: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fb448764350 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-20 04:42:57.951241: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-20 04:42:58.095863: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-20 04:42:59.220207: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-20 04:42:59.567652: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 1.090913
Step #4000	Loss: 0.321024
Step #8000	Loss: 0.448081
Step #12000	Loss: 0.367288
Step #16000	Loss: 0.342016
Step #20000	Loss: 0.411416
Step #24000	Loss: 0.367891
Step #28000	Loss: 0.339402
Step #32000	Loss: 0.402304
Step #36000	Loss: 0.340322
Step #40000	Loss: 0.389297
Step #44000	Loss: 0.354941
Step #48000	Loss: 0.446970
Step #52000	Loss: 0.316625
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 667404.73307 ms
train loss 0.36304759979248047
Code block 'val epoch=0' took: 66508.80893 ms
validation loss 0.5949246883392334
Step #0	Loss: 0.456297
Step #4000	Loss: 0.301980
Step #8000	Loss: 0.357943
Step #12000	Loss: 0.321389
Step #16000	Loss: 0.302072
Step #20000	Loss: 0.334693
Step #24000	Loss: 0.324512
Step #28000	Loss: 0.315260
Step #32000	Loss: 0.331477
Step #36000	Loss: 0.318885
Step #40000	Loss: 0.323457
Step #44000	Loss: 0.304574
Step #48000	Loss: 0.368956
Step #52000	Loss: 0.306456
Code block 'train epoch=1' took: 635049.19511 ms
train loss 0.3235842287540436
Code block 'val epoch=1' took: 65568.23763 ms
validation loss 0.6682943105697632
Step #0	Loss: 0.345762
Step #4000	Loss: 0.299626
Step #8000	Loss: 0.316719
Step #12000	Loss: 0.305380
Step #16000	Loss: 0.295531
Step #20000	Loss: 0.316735
Step #24000	Loss: 0.312098
Step #28000	Loss: 0.304168
Step #32000	Loss: 0.316848
Step #36000	Loss: 0.307558
Step #40000	Loss: 0.302455
Step #44000	Loss: 0.292025
Step #48000	Loss: 0.335709
Step #52000	Loss: 0.295434
Code block 'train epoch=2' took: 635892.82308 ms
train loss 0.310056209564209
Code block 'val epoch=2' took: 66514.32559 ms
validation loss 0.7357295751571655
Step #0	Loss: 0.319261
Step #4000	Loss: 0.298581
Step #8000	Loss: 0.299430
Step #12000	Loss: 0.293991
Step #16000	Loss: 0.291820
Step #20000	Loss: 0.300588
Step #24000	Loss: 0.306474
Step #28000	Loss: 0.295226
Step #32000	Loss: 0.312665
Step #36000	Loss: 0.298505
Step #40000	Loss: 0.291470
Step #44000	Loss: 0.289204
Step #48000	Loss: 0.321980
Step #52000	Loss: 0.297492
Code block 'train epoch=3' took: 634040.55443 ms
train loss 0.30470359325408936
Code block 'val epoch=3' took: 64970.03173 ms
validation loss 0.7887363433837891
Step #0	Loss: 0.310746
Step #4000	Loss: 0.293161
Step #8000	Loss: 0.298681
Step #12000	Loss: 0.295888
Step #16000	Loss: 0.290875
Step #20000	Loss: 0.299309
Step #24000	Loss: 0.306872
Step #28000	Loss: 0.296516
Step #32000	Loss: 0.309985
Step #36000	Loss: 0.298575
Step #40000	Loss: 0.293442
Step #44000	Loss: 0.281241
Step #48000	Loss: 0.319935
Step #52000	Loss: 0.292959
Code block 'train epoch=4' took: 636616.15668 ms
train loss 0.3020031452178955
Code block 'val epoch=4' took: 67134.85949 ms
validation loss 0.8460413217544556
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --force-host-read --batch-size 32768 --epochs 5'
[WARN  tini (2628365)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-20 05:41:52.487217: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-20 05:41:56.290492: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-20 05:42:22.181863: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-20 05:46:14.337775: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-20 05:46:14.781340: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f0baca61080 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-20 05:46:14.781412: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-20 05:46:14.939534: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-20 05:46:16.057525: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-20 05:46:16.385333: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 1.086919
Step #4000	Loss: 0.347218
Step #8000	Loss: 0.347601
Step #12000	Loss: 0.315117
Step #16000	Loss: 0.312396
Step #20000	Loss: 0.348517
Step #24000	Loss: 0.403861
Step #28000	Loss: 0.311369
Step #32000	Loss: 0.340713
Step #36000	Loss: 0.385338
Step #40000	Loss: 0.418567
Step #44000	Loss: 0.410255
Step #48000	Loss: 0.361014
Step #52000	Loss: 0.358372
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 662534.96473 ms
train loss 0.36040636897087097
Code block 'val epoch=0' took: 66158.39680 ms
validation loss 0.6341932415962219
Step #0	Loss: 0.464326
Step #4000	Loss: 0.318550
Step #8000	Loss: 0.308092
Step #12000	Loss: 0.295759
Step #16000	Loss: 0.298065
Step #20000	Loss: 0.314260
Step #24000	Loss: 0.343587
Step #28000	Loss: 0.302609
Step #32000	Loss: 0.320917
Step #36000	Loss: 0.324847
Step #40000	Loss: 0.328782
Step #44000	Loss: 0.323046
Step #48000	Loss: 0.324446
Step #52000	Loss: 0.314226
Code block 'train epoch=1' took: 634574.56398 ms
train loss 0.32118040323257446
Code block 'val epoch=1' took: 65303.91598 ms
validation loss 0.7020206451416016
Step #0	Loss: 0.358888
Step #4000	Loss: 0.304300
Step #8000	Loss: 0.301950
Step #12000	Loss: 0.293312
Step #16000	Loss: 0.294057
Step #20000	Loss: 0.304590
Step #24000	Loss: 0.319596
Step #28000	Loss: 0.295860
Step #32000	Loss: 0.310831
Step #36000	Loss: 0.313529
Step #40000	Loss: 0.306604
Step #44000	Loss: 0.306514
Step #48000	Loss: 0.318721
Step #52000	Loss: 0.312181
Code block 'train epoch=2' took: 635283.96575 ms
train loss 0.30887213349342346
Code block 'val epoch=2' took: 66134.68935 ms
validation loss 0.726324200630188
Step #0	Loss: 0.330223
Step #4000	Loss: 0.301052
Step #8000	Loss: 0.292832
Step #12000	Loss: 0.294909
Step #16000	Loss: 0.293302
Step #20000	Loss: 0.304399
Step #24000	Loss: 0.316147
Step #28000	Loss: 0.295285
Step #32000	Loss: 0.306706
Step #36000	Loss: 0.304050
Step #40000	Loss: 0.293108
Step #44000	Loss: 0.292579
Step #48000	Loss: 0.317331
Step #52000	Loss: 0.299821
Code block 'train epoch=3' took: 635036.46753 ms
train loss 0.3039740324020386
Code block 'val epoch=3' took: 66153.21718 ms
validation loss 0.8146588206291199
Step #0	Loss: 0.317021
Step #4000	Loss: 0.296821
Step #8000	Loss: 0.291213
Step #12000	Loss: 0.285654
Step #16000	Loss: 0.285185
Step #20000	Loss: 0.300395
Step #24000	Loss: 0.312871
Step #28000	Loss: 0.291950
Step #32000	Loss: 0.309110
Step #36000	Loss: 0.302489
Step #40000	Loss: 0.294401
Step #44000	Loss: 0.296298
Step #48000	Loss: 0.317918
Step #52000	Loss: 0.300290
Code block 'train epoch=4' took: 633333.43130 ms
train loss 0.30152538418769836
Code block 'val epoch=4' took: 65067.60013 ms
validation loss 0.8631786704063416
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --force-host-read --batch-size 32768 --epochs 5'
[WARN  tini (2676820)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-20 06:44:55.408524: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-20 06:44:58.786512: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-20 06:45:26.364868: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-20 06:49:23.135460: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-20 06:49:23.646919: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fc737ef0340 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-20 06:49:23.647002: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-20 06:49:23.822991: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-20 06:49:24.864188: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-20 06:49:25.240975: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.949636
Step #4000	Loss: 0.323136
Step #8000	Loss: 0.351826
Step #12000	Loss: 0.311215
Step #16000	Loss: 0.343022
Step #20000	Loss: 0.336432
Step #24000	Loss: 0.393084
Step #28000	Loss: 0.348397
Step #32000	Loss: 0.361749
Step #36000	Loss: 0.331513
Step #40000	Loss: 0.342848
Step #44000	Loss: 0.339317
Step #48000	Loss: 0.350622
Step #52000	Loss: 0.314653
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 667139.63689 ms
train loss 0.36178845167160034
Code block 'val epoch=0' took: 65952.53819 ms
validation loss 0.6057094931602478
Step #0	Loss: 0.490312
Step #4000	Loss: 0.308336
Step #8000	Loss: 0.319827
Step #12000	Loss: 0.296420
Step #16000	Loss: 0.313915
Step #20000	Loss: 0.311564
Step #24000	Loss: 0.329258
Step #28000	Loss: 0.318586
Step #32000	Loss: 0.330101
Step #36000	Loss: 0.308874
Step #40000	Loss: 0.320708
Step #44000	Loss: 0.306434
Step #48000	Loss: 0.331553
Step #52000	Loss: 0.303887
Code block 'train epoch=1' took: 639022.53985 ms
train loss 0.3230263888835907
Code block 'val epoch=1' took: 65314.89156 ms
validation loss 0.6447141766548157
Step #0	Loss: 0.374685
Step #4000	Loss: 0.300322
Step #8000	Loss: 0.294262
Step #12000	Loss: 0.289099
Step #16000	Loss: 0.300145
Step #20000	Loss: 0.306115
Step #24000	Loss: 0.316507
Step #28000	Loss: 0.308873
Step #32000	Loss: 0.323700
Step #36000	Loss: 0.296307
Step #40000	Loss: 0.307267
Step #44000	Loss: 0.296851
Step #48000	Loss: 0.326034
Step #52000	Loss: 0.296479
Code block 'train epoch=2' took: 639745.17257 ms
train loss 0.3105010390281677
Code block 'val epoch=2' took: 65587.42330 ms
validation loss 0.681326687335968
Step #0	Loss: 0.341116
Step #4000	Loss: 0.295778
Step #8000	Loss: 0.298637
Step #12000	Loss: 0.288688
Step #16000	Loss: 0.292869
Step #20000	Loss: 0.302697
Step #24000	Loss: 0.313399
Step #28000	Loss: 0.307936
Step #32000	Loss: 0.312964
Step #36000	Loss: 0.297464
Step #40000	Loss: 0.306910
Step #44000	Loss: 0.298768
Step #48000	Loss: 0.319494
Step #52000	Loss: 0.293764
Code block 'train epoch=3' took: 639520.55525 ms
train loss 0.3053649961948395
Code block 'val epoch=3' took: 65442.13767 ms
validation loss 0.6937445402145386
Step #0	Loss: 0.329884
Step #4000	Loss: 0.301731
Step #8000	Loss: 0.296535
Step #12000	Loss: 0.283387
Step #16000	Loss: 0.297218
Step #20000	Loss: 0.303784
Step #24000	Loss: 0.307214
Step #28000	Loss: 0.303986
Step #32000	Loss: 0.314213
Step #36000	Loss: 0.296152
Step #40000	Loss: 0.313075
Step #44000	Loss: 0.284577
Step #48000	Loss: 0.320065
Step #52000	Loss: 0.291817
Code block 'train epoch=4' took: 641061.70336 ms
train loss 0.3025330901145935
Code block 'val epoch=4' took: 65408.31035 ms
validation loss 0.7288606762886047
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --force-host-read --batch-size 32768 --epochs 5'
[WARN  tini (2725712)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-20 07:48:24.873754: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-20 07:48:28.327226: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-20 07:48:58.427162: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-20 07:52:49.495825: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-20 07:52:50.258351: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f8d081891f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-20 07:52:50.259919: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-20 07:52:50.426023: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-20 07:52:51.548701: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-20 07:52:51.943502: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.882463
Failed to transform operator <nvtabular.ops.categorify.Categorify object at 0x7f9420463af0>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1778, in _encode
    labels = codes.merge(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/dataframe.py", line 4004, in merge
    ).perform_merge()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/join/join.py", line 203, in perform_merge
    self.rhs._gather(gather_map=right_rows, **gather_kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
Code block 'train epoch=0' took: 65680.13794 ms
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 332, in _get_next_batch
    batch = next(self._batch_itr)
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home2/faculty/pwesolowski/praca-mgr/pipelines-repo/2_merlin/run_merlin.py", line 155, in <module>
    for batch, (examples, labels) in enumerate(train_tf_ds):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/tensorflow.py", line 97, in __next__
    converted_batch = self.convert_batch(super().__next__())
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 261, in __next__
    return self._get_next_batch()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 344, in _get_next_batch
    batch = next(self._batch_itr)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 369, in make_tensors
    tensors_by_name = self._convert_df_to_tensors(gdf)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 520, in _convert_df_to_tensors
    tensors_by_name[column_name] = self._to_tensor(gdf_i[[column_name]])
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 450, in _to_tensor
    tensor = df_or_series.to_cupy()
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/single_column_frame.py", line 131, in to_cupy
    return super().to_cupy(dtype, copy, na_value).flatten()
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 533, in to_cupy
    return self._to_array(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 498, in _to_array
    matrix[:, i] = get_column_values_na(col)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 477, in get_column_values_na
    return get_column_values(col)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 534, in <lambda>
    (lambda col: col.values.copy())
  File "cupy/_core/core.pyx", line 590, in cupy._core.core._ndarray_base.copy
  File "cupy/_core/core.pyx", line 616, in cupy._core.core._ndarray_base.copy
  File "cupy/_core/core.pyx", line 575, in cupy._core.core._ndarray_base.astype
  File "cupy/_core/core.pyx", line 136, in cupy._core.core.ndarray.__new__
  File "cupy/_core/core.pyx", line 224, in cupy._core.core._ndarray_base._init
  File "cupy/cuda/memory.pyx", line 742, in cupy.cuda.memory.alloc
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/rmm/rmm.py", line 230, in rmm_cupy_allocator
    buf = librmm.device_buffer.DeviceBuffer(size=nbytes, stream=stream)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --force-host-read --batch-size 32768 --epochs 5'
[WARN  tini (2731102)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-20 07:53:47.870595: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-20 07:53:51.158714: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-20 07:54:19.494523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
Failed to transform operator <nvtabular.ops.categorify.Categorify object at 0x7fa2e22a3a60>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1780, in _encode
    ).sort_values("order")["labels"]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 2214, in sort_values
    out = self._gather(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-20 07:58:16.614597: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-20 07:58:17.242510: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f99a4cc42b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-20 07:58:17.242575: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-20 07:58:17.420919: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-20 07:58:18.669784: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-20 07:58:19.092308: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.930045
Code block 'train epoch=0' took: 46078.97913 ms
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 332, in _get_next_batch
    batch = next(self._batch_itr)
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home2/faculty/pwesolowski/praca-mgr/pipelines-repo/2_merlin/run_merlin.py", line 155, in <module>
    for batch, (examples, labels) in enumerate(train_tf_ds):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/tensorflow.py", line 97, in __next__
    converted_batch = self.convert_batch(super().__next__())
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 261, in __next__
    return self._get_next_batch()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 344, in _get_next_batch
    batch = next(self._batch_itr)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 369, in make_tensors
    tensors_by_name = self._convert_df_to_tensors(gdf)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 520, in _convert_df_to_tensors
    tensors_by_name[column_name] = self._to_tensor(gdf_i[[column_name]])
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 450, in _to_tensor
    tensor = df_or_series.to_cupy()
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/single_column_frame.py", line 131, in to_cupy
    return super().to_cupy(dtype, copy, na_value).flatten()
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 533, in to_cupy
    return self._to_array(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 498, in _to_array
    matrix[:, i] = get_column_values_na(col)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 477, in get_column_values_na
    return get_column_values(col)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 534, in <lambda>
    (lambda col: col.values.copy())
  File "cupy/_core/core.pyx", line 590, in cupy._core.core._ndarray_base.copy
  File "cupy/_core/core.pyx", line 616, in cupy._core.core._ndarray_base.copy
  File "cupy/_core/core.pyx", line 575, in cupy._core.core._ndarray_base.astype
  File "cupy/_core/core.pyx", line 136, in cupy._core.core.ndarray.__new__
  File "cupy/_core/core.pyx", line 224, in cupy._core.core._ndarray_base._init
  File "cupy/cuda/memory.pyx", line 742, in cupy.cuda.memory.alloc
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/rmm/rmm.py", line 230, in rmm_cupy_allocator
    buf = librmm.device_buffer.DeviceBuffer(size=nbytes, stream=stream)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --force-host-read --batch-size 32768 --epochs 5'
[WARN  tini (2736082)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-20 07:58:49.588182: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-20 07:58:52.915502: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-20 07:59:20.125767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
Failed to transform operator <nvtabular.ops.categorify.Categorify object at 0x7f6bc6bfba90>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1780, in _encode
    ).sort_values("order")["labels"]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 2214, in sort_values
    out = self._gather(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-20 08:03:16.822928: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-20 08:03:17.381251: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f63210aa570 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-20 08:03:17.382985: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-20 08:03:17.552407: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-20 08:03:18.735380: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-20 08:03:19.138868: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.880746
Code block 'train epoch=0' took: 54521.25163 ms
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1780, in _encode
    ).sort_values("order")["labels"]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 2214, in sort_values
    out = self._gather(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home2/faculty/pwesolowski/praca-mgr/pipelines-repo/2_merlin/run_merlin.py", line 155, in <module>
    for batch, (examples, labels) in enumerate(train_tf_ds):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/tensorflow.py", line 97, in __next__
    converted_batch = self.convert_batch(super().__next__())
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 261, in __next__
    return self._get_next_batch()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 343, in _get_next_batch
    self._fetch_chunk()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 277, in _fetch_chunk
    raise chunks
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 791, in load_chunks
    self.chunk_logic(itr)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 759, in chunk_logic
    for chunks in self.batch(itr):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 745, in batch
    value = next(itr)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/io/dataframe_iter.py", line 44, in __iter__
    yield part.compute(scheduler="synchronous")
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/base.py", line 314, in compute
    (result,) = compute(self, traverse=False, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/base.py", line 599, in compute
    results = schedule(dsk, keys, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 557, in get_sync
    return get_async(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 500, in get_async
    for key, res_info, failed in queue_get(queue).result():
  File "/opt/conda/envs/rapids/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/opt/conda/envs/rapids/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 542, in submit
    fut.set_result(fn(*args, **kwargs))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 238, in batch_execute_tasks
    return [execute_task(*a) for a in it]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 238, in <listcomp>
    return [execute_task(*a) for a in it]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 229, in execute_task
    result = pack_exception(e, dumps)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 224, in execute_task
    result = _execute_task(task, data)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/optimization.py", line 990, in __call__
    return core.get(self.dsk, self.outkey, dict(zip(self.inkeys, args)))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 149, in get
    result = _execute_task(task, cache)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in <genexpr>
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/utils.py", line 72, in apply
    return func(*args, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 87, in transform
    transformed_data = self._execute_node(node, transformable, capture_dtypes, strict)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 101, in _execute_node
    upstream_outputs = self._run_upstream_transforms(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 114, in _run_upstream_transforms
    node_output = self._execute_node(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 107, in _execute_node
    transform_output = self._run_node_transform(node, transform_input, capture_dtypes, strict)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 227, in _run_node_transform
    raise exc
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
+ for BATCH_SIZE in 8192 16384 32768
+ for CUFILE_THREAD_COUNT in 4 8 16 32 64
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --cufile-thread-count 4 --batch-size 8192 --epochs 5'
[WARN  tini (2741342)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-20 08:03:58.041503: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-20 08:04:01.637724: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-20 08:04:32.358143: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-20 08:08:27.234500: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-20 08:08:27.738985: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f23141cd940 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-20 08:08:27.740433: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-20 08:08:27.907475: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-20 08:08:29.013446: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-20 08:08:29.378804: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.632160
Step #4000	Loss: 0.289414
Step #8000	Loss: 0.314042
Step #12000	Loss: 0.295966
Step #16000	Loss: 0.342372
Step #20000	Loss: 0.324567
Step #24000	Loss: 0.418650
Step #28000	Loss: 0.407844
Step #32000	Loss: 0.431627
Step #36000	Loss: 0.377841
Step #40000	Loss: 0.334024
Step #44000	Loss: 0.350571
Step #48000	Loss: 0.326938
Step #52000	Loss: 0.341241
Step #56000	Loss: 0.339706
Step #60000	Loss: 0.389063
Step #64000	Loss: 0.304666
Step #68000	Loss: 0.332867
Step #72000	Loss: 0.366607
Step #76000	Loss: 0.361943
Step #80000	Loss: 0.356127
Step #84000	Loss: 0.365104
Step #88000	Loss: 0.359028
Step #92000	Loss: 0.374593
Step #96000	Loss: 0.324233
Step #100000	Loss: 0.419597
Step #104000	Loss: 0.331769
Step #108000	Loss: 0.339685
Step #112000	Loss: 0.337588
Step #116000	Loss: 0.376625
Step #120000	Loss: 0.316992
Step #124000	Loss: 0.344111
Step #128000	Loss: 0.374347
Step #132000	Loss: 0.331786
Step #136000	Loss: 0.435937
Step #140000	Loss: 0.410709
Step #144000	Loss: 0.434844
Step #148000	Loss: 0.316035
Step #152000	Loss: 0.430269
Step #156000	Loss: 0.320512
Step #160000	Loss: 0.334777
Step #164000	Loss: 0.306919
Step #168000	Loss: 0.422808
Step #172000	Loss: 0.413530
Step #176000	Loss: 0.306013
Step #180000	Loss: 0.344861
Step #184000	Loss: 0.329450
Step #188000	Loss: 0.463331
Step #192000	Loss: 0.423067
Step #196000	Loss: 0.463576
Step #200000	Loss: 0.335280
Step #204000	Loss: 0.291530
Step #208000	Loss: 0.335105
Step #212000	Loss: 0.339606
Step #216000	Loss: 0.394746
Step #220000	Loss: 0.423985
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 1713860.89472 ms
train loss 0.35975441336631775
Code block 'val epoch=0' took: 93913.17899 ms
validation loss 0.5900688171386719
Step #0	Loss: 0.449271
Step #4000	Loss: 0.284220
Step #8000	Loss: 0.312776
Step #12000	Loss: 0.303850
Step #16000	Loss: 0.315976
Step #20000	Loss: 0.315203
Step #24000	Loss: 0.341165
Step #28000	Loss: 0.343756
Step #32000	Loss: 0.343431
Step #36000	Loss: 0.325585
Step #40000	Loss: 0.317845
Step #44000	Loss: 0.314401
Step #48000	Loss: 0.305744
Step #52000	Loss: 0.312064
Step #56000	Loss: 0.315027
Step #60000	Loss: 0.339897
Step #64000	Loss: 0.297202
Step #68000	Loss: 0.319735
Step #72000	Loss: 0.318676
Step #76000	Loss: 0.319662
Step #80000	Loss: 0.312340
Step #84000	Loss: 0.341828
Step #88000	Loss: 0.307491
Step #92000	Loss: 0.334150
Step #96000	Loss: 0.292313
Step #100000	Loss: 0.347809
Step #104000	Loss: 0.332131
Step #108000	Loss: 0.319128
Step #112000	Loss: 0.317359
Step #116000	Loss: 0.334486
Step #120000	Loss: 0.309166
Step #124000	Loss: 0.313565
Step #128000	Loss: 0.333008
Step #132000	Loss: 0.316333
Step #136000	Loss: 0.367574
Step #140000	Loss: 0.361962
Step #144000	Loss: 0.344552
Step #148000	Loss: 0.305218
Step #152000	Loss: 0.350031
Step #156000	Loss: 0.307774
Step #160000	Loss: 0.301645
Step #164000	Loss: 0.299375
Step #168000	Loss: 0.355021
Step #172000	Loss: 0.336859
Step #176000	Loss: 0.284009
Step #180000	Loss: 0.322497
Step #184000	Loss: 0.294211
Step #188000	Loss: 0.355568
Step #192000	Loss: 0.353132
Step #196000	Loss: 0.367752
Step #200000	Loss: 0.320079
Step #204000	Loss: 0.279592
Step #208000	Loss: 0.314825
Step #212000	Loss: 0.327590
Step #216000	Loss: 0.341376
Step #220000	Loss: 0.346836
Code block 'train epoch=1' took: 1686936.21216 ms
train loss 0.324640154838562
Code block 'val epoch=1' took: 95256.04557 ms
validation loss 0.6204836964607239
Step #0	Loss: 0.311926
Step #4000	Loss: 0.279160
Step #8000	Loss: 0.295501
Step #12000	Loss: 0.297466
Step #16000	Loss: 0.305447
Step #20000	Loss: 0.308596
Step #24000	Loss: 0.325213
Step #28000	Loss: 0.320338
Step #32000	Loss: 0.320590
Step #36000	Loss: 0.316477
Step #40000	Loss: 0.315639
Step #44000	Loss: 0.292761
Step #48000	Loss: 0.294231
Step #52000	Loss: 0.314060
Step #56000	Loss: 0.293961
Step #60000	Loss: 0.312385
Step #64000	Loss: 0.283888
Step #68000	Loss: 0.310778
Step #72000	Loss: 0.310773
Step #76000	Loss: 0.300640
Step #80000	Loss: 0.296309
Step #84000	Loss: 0.325761
Step #88000	Loss: 0.312025
Step #92000	Loss: 0.312303
Step #96000	Loss: 0.303552
Step #100000	Loss: 0.328476
Step #104000	Loss: 0.308990
Step #108000	Loss: 0.313277
Step #112000	Loss: 0.304289
Step #116000	Loss: 0.313729
Step #120000	Loss: 0.307511
Step #124000	Loss: 0.282859
Step #128000	Loss: 0.315251
Step #132000	Loss: 0.323788
Step #136000	Loss: 0.322403
Step #140000	Loss: 0.338671
Step #144000	Loss: 0.315515
Step #148000	Loss: 0.302235
Step #152000	Loss: 0.321465
Step #156000	Loss: 0.312003
Step #160000	Loss: 0.291009
Step #164000	Loss: 0.306362
Step #168000	Loss: 0.321443
Step #172000	Loss: 0.320819
Step #176000	Loss: 0.280162
Step #180000	Loss: 0.304061
Step #184000	Loss: 0.298614
Step #188000	Loss: 0.340457
Step #192000	Loss: 0.329236
Step #196000	Loss: 0.334132
Step #200000	Loss: 0.306107
Step #204000	Loss: 0.277870
Step #208000	Loss: 0.316971
Step #212000	Loss: 0.305010
Step #216000	Loss: 0.319321
Step #220000	Loss: 0.328762
Code block 'train epoch=2' took: 1684496.61456 ms
train loss 0.31130895018577576
Code block 'val epoch=2' took: 93369.32187 ms
validation loss 0.6909226179122925
Step #0	Loss: 0.307745
Step #4000	Loss: 0.285296
Step #8000	Loss: 0.298808
Step #12000	Loss: 0.312351
Step #16000	Loss: 0.291166
Step #20000	Loss: 0.303896
Step #24000	Loss: 0.317757
Step #28000	Loss: 0.307056
Step #32000	Loss: 0.306656
Step #36000	Loss: 0.303167
Step #40000	Loss: 0.313724
Step #44000	Loss: 0.287665
Step #48000	Loss: 0.295265
Step #52000	Loss: 0.298494
Step #56000	Loss: 0.303150
Step #60000	Loss: 0.306775
Step #64000	Loss: 0.293517
Step #68000	Loss: 0.314820
Step #72000	Loss: 0.310584
Step #76000	Loss: 0.292718
Step #80000	Loss: 0.291095
Step #84000	Loss: 0.327688
Step #88000	Loss: 0.300865
Step #92000	Loss: 0.314096
Step #96000	Loss: 0.296439
Step #100000	Loss: 0.311579
Step #104000	Loss: 0.314187
Step #108000	Loss: 0.314628
Step #112000	Loss: 0.293603
Step #116000	Loss: 0.302540
Step #120000	Loss: 0.303945
Step #124000	Loss: 0.278487
Step #128000	Loss: 0.305699
Step #132000	Loss: 0.315350
Step #136000	Loss: 0.323828
Step #140000	Loss: 0.320129
Step #144000	Loss: 0.306583
Step #148000	Loss: 0.298792
Step #152000	Loss: 0.320157
Step #156000	Loss: 0.301621
Step #160000	Loss: 0.287760
Step #164000	Loss: 0.285876
Step #168000	Loss: 0.316117
Step #172000	Loss: 0.311943
Step #176000	Loss: 0.285028
Step #180000	Loss: 0.296742
Step #184000	Loss: 0.304394
Step #188000	Loss: 0.332757
Step #192000	Loss: 0.322137
Step #196000	Loss: 0.324625
Step #200000	Loss: 0.315054
Step #204000	Loss: 0.272808
Step #208000	Loss: 0.306328
Step #212000	Loss: 0.302680
Step #216000	Loss: 0.310995
Step #220000	Loss: 0.305468
Code block 'train epoch=3' took: 1685490.68480 ms
train loss 0.3053496778011322
Code block 'val epoch=3' took: 94653.65271 ms
validation loss 0.6859824657440186
Step #0	Loss: 0.300173
Step #4000	Loss: 0.274747
Step #8000	Loss: 0.281535
Step #12000	Loss: 0.292228
Step #16000	Loss: 0.303624
Step #20000	Loss: 0.296260
Step #24000	Loss: 0.309441
Step #28000	Loss: 0.310041
Step #32000	Loss: 0.303042
Step #36000	Loss: 0.307598
Step #40000	Loss: 0.314253
Step #44000	Loss: 0.278671
Step #48000	Loss: 0.288825
Step #52000	Loss: 0.292579
Step #56000	Loss: 0.304772
Step #60000	Loss: 0.297825
Step #64000	Loss: 0.282711
Step #68000	Loss: 0.313900
Step #72000	Loss: 0.301255
Step #76000	Loss: 0.295504
Step #80000	Loss: 0.301940
Step #84000	Loss: 0.312064
Step #88000	Loss: 0.301328
Step #92000	Loss: 0.306567
Step #96000	Loss: 0.294441
Step #100000	Loss: 0.303769
Step #104000	Loss: 0.317909
Step #108000	Loss: 0.311833
Step #112000	Loss: 0.300564
Step #116000	Loss: 0.305603
Step #120000	Loss: 0.290356
Step #124000	Loss: 0.287884
Step #128000	Loss: 0.302910
Step #132000	Loss: 0.314180
Step #136000	Loss: 0.323895
Step #140000	Loss: 0.320413
Step #144000	Loss: 0.307682
Step #148000	Loss: 0.285045
Step #152000	Loss: 0.305063
Step #156000	Loss: 0.303049
Step #160000	Loss: 0.273409
Step #164000	Loss: 0.301212
Step #168000	Loss: 0.304412
Step #172000	Loss: 0.312938
Step #176000	Loss: 0.265796
Step #180000	Loss: 0.300147
Step #184000	Loss: 0.299157
Step #188000	Loss: 0.327555
Step #192000	Loss: 0.315656
Step #196000	Loss: 0.311156
Step #200000	Loss: 0.318930
Step #204000	Loss: 0.271149
Step #208000	Loss: 0.298359
Step #212000	Loss: 0.297256
Step #216000	Loss: 0.321253
Step #220000	Loss: 0.302278
Code block 'train epoch=4' took: 1685250.44575 ms
train loss 0.3024436831474304
Code block 'val epoch=4' took: 94152.66591 ms
validation loss 0.749828577041626
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --cufile-thread-count 4 --batch-size 8192 --epochs 5'
[WARN  tini (2857029)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-20 10:37:31.750841: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-20 10:37:36.209310: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-20 10:38:11.487329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-20 10:42:21.209838: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-20 10:42:22.018405: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f931a533bb0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-20 10:42:22.019801: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-20 10:42:22.198769: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-20 10:42:23.436795: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-20 10:42:23.860441: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 1.119046
Step #4000	Loss: 0.312529
Step #8000	Loss: 0.317317
Step #12000	Loss: 0.337564
Step #16000	Loss: 0.328301
Step #20000	Loss: 0.312329
Step #24000	Loss: 0.438782
Step #28000	Loss: 0.440843
Step #32000	Loss: 0.420588
Step #36000	Loss: 0.418538
Step #40000	Loss: 0.348375
Step #44000	Loss: 0.364078
Step #48000	Loss: 0.360492
Step #52000	Loss: 0.369113
Step #56000	Loss: 0.390528
Step #60000	Loss: 0.425796
Step #64000	Loss: 0.327600
Step #68000	Loss: 0.379549
Step #72000	Loss: 0.347286
Step #76000	Loss: 0.327617
Step #80000	Loss: 0.331280
Step #84000	Loss: 0.348125
Step #88000	Loss: 0.392258
Step #92000	Loss: 0.394469
Step #96000	Loss: 0.328183
Step #100000	Loss: 0.441108
Step #104000	Loss: 0.364385
Step #108000	Loss: 0.365186
Step #112000	Loss: 0.321938
Step #116000	Loss: 0.330283
Step #120000	Loss: 0.324746
Step #124000	Loss: 0.381362
Step #128000	Loss: 0.393825
Step #132000	Loss: 0.325642
Step #136000	Loss: 0.450656
Step #140000	Loss: 0.426221
Step #144000	Loss: 0.335747
Step #148000	Loss: 0.332560
Step #152000	Loss: 0.456252
Step #156000	Loss: 0.320782
Step #160000	Loss: 0.374060
Step #164000	Loss: 0.293607
Step #168000	Loss: 0.431645
Step #172000	Loss: 0.322787
Step #176000	Loss: 0.361074
Step #180000	Loss: 0.365396
Step #184000	Loss: 0.307873
Step #188000	Loss: 0.474142
Step #192000	Loss: 0.445447
Step #196000	Loss: 0.455876
Step #200000	Loss: 0.321217
Step #204000	Loss: 0.314140
Step #208000	Loss: 0.320038
Step #212000	Loss: 0.331878
Step #216000	Loss: 0.401416
Step #220000	Loss: 0.353302
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 1706311.04245 ms
train loss 0.3589085638523102
Code block 'val epoch=0' took: 95429.07480 ms
validation loss 0.5838772058486938
Step #0	Loss: 0.443727
Step #4000	Loss: 0.302186
Step #8000	Loss: 0.305329
Step #12000	Loss: 0.318667
Step #16000	Loss: 0.313725
Step #20000	Loss: 0.313813
Step #24000	Loss: 0.356427
Step #28000	Loss: 0.365831
Step #32000	Loss: 0.356976
Step #36000	Loss: 0.349215
Step #40000	Loss: 0.324754
Step #44000	Loss: 0.315645
Step #48000	Loss: 0.325918
Step #52000	Loss: 0.319312
Step #56000	Loss: 0.341982
Step #60000	Loss: 0.361087
Step #64000	Loss: 0.317265
Step #68000	Loss: 0.332159
Step #72000	Loss: 0.329864
Step #76000	Loss: 0.303511
Step #80000	Loss: 0.312972
Step #84000	Loss: 0.324574
Step #88000	Loss: 0.332721
Step #92000	Loss: 0.329692
Step #96000	Loss: 0.315530
Step #100000	Loss: 0.342989
Step #104000	Loss: 0.331598
Step #108000	Loss: 0.316251
Step #112000	Loss: 0.316057
Step #116000	Loss: 0.317840
Step #120000	Loss: 0.322369
Step #124000	Loss: 0.322004
Step #128000	Loss: 0.336713
Step #132000	Loss: 0.319719
Step #136000	Loss: 0.367341
Step #140000	Loss: 0.352563
Step #144000	Loss: 0.319004
Step #148000	Loss: 0.311870
Step #152000	Loss: 0.354792
Step #156000	Loss: 0.319026
Step #160000	Loss: 0.319706
Step #164000	Loss: 0.302404
Step #168000	Loss: 0.352447
Step #172000	Loss: 0.302423
Step #176000	Loss: 0.310525
Step #180000	Loss: 0.326252
Step #184000	Loss: 0.296816
Step #188000	Loss: 0.374261
Step #192000	Loss: 0.360973
Step #196000	Loss: 0.366654
Step #200000	Loss: 0.312506
Step #204000	Loss: 0.306363
Step #208000	Loss: 0.300151
Step #212000	Loss: 0.309075
Step #216000	Loss: 0.353695
Step #220000	Loss: 0.321014
Code block 'train epoch=1' took: 1681482.78871 ms
train loss 0.3229716718196869
Code block 'val epoch=1' took: 94351.08034 ms
validation loss 0.6378442049026489
Step #0	Loss: 0.333830
Step #4000	Loss: 0.283709
Step #8000	Loss: 0.287349
Step #12000	Loss: 0.307944
Step #16000	Loss: 0.301569
Step #20000	Loss: 0.316397
Step #24000	Loss: 0.321177
Step #28000	Loss: 0.329238
Step #32000	Loss: 0.326433
Step #36000	Loss: 0.320099
Step #40000	Loss: 0.321213
Step #44000	Loss: 0.289728
Step #48000	Loss: 0.307108
Step #52000	Loss: 0.316700
Step #56000	Loss: 0.310284
Step #60000	Loss: 0.319111
Step #64000	Loss: 0.292547
Step #68000	Loss: 0.314952
Step #72000	Loss: 0.303076
Step #76000	Loss: 0.295654
Step #80000	Loss: 0.312010
Step #84000	Loss: 0.323547
Step #88000	Loss: 0.307043
Step #92000	Loss: 0.312117
Step #96000	Loss: 0.298413
Step #100000	Loss: 0.315929
Step #104000	Loss: 0.312776
Step #108000	Loss: 0.315010
Step #112000	Loss: 0.307207
Step #116000	Loss: 0.299079
Step #120000	Loss: 0.307594
Step #124000	Loss: 0.310499
Step #128000	Loss: 0.318952
Step #132000	Loss: 0.302210
Step #136000	Loss: 0.334723
Step #140000	Loss: 0.326137
Step #144000	Loss: 0.304833
Step #148000	Loss: 0.304540
Step #152000	Loss: 0.316165
Step #156000	Loss: 0.312910
Step #160000	Loss: 0.299308
Step #164000	Loss: 0.291352
Step #168000	Loss: 0.331704
Step #172000	Loss: 0.290751
Step #176000	Loss: 0.291110
Step #180000	Loss: 0.307758
Step #184000	Loss: 0.288594
Step #188000	Loss: 0.324503
Step #192000	Loss: 0.322526
Step #196000	Loss: 0.338056
Step #200000	Loss: 0.312409
Step #204000	Loss: 0.290002
Step #208000	Loss: 0.294882
Step #212000	Loss: 0.299867
Step #216000	Loss: 0.322969
Step #220000	Loss: 0.316758
Code block 'train epoch=2' took: 1679504.47183 ms
train loss 0.3099699318408966
Code block 'val epoch=2' took: 94199.71942 ms
validation loss 0.6735765337944031
Step #0	Loss: 0.311817
Step #4000	Loss: 0.290677
Step #8000	Loss: 0.296255
Step #12000	Loss: 0.309117
Step #16000	Loss: 0.297476
Step #20000	Loss: 0.309698
Step #24000	Loss: 0.308210
Step #28000	Loss: 0.306458
Step #32000	Loss: 0.296787
Step #36000	Loss: 0.313302
Step #40000	Loss: 0.312447
Step #44000	Loss: 0.283161
Step #48000	Loss: 0.295189
Step #52000	Loss: 0.295791
Step #56000	Loss: 0.303732
Step #60000	Loss: 0.302516
Step #64000	Loss: 0.289635
Step #68000	Loss: 0.316553
Step #72000	Loss: 0.310212
Step #76000	Loss: 0.293863
Step #80000	Loss: 0.296380
Step #84000	Loss: 0.307423
Step #88000	Loss: 0.302506
Step #92000	Loss: 0.305907
Step #96000	Loss: 0.295747
Step #100000	Loss: 0.316142
Step #104000	Loss: 0.315337
Step #108000	Loss: 0.308486
Step #112000	Loss: 0.297070
Step #116000	Loss: 0.303981
Step #120000	Loss: 0.304364
Step #124000	Loss: 0.302203
Step #128000	Loss: 0.311592
Step #132000	Loss: 0.319715
Step #136000	Loss: 0.332885
Step #140000	Loss: 0.316717
Step #144000	Loss: 0.299334
Step #148000	Loss: 0.298597
Step #152000	Loss: 0.314339
Step #156000	Loss: 0.308790
Step #160000	Loss: 0.289178
Step #164000	Loss: 0.284848
Step #168000	Loss: 0.332689
Step #172000	Loss: 0.280906
Step #176000	Loss: 0.292961
Step #180000	Loss: 0.298530
Step #184000	Loss: 0.286190
Step #188000	Loss: 0.328138
Step #192000	Loss: 0.320795
Step #196000	Loss: 0.318376
Step #200000	Loss: 0.297197
Step #204000	Loss: 0.289597
Step #208000	Loss: 0.294672
Step #212000	Loss: 0.302242
Step #216000	Loss: 0.323150
Step #220000	Loss: 0.308375
Code block 'train epoch=3' took: 1677987.83107 ms
train loss 0.3049073815345764
Code block 'val epoch=3' took: 94770.03139 ms
validation loss 0.7440029978752136
Step #0	Loss: 0.301096
Step #4000	Loss: 0.284981
Step #8000	Loss: 0.289439
Step #12000	Loss: 0.293551
Step #16000	Loss: 0.297893
Step #20000	Loss: 0.294805
Step #24000	Loss: 0.305077
Step #28000	Loss: 0.308329
Step #32000	Loss: 0.284550
Step #36000	Loss: 0.310268
Step #40000	Loss: 0.313148
Step #44000	Loss: 0.277284
Step #48000	Loss: 0.298491
Step #52000	Loss: 0.303198
Step #56000	Loss: 0.301769
Step #60000	Loss: 0.306704
Step #64000	Loss: 0.282444
Step #68000	Loss: 0.307815
Step #72000	Loss: 0.307348
Step #76000	Loss: 0.280820
Step #80000	Loss: 0.293048
Step #84000	Loss: 0.315761
Step #88000	Loss: 0.296814
Step #92000	Loss: 0.309090
Step #96000	Loss: 0.298471
Step #100000	Loss: 0.312255
Step #104000	Loss: 0.312096
Step #108000	Loss: 0.302486
Step #112000	Loss: 0.299808
Step #116000	Loss: 0.305298
Step #120000	Loss: 0.304995
Step #124000	Loss: 0.305682
Step #128000	Loss: 0.310282
Step #132000	Loss: 0.309329
Step #136000	Loss: 0.318078
Step #140000	Loss: 0.306960
Step #144000	Loss: 0.296433
Step #148000	Loss: 0.295988
Step #152000	Loss: 0.305242
Step #156000	Loss: 0.308666
Step #160000	Loss: 0.288555
Step #164000	Loss: 0.294636
Step #168000	Loss: 0.317988
Step #172000	Loss: 0.295544
Step #176000	Loss: 0.278516
Step #180000	Loss: 0.297205
Step #184000	Loss: 0.295085
Step #188000	Loss: 0.327085
Step #192000	Loss: 0.301428
Step #196000	Loss: 0.321066
Step #200000	Loss: 0.305813
Step #204000	Loss: 0.294192
Step #208000	Loss: 0.291394
Step #212000	Loss: 0.302431
Step #216000	Loss: 0.310761
Step #220000	Loss: 0.290542
Code block 'train epoch=4' took: 1679969.78434 ms
train loss 0.30231747031211853
Code block 'val epoch=4' took: 94427.32925 ms
validation loss 0.6963412165641785
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --cufile-thread-count 4 --batch-size 8192 --epochs 5'
[WARN  tini (2972696)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-20 13:10:45.681529: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-20 13:10:49.362075: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-20 13:11:24.276145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-20 13:15:30.566436: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-20 13:15:31.062218: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f149c077250 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-20 13:15:31.062287: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-20 13:15:31.228865: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-20 13:15:32.495949: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-20 13:15:32.845582: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 1.170031
Step #4000	Loss: 0.306659
Step #8000	Loss: 0.358290
Step #12000	Loss: 0.322130
Step #16000	Loss: 0.325762
Step #20000	Loss: 0.325718
Step #24000	Loss: 0.369221
Step #28000	Loss: 0.327882
Step #32000	Loss: 0.419944
Step #36000	Loss: 0.354873
Step #40000	Loss: 0.327448
Step #44000	Loss: 0.292570
Step #48000	Loss: 0.391995
Step #52000	Loss: 0.337571
Step #56000	Loss: 0.319291
Step #60000	Loss: 0.425655
Step #64000	Loss: 0.321869
Step #68000	Loss: 0.329772
Step #72000	Loss: 0.350997
Step #76000	Loss: 0.339845
Step #80000	Loss: 0.329184
Step #84000	Loss: 0.426849
Step #88000	Loss: 0.322928
Step #92000	Loss: 0.415907
Step #96000	Loss: 0.320465
Step #100000	Loss: 0.366257
Step #104000	Loss: 0.318560
Step #108000	Loss: 0.377811
Step #112000	Loss: 0.322851
Step #116000	Loss: 0.311370
Step #120000	Loss: 0.338216
Step #124000	Loss: 0.342893
Step #128000	Loss: 0.332932
Step #132000	Loss: 0.337229
Step #136000	Loss: 0.446127
Step #140000	Loss: 0.368679
Step #144000	Loss: 0.449621
Step #148000	Loss: 0.356342
Step #152000	Loss: 0.456818
Step #156000	Loss: 0.373269
Step #160000	Loss: 0.340125
Step #164000	Loss: 0.332316
Step #168000	Loss: 0.441991
Step #172000	Loss: 0.319529
Step #176000	Loss: 0.323079
Step #180000	Loss: 0.326755
Step #184000	Loss: 0.316858
Step #188000	Loss: 0.479059
Step #192000	Loss: 0.389212
Step #196000	Loss: 0.350243
Step #200000	Loss: 0.330830
Step #204000	Loss: 0.368315
Step #208000	Loss: 0.413534
Step #212000	Loss: 0.332538
Step #216000	Loss: 0.423321
Step #220000	Loss: 0.331738
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 1705817.95733 ms
train loss 0.3594162166118622
Code block 'val epoch=0' took: 94698.77309 ms
validation loss 0.7065722346305847
Step #0	Loss: 0.494803
Step #4000	Loss: 0.300508
Step #8000	Loss: 0.330140
Step #12000	Loss: 0.307994
Step #16000	Loss: 0.298761
Step #20000	Loss: 0.305833
Step #24000	Loss: 0.329214
Step #28000	Loss: 0.307453
Step #32000	Loss: 0.355164
Step #36000	Loss: 0.325243
Step #40000	Loss: 0.302191
Step #44000	Loss: 0.284736
Step #48000	Loss: 0.331918
Step #52000	Loss: 0.324334
Step #56000	Loss: 0.313107
Step #60000	Loss: 0.345291
Step #64000	Loss: 0.321252
Step #68000	Loss: 0.303106
Step #72000	Loss: 0.313194
Step #76000	Loss: 0.307389
Step #80000	Loss: 0.318301
Step #84000	Loss: 0.354524
Step #88000	Loss: 0.316700
Step #92000	Loss: 0.348180
Step #96000	Loss: 0.306292
Step #100000	Loss: 0.324925
Step #104000	Loss: 0.310109
Step #108000	Loss: 0.343108
Step #112000	Loss: 0.306414
Step #116000	Loss: 0.307377
Step #120000	Loss: 0.305137
Step #124000	Loss: 0.309158
Step #128000	Loss: 0.323992
Step #132000	Loss: 0.318012
Step #136000	Loss: 0.368272
Step #140000	Loss: 0.320823
Step #144000	Loss: 0.365231
Step #148000	Loss: 0.323396
Step #152000	Loss: 0.369006
Step #156000	Loss: 0.332028
Step #160000	Loss: 0.326314
Step #164000	Loss: 0.299944
Step #168000	Loss: 0.354397
Step #172000	Loss: 0.299204
Step #176000	Loss: 0.300561
Step #180000	Loss: 0.318488
Step #184000	Loss: 0.305087
Step #188000	Loss: 0.365044
Step #192000	Loss: 0.336319
Step #196000	Loss: 0.322010
Step #200000	Loss: 0.309001
Step #204000	Loss: 0.316264
Step #208000	Loss: 0.343708
Step #212000	Loss: 0.311754
Step #216000	Loss: 0.344958
Step #220000	Loss: 0.314125
Code block 'train epoch=1' took: 1682685.25827 ms
train loss 0.32338613271713257
Code block 'val epoch=1' took: 95476.08547 ms
validation loss 0.685609757900238
Step #0	Loss: 0.365111
Step #4000	Loss: 0.294881
Step #8000	Loss: 0.293942
Step #12000	Loss: 0.311965
Step #16000	Loss: 0.303626
Step #20000	Loss: 0.299145
Step #24000	Loss: 0.300896
Step #28000	Loss: 0.307228
Step #32000	Loss: 0.304682
Step #36000	Loss: 0.314240
Step #40000	Loss: 0.313661
Step #44000	Loss: 0.270888
Step #48000	Loss: 0.313966
Step #52000	Loss: 0.295505
Step #56000	Loss: 0.301241
Step #60000	Loss: 0.313871
Step #64000	Loss: 0.304984
Step #68000	Loss: 0.320363
Step #72000	Loss: 0.308973
Step #76000	Loss: 0.299359
Step #80000	Loss: 0.308709
Step #84000	Loss: 0.329988
Step #88000	Loss: 0.306750
Step #92000	Loss: 0.314720
Step #96000	Loss: 0.311606
Step #100000	Loss: 0.309272
Step #104000	Loss: 0.309460
Step #108000	Loss: 0.321905
Step #112000	Loss: 0.301995
Step #116000	Loss: 0.305619
Step #120000	Loss: 0.310973
Step #124000	Loss: 0.302114
Step #128000	Loss: 0.311706
Step #132000	Loss: 0.308781
Step #136000	Loss: 0.340257
Step #140000	Loss: 0.323620
Step #144000	Loss: 0.310360
Step #148000	Loss: 0.317153
Step #152000	Loss: 0.326078
Step #156000	Loss: 0.316803
Step #160000	Loss: 0.321470
Step #164000	Loss: 0.292962
Step #168000	Loss: 0.340339
Step #172000	Loss: 0.305377
Step #176000	Loss: 0.294075
Step #180000	Loss: 0.300289
Step #184000	Loss: 0.300798
Step #188000	Loss: 0.336686
Step #192000	Loss: 0.318103
Step #196000	Loss: 0.322629
Step #200000	Loss: 0.319175
Step #204000	Loss: 0.291370
Step #208000	Loss: 0.323168
Step #212000	Loss: 0.298314
Step #216000	Loss: 0.332024
Step #220000	Loss: 0.311874
Code block 'train epoch=2' took: 1680856.80860 ms
train loss 0.31189268827438354
Code block 'val epoch=2' took: 96708.18081 ms
validation loss 0.7267778515815735
Step #0	Loss: 0.332230
Step #4000	Loss: 0.291799
Step #8000	Loss: 0.304799
Step #12000	Loss: 0.313541
Step #16000	Loss: 0.298173
Step #20000	Loss: 0.307792
Step #24000	Loss: 0.316327
Step #28000	Loss: 0.296606
Step #32000	Loss: 0.299619
Step #36000	Loss: 0.303586
Step #40000	Loss: 0.301982
Step #44000	Loss: 0.276871
Step #48000	Loss: 0.284041
Step #52000	Loss: 0.297931
Step #56000	Loss: 0.301041
Step #60000	Loss: 0.312037
Step #64000	Loss: 0.286231
Step #68000	Loss: 0.308065
Step #72000	Loss: 0.306334
Step #76000	Loss: 0.301701
Step #80000	Loss: 0.310009
Step #84000	Loss: 0.321114
Step #88000	Loss: 0.299734
Step #92000	Loss: 0.317687
Step #96000	Loss: 0.312571
Step #100000	Loss: 0.317184
Step #104000	Loss: 0.303085
Step #108000	Loss: 0.330843
Step #112000	Loss: 0.296101
Step #116000	Loss: 0.300440
Step #120000	Loss: 0.296016
Step #124000	Loss: 0.298667
Step #128000	Loss: 0.310302
Step #132000	Loss: 0.310929
Step #136000	Loss: 0.332911
Step #140000	Loss: 0.321127
Step #144000	Loss: 0.306106
Step #148000	Loss: 0.297205
Step #152000	Loss: 0.328640
Step #156000	Loss: 0.301023
Step #160000	Loss: 0.308437
Step #164000	Loss: 0.288010
Step #168000	Loss: 0.307330
Step #172000	Loss: 0.289162
Step #176000	Loss: 0.294091
Step #180000	Loss: 0.283446
Step #184000	Loss: 0.291544
Step #188000	Loss: 0.324855
Step #192000	Loss: 0.317576
Step #196000	Loss: 0.321913
Step #200000	Loss: 0.304849
Step #204000	Loss: 0.296983
Step #208000	Loss: 0.318711
Step #212000	Loss: 0.302530
Step #216000	Loss: 0.331667
Step #220000	Loss: 0.298345
Code block 'train epoch=3' took: 1679138.82635 ms
train loss 0.3065662086009979
Code block 'val epoch=3' took: 95501.66285 ms
validation loss 0.8256314396858215
Step #0	Loss: 0.327929
Step #4000	Loss: 0.286405
Step #8000	Loss: 0.284385
Step #12000	Loss: 0.315372
Step #16000	Loss: 0.300805
Step #20000	Loss: 0.297082
Step #24000	Loss: 0.302026
Step #28000	Loss: 0.311294
Step #32000	Loss: 0.300807
Step #36000	Loss: 0.297375
Step #40000	Loss: 0.308782
Step #44000	Loss: 0.285981
Step #48000	Loss: 0.288053
Step #52000	Loss: 0.300501
Step #56000	Loss: 0.285796
Step #60000	Loss: 0.305680
Step #64000	Loss: 0.291981
Step #68000	Loss: 0.301041
Step #72000	Loss: 0.293212
Step #76000	Loss: 0.307173
Step #80000	Loss: 0.301061
Step #84000	Loss: 0.317576
Step #88000	Loss: 0.301600
Step #92000	Loss: 0.323186
Step #96000	Loss: 0.296765
Step #100000	Loss: 0.300440
Step #104000	Loss: 0.302035
Step #108000	Loss: 0.307033
Step #112000	Loss: 0.286523
Step #116000	Loss: 0.293622
Step #120000	Loss: 0.302634
Step #124000	Loss: 0.301060
Step #128000	Loss: 0.309201
Step #132000	Loss: 0.315802
Step #136000	Loss: 0.324036
Step #140000	Loss: 0.315077
Step #144000	Loss: 0.309456
Step #148000	Loss: 0.302567
Step #152000	Loss: 0.313031
Step #156000	Loss: 0.302141
Step #160000	Loss: 0.303914
Step #164000	Loss: 0.291424
Step #168000	Loss: 0.310201
Step #172000	Loss: 0.292008
Step #176000	Loss: 0.293671
Step #180000	Loss: 0.303155
Step #184000	Loss: 0.277830
Step #188000	Loss: 0.321541
Step #192000	Loss: 0.319123
Step #196000	Loss: 0.307813
Step #200000	Loss: 0.312355
Step #204000	Loss: 0.289413
Step #208000	Loss: 0.318025
Step #212000	Loss: 0.301419
Step #216000	Loss: 0.319164
Step #220000	Loss: 0.298189
Code block 'train epoch=4' took: 1681198.06853 ms
train loss 0.30303722620010376
Code block 'val epoch=4' took: 95599.63487 ms
validation loss 0.8579035997390747
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --cufile-thread-count 4 --batch-size 8192 --epochs 5'
[WARN  tini (3189269)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-20 15:44:02.110105: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-20 15:44:05.708832: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-20 15:44:41.722707: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-20 15:48:36.992555: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-20 15:48:37.772604: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f558c0902b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-20 15:48:37.772670: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-20 15:48:37.964183: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-20 15:48:39.235958: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-20 15:48:39.601185: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 4.963531
Step #4000	Loss: 0.323361
Step #8000	Loss: 0.356275
Step #12000	Loss: 0.333484
Step #16000	Loss: 0.328698
Step #20000	Loss: 0.317034
Step #24000	Loss: 0.436068
Step #28000	Loss: 0.435368
Step #32000	Loss: 0.418693
Step #36000	Loss: 0.410571
Step #40000	Loss: 0.346602
Step #44000	Loss: 0.361242
Step #48000	Loss: 0.353629
Step #52000	Loss: 0.356862
Step #56000	Loss: 0.394104
Step #60000	Loss: 0.426822
Step #64000	Loss: 0.329294
Step #68000	Loss: 0.367620
Step #72000	Loss: 0.372359
Step #76000	Loss: 0.399681
Step #80000	Loss: 0.409301
Step #84000	Loss: 0.405515
Step #88000	Loss: 0.401519
Step #92000	Loss: 0.375824
Step #96000	Loss: 0.366092
Step #100000	Loss: 0.339329
Step #104000	Loss: 0.315312
Step #108000	Loss: 0.334074
Step #112000	Loss: 0.339881
Step #116000	Loss: 0.421393
Step #120000	Loss: 0.319104
Step #124000	Loss: 0.373454
Step #128000	Loss: 0.388357
Step #132000	Loss: 0.325439
Step #136000	Loss: 0.454508
Step #140000	Loss: 0.426131
Step #144000	Loss: 0.338233
Step #148000	Loss: 0.349217
Step #152000	Loss: 0.342975
Step #156000	Loss: 0.365139
Step #160000	Loss: 0.375920
Step #164000	Loss: 0.337410
Step #168000	Loss: 0.361269
Step #172000	Loss: 0.332407
Step #176000	Loss: 0.345585
Step #180000	Loss: 0.374427
Step #184000	Loss: 0.311895
Step #188000	Loss: 0.464573
Step #192000	Loss: 0.440899
Step #196000	Loss: 0.458569
Step #200000	Loss: 0.331266
Step #204000	Loss: 0.334597
Step #208000	Loss: 0.313341
Step #212000	Loss: 0.323262
Step #216000	Loss: 0.396372
Step #220000	Loss: 0.426991
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 1694174.04862 ms
train loss 0.35931676626205444
Code block 'val epoch=0' took: 92471.81708 ms
validation loss 0.6490552425384521
Step #0	Loss: 0.449385
Step #4000	Loss: 0.308457
Step #8000	Loss: 0.316146
Step #12000	Loss: 0.300346
Step #16000	Loss: 0.310033
Step #20000	Loss: 0.325604
Step #24000	Loss: 0.367999
Step #28000	Loss: 0.364180
Step #32000	Loss: 0.352558
Step #36000	Loss: 0.351369
Step #40000	Loss: 0.330735
Step #44000	Loss: 0.316986
Step #48000	Loss: 0.322344
Step #52000	Loss: 0.335238
Step #56000	Loss: 0.339616
Step #60000	Loss: 0.347287
Step #64000	Loss: 0.302770
Step #68000	Loss: 0.325828
Step #72000	Loss: 0.326161
Step #76000	Loss: 0.341892
Step #80000	Loss: 0.347684
Step #84000	Loss: 0.357745
Step #88000	Loss: 0.331257
Step #92000	Loss: 0.332119
Step #96000	Loss: 0.334940
Step #100000	Loss: 0.313471
Step #104000	Loss: 0.296407
Step #108000	Loss: 0.327039
Step #112000	Loss: 0.304293
Step #116000	Loss: 0.347051
Step #120000	Loss: 0.300519
Step #124000	Loss: 0.315695
Step #128000	Loss: 0.334880
Step #132000	Loss: 0.303113
Step #136000	Loss: 0.364993
Step #140000	Loss: 0.378430
Step #144000	Loss: 0.318167
Step #148000	Loss: 0.317599
Step #152000	Loss: 0.322049
Step #156000	Loss: 0.325407
Step #160000	Loss: 0.335248
Step #164000	Loss: 0.309676
Step #168000	Loss: 0.329343
Step #172000	Loss: 0.298095
Step #176000	Loss: 0.310306
Step #180000	Loss: 0.320654
Step #184000	Loss: 0.297083
Step #188000	Loss: 0.376375
Step #192000	Loss: 0.371136
Step #196000	Loss: 0.362735
Step #200000	Loss: 0.312378
Step #204000	Loss: 0.287798
Step #208000	Loss: 0.302560
Step #212000	Loss: 0.315322
Step #216000	Loss: 0.340721
Step #220000	Loss: 0.355039
Code block 'train epoch=1' took: 1663514.90637 ms
train loss 0.32434526085853577
Code block 'val epoch=1' took: 92503.56712 ms
validation loss 0.6944519877433777
Step #0	Loss: 0.337672
Step #4000	Loss: 0.298677
Step #8000	Loss: 0.294235
Step #12000	Loss: 0.301641
Step #16000	Loss: 0.302563
Step #20000	Loss: 0.304269
Step #24000	Loss: 0.333845
Step #28000	Loss: 0.332629
Step #32000	Loss: 0.322990
Step #36000	Loss: 0.328680
Step #40000	Loss: 0.317408
Step #44000	Loss: 0.288117
Step #48000	Loss: 0.300707
Step #52000	Loss: 0.311511
Step #56000	Loss: 0.313839
Step #60000	Loss: 0.323603
Step #64000	Loss: 0.298247
Step #68000	Loss: 0.326143
Step #72000	Loss: 0.327592
Step #76000	Loss: 0.318522
Step #80000	Loss: 0.311070
Step #84000	Loss: 0.333135
Step #88000	Loss: 0.318469
Step #92000	Loss: 0.314682
Step #96000	Loss: 0.311342
Step #100000	Loss: 0.317645
Step #104000	Loss: 0.299904
Step #108000	Loss: 0.314301
Step #112000	Loss: 0.311059
Step #116000	Loss: 0.324346
Step #120000	Loss: 0.305111
Step #124000	Loss: 0.307579
Step #128000	Loss: 0.318189
Step #132000	Loss: 0.311894
Step #136000	Loss: 0.342401
Step #140000	Loss: 0.344698
Step #144000	Loss: 0.312122
Step #148000	Loss: 0.305267
Step #152000	Loss: 0.294216
Step #156000	Loss: 0.306636
Step #160000	Loss: 0.302420
Step #164000	Loss: 0.289807
Step #168000	Loss: 0.321798
Step #172000	Loss: 0.304580
Step #176000	Loss: 0.292930
Step #180000	Loss: 0.299628
Step #184000	Loss: 0.296219
Step #188000	Loss: 0.343518
Step #192000	Loss: 0.328468
Step #196000	Loss: 0.337615
Step #200000	Loss: 0.309046
Step #204000	Loss: 0.287584
Step #208000	Loss: 0.304956
Step #212000	Loss: 0.309887
Step #216000	Loss: 0.327463
Step #220000	Loss: 0.329610
Code block 'train epoch=2' took: 1665669.77360 ms
train loss 0.31059643626213074
Code block 'val epoch=2' took: 92650.50803 ms
validation loss 0.7467662692070007
Step #0	Loss: 0.307355
Step #4000	Loss: 0.289420
Step #8000	Loss: 0.287845
Step #12000	Loss: 0.301038
Step #16000	Loss: 0.296811
Step #20000	Loss: 0.304977
Step #24000	Loss: 0.309933
Step #28000	Loss: 0.319743
Step #32000	Loss: 0.311481
Step #36000	Loss: 0.315873
Step #40000	Loss: 0.314417
Step #44000	Loss: 0.287056
Step #48000	Loss: 0.297233
Step #52000	Loss: 0.296632
Step #56000	Loss: 0.305757
Step #60000	Loss: 0.315619
Step #64000	Loss: 0.290837
Step #68000	Loss: 0.326120
Step #72000	Loss: 0.298162
Step #76000	Loss: 0.310680
Step #80000	Loss: 0.293748
Step #84000	Loss: 0.322834
Step #88000	Loss: 0.314902
Step #92000	Loss: 0.313293
Step #96000	Loss: 0.317135
Step #100000	Loss: 0.313776
Step #104000	Loss: 0.304951
Step #108000	Loss: 0.308432
Step #112000	Loss: 0.309223
Step #116000	Loss: 0.309562
Step #120000	Loss: 0.305901
Step #124000	Loss: 0.292626
Step #128000	Loss: 0.319427
Step #132000	Loss: 0.303977
Step #136000	Loss: 0.319254
Step #140000	Loss: 0.320590
Step #144000	Loss: 0.289444
Step #148000	Loss: 0.304602
Step #152000	Loss: 0.302328
Step #156000	Loss: 0.310432
Step #160000	Loss: 0.290551
Step #164000	Loss: 0.286121
Step #168000	Loss: 0.309506
Step #172000	Loss: 0.287586
Step #176000	Loss: 0.291307
Step #180000	Loss: 0.292324
Step #184000	Loss: 0.287110
Step #188000	Loss: 0.314357
Step #192000	Loss: 0.318514
Step #196000	Loss: 0.310806
Step #200000	Loss: 0.306204
Step #204000	Loss: 0.291695
Step #208000	Loss: 0.291265
Step #212000	Loss: 0.307917
Step #216000	Loss: 0.316106
Step #220000	Loss: 0.310853
Code block 'train epoch=3' took: 1666948.93129 ms
train loss 0.30507102608680725
Code block 'val epoch=3' took: 91911.25691 ms
validation loss 0.7733871340751648
Step #0	Loss: 0.321000
Step #4000	Loss: 0.294914
Step #8000	Loss: 0.292704
Step #12000	Loss: 0.294930
Step #16000	Loss: 0.299102
Step #20000	Loss: 0.302937
Step #24000	Loss: 0.302879
Step #28000	Loss: 0.309124
Step #32000	Loss: 0.288308
Step #36000	Loss: 0.309767
Step #40000	Loss: 0.307884
Step #44000	Loss: 0.284958
Step #48000	Loss: 0.294926
Step #52000	Loss: 0.298605
Step #56000	Loss: 0.307145
Step #60000	Loss: 0.307965
Step #64000	Loss: 0.290980
Step #68000	Loss: 0.312157
Step #72000	Loss: 0.294979
Step #76000	Loss: 0.293416
Step #80000	Loss: 0.297039
Step #84000	Loss: 0.317169
Step #88000	Loss: 0.305711
Step #92000	Loss: 0.313215
Step #96000	Loss: 0.311919
Step #100000	Loss: 0.309725
Step #104000	Loss: 0.308760
Step #108000	Loss: 0.310282
Step #112000	Loss: 0.301550
Step #116000	Loss: 0.300712
Step #120000	Loss: 0.301228
Step #124000	Loss: 0.302556
Step #128000	Loss: 0.304141
Step #132000	Loss: 0.315884
Step #136000	Loss: 0.328399
Step #140000	Loss: 0.320356
Step #144000	Loss: 0.298941
Step #148000	Loss: 0.287706
Step #152000	Loss: 0.306003
Step #156000	Loss: 0.297758
Step #160000	Loss: 0.288927
Step #164000	Loss: 0.284849
Step #168000	Loss: 0.303733
Step #172000	Loss: 0.289268
Step #176000	Loss: 0.289150
Step #180000	Loss: 0.294052
Step #184000	Loss: 0.291380
Step #188000	Loss: 0.325197
Step #192000	Loss: 0.314357
Step #196000	Loss: 0.306637
Step #200000	Loss: 0.302942
Step #204000	Loss: 0.286878
Step #208000	Loss: 0.298856
Step #212000	Loss: 0.311506
Step #216000	Loss: 0.306280
Step #220000	Loss: 0.298367
Code block 'train epoch=4' took: 1663488.28124 ms
train loss 0.3021267354488373
Code block 'val epoch=4' took: 91671.90646 ms
validation loss 0.79167640209198
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --cufile-thread-count 4 --batch-size 8192 --epochs 5'
[WARN  tini (3385294)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-20 18:15:30.543554: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-20 18:15:33.903097: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-20 18:16:02.130732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-20 18:19:54.627321: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-20 18:19:55.071857: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7efdc8a2aec0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-20 18:19:55.071945: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-20 18:19:55.235984: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-20 18:19:56.350854: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-20 18:19:56.679154: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 1.051099
Step #4000	Loss: 0.334875
Step #8000	Loss: 0.337718
Step #12000	Loss: 0.368185
Step #16000	Loss: 0.346198
Step #20000	Loss: 0.359768
Step #24000	Loss: 0.369882
Step #28000	Loss: 0.344157
Step #32000	Loss: 0.334817
Step #36000	Loss: 0.328143
Step #40000	Loss: 0.337848
Step #44000	Loss: 0.290644
Step #48000	Loss: 0.317660
Step #52000	Loss: 0.326642
Step #56000	Loss: 0.339305
Step #60000	Loss: 0.339284
Step #64000	Loss: 0.326022
Step #68000	Loss: 0.342163
Step #72000	Loss: 0.393454
Step #76000	Loss: 0.317379
Step #80000	Loss: 0.335049
Step #84000	Loss: 0.351832
Step #88000	Loss: 0.437344
Step #92000	Loss: 0.415300
Step #96000	Loss: 0.395185
Step #100000	Loss: 0.367662
Step #104000	Loss: 0.349293
Step #108000	Loss: 0.361993
Step #112000	Loss: 0.329611
Step #116000	Loss: 0.434963
Step #120000	Loss: 0.318203
Step #124000	Loss: 0.340281
Step #128000	Loss: 0.338033
Step #132000	Loss: 0.340926
Step #136000	Loss: 0.449038
Step #140000	Loss: 0.415434
Step #144000	Loss: 0.381771
Step #148000	Loss: 0.360487
Step #152000	Loss: 0.313084
Step #156000	Loss: 0.333186
Step #160000	Loss: 0.420107
Step #164000	Loss: 0.316343
Step #168000	Loss: 0.340715
Step #172000	Loss: 0.369696
Step #176000	Loss: 0.400871
Step #180000	Loss: 0.372149
Step #184000	Loss: 0.329225
Step #188000	Loss: 0.352970
Step #192000	Loss: 0.347877
Step #196000	Loss: 0.371893
Step #200000	Loss: 0.370593
Step #204000	Loss: 0.338898
Step #208000	Loss: 0.357340
Step #212000	Loss: 0.344076
Step #216000	Loss: 0.356225
Step #220000	Loss: 0.425156
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 1690339.94956 ms
train loss 0.3588130474090576
Code block 'val epoch=0' took: 92426.83690 ms
validation loss 0.656102180480957
Step #0	Loss: 0.510158
Step #4000	Loss: 0.307546
Step #8000	Loss: 0.314806
Step #12000	Loss: 0.327317
Step #16000	Loss: 0.328492
Step #20000	Loss: 0.327383
Step #24000	Loss: 0.327666
Step #28000	Loss: 0.309567
Step #32000	Loss: 0.300146
Step #36000	Loss: 0.315711
Step #40000	Loss: 0.316816
Step #44000	Loss: 0.282690
Step #48000	Loss: 0.291714
Step #52000	Loss: 0.308244
Step #56000	Loss: 0.313034
Step #60000	Loss: 0.302980
Step #64000	Loss: 0.298346
Step #68000	Loss: 0.318464
Step #72000	Loss: 0.329880
Step #76000	Loss: 0.301216
Step #80000	Loss: 0.316556
Step #84000	Loss: 0.329783
Step #88000	Loss: 0.347839
Step #92000	Loss: 0.338062
Step #96000	Loss: 0.340775
Step #100000	Loss: 0.332259
Step #104000	Loss: 0.317664
Step #108000	Loss: 0.320257
Step #112000	Loss: 0.291234
Step #116000	Loss: 0.337583
Step #120000	Loss: 0.308412
Step #124000	Loss: 0.316025
Step #128000	Loss: 0.319928
Step #132000	Loss: 0.333275
Step #136000	Loss: 0.362539
Step #140000	Loss: 0.328240
Step #144000	Loss: 0.318994
Step #148000	Loss: 0.317070
Step #152000	Loss: 0.310996
Step #156000	Loss: 0.316912
Step #160000	Loss: 0.344211
Step #164000	Loss: 0.302440
Step #168000	Loss: 0.319152
Step #172000	Loss: 0.329566
Step #176000	Loss: 0.323634
Step #180000	Loss: 0.315117
Step #184000	Loss: 0.312538
Step #188000	Loss: 0.337890
Step #192000	Loss: 0.326668
Step #196000	Loss: 0.336140
Step #200000	Loss: 0.330173
Step #204000	Loss: 0.308717
Step #208000	Loss: 0.334621
Step #212000	Loss: 0.325367
Step #216000	Loss: 0.326643
Step #220000	Loss: 0.349970
Code block 'train epoch=1' took: 1665041.39306 ms
train loss 0.3218943476676941
Code block 'val epoch=1' took: 92434.52846 ms
validation loss 0.7162768840789795
Step #0	Loss: 0.387499
Step #4000	Loss: 0.298319
Step #8000	Loss: 0.296656
Step #12000	Loss: 0.304894
Step #16000	Loss: 0.307972
Step #20000	Loss: 0.312284
Step #24000	Loss: 0.312244
Step #28000	Loss: 0.293966
Step #32000	Loss: 0.294125
Step #36000	Loss: 0.306299
Step #40000	Loss: 0.302791
Step #44000	Loss: 0.280090
Step #48000	Loss: 0.306522
Step #52000	Loss: 0.302264
Step #56000	Loss: 0.308467
Step #60000	Loss: 0.299459
Step #64000	Loss: 0.290403
Step #68000	Loss: 0.306247
Step #72000	Loss: 0.303137
Step #76000	Loss: 0.301683
Step #80000	Loss: 0.296928
Step #84000	Loss: 0.321642
Step #88000	Loss: 0.312593
Step #92000	Loss: 0.311199
Step #96000	Loss: 0.323222
Step #100000	Loss: 0.317880
Step #104000	Loss: 0.304972
Step #108000	Loss: 0.320537
Step #112000	Loss: 0.297174
Step #116000	Loss: 0.327975
Step #120000	Loss: 0.304609
Step #124000	Loss: 0.304701
Step #128000	Loss: 0.314396
Step #132000	Loss: 0.322126
Step #136000	Loss: 0.345472
Step #140000	Loss: 0.305273
Step #144000	Loss: 0.310037
Step #148000	Loss: 0.305922
Step #152000	Loss: 0.297069
Step #156000	Loss: 0.302737
Step #160000	Loss: 0.307390
Step #164000	Loss: 0.299207
Step #168000	Loss: 0.305748
Step #172000	Loss: 0.301578
Step #176000	Loss: 0.309496
Step #180000	Loss: 0.301875
Step #184000	Loss: 0.305960
Step #188000	Loss: 0.316634
Step #192000	Loss: 0.319318
Step #196000	Loss: 0.336553
Step #200000	Loss: 0.307046
Step #204000	Loss: 0.293291
Step #208000	Loss: 0.309668
Step #212000	Loss: 0.303063
Step #216000	Loss: 0.313419
Step #220000	Loss: 0.325460
Code block 'train epoch=2' took: 1664507.50745 ms
train loss 0.30966296792030334
Code block 'val epoch=2' took: 92317.31558 ms
validation loss 0.741670548915863
Step #0	Loss: 0.373513
Step #4000	Loss: 0.292106
Step #8000	Loss: 0.283342
Step #12000	Loss: 0.308915
Step #16000	Loss: 0.308750
Step #20000	Loss: 0.304160
Step #24000	Loss: 0.310024
Step #28000	Loss: 0.302425
Step #32000	Loss: 0.289490
Step #36000	Loss: 0.305034
Step #40000	Loss: 0.309114
Step #44000	Loss: 0.283439
Step #48000	Loss: 0.299396
Step #52000	Loss: 0.296608
Step #56000	Loss: 0.296155
Step #60000	Loss: 0.311183
Step #64000	Loss: 0.297113
Step #68000	Loss: 0.317132
Step #72000	Loss: 0.306096
Step #76000	Loss: 0.293555
Step #80000	Loss: 0.303156
Step #84000	Loss: 0.315731
Step #88000	Loss: 0.306493
Step #92000	Loss: 0.315023
Step #96000	Loss: 0.317787
Step #100000	Loss: 0.307513
Step #104000	Loss: 0.302306
Step #108000	Loss: 0.321801
Step #112000	Loss: 0.301321
Step #116000	Loss: 0.306936
Step #120000	Loss: 0.291867
Step #124000	Loss: 0.286821
Step #128000	Loss: 0.304489
Step #132000	Loss: 0.329665
Step #136000	Loss: 0.315984
Step #140000	Loss: 0.290359
Step #144000	Loss: 0.298835
Step #148000	Loss: 0.309750
Step #152000	Loss: 0.292932
Step #156000	Loss: 0.310010
Step #160000	Loss: 0.288839
Step #164000	Loss: 0.283598
Step #168000	Loss: 0.319326
Step #172000	Loss: 0.311885
Step #176000	Loss: 0.301256
Step #180000	Loss: 0.305876
Step #184000	Loss: 0.297975
Step #188000	Loss: 0.321673
Step #192000	Loss: 0.319626
Step #196000	Loss: 0.306338
Step #200000	Loss: 0.304927
Step #204000	Loss: 0.298010
Step #208000	Loss: 0.308039
Step #212000	Loss: 0.303103
Step #216000	Loss: 0.310695
Step #220000	Loss: 0.304273
Code block 'train epoch=3' took: 1667759.14172 ms
train loss 0.30475568771362305
Code block 'val epoch=3' took: 91799.24670 ms
validation loss 0.726121723651886
Step #0	Loss: 0.356062
Step #4000	Loss: 0.292567
Step #8000	Loss: 0.286348
Step #12000	Loss: 0.291004
Step #16000	Loss: 0.301203
Step #20000	Loss: 0.303272
Step #24000	Loss: 0.300966
Step #28000	Loss: 0.312200
Step #32000	Loss: 0.297436
Step #36000	Loss: 0.298948
Step #40000	Loss: 0.311763
Step #44000	Loss: 0.277580
Step #48000	Loss: 0.299629
Step #52000	Loss: 0.302598
Step #56000	Loss: 0.298694
Step #60000	Loss: 0.290511
Step #64000	Loss: 0.287750
Step #68000	Loss: 0.307411
Step #72000	Loss: 0.291755
Step #76000	Loss: 0.289361
Step #80000	Loss: 0.299044
Step #84000	Loss: 0.313837
Step #88000	Loss: 0.303731
Step #92000	Loss: 0.318381
Step #96000	Loss: 0.309671
Step #100000	Loss: 0.296585
Step #104000	Loss: 0.304212
Step #108000	Loss: 0.303759
Step #112000	Loss: 0.287445
Step #116000	Loss: 0.308865
Step #120000	Loss: 0.314500
Step #124000	Loss: 0.303196
Step #128000	Loss: 0.318521
Step #132000	Loss: 0.315648
Step #136000	Loss: 0.323059
Step #140000	Loss: 0.288516
Step #144000	Loss: 0.302652
Step #148000	Loss: 0.302706
Step #152000	Loss: 0.297623
Step #156000	Loss: 0.298009
Step #160000	Loss: 0.298527
Step #164000	Loss: 0.301070
Step #168000	Loss: 0.299356
Step #172000	Loss: 0.299510
Step #176000	Loss: 0.292379
Step #180000	Loss: 0.301410
Step #184000	Loss: 0.296199
Step #188000	Loss: 0.315600
Step #192000	Loss: 0.311692
Step #196000	Loss: 0.314958
Step #200000	Loss: 0.300168
Step #204000	Loss: 0.298084
Step #208000	Loss: 0.292970
Step #212000	Loss: 0.302772
Step #216000	Loss: 0.291409
Step #220000	Loss: 0.305707
Code block 'train epoch=4' took: 1665457.78534 ms
train loss 0.30252552032470703
Code block 'val epoch=4' took: 92084.86298 ms
validation loss 0.7784149646759033
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --cufile-thread-count 4 --batch-size 8192 --epochs 5'
[WARN  tini (3590379)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-20 20:46:43.870775: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-20 20:46:47.506585: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-20 20:47:15.641450: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-20 20:51:07.400535: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-20 20:51:07.880691: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f36fbdb2840 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-20 20:51:07.904316: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-20 20:51:08.058866: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-20 20:51:09.159480: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-20 20:51:09.516428: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 1.257583
Step #4000	Loss: 0.399484
Step #8000	Loss: 0.308531
Step #12000	Loss: 0.330394
Step #16000	Loss: 0.324591
Step #20000	Loss: 0.375715
Step #24000	Loss: 0.443661
Step #28000	Loss: 0.334413
Step #32000	Loss: 0.352071
Step #36000	Loss: 0.432133
Step #40000	Loss: 0.341653
Step #44000	Loss: 0.407647
Step #48000	Loss: 0.312052
Step #52000	Loss: 0.352375
Step #56000	Loss: 0.429676
Step #60000	Loss: 0.321376
Step #64000	Loss: 0.343617
Step #68000	Loss: 0.420889
Step #72000	Loss: 0.398775
Step #76000	Loss: 0.434262
Step #80000	Loss: 0.327833
Step #84000	Loss: 0.351311
Step #88000	Loss: 0.367588
Step #92000	Loss: 0.430509
Step #96000	Loss: 0.375894
Step #100000	Loss: 0.370516
Step #104000	Loss: 0.314585
Step #108000	Loss: 0.361739
Step #112000	Loss: 0.331972
Step #116000	Loss: 0.346644
Step #120000	Loss: 0.351710
Step #124000	Loss: 0.343973
Step #128000	Loss: 0.370154
Step #132000	Loss: 0.353405
Step #136000	Loss: 0.456270
Step #140000	Loss: 0.343073
Step #144000	Loss: 0.335477
Step #148000	Loss: 0.360196
Step #152000	Loss: 0.421823
Step #156000	Loss: 0.334120
Step #160000	Loss: 0.336210
Step #164000	Loss: 0.323474
Step #168000	Loss: 0.359954
Step #172000	Loss: 0.349949
Step #176000	Loss: 0.346437
Step #180000	Loss: 0.337148
Step #184000	Loss: 0.366305
Step #188000	Loss: 0.481722
Step #192000	Loss: 0.345640
Step #196000	Loss: 0.385186
Step #200000	Loss: 0.336652
Step #204000	Loss: 0.328912
Step #208000	Loss: 0.324430
Step #212000	Loss: 0.352156
Step #216000	Loss: 0.370846
Step #220000	Loss: 0.342793
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 1690613.31702 ms
train loss 0.3598291277885437
Code block 'val epoch=0' took: 91745.97188 ms
validation loss 0.5875203609466553
Step #0	Loss: 0.460275
Step #4000	Loss: 0.328552
Step #8000	Loss: 0.301278
Step #12000	Loss: 0.320922
Step #16000	Loss: 0.327380
Step #20000	Loss: 0.324224
Step #24000	Loss: 0.362047
Step #28000	Loss: 0.306263
Step #32000	Loss: 0.302433
Step #36000	Loss: 0.347890
Step #40000	Loss: 0.318983
Step #44000	Loss: 0.342429
Step #48000	Loss: 0.297352
Step #52000	Loss: 0.315247
Step #56000	Loss: 0.328067
Step #60000	Loss: 0.304947
Step #64000	Loss: 0.303373
Step #68000	Loss: 0.352975
Step #72000	Loss: 0.337007
Step #76000	Loss: 0.352353
Step #80000	Loss: 0.320987
Step #84000	Loss: 0.334081
Step #88000	Loss: 0.324271
Step #92000	Loss: 0.350771
Step #96000	Loss: 0.338819
Step #100000	Loss: 0.321147
Step #104000	Loss: 0.307227
Step #108000	Loss: 0.316941
Step #112000	Loss: 0.334294
Step #116000	Loss: 0.321439
Step #120000	Loss: 0.318078
Step #124000	Loss: 0.315368
Step #128000	Loss: 0.335593
Step #132000	Loss: 0.342917
Step #136000	Loss: 0.363480
Step #140000	Loss: 0.323804
Step #144000	Loss: 0.303132
Step #148000	Loss: 0.315807
Step #152000	Loss: 0.329735
Step #156000	Loss: 0.321743
Step #160000	Loss: 0.309285
Step #164000	Loss: 0.299885
Step #168000	Loss: 0.321544
Step #172000	Loss: 0.312633
Step #176000	Loss: 0.302702
Step #180000	Loss: 0.311213
Step #184000	Loss: 0.315625
Step #188000	Loss: 0.358757
Step #192000	Loss: 0.326917
Step #196000	Loss: 0.329634
Step #200000	Loss: 0.314646
Step #204000	Loss: 0.310847
Step #208000	Loss: 0.298869
Step #212000	Loss: 0.318671
Step #216000	Loss: 0.329809
Step #220000	Loss: 0.309760
Code block 'train epoch=1' took: 1670289.80760 ms
train loss 0.32217156887054443
Code block 'val epoch=1' took: 91620.66734 ms
validation loss 0.6348687410354614
Step #0	Loss: 0.394935
Step #4000	Loss: 0.310811
Step #8000	Loss: 0.307052
Step #12000	Loss: 0.310186
Step #16000	Loss: 0.298192
Step #20000	Loss: 0.322053
Step #24000	Loss: 0.314314
Step #28000	Loss: 0.306377
Step #32000	Loss: 0.311146
Step #36000	Loss: 0.333082
Step #40000	Loss: 0.312411
Step #44000	Loss: 0.310747
Step #48000	Loss: 0.291092
Step #52000	Loss: 0.310094
Step #56000	Loss: 0.330106
Step #60000	Loss: 0.298616
Step #64000	Loss: 0.302531
Step #68000	Loss: 0.325277
Step #72000	Loss: 0.300248
Step #76000	Loss: 0.323154
Step #80000	Loss: 0.310922
Step #84000	Loss: 0.324910
Step #88000	Loss: 0.314684
Step #92000	Loss: 0.334395
Step #96000	Loss: 0.320734
Step #100000	Loss: 0.308823
Step #104000	Loss: 0.301133
Step #108000	Loss: 0.321999
Step #112000	Loss: 0.317106
Step #116000	Loss: 0.304648
Step #120000	Loss: 0.307596
Step #124000	Loss: 0.309965
Step #128000	Loss: 0.332911
Step #132000	Loss: 0.322181
Step #136000	Loss: 0.335560
Step #140000	Loss: 0.316408
Step #144000	Loss: 0.298820
Step #148000	Loss: 0.298176
Step #152000	Loss: 0.306432
Step #156000	Loss: 0.315193
Step #160000	Loss: 0.305693
Step #164000	Loss: 0.299290
Step #168000	Loss: 0.307774
Step #172000	Loss: 0.303085
Step #176000	Loss: 0.296798
Step #180000	Loss: 0.300962
Step #184000	Loss: 0.299981
Step #188000	Loss: 0.334357
Step #192000	Loss: 0.319085
Step #196000	Loss: 0.316532
Step #200000	Loss: 0.324813
Step #204000	Loss: 0.303224
Step #208000	Loss: 0.288048
Step #212000	Loss: 0.314025
Step #216000	Loss: 0.317818
Step #220000	Loss: 0.306639
Code block 'train epoch=2' took: 1671512.10860 ms
train loss 0.31121936440467834
Code block 'val epoch=2' took: 91384.71739 ms
validation loss 0.6778528690338135
Step #0	Loss: 0.374660
Step #4000	Loss: 0.288323
Step #8000	Loss: 0.293084
Step #12000	Loss: 0.292763
Step #16000	Loss: 0.302974
Step #20000	Loss: 0.317143
Step #24000	Loss: 0.313041
Step #28000	Loss: 0.312844
Step #32000	Loss: 0.302096
Step #36000	Loss: 0.317427
Step #40000	Loss: 0.301747
Step #44000	Loss: 0.291543
Step #48000	Loss: 0.291466
Step #52000	Loss: 0.288369
Step #56000	Loss: 0.303708
Step #60000	Loss: 0.291898
Step #64000	Loss: 0.292738
Step #68000	Loss: 0.323635
Step #72000	Loss: 0.293252
Step #76000	Loss: 0.310379
Step #80000	Loss: 0.300455
Step #84000	Loss: 0.314215
Step #88000	Loss: 0.307488
Step #92000	Loss: 0.312631
Step #96000	Loss: 0.311989
Step #100000	Loss: 0.300431
Step #104000	Loss: 0.299256
Step #108000	Loss: 0.309989
Step #112000	Loss: 0.310220
Step #116000	Loss: 0.310275
Step #120000	Loss: 0.308493
Step #124000	Loss: 0.291282
Step #128000	Loss: 0.312112
Step #132000	Loss: 0.319422
Step #136000	Loss: 0.321008
Step #140000	Loss: 0.310410
Step #144000	Loss: 0.291352
Step #148000	Loss: 0.295533
Step #152000	Loss: 0.307739
Step #156000	Loss: 0.303302
Step #160000	Loss: 0.308273
Step #164000	Loss: 0.294044
Step #168000	Loss: 0.306692
Step #172000	Loss: 0.309918
Step #176000	Loss: 0.274124
Step #180000	Loss: 0.304616
Step #184000	Loss: 0.307947
Step #188000	Loss: 0.314356
Step #192000	Loss: 0.318423
Step #196000	Loss: 0.307836
Step #200000	Loss: 0.313316
Step #204000	Loss: 0.297888
Step #208000	Loss: 0.304143
Step #212000	Loss: 0.313069
Step #216000	Loss: 0.320028
Step #220000	Loss: 0.292620
Code block 'train epoch=3' took: 1672918.42415 ms
train loss 0.30552834272384644
Code block 'val epoch=3' took: 91675.37579 ms
validation loss 0.6879268884658813
Step #0	Loss: 0.367067
Step #4000	Loss: 0.301249
Step #8000	Loss: 0.290244
Step #12000	Loss: 0.301133
Step #16000	Loss: 0.301177
Step #20000	Loss: 0.302641
Step #24000	Loss: 0.302021
Step #28000	Loss: 0.297390
Step #32000	Loss: 0.295531
Step #36000	Loss: 0.307297
Step #40000	Loss: 0.311884
Step #44000	Loss: 0.294695
Step #48000	Loss: 0.286711
Step #52000	Loss: 0.294801
Step #56000	Loss: 0.299634
Step #60000	Loss: 0.290777
Step #64000	Loss: 0.302022
Step #68000	Loss: 0.316818
Step #72000	Loss: 0.289070
Step #76000	Loss: 0.299505
Step #80000	Loss: 0.293735
Step #84000	Loss: 0.310117
Step #88000	Loss: 0.297813
Step #92000	Loss: 0.321472
Step #96000	Loss: 0.312281
Step #100000	Loss: 0.298364
Step #104000	Loss: 0.289331
Step #108000	Loss: 0.306029
Step #112000	Loss: 0.297855
Step #116000	Loss: 0.298305
Step #120000	Loss: 0.311651
Step #124000	Loss: 0.306342
Step #128000	Loss: 0.326111
Step #132000	Loss: 0.322397
Step #136000	Loss: 0.310898
Step #140000	Loss: 0.316149
Step #144000	Loss: 0.295670
Step #148000	Loss: 0.296602
Step #152000	Loss: 0.306176
Step #156000	Loss: 0.298779
Step #160000	Loss: 0.301899
Step #164000	Loss: 0.283147
Step #168000	Loss: 0.308809
Step #172000	Loss: 0.305055
Step #176000	Loss: 0.292288
Step #180000	Loss: 0.300173
Step #184000	Loss: 0.297892
Step #188000	Loss: 0.327958
Step #192000	Loss: 0.323537
Step #196000	Loss: 0.312429
Step #200000	Loss: 0.309619
Step #204000	Loss: 0.296617
Step #208000	Loss: 0.292246
Step #212000	Loss: 0.309003
Step #216000	Loss: 0.324657
Step #220000	Loss: 0.297231
Code block 'train epoch=4' took: 1671968.29160 ms
train loss 0.30306175351142883
Code block 'val epoch=4' took: 91383.66046 ms
validation loss 0.736799955368042
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --cufile-thread-count 4 --batch-size 8192 --epochs 5'
[WARN  tini (3777415)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-20 23:18:20.518657: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-20 23:18:24.454934: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-20 23:18:55.859932: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-20 23:22:45.395224: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-20 23:22:46.035735: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f74a535d7d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-20 23:22:46.036851: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-20 23:22:46.208203: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-20 23:22:47.257468: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-20 23:22:47.662577: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 2.535566
Step #4000	Loss: 0.368843
Step #8000	Loss: 0.376156
Failed to transform operator <nvtabular.ops.categorify.Categorify object at 0x7f7c001b7a60>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1778, in _encode
    labels = codes.merge(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/dataframe.py", line 4004, in merge
    ).perform_merge()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/join/join.py", line 203, in perform_merge
    self.rhs._gather(gather_map=right_rows, **gather_kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
Step #12000	Loss: 0.348163
Code block 'train epoch=0' took: 139294.20659 ms
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1778, in _encode
    labels = codes.merge(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/dataframe.py", line 4004, in merge
    ).perform_merge()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/join/join.py", line 203, in perform_merge
    self.rhs._gather(gather_map=right_rows, **gather_kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home2/faculty/pwesolowski/praca-mgr/pipelines-repo/2_merlin/run_merlin.py", line 155, in <module>
    for batch, (examples, labels) in enumerate(train_tf_ds):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/tensorflow.py", line 97, in __next__
    converted_batch = self.convert_batch(super().__next__())
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 261, in __next__
    return self._get_next_batch()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 343, in _get_next_batch
    self._fetch_chunk()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 277, in _fetch_chunk
    raise chunks
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 791, in load_chunks
    self.chunk_logic(itr)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 759, in chunk_logic
    for chunks in self.batch(itr):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 745, in batch
    value = next(itr)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/io/dataframe_iter.py", line 44, in __iter__
    yield part.compute(scheduler="synchronous")
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/base.py", line 314, in compute
    (result,) = compute(self, traverse=False, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/base.py", line 599, in compute
    results = schedule(dsk, keys, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 557, in get_sync
    return get_async(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 500, in get_async
    for key, res_info, failed in queue_get(queue).result():
  File "/opt/conda/envs/rapids/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/opt/conda/envs/rapids/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 542, in submit
    fut.set_result(fn(*args, **kwargs))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 238, in batch_execute_tasks
    return [execute_task(*a) for a in it]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 238, in <listcomp>
    return [execute_task(*a) for a in it]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 229, in execute_task
    result = pack_exception(e, dumps)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 224, in execute_task
    result = _execute_task(task, data)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/optimization.py", line 990, in __call__
    return core.get(self.dsk, self.outkey, dict(zip(self.inkeys, args)))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 149, in get
    result = _execute_task(task, cache)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in <genexpr>
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/utils.py", line 72, in apply
    return func(*args, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 87, in transform
    transformed_data = self._execute_node(node, transformable, capture_dtypes, strict)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 101, in _execute_node
    upstream_outputs = self._run_upstream_transforms(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 114, in _run_upstream_transforms
    node_output = self._execute_node(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 107, in _execute_node
    transform_output = self._run_node_transform(node, transform_input, capture_dtypes, strict)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 227, in _run_node_transform
    raise exc
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --cufile-thread-count 4 --batch-size 8192 --epochs 5'
[WARN  tini (3785288)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-20 23:24:58.191859: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-20 23:25:01.481602: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-20 23:25:28.365012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
Failed to transform operator <nvtabular.ops.categorify.Categorify object at 0x7fb345c33af0>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1780, in _encode
    ).sort_values("order")["labels"]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 2214, in sort_values
    out = self._gather(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-20 23:29:20.730329: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-20 23:29:21.333344: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fae8004fa40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-20 23:29:21.334415: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-20 23:29:21.509732: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-20 23:29:22.715543: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-20 23:29:23.119999: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 2.289061
Code block 'train epoch=0' took: 59266.64200 ms
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 332, in _get_next_batch
    batch = next(self._batch_itr)
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home2/faculty/pwesolowski/praca-mgr/pipelines-repo/2_merlin/run_merlin.py", line 155, in <module>
    for batch, (examples, labels) in enumerate(train_tf_ds):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/tensorflow.py", line 97, in __next__
    converted_batch = self.convert_batch(super().__next__())
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 261, in __next__
    return self._get_next_batch()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 344, in _get_next_batch
    batch = next(self._batch_itr)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 369, in make_tensors
    tensors_by_name = self._convert_df_to_tensors(gdf)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 520, in _convert_df_to_tensors
    tensors_by_name[column_name] = self._to_tensor(gdf_i[[column_name]])
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 450, in _to_tensor
    tensor = df_or_series.to_cupy()
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/single_column_frame.py", line 131, in to_cupy
    return super().to_cupy(dtype, copy, na_value).flatten()
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 533, in to_cupy
    return self._to_array(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 498, in _to_array
    matrix[:, i] = get_column_values_na(col)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 477, in get_column_values_na
    return get_column_values(col)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 534, in <lambda>
    (lambda col: col.values.copy())
  File "cupy/_core/core.pyx", line 590, in cupy._core.core._ndarray_base.copy
  File "cupy/_core/core.pyx", line 616, in cupy._core.core._ndarray_base.copy
  File "cupy/_core/core.pyx", line 575, in cupy._core.core._ndarray_base.astype
  File "cupy/_core/core.pyx", line 136, in cupy._core.core.ndarray.__new__
  File "cupy/_core/core.pyx", line 224, in cupy._core.core._ndarray_base._init
  File "cupy/cuda/memory.pyx", line 742, in cupy.cuda.memory.alloc
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/rmm/rmm.py", line 230, in rmm_cupy_allocator
    buf = librmm.device_buffer.DeviceBuffer(size=nbytes, stream=stream)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --cufile-thread-count 4 --batch-size 8192 --epochs 5'
[WARN  tini (3792085)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-20 23:30:12.790072: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-20 23:30:16.967568: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-20 23:30:48.837686: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
terminate called after throwing an instance of 'rmm::out_of_memory'
  what():  std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp
[dgx-2:3792110] *** Process received signal ***
[dgx-2:3792110] Signal: Aborted (6)
[dgx-2:3792110] Signal code:  (-6)
[dgx-2:3792110] [ 0] /lib/x86_64-linux-gnu/libc.so.6(+0x42520)[0x7efd98810520]
[dgx-2:3792110] [ 1] /lib/x86_64-linux-gnu/libc.so.6(pthread_kill+0x12c)[0x7efd98864a7c]
[dgx-2:3792110] [ 2] /lib/x86_64-linux-gnu/libc.so.6(raise+0x16)[0x7efd98810476]
[dgx-2:3792110] [ 3] /lib/x86_64-linux-gnu/libc.so.6(abort+0xd3)[0x7efd987f67f3]
[dgx-2:3792110] [ 4] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(_ZN9__gnu_cxx27__verbose_terminate_handlerEv+0xc0)[0x7efd9597e026]
[dgx-2:3792110] [ 5] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(+0xb0514)[0x7efd9597c514]
[dgx-2:3792110] [ 6] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(+0xb0566)[0x7efd9597c566]
[dgx-2:3792110] [ 7] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(__cxa_rethrow+0x0)[0x7efd9597c758]
[dgx-2:3792110] [ 8] /opt/conda/envs/rapids/lib/python3.10/site-packages/rmm/_lib/device_buffer.cpython-310-x86_64-linux-gnu.so(+0x4b67d)[0x7efca428067d]
[dgx-2:3792110] [ 9] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf6columnC2ERKS0_N3rmm16cuda_stream_viewEPNS3_2mr22device_memory_resourceE+0x6d)[0x7efb63ad6add]
[dgx-2:3792110] [10] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf5tableC1ERKS0_+0x263)[0x7efb65210ec3]
[dgx-2:3792110] [11] /home2/faculty/pwesolowski/praca-mgr/parser-repo/build/libmeta-cudf-parser-1.so(_Z25generate_example_metadataPKcmmi11end_of_linebb+0x87d)[0x7ef5c256227d]
[dgx-2:3792110] [12] /home2/faculty/pwesolowski/praca-mgr/parser-repo/python_binding/metajsonparser/_lib/json_cudf.cpython-310-x86_64-linux-gnu.so(+0x4b344)[0x7ef5c2639344]
[dgx-2:3792110] [13] python(+0x13fb27)[0x5600e37fcb27]
[dgx-2:3792110] [14] python(PyObject_Call+0x209)[0x5600e3809139]
[dgx-2:3792110] [15] python(_PyEval_EvalFrameDefault+0x5d8c)[0x5600e37f2b7c]
[dgx-2:3792110] [16] python(_PyFunction_Vectorcall+0x6f)[0x5600e37fcf8f]
[dgx-2:3792110] [17] python(_PyEval_EvalFrameDefault+0x2ec2)[0x5600e37efcb2]
[dgx-2:3792110] [18] python(_PyFunction_Vectorcall+0x6f)[0x5600e37fcf8f]
[dgx-2:3792110] [19] python(_PyEval_EvalFrameDefault+0x332)[0x5600e37ed122]
[dgx-2:3792110] [20] python(_PyFunction_Vectorcall+0x6f)[0x5600e37fcf8f]
[dgx-2:3792110] [21] python(_PyEval_EvalFrameDefault+0x2ec2)[0x5600e37efcb2]
[dgx-2:3792110] [22] python(_PyFunction_Vectorcall+0x6f)[0x5600e37fcf8f]
[dgx-2:3792110] [23] python(_PyEval_EvalFrameDefault+0x332)[0x5600e37ed122]
[dgx-2:3792110] [24] python(_PyFunction_Vectorcall+0x6f)[0x5600e37fcf8f]
[dgx-2:3792110] [25] python(_PyEval_EvalFrameDefault+0x2ec2)[0x5600e37efcb2]
[dgx-2:3792110] [26] python(+0x14b641)[0x5600e3808641]
[dgx-2:3792110] [27] python(_PyEval_EvalFrameDefault+0x332)[0x5600e37ed122]
[dgx-2:3792110] [28] python(_PyFunction_Vectorcall+0x6f)[0x5600e37fcf8f]
[dgx-2:3792110] [29] python(_PyEval_EvalFrameDefault+0x332)[0x5600e37ed122]
[dgx-2:3792110] *** End of error message ***
+ for CUFILE_THREAD_COUNT in 4 8 16 32 64
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --cufile-thread-count 8 --batch-size 8192 --epochs 5'
[WARN  tini (3797852)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-20 23:34:40.693433: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-20 23:34:44.150133: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-20 23:35:11.379623: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-20 23:39:07.757236: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-20 23:39:08.263759: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f82533aaa30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-20 23:39:08.264802: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-20 23:39:08.429163: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-20 23:39:09.564793: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-20 23:39:10.100663: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.697156
Step #4000	Loss: 0.284670
Step #8000	Loss: 0.333544
Step #12000	Loss: 0.313239
Step #16000	Loss: 0.331208
Step #20000	Loss: 0.321867
Step #24000	Loss: 0.432161
Step #28000	Loss: 0.400796
Step #32000	Loss: 0.434102
Step #36000	Loss: 0.383767
Step #40000	Loss: 0.332020
Step #44000	Loss: 0.363542
Step #48000	Loss: 0.320509
Step #52000	Loss: 0.324128
Step #56000	Loss: 0.343005
Step #60000	Loss: 0.383428
Step #64000	Loss: 0.317316
Step #68000	Loss: 0.339522
Step #72000	Loss: 0.352378
Step #76000	Loss: 0.360806
Step #80000	Loss: 0.380778
Step #84000	Loss: 0.359269
Step #88000	Loss: 0.365578
Step #92000	Loss: 0.378609
Step #96000	Loss: 0.310990
Step #100000	Loss: 0.430496
Step #104000	Loss: 0.322120
Step #108000	Loss: 0.344615
Step #112000	Loss: 0.334043
Step #116000	Loss: 0.379888
Step #120000	Loss: 0.327231
Step #124000	Loss: 0.330163
Step #128000	Loss: 0.386009
Step #132000	Loss: 0.335900
Step #136000	Loss: 0.434190
Step #140000	Loss: 0.414038
Step #144000	Loss: 0.425875
Step #148000	Loss: 0.324148
Step #152000	Loss: 0.426441
Step #156000	Loss: 0.323284
Step #160000	Loss: 0.353942
Step #164000	Loss: 0.302094
Step #168000	Loss: 0.437839
Step #172000	Loss: 0.405961
Step #176000	Loss: 0.293683
Step #180000	Loss: 0.358898
Step #184000	Loss: 0.329204
Step #188000	Loss: 0.465658
Step #192000	Loss: 0.418577
Step #196000	Loss: 0.449642
Step #200000	Loss: 0.337244
Step #204000	Loss: 0.291768
Step #208000	Loss: 0.344653
Step #212000	Loss: 0.346156
Step #216000	Loss: 0.403744
Step #220000	Loss: 0.416719
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 1715197.97894 ms
train loss 0.3613389730453491
Code block 'val epoch=0' took: 95565.94932 ms
validation loss 0.5919610261917114
Step #0	Loss: 0.449341
Step #4000	Loss: 0.291176
Step #8000	Loss: 0.314076
Step #12000	Loss: 0.307020
Step #16000	Loss: 0.312774
Step #20000	Loss: 0.321637
Step #24000	Loss: 0.352352
Step #28000	Loss: 0.349041
Step #32000	Loss: 0.363551
Step #36000	Loss: 0.336292
Step #40000	Loss: 0.320992
Step #44000	Loss: 0.309175
Step #48000	Loss: 0.306752
Step #52000	Loss: 0.316150
Step #56000	Loss: 0.322899
Step #60000	Loss: 0.331643
Step #64000	Loss: 0.296680
Step #68000	Loss: 0.327125
Step #72000	Loss: 0.331432
Step #76000	Loss: 0.324635
Step #80000	Loss: 0.331634
Step #84000	Loss: 0.344379
Step #88000	Loss: 0.321135
Step #92000	Loss: 0.334403
Step #96000	Loss: 0.298933
Step #100000	Loss: 0.354875
Step #104000	Loss: 0.314545
Step #108000	Loss: 0.322861
Step #112000	Loss: 0.298968
Step #116000	Loss: 0.319799
Step #120000	Loss: 0.300392
Step #124000	Loss: 0.303193
Step #128000	Loss: 0.329049
Step #132000	Loss: 0.322552
Step #136000	Loss: 0.365710
Step #140000	Loss: 0.364922
Step #144000	Loss: 0.354813
Step #148000	Loss: 0.313006
Step #152000	Loss: 0.353237
Step #156000	Loss: 0.303914
Step #160000	Loss: 0.310432
Step #164000	Loss: 0.298696
Step #168000	Loss: 0.353628
Step #172000	Loss: 0.350535
Step #176000	Loss: 0.285514
Step #180000	Loss: 0.321328
Step #184000	Loss: 0.299533
Step #188000	Loss: 0.374743
Step #192000	Loss: 0.349361
Step #196000	Loss: 0.374572
Step #200000	Loss: 0.316837
Step #204000	Loss: 0.280946
Step #208000	Loss: 0.325331
Step #212000	Loss: 0.319676
Step #216000	Loss: 0.341450
Step #220000	Loss: 0.348643
Code block 'train epoch=1' took: 1687262.93353 ms
train loss 0.3270168602466583
Code block 'val epoch=1' took: 95505.67174 ms
validation loss 0.6444392204284668
Step #0	Loss: 0.333821
Step #4000	Loss: 0.278300
Step #8000	Loss: 0.298933
Step #12000	Loss: 0.299004
Step #16000	Loss: 0.301475
Step #20000	Loss: 0.309495
Step #24000	Loss: 0.325594
Step #28000	Loss: 0.322330
Step #32000	Loss: 0.316677
Step #36000	Loss: 0.306526
Step #40000	Loss: 0.330078
Step #44000	Loss: 0.292911
Step #48000	Loss: 0.294297
Step #52000	Loss: 0.299231
Step #56000	Loss: 0.309616
Step #60000	Loss: 0.309021
Step #64000	Loss: 0.291206
Step #68000	Loss: 0.308646
Step #72000	Loss: 0.301301
Step #76000	Loss: 0.309263
Step #80000	Loss: 0.303101
Step #84000	Loss: 0.332579
Step #88000	Loss: 0.301410
Step #92000	Loss: 0.318134
Step #96000	Loss: 0.304663
Step #100000	Loss: 0.322792
Step #104000	Loss: 0.322606
Step #108000	Loss: 0.321791
Step #112000	Loss: 0.311050
Step #116000	Loss: 0.320145
Step #120000	Loss: 0.304757
Step #124000	Loss: 0.287597
Step #128000	Loss: 0.318676
Step #132000	Loss: 0.318870
Step #136000	Loss: 0.334548
Step #140000	Loss: 0.327038
Step #144000	Loss: 0.316600
Step #148000	Loss: 0.301110
Step #152000	Loss: 0.318712
Step #156000	Loss: 0.317684
Step #160000	Loss: 0.288332
Step #164000	Loss: 0.296376
Step #168000	Loss: 0.326600
Step #172000	Loss: 0.317647
Step #176000	Loss: 0.277591
Step #180000	Loss: 0.303596
Step #184000	Loss: 0.295084
Step #188000	Loss: 0.338489
Step #192000	Loss: 0.340428
Step #196000	Loss: 0.328626
Step #200000	Loss: 0.311128
Step #204000	Loss: 0.267159
Step #208000	Loss: 0.303507
Step #212000	Loss: 0.300067
Step #216000	Loss: 0.325763
Step #220000	Loss: 0.311032
Code block 'train epoch=2' took: 1686451.99568 ms
train loss 0.31247150897979736
Code block 'val epoch=2' took: 94858.48683 ms
validation loss 0.6716431379318237
Step #0	Loss: 0.308978
Step #4000	Loss: 0.275643
Step #8000	Loss: 0.290471
Step #12000	Loss: 0.304198
Step #16000	Loss: 0.290389
Step #20000	Loss: 0.302131
Step #24000	Loss: 0.307504
Step #28000	Loss: 0.305362
Step #32000	Loss: 0.295720
Step #36000	Loss: 0.298969
Step #40000	Loss: 0.312703
Step #44000	Loss: 0.284685
Step #48000	Loss: 0.298557
Step #52000	Loss: 0.303980
Step #56000	Loss: 0.314905
Step #60000	Loss: 0.311695
Step #64000	Loss: 0.285428
Step #68000	Loss: 0.310189
Step #72000	Loss: 0.294106
Step #76000	Loss: 0.295953
Step #80000	Loss: 0.310457
Step #84000	Loss: 0.325714
Step #88000	Loss: 0.306516
Step #92000	Loss: 0.308124
Step #96000	Loss: 0.304674
Step #100000	Loss: 0.329490
Step #104000	Loss: 0.303861
Step #108000	Loss: 0.314900
Step #112000	Loss: 0.299512
Step #116000	Loss: 0.305950
Step #120000	Loss: 0.291397
Step #124000	Loss: 0.282308
Step #128000	Loss: 0.309267
Step #132000	Loss: 0.317789
Step #136000	Loss: 0.322216
Step #140000	Loss: 0.329640
Step #144000	Loss: 0.301676
Step #148000	Loss: 0.300317
Step #152000	Loss: 0.317815
Step #156000	Loss: 0.299825
Step #160000	Loss: 0.276352
Step #164000	Loss: 0.298199
Step #168000	Loss: 0.325066
Step #172000	Loss: 0.318395
Step #176000	Loss: 0.282487
Step #180000	Loss: 0.304185
Step #184000	Loss: 0.299277
Step #188000	Loss: 0.323270
Step #192000	Loss: 0.312097
Step #196000	Loss: 0.322847
Step #200000	Loss: 0.316371
Step #204000	Loss: 0.268389
Step #208000	Loss: 0.311671
Step #212000	Loss: 0.303856
Step #216000	Loss: 0.318095
Step #220000	Loss: 0.300516
Code block 'train epoch=3' took: 1687858.10559 ms
train loss 0.30612272024154663
Code block 'val epoch=3' took: 95695.70008 ms
validation loss 0.7101337909698486
Step #0	Loss: 0.299332
Step #4000	Loss: 0.268697
Step #8000	Loss: 0.289020
Step #12000	Loss: 0.304817
Step #16000	Loss: 0.295361
Step #20000	Loss: 0.301568
Step #24000	Loss: 0.305782
Step #28000	Loss: 0.300485
Step #32000	Loss: 0.300664
Step #36000	Loss: 0.302333
Step #40000	Loss: 0.313445
Step #44000	Loss: 0.276294
Step #48000	Loss: 0.295137
Step #52000	Loss: 0.300796
Step #56000	Loss: 0.294249
Step #60000	Loss: 0.292703
Step #64000	Loss: 0.277814
Step #68000	Loss: 0.310667
Step #72000	Loss: 0.306451
Step #76000	Loss: 0.299903
Step #80000	Loss: 0.289324
Step #84000	Loss: 0.315659
Step #88000	Loss: 0.308068
Step #92000	Loss: 0.316108
Step #96000	Loss: 0.301099
Step #100000	Loss: 0.316288
Step #104000	Loss: 0.303540
Step #108000	Loss: 0.325965
Step #112000	Loss: 0.294255
Step #116000	Loss: 0.306313
Step #120000	Loss: 0.297431
Step #124000	Loss: 0.279993
Step #128000	Loss: 0.306572
Step #132000	Loss: 0.319540
Step #136000	Loss: 0.326294
Step #140000	Loss: 0.313156
Step #144000	Loss: 0.296421
Step #148000	Loss: 0.289388
Step #152000	Loss: 0.305069
Step #156000	Loss: 0.305254
Step #160000	Loss: 0.291249
Step #164000	Loss: 0.288656
Step #168000	Loss: 0.309837
Step #172000	Loss: 0.327801
Step #176000	Loss: 0.268932
Step #180000	Loss: 0.291260
Step #184000	Loss: 0.294180
Step #188000	Loss: 0.317697
Step #192000	Loss: 0.312380
Step #196000	Loss: 0.308309
Step #200000	Loss: 0.317974
Step #204000	Loss: 0.271445
Step #208000	Loss: 0.298241
Step #212000	Loss: 0.306734
Step #216000	Loss: 0.312902
Step #220000	Loss: 0.311065
Code block 'train epoch=4' took: 1686979.05515 ms
train loss 0.303078293800354
Code block 'val epoch=4' took: 95375.37062 ms
validation loss 0.7232301831245422
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --cufile-thread-count 8 --batch-size 8192 --epochs 5'
[WARN  tini (3979749)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-21 02:08:15.020930: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 02:08:18.666465: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-21 02:08:54.624208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-21 02:13:00.597555: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-21 02:13:01.402301: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f139c090690 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-21 02:13:01.403973: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-21 02:13:01.558777: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-21 02:13:02.748052: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-21 02:13:03.129017: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.496668
Step #4000	Loss: 0.300161
Step #8000	Loss: 0.315141
Step #12000	Loss: 0.341842
Step #16000	Loss: 0.318314
Step #20000	Loss: 0.308186
Step #24000	Loss: 0.432664
Step #28000	Loss: 0.434097
Step #32000	Loss: 0.436340
Step #36000	Loss: 0.417535
Step #40000	Loss: 0.340696
Step #44000	Loss: 0.349620
Step #48000	Loss: 0.361247
Step #52000	Loss: 0.358774
Step #56000	Loss: 0.391909
Step #60000	Loss: 0.427115
Step #64000	Loss: 0.342175
Step #68000	Loss: 0.378753
Step #72000	Loss: 0.349849
Step #76000	Loss: 0.328412
Step #80000	Loss: 0.341835
Step #84000	Loss: 0.345871
Step #88000	Loss: 0.398622
Step #92000	Loss: 0.389692
Step #96000	Loss: 0.320785
Step #100000	Loss: 0.431035
Step #104000	Loss: 0.356463
Step #108000	Loss: 0.373944
Step #112000	Loss: 0.321183
Step #116000	Loss: 0.334683
Step #120000	Loss: 0.313432
Step #124000	Loss: 0.374373
Step #128000	Loss: 0.395522
Step #132000	Loss: 0.329943
Step #136000	Loss: 0.442588
Step #140000	Loss: 0.416836
Step #144000	Loss: 0.333430
Step #148000	Loss: 0.343121
Step #152000	Loss: 0.453116
Step #156000	Loss: 0.325631
Step #160000	Loss: 0.382796
Step #164000	Loss: 0.301066
Step #168000	Loss: 0.446692
Step #172000	Loss: 0.317956
Step #176000	Loss: 0.357585
Step #180000	Loss: 0.376912
Step #184000	Loss: 0.312186
Step #188000	Loss: 0.463507
Step #192000	Loss: 0.452222
Step #196000	Loss: 0.457273
Step #200000	Loss: 0.326642
Step #204000	Loss: 0.320371
Step #208000	Loss: 0.320359
Step #212000	Loss: 0.325560
Step #216000	Loss: 0.404129
Step #220000	Loss: 0.358064
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 1708750.65933 ms
train loss 0.359565794467926
Code block 'val epoch=0' took: 95495.36274 ms
validation loss 0.6239576935768127
Step #0	Loss: 0.521114
Step #4000	Loss: 0.298191
Step #8000	Loss: 0.300523
Step #12000	Loss: 0.313728
Step #16000	Loss: 0.304264
Step #20000	Loss: 0.312942
Step #24000	Loss: 0.363928
Step #28000	Loss: 0.358780
Step #32000	Loss: 0.364891
Step #36000	Loss: 0.348733
Step #40000	Loss: 0.328948
Step #44000	Loss: 0.310551
Step #48000	Loss: 0.311226
Step #52000	Loss: 0.321266
Step #56000	Loss: 0.337944
Step #60000	Loss: 0.350138
Step #64000	Loss: 0.305460
Step #68000	Loss: 0.334942
Step #72000	Loss: 0.325663
Step #76000	Loss: 0.304279
Step #80000	Loss: 0.317605
Step #84000	Loss: 0.340951
Step #88000	Loss: 0.333810
Step #92000	Loss: 0.334653
Step #96000	Loss: 0.311268
Step #100000	Loss: 0.345131
Step #104000	Loss: 0.325110
Step #108000	Loss: 0.322484
Step #112000	Loss: 0.305632
Step #116000	Loss: 0.317477
Step #120000	Loss: 0.297269
Step #124000	Loss: 0.331502
Step #128000	Loss: 0.335049
Step #132000	Loss: 0.311189
Step #136000	Loss: 0.370611
Step #140000	Loss: 0.359509
Step #144000	Loss: 0.308878
Step #148000	Loss: 0.326801
Step #152000	Loss: 0.366181
Step #156000	Loss: 0.319378
Step #160000	Loss: 0.314164
Step #164000	Loss: 0.286696
Step #168000	Loss: 0.360405
Step #172000	Loss: 0.299399
Step #176000	Loss: 0.311669
Step #180000	Loss: 0.323162
Step #184000	Loss: 0.303259
Step #188000	Loss: 0.373580
Step #192000	Loss: 0.367331
Step #196000	Loss: 0.375296
Step #200000	Loss: 0.314279
Step #204000	Loss: 0.299316
Step #208000	Loss: 0.302233
Step #212000	Loss: 0.325560
Step #216000	Loss: 0.350654
Step #220000	Loss: 0.321837
Code block 'train epoch=1' took: 1682733.22458 ms
train loss 0.3238392770290375
Code block 'val epoch=1' took: 94515.91183 ms
validation loss 0.6377975940704346
Step #0	Loss: 0.384469
Step #4000	Loss: 0.291290
Step #8000	Loss: 0.299232
Step #12000	Loss: 0.302509
Step #16000	Loss: 0.303966
Step #20000	Loss: 0.305926
Step #24000	Loss: 0.327948
Step #28000	Loss: 0.318876
Step #32000	Loss: 0.310793
Step #36000	Loss: 0.324265
Step #40000	Loss: 0.314090
Step #44000	Loss: 0.301208
Step #48000	Loss: 0.304560
Step #52000	Loss: 0.313399
Step #56000	Loss: 0.318645
Step #60000	Loss: 0.321898
Step #64000	Loss: 0.293709
Step #68000	Loss: 0.323722
Step #72000	Loss: 0.314135
Step #76000	Loss: 0.300946
Step #80000	Loss: 0.306616
Step #84000	Loss: 0.325536
Step #88000	Loss: 0.311497
Step #92000	Loss: 0.316292
Step #96000	Loss: 0.298417
Step #100000	Loss: 0.317652
Step #104000	Loss: 0.309097
Step #108000	Loss: 0.316858
Step #112000	Loss: 0.295705
Step #116000	Loss: 0.315521
Step #120000	Loss: 0.315160
Step #124000	Loss: 0.307316
Step #128000	Loss: 0.323747
Step #132000	Loss: 0.312435
Step #136000	Loss: 0.338195
Step #140000	Loss: 0.333469
Step #144000	Loss: 0.306936
Step #148000	Loss: 0.299539
Step #152000	Loss: 0.340061
Step #156000	Loss: 0.311565
Step #160000	Loss: 0.306539
Step #164000	Loss: 0.296599
Step #168000	Loss: 0.327747
Step #172000	Loss: 0.299241
Step #176000	Loss: 0.293140
Step #180000	Loss: 0.308655
Step #184000	Loss: 0.300242
Step #188000	Loss: 0.342463
Step #192000	Loss: 0.341096
Step #196000	Loss: 0.338239
Step #200000	Loss: 0.301627
Step #204000	Loss: 0.293426
Step #208000	Loss: 0.301473
Step #212000	Loss: 0.306714
Step #216000	Loss: 0.332123
Step #220000	Loss: 0.309530
Code block 'train epoch=2' took: 1680145.29493 ms
train loss 0.31087252497673035
Code block 'val epoch=2' took: 94798.58858 ms
validation loss 0.6341972351074219
Step #0	Loss: 0.331745
Step #4000	Loss: 0.289502
Step #8000	Loss: 0.292690
Step #12000	Loss: 0.291164
Step #16000	Loss: 0.297897
Step #20000	Loss: 0.307091
Step #24000	Loss: 0.307576
Step #28000	Loss: 0.312968
Step #32000	Loss: 0.302358
Step #36000	Loss: 0.299059
Step #40000	Loss: 0.312407
Step #44000	Loss: 0.272846
Step #48000	Loss: 0.294945
Step #52000	Loss: 0.306132
Step #56000	Loss: 0.313389
Step #60000	Loss: 0.303206
Step #64000	Loss: 0.301085
Step #68000	Loss: 0.324170
Step #72000	Loss: 0.300877
Step #76000	Loss: 0.295462
Step #80000	Loss: 0.309415
Step #84000	Loss: 0.316127
Step #88000	Loss: 0.306130
Step #92000	Loss: 0.309180
Step #96000	Loss: 0.296304
Step #100000	Loss: 0.311623
Step #104000	Loss: 0.298703
Step #108000	Loss: 0.312854
Step #112000	Loss: 0.300004
Step #116000	Loss: 0.310145
Step #120000	Loss: 0.307797
Step #124000	Loss: 0.300113
Step #128000	Loss: 0.310578
Step #132000	Loss: 0.309619
Step #136000	Loss: 0.328851
Step #140000	Loss: 0.323711
Step #144000	Loss: 0.303031
Step #148000	Loss: 0.295875
Step #152000	Loss: 0.329415
Step #156000	Loss: 0.303871
Step #160000	Loss: 0.292304
Step #164000	Loss: 0.296320
Step #168000	Loss: 0.322861
Step #172000	Loss: 0.291345
Step #176000	Loss: 0.291432
Step #180000	Loss: 0.304243
Step #184000	Loss: 0.295296
Step #188000	Loss: 0.330044
Step #192000	Loss: 0.327174
Step #196000	Loss: 0.326023
Step #200000	Loss: 0.309326
Step #204000	Loss: 0.288048
Step #208000	Loss: 0.290159
Step #212000	Loss: 0.301952
Step #216000	Loss: 0.321801
Step #220000	Loss: 0.303360
Code block 'train epoch=3' took: 1682806.79853 ms
train loss 0.3052797317504883
Code block 'val epoch=3' took: 95891.42541 ms
validation loss 0.6834758520126343
Step #0	Loss: 0.325511
Step #4000	Loss: 0.280466
Step #8000	Loss: 0.286847
Step #12000	Loss: 0.296088
Step #16000	Loss: 0.297726
Step #20000	Loss: 0.303428
Step #24000	Loss: 0.307207
Step #28000	Loss: 0.313637
Step #32000	Loss: 0.292512
Step #36000	Loss: 0.297805
Step #40000	Loss: 0.305696
Step #44000	Loss: 0.274562
Step #48000	Loss: 0.303140
Step #52000	Loss: 0.297740
Step #56000	Loss: 0.303931
Step #60000	Loss: 0.304948
Step #64000	Loss: 0.288524
Step #68000	Loss: 0.306829
Step #72000	Loss: 0.290581
Step #76000	Loss: 0.296277
Step #80000	Loss: 0.296968
Step #84000	Loss: 0.319962
Step #88000	Loss: 0.289319
Step #92000	Loss: 0.307646
Step #96000	Loss: 0.300719
Step #100000	Loss: 0.305249
Step #104000	Loss: 0.303739
Step #108000	Loss: 0.299967
Step #112000	Loss: 0.302559
Step #116000	Loss: 0.310710
Step #120000	Loss: 0.299490
Step #124000	Loss: 0.286453
Step #128000	Loss: 0.303373
Step #132000	Loss: 0.309764
Step #136000	Loss: 0.319815
Step #140000	Loss: 0.313276
Step #144000	Loss: 0.299755
Step #148000	Loss: 0.295510
Step #152000	Loss: 0.301892
Step #156000	Loss: 0.319825
Step #160000	Loss: 0.289209
Step #164000	Loss: 0.300507
Step #168000	Loss: 0.294037
Step #172000	Loss: 0.287768
Step #176000	Loss: 0.300084
Step #180000	Loss: 0.307252
Step #184000	Loss: 0.294266
Step #188000	Loss: 0.318506
Step #192000	Loss: 0.313110
Step #196000	Loss: 0.306140
Step #200000	Loss: 0.306343
Step #204000	Loss: 0.295534
Step #208000	Loss: 0.288599
Step #212000	Loss: 0.301130
Step #216000	Loss: 0.309237
Step #220000	Loss: 0.308870
Code block 'train epoch=4' took: 1681825.68838 ms
train loss 0.30268675088882446
Code block 'val epoch=4' took: 94569.29976 ms
validation loss 0.6873434782028198
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --cufile-thread-count 8 --batch-size 8192 --epochs 5'
[WARN  tini (4178396)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-21 04:41:30.139253: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 04:41:34.051312: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-21 04:42:06.727050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-21 04:46:09.179119: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-21 04:46:09.774485: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f56f7d0bcf0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-21 04:46:09.775839: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-21 04:46:09.941711: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-21 04:46:11.161949: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-21 04:46:11.466727: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 4.256944
Step #4000	Loss: 0.312829
Step #8000	Loss: 0.366773
Step #12000	Loss: 0.317196
Step #16000	Loss: 0.341990
Step #20000	Loss: 0.323202
Step #24000	Loss: 0.380479
Step #28000	Loss: 0.320883
Step #32000	Loss: 0.427222
Step #36000	Loss: 0.361977
Step #40000	Loss: 0.335297
Step #44000	Loss: 0.289823
Step #48000	Loss: 0.394323
Step #52000	Loss: 0.346273
Step #56000	Loss: 0.316729
Step #60000	Loss: 0.431462
Step #64000	Loss: 0.334368
Step #68000	Loss: 0.323424
Step #72000	Loss: 0.354203
Step #76000	Loss: 0.344386
Step #80000	Loss: 0.327596
Step #84000	Loss: 0.435206
Step #88000	Loss: 0.354103
Step #92000	Loss: 0.416427
Step #96000	Loss: 0.319421
Step #100000	Loss: 0.352635
Step #104000	Loss: 0.307151
Step #108000	Loss: 0.365690
Step #112000	Loss: 0.318711
Step #116000	Loss: 0.314701
Step #120000	Loss: 0.334772
Step #124000	Loss: 0.338040
Step #128000	Loss: 0.346320
Step #132000	Loss: 0.335166
Step #136000	Loss: 0.465119
Step #140000	Loss: 0.380895
Step #144000	Loss: 0.439217
Step #148000	Loss: 0.358066
Step #152000	Loss: 0.456876
Step #156000	Loss: 0.367410
Step #160000	Loss: 0.349532
Step #164000	Loss: 0.327155
Step #168000	Loss: 0.437008
Step #172000	Loss: 0.322848
Step #176000	Loss: 0.339887
Step #180000	Loss: 0.332185
Step #184000	Loss: 0.319429
Step #188000	Loss: 0.467650
Step #192000	Loss: 0.385161
Step #196000	Loss: 0.356296
Step #200000	Loss: 0.327737
Step #204000	Loss: 0.372646
Step #208000	Loss: 0.411254
Step #212000	Loss: 0.335758
Step #216000	Loss: 0.423981
Step #220000	Loss: 0.354878
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 1709756.21878 ms
train loss 0.3603356182575226
Code block 'val epoch=0' took: 94328.12391 ms
validation loss 0.6622832417488098
Step #0	Loss: 0.501516
Step #4000	Loss: 0.308709
Step #8000	Loss: 0.310841
Step #12000	Loss: 0.316445
Step #16000	Loss: 0.319168
Step #20000	Loss: 0.313666
Step #24000	Loss: 0.327922
Step #28000	Loss: 0.311910
Step #32000	Loss: 0.359356
Step #36000	Loss: 0.321618
Step #40000	Loss: 0.309340
Step #44000	Loss: 0.295172
Step #48000	Loss: 0.335931
Step #52000	Loss: 0.320789
Step #56000	Loss: 0.309266
Step #60000	Loss: 0.348342
Step #64000	Loss: 0.305546
Step #68000	Loss: 0.303328
Step #72000	Loss: 0.324777
Step #76000	Loss: 0.317710
Step #80000	Loss: 0.313722
Step #84000	Loss: 0.361171
Step #88000	Loss: 0.307850
Step #92000	Loss: 0.360137
Step #96000	Loss: 0.315552
Step #100000	Loss: 0.318118
Step #104000	Loss: 0.301554
Step #108000	Loss: 0.334541
Step #112000	Loss: 0.298413
Step #116000	Loss: 0.304070
Step #120000	Loss: 0.323940
Step #124000	Loss: 0.310943
Step #128000	Loss: 0.329705
Step #132000	Loss: 0.311105
Step #136000	Loss: 0.373624
Step #140000	Loss: 0.337013
Step #144000	Loss: 0.352480
Step #148000	Loss: 0.305686
Step #152000	Loss: 0.369213
Step #156000	Loss: 0.330517
Step #160000	Loss: 0.328275
Step #164000	Loss: 0.305415
Step #168000	Loss: 0.367306
Step #172000	Loss: 0.304044
Step #176000	Loss: 0.306376
Step #180000	Loss: 0.305417
Step #184000	Loss: 0.286767
Step #188000	Loss: 0.366630
Step #192000	Loss: 0.340437
Step #196000	Loss: 0.319877
Step #200000	Loss: 0.312950
Step #204000	Loss: 0.316831
Step #208000	Loss: 0.332811
Step #212000	Loss: 0.319839
Step #216000	Loss: 0.359712
Step #220000	Loss: 0.309550
Code block 'train epoch=1' took: 1680746.34968 ms
train loss 0.3237171173095703
Code block 'val epoch=1' took: 93996.92451 ms
validation loss 0.6905954480171204
Step #0	Loss: 0.407148
Step #4000	Loss: 0.293933
Step #8000	Loss: 0.301887
Step #12000	Loss: 0.317290
Step #16000	Loss: 0.301792
Step #20000	Loss: 0.317845
Step #24000	Loss: 0.322188
Step #28000	Loss: 0.302253
Step #32000	Loss: 0.320332
Step #36000	Loss: 0.309583
Step #40000	Loss: 0.317142
Step #44000	Loss: 0.286616
Step #48000	Loss: 0.300917
Step #52000	Loss: 0.314885
Step #56000	Loss: 0.300298
Step #60000	Loss: 0.315878
Step #64000	Loss: 0.305557
Step #68000	Loss: 0.310506
Step #72000	Loss: 0.303964
Step #76000	Loss: 0.308234
Step #80000	Loss: 0.317607
Step #84000	Loss: 0.342663
Step #88000	Loss: 0.311534
Step #92000	Loss: 0.331182
Step #96000	Loss: 0.302491
Step #100000	Loss: 0.306948
Step #104000	Loss: 0.299322
Step #108000	Loss: 0.317658
Step #112000	Loss: 0.289861
Step #116000	Loss: 0.300133
Step #120000	Loss: 0.299713
Step #124000	Loss: 0.308646
Step #128000	Loss: 0.310680
Step #132000	Loss: 0.312464
Step #136000	Loss: 0.342376
Step #140000	Loss: 0.320114
Step #144000	Loss: 0.326194
Step #148000	Loss: 0.307786
Step #152000	Loss: 0.330827
Step #156000	Loss: 0.313644
Step #160000	Loss: 0.315560
Step #164000	Loss: 0.300131
Step #168000	Loss: 0.330219
Step #172000	Loss: 0.295002
Step #176000	Loss: 0.299766
Step #180000	Loss: 0.310991
Step #184000	Loss: 0.296170
Step #188000	Loss: 0.329421
Step #192000	Loss: 0.317098
Step #196000	Loss: 0.332955
Step #200000	Loss: 0.312182
Step #204000	Loss: 0.300562
Step #208000	Loss: 0.315260
Step #212000	Loss: 0.299285
Step #216000	Loss: 0.338610
Step #220000	Loss: 0.308241
Code block 'train epoch=2' took: 1681608.05682 ms
train loss 0.31085386872291565
Code block 'val epoch=2' took: 94238.24852 ms
validation loss 0.7311018705368042
Step #0	Loss: 0.382464
Step #4000	Loss: 0.302855
Step #8000	Loss: 0.294992
Step #12000	Loss: 0.313555
Step #16000	Loss: 0.289541
Step #20000	Loss: 0.302533
Step #24000	Loss: 0.303255
Step #28000	Loss: 0.292701
Step #32000	Loss: 0.297916
Step #36000	Loss: 0.298360
Step #40000	Loss: 0.305689
Step #44000	Loss: 0.277630
Step #48000	Loss: 0.294880
Step #52000	Loss: 0.301046
Step #56000	Loss: 0.307310
Step #60000	Loss: 0.312721
Step #64000	Loss: 0.285096
Step #68000	Loss: 0.313771
Step #72000	Loss: 0.304958
Step #76000	Loss: 0.301072
Step #80000	Loss: 0.299935
Step #84000	Loss: 0.328250
Step #88000	Loss: 0.292690
Step #92000	Loss: 0.319563
Step #96000	Loss: 0.302550
Step #100000	Loss: 0.300076
Step #104000	Loss: 0.307044
Step #108000	Loss: 0.315061
Step #112000	Loss: 0.291325
Step #116000	Loss: 0.304630
Step #120000	Loss: 0.298321
Step #124000	Loss: 0.298401
Step #128000	Loss: 0.310358
Step #132000	Loss: 0.318173
Step #136000	Loss: 0.328162
Step #140000	Loss: 0.320830
Step #144000	Loss: 0.310105
Step #148000	Loss: 0.297799
Step #152000	Loss: 0.314409
Step #156000	Loss: 0.310175
Step #160000	Loss: 0.310531
Step #164000	Loss: 0.286967
Step #168000	Loss: 0.323313
Step #172000	Loss: 0.306476
Step #176000	Loss: 0.287509
Step #180000	Loss: 0.301765
Step #184000	Loss: 0.303672
Step #188000	Loss: 0.325345
Step #192000	Loss: 0.321628
Step #196000	Loss: 0.314861
Step #200000	Loss: 0.299786
Step #204000	Loss: 0.291015
Step #208000	Loss: 0.311002
Step #212000	Loss: 0.303702
Step #216000	Loss: 0.324763
Step #220000	Loss: 0.303851
Code block 'train epoch=3' took: 1681701.52628 ms
train loss 0.30535566806793213
Code block 'val epoch=3' took: 94148.48910 ms
validation loss 0.7470039129257202
Step #0	Loss: 0.353949
Step #4000	Loss: 0.282309
Step #8000	Loss: 0.288225
Step #12000	Loss: 0.310124
Step #16000	Loss: 0.297856
Step #20000	Loss: 0.295023
Step #24000	Loss: 0.306591
Step #28000	Loss: 0.294916
Step #32000	Loss: 0.289761
Step #36000	Loss: 0.309564
Step #40000	Loss: 0.299648
Step #44000	Loss: 0.261761
Step #48000	Loss: 0.292423
Step #52000	Loss: 0.302340
Step #56000	Loss: 0.291602
Step #60000	Loss: 0.297740
Step #64000	Loss: 0.284334
Step #68000	Loss: 0.313296
Step #72000	Loss: 0.295222
Step #76000	Loss: 0.300910
Step #80000	Loss: 0.299093
Step #84000	Loss: 0.321278
Step #88000	Loss: 0.316315
Step #92000	Loss: 0.316058
Step #96000	Loss: 0.311112
Step #100000	Loss: 0.314784
Step #104000	Loss: 0.300644
Step #108000	Loss: 0.308588
Step #112000	Loss: 0.292999
Step #116000	Loss: 0.286841
Step #120000	Loss: 0.308756
Step #124000	Loss: 0.291870
Step #128000	Loss: 0.298965
Step #132000	Loss: 0.321505
Step #136000	Loss: 0.327813
Step #140000	Loss: 0.320054
Step #144000	Loss: 0.305374
Step #148000	Loss: 0.298319
Step #152000	Loss: 0.314299
Step #156000	Loss: 0.301169
Step #160000	Loss: 0.319653
Step #164000	Loss: 0.297361
Step #168000	Loss: 0.319125
Step #172000	Loss: 0.290588
Step #176000	Loss: 0.282353
Step #180000	Loss: 0.290599
Step #184000	Loss: 0.287529
Step #188000	Loss: 0.323923
Step #192000	Loss: 0.321158
Step #196000	Loss: 0.312661
Step #200000	Loss: 0.302071
Step #204000	Loss: 0.286255
Step #208000	Loss: 0.320557
Step #212000	Loss: 0.300312
Step #216000	Loss: 0.321739
Step #220000	Loss: 0.296428
Code block 'train epoch=4' took: 1682187.69004 ms
train loss 0.3026353120803833
Code block 'val epoch=4' took: 94259.40587 ms
validation loss 0.8077487945556641
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --cufile-thread-count 8 --batch-size 8192 --epochs 5'
[WARN  tini (177826)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-21 07:14:31.115727: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 07:14:34.562311: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-21 07:15:03.956941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-21 07:18:56.210452: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-21 07:18:56.849121: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f96b2a8d610 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-21 07:18:56.849187: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-21 07:18:57.021497: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-21 07:18:58.277220: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-21 07:18:58.646159: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 1.581360
Step #4000	Loss: 0.336867
Step #8000	Loss: 0.372606
Step #12000	Loss: 0.329372
Step #16000	Loss: 0.326543
Step #20000	Loss: 0.322674
Step #24000	Loss: 0.439972
Step #28000	Loss: 0.439432
Step #32000	Loss: 0.425561
Step #36000	Loss: 0.422313
Step #40000	Loss: 0.354287
Step #44000	Loss: 0.364487
Step #48000	Loss: 0.366678
Step #52000	Loss: 0.367673
Step #56000	Loss: 0.394280
Step #60000	Loss: 0.408014
Step #64000	Loss: 0.333286
Step #68000	Loss: 0.383674
Step #72000	Loss: 0.366230
Step #76000	Loss: 0.396437
Step #80000	Loss: 0.404277
Step #84000	Loss: 0.418762
Step #88000	Loss: 0.398026
Step #92000	Loss: 0.370174
Step #96000	Loss: 0.373078
Step #100000	Loss: 0.339890
Step #104000	Loss: 0.313368
Step #108000	Loss: 0.346611
Step #112000	Loss: 0.353274
Step #116000	Loss: 0.416970
Step #120000	Loss: 0.323788
Step #124000	Loss: 0.358543
Step #128000	Loss: 0.405310
Step #132000	Loss: 0.312155
Step #136000	Loss: 0.457923
Step #140000	Loss: 0.420963
Step #144000	Loss: 0.343311
Step #148000	Loss: 0.348986
Step #152000	Loss: 0.341251
Step #156000	Loss: 0.352742
Step #160000	Loss: 0.386347
Step #164000	Loss: 0.328343
Step #168000	Loss: 0.349469
Step #172000	Loss: 0.321696
Step #176000	Loss: 0.353171
Step #180000	Loss: 0.370543
Step #184000	Loss: 0.307430
Step #188000	Loss: 0.468084
Step #192000	Loss: 0.444421
Step #196000	Loss: 0.455701
Step #200000	Loss: 0.322160
Step #204000	Loss: 0.348885
Step #208000	Loss: 0.303927
Step #212000	Loss: 0.325412
Step #216000	Loss: 0.397697
Step #220000	Loss: 0.421769
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 1694341.68140 ms
train loss 0.3591300845146179
Code block 'val epoch=0' took: 92099.04100 ms
validation loss 0.6570273637771606
Step #0	Loss: 0.441256
Step #4000	Loss: 0.316319
Step #8000	Loss: 0.312657
Step #12000	Loss: 0.314032
Step #16000	Loss: 0.317447
Step #20000	Loss: 0.304332
Step #24000	Loss: 0.358820
Step #28000	Loss: 0.346870
Step #32000	Loss: 0.348267
Step #36000	Loss: 0.344702
Step #40000	Loss: 0.329669
Step #44000	Loss: 0.312471
Step #48000	Loss: 0.319153
Step #52000	Loss: 0.319598
Step #56000	Loss: 0.339044
Step #60000	Loss: 0.342772
Step #64000	Loss: 0.303809
Step #68000	Loss: 0.335937
Step #72000	Loss: 0.332475
Step #76000	Loss: 0.321226
Step #80000	Loss: 0.346303
Step #84000	Loss: 0.349693
Step #88000	Loss: 0.334699
Step #92000	Loss: 0.330353
Step #96000	Loss: 0.331514
Step #100000	Loss: 0.313424
Step #104000	Loss: 0.302856
Step #108000	Loss: 0.334950
Step #112000	Loss: 0.310771
Step #116000	Loss: 0.354469
Step #120000	Loss: 0.303106
Step #124000	Loss: 0.326691
Step #128000	Loss: 0.341241
Step #132000	Loss: 0.321862
Step #136000	Loss: 0.366500
Step #140000	Loss: 0.364996
Step #144000	Loss: 0.300432
Step #148000	Loss: 0.313024
Step #152000	Loss: 0.313624
Step #156000	Loss: 0.312112
Step #160000	Loss: 0.314516
Step #164000	Loss: 0.307028
Step #168000	Loss: 0.321249
Step #172000	Loss: 0.295730
Step #176000	Loss: 0.307790
Step #180000	Loss: 0.309763
Step #184000	Loss: 0.306161
Step #188000	Loss: 0.366693
Step #192000	Loss: 0.380551
Step #196000	Loss: 0.374320
Step #200000	Loss: 0.312779
Step #204000	Loss: 0.294180
Step #208000	Loss: 0.301460
Step #212000	Loss: 0.306019
Step #216000	Loss: 0.333410
Step #220000	Loss: 0.349346
Code block 'train epoch=1' took: 1663781.85184 ms
train loss 0.3242200016975403
Code block 'val epoch=1' took: 90949.01891 ms
validation loss 0.6471623778343201
Step #0	Loss: 0.331906
Step #4000	Loss: 0.295054
Step #8000	Loss: 0.301894
Step #12000	Loss: 0.297689
Step #16000	Loss: 0.309940
Step #20000	Loss: 0.316643
Step #24000	Loss: 0.323966
Step #28000	Loss: 0.325652
Step #32000	Loss: 0.310690
Step #36000	Loss: 0.316256
Step #40000	Loss: 0.318282
Step #44000	Loss: 0.280647
Step #48000	Loss: 0.300281
Step #52000	Loss: 0.305626
Step #56000	Loss: 0.313675
Step #60000	Loss: 0.319373
Step #64000	Loss: 0.299675
Step #68000	Loss: 0.324021
Step #72000	Loss: 0.310639
Step #76000	Loss: 0.310436
Step #80000	Loss: 0.324648
Step #84000	Loss: 0.345009
Step #88000	Loss: 0.315407
Step #92000	Loss: 0.321486
Step #96000	Loss: 0.306372
Step #100000	Loss: 0.301948
Step #104000	Loss: 0.294268
Step #108000	Loss: 0.313469
Step #112000	Loss: 0.305249
Step #116000	Loss: 0.330952
Step #120000	Loss: 0.308309
Step #124000	Loss: 0.297747
Step #128000	Loss: 0.312403
Step #132000	Loss: 0.310345
Step #136000	Loss: 0.343310
Step #140000	Loss: 0.346510
Step #144000	Loss: 0.299225
Step #148000	Loss: 0.303614
Step #152000	Loss: 0.309167
Step #156000	Loss: 0.305462
Step #160000	Loss: 0.302943
Step #164000	Loss: 0.296292
Step #168000	Loss: 0.315559
Step #172000	Loss: 0.289910
Step #176000	Loss: 0.296119
Step #180000	Loss: 0.298223
Step #184000	Loss: 0.292274
Step #188000	Loss: 0.333904
Step #192000	Loss: 0.328216
Step #196000	Loss: 0.335652
Step #200000	Loss: 0.319523
Step #204000	Loss: 0.296631
Step #208000	Loss: 0.299002
Step #212000	Loss: 0.304854
Step #216000	Loss: 0.327581
Step #220000	Loss: 0.315569
Code block 'train epoch=2' took: 1662216.51161 ms
train loss 0.31073489785194397
Code block 'val epoch=2' took: 91928.38334 ms
validation loss 0.6798281669616699
Step #0	Loss: 0.307116
Step #4000	Loss: 0.286392
Step #8000	Loss: 0.305193
Step #12000	Loss: 0.300419
Step #16000	Loss: 0.282310
Step #20000	Loss: 0.314973
Step #24000	Loss: 0.313606
Step #28000	Loss: 0.311327
Step #32000	Loss: 0.298880
Step #36000	Loss: 0.307705
Step #40000	Loss: 0.306445
Step #44000	Loss: 0.283627
Step #48000	Loss: 0.309043
Step #52000	Loss: 0.315550
Step #56000	Loss: 0.305644
Step #60000	Loss: 0.310091
Step #64000	Loss: 0.283833
Step #68000	Loss: 0.321081
Step #72000	Loss: 0.299898
Step #76000	Loss: 0.301690
Step #80000	Loss: 0.306308
Step #84000	Loss: 0.330349
Step #88000	Loss: 0.304898
Step #92000	Loss: 0.312571
Step #96000	Loss: 0.316248
Step #100000	Loss: 0.309072
Step #104000	Loss: 0.297259
Step #108000	Loss: 0.313163
Step #112000	Loss: 0.297612
Step #116000	Loss: 0.315437
Step #120000	Loss: 0.294465
Step #124000	Loss: 0.295856
Step #128000	Loss: 0.311616
Step #132000	Loss: 0.316980
Step #136000	Loss: 0.322753
Step #140000	Loss: 0.320940
Step #144000	Loss: 0.298413
Step #148000	Loss: 0.297966
Step #152000	Loss: 0.304677
Step #156000	Loss: 0.300295
Step #160000	Loss: 0.297061
Step #164000	Loss: 0.293515
Step #168000	Loss: 0.317095
Step #172000	Loss: 0.295738
Step #176000	Loss: 0.281731
Step #180000	Loss: 0.296653
Step #184000	Loss: 0.296279
Step #188000	Loss: 0.322203
Step #192000	Loss: 0.325495
Step #196000	Loss: 0.321047
Step #200000	Loss: 0.306370
Step #204000	Loss: 0.291902
Step #208000	Loss: 0.296515
Step #212000	Loss: 0.313795
Step #216000	Loss: 0.311962
Step #220000	Loss: 0.300393
Code block 'train epoch=3' took: 1666950.59391 ms
train loss 0.3050578534603119
Code block 'val epoch=3' took: 90940.02098 ms
validation loss 0.6927899718284607
Step #0	Loss: 0.319357
Step #4000	Loss: 0.289910
Step #8000	Loss: 0.281655
Step #12000	Loss: 0.298929
Step #16000	Loss: 0.301381
Step #20000	Loss: 0.297078
Step #24000	Loss: 0.309693
Step #28000	Loss: 0.306005
Step #32000	Loss: 0.290957
Step #36000	Loss: 0.302561
Step #40000	Loss: 0.314693
Step #44000	Loss: 0.282532
Step #48000	Loss: 0.290236
Step #52000	Loss: 0.307008
Step #56000	Loss: 0.307985
Step #60000	Loss: 0.310205
Step #64000	Loss: 0.286718
Step #68000	Loss: 0.312615
Step #72000	Loss: 0.290150
Step #76000	Loss: 0.310611
Step #80000	Loss: 0.305488
Step #84000	Loss: 0.324036
Step #88000	Loss: 0.309181
Step #92000	Loss: 0.316206
Step #96000	Loss: 0.303744
Step #100000	Loss: 0.305107
Step #104000	Loss: 0.306090
Step #108000	Loss: 0.310748
Step #112000	Loss: 0.299000
Step #116000	Loss: 0.296849
Step #120000	Loss: 0.290140
Step #124000	Loss: 0.290494
Step #128000	Loss: 0.300426
Step #132000	Loss: 0.314342
Step #136000	Loss: 0.332685
Step #140000	Loss: 0.318208
Step #144000	Loss: 0.298872
Step #148000	Loss: 0.308396
Step #152000	Loss: 0.309056
Step #156000	Loss: 0.301876
Step #160000	Loss: 0.299525
Step #164000	Loss: 0.290749
Step #168000	Loss: 0.302532
Step #172000	Loss: 0.297748
Step #176000	Loss: 0.280709
Step #180000	Loss: 0.290961
Step #184000	Loss: 0.291918
Step #188000	Loss: 0.324348
Step #192000	Loss: 0.324430
Step #196000	Loss: 0.307235
Step #200000	Loss: 0.306981
Step #204000	Loss: 0.278196
Step #208000	Loss: 0.297626
Step #212000	Loss: 0.292807
Step #216000	Loss: 0.307734
Step #220000	Loss: 0.299372
Code block 'train epoch=4' took: 1662847.98072 ms
train loss 0.3023190498352051
Code block 'val epoch=4' took: 92895.00033 ms
validation loss 0.7857255935668945
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --cufile-thread-count 8 --batch-size 8192 --epochs 5'
[WARN  tini (931809)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-21 09:45:52.924345: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 09:45:56.425657: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-21 09:46:32.260391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-21 09:50:34.888275: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-21 09:50:35.592505: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fe93f2541a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-21 09:50:35.592667: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-21 09:50:35.764616: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-21 09:50:37.013595: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-21 09:50:37.356869: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 1.578011
Step #4000	Loss: 2.661916
Step #8000	Loss: 3.010012
Step #12000	Loss: 2.505551
Step #16000	Loss: 2.827587
Step #20000	Loss: 3.000705
Step #24000	Loss: 3.147761
Step #28000	Loss: 2.777327
Step #32000	Loss: 2.803388
Step #36000	Loss: 2.963475
Step #40000	Loss: 3.045380
Step #44000	Loss: 2.367802
Step #48000	Loss: 2.784773
Step #52000	Loss: 2.972782
Step #56000	Loss: 3.112393
Step #60000	Loss: 2.920661
Step #64000	Loss: 2.699145
Step #68000	Loss: 3.235251
Step #72000	Loss: 2.762435
Step #76000	Loss: 2.697284
Step #80000	Loss: 3.151484
Step #84000	Loss: 3.391615
Step #88000	Loss: 3.246420
Step #92000	Loss: 3.305987
Step #96000	Loss: 3.164515
Step #100000	Loss: 2.877847
Step #104000	Loss: 2.996982
Step #108000	Loss: 3.335771
Step #112000	Loss: 3.036073
Step #116000	Loss: 3.391615
Step #120000	Loss: 2.983951
Step #124000	Loss: 2.667500
Step #128000	Loss: 3.164515
Step #132000	Loss: 2.922523
Step #136000	Loss: 3.229667
Step #140000	Loss: 2.550227
Step #144000	Loss: 3.043519
Step #148000	Loss: 3.106809
Step #152000	Loss: 2.967198
Step #156000	Loss: 3.413953
Step #160000	Loss: 2.853648
Step #164000	Loss: 2.427369
Step #168000	Loss: 3.084471
Step #172000	Loss: 3.106809
Step #176000	Loss: 3.002566
Step #180000	Loss: 2.816418
Step #184000	Loss: 2.822003
Step #188000	Loss: 3.177545
Step #192000	Loss: 3.149623
Step #196000	Loss: 3.291095
Step #200000	Loss: 2.965337
Step #204000	Loss: 2.833171
Step #208000	Loss: 3.043519
Step #212000	Loss: 3.021181
Step #216000	Loss: 3.028627
Step #220000	Loss: 3.168238
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 1690876.52572 ms
train loss 3.0126044750213623
Code block 'val epoch=0' took: 90840.15262 ms
validation loss 3.013434648513794
Step #0	Loss: 3.142177
Step #4000	Loss: 2.661915
Step #8000	Loss: 3.028627
Step #12000	Loss: 2.524166
Step #16000	Loss: 2.889016
Step #20000	Loss: 2.942999
Step #24000	Loss: 3.106809
Step #28000	Loss: 2.991397
Step #32000	Loss: 2.704730
Step #36000	Loss: 2.933692
Step #40000	Loss: 3.114255
Step #44000	Loss: 2.369663
Step #48000	Loss: 2.844340
Step #52000	Loss: 3.023043
Step #56000	Loss: 3.199883
Step #60000	Loss: 2.933692
Step #64000	Loss: 2.801527
Step #68000	Loss: 3.346940
Step #72000	Loss: 2.689838
Step #76000	Loss: 2.714037
Step #80000	Loss: 3.162653
Step #84000	Loss: 3.376724
Step #88000	Loss: 3.145900
Step #92000	Loss: 3.166376
Step #96000	Loss: 2.976505
Step #100000	Loss: 2.816418
Step #104000	Loss: 2.948583
Step #108000	Loss: 3.421399
Step #112000	Loss: 3.047242
Step #116000	Loss: 3.499581
Step #120000	Loss: 2.980228
Step #124000	Loss: 2.643301
Step #128000	Loss: 2.931830
Step #132000	Loss: 2.974644
Step #136000	Loss: 3.129147
Step #140000	Loss: 2.581872
Step #144000	Loss: 3.062134
Step #148000	Loss: 3.142177
Step #152000	Loss: 2.991397
Step #156000	Loss: 3.302264
Step #160000	Loss: 2.875986
Step #164000	Loss: 2.401308
Step #168000	Loss: 3.036073
Step #172000	Loss: 3.149623
Step #176000	Loss: 3.052826
Step #180000	Loss: 2.816418
Step #184000	Loss: 2.704729
Step #188000	Loss: 3.103086
Step #192000	Loss: 3.263173
Step #196000	Loss: 3.348801
Step #200000	Loss: 3.166376
Step #204000	Loss: 2.954168
Step #208000	Loss: 2.969059
Step #212000	Loss: 2.887155
Step #216000	Loss: 3.058411
Step #220000	Loss: 3.214775
Code block 'train epoch=1' took: 1663786.18794 ms
train loss 3.0126075744628906
Code block 'val epoch=1' took: 90489.12334 ms
validation loss 3.013434648513794
Step #0	Loss: 3.289234
Step #4000	Loss: 2.771743
Step #8000	Loss: 2.987674
Step #12000	Loss: 2.418062
Step #16000	Loss: 2.719621
Step #20000	Loss: 3.054688
Step #24000	Loss: 2.952306
Step #28000	Loss: 3.030488
Step #32000	Loss: 2.823864
Step #36000	Loss: 3.039796
Step #40000	Loss: 2.998843
Step #44000	Loss: 2.384555
Step #48000	Loss: 2.851786
Step #52000	Loss: 2.937414
Step #56000	Loss: 3.101224
Step #60000	Loss: 2.937414
Step #64000	Loss: 2.753128
Step #68000	Loss: 3.322741
Step #72000	Loss: 2.661915
Step #76000	Loss: 2.680530
Step #80000	Loss: 3.073302
Step #84000	Loss: 3.278065
Step #88000	Loss: 3.186852
Step #92000	Loss: 3.062134
Step #96000	Loss: 3.140316
Step #100000	Loss: 2.708452
Step #104000	Loss: 2.982090
Step #108000	Loss: 3.443737
Step #112000	Loss: 2.827587
Step #116000	Loss: 3.283649
Step #120000	Loss: 2.918799
Step #124000	Loss: 2.652608
Step #128000	Loss: 3.039796
Step #132000	Loss: 2.991397
Step #136000	Loss: 3.047242
Step #140000	Loss: 2.635855
Step #144000	Loss: 3.034211
Step #148000	Loss: 3.192437
Step #152000	Loss: 2.989536
Step #156000	Loss: 3.296680
Step #160000	Loss: 2.794080
Step #164000	Loss: 2.436677
Step #168000	Loss: 3.099363
Step #172000	Loss: 3.322741
Step #176000	Loss: 3.104948
Step #180000	Loss: 2.792219
Step #184000	Loss: 2.762435
Step #188000	Loss: 3.229667
Step #192000	Loss: 3.173822
Step #196000	Loss: 3.212914
Step #200000	Loss: 3.168238
Step #204000	Loss: 2.920661
Step #208000	Loss: 2.995121
Step #212000	Loss: 2.985813
Step #216000	Loss: 3.086333
Step #220000	Loss: 3.281788
Code block 'train epoch=2' took: 1662497.26886 ms
train loss 3.012594699859619
Code block 'val epoch=2' took: 90862.27115 ms
validation loss 3.013434648513794
Step #0	Loss: 3.356247
Step #4000	Loss: 2.751266
Step #8000	Loss: 2.857371
Step #12000	Loss: 2.607933
Step #16000	Loss: 2.738236
Step #20000	Loss: 2.980228
Step #24000	Loss: 3.142177
Step #28000	Loss: 2.983951
Step #32000	Loss: 2.654469
Step #36000	Loss: 2.944860
Step #40000	Loss: 3.132870
Step #44000	Loss: 2.388278
Step #48000	Loss: 2.851786
Step #52000	Loss: 2.980228
Step #56000	Loss: 3.144039
Step #60000	Loss: 2.864817
Step #64000	Loss: 2.825726
Step #68000	Loss: 3.287373
Step #72000	Loss: 2.684253
Step #76000	Loss: 2.693561
Step #80000	Loss: 3.237113
Step #84000	Loss: 3.387892
Step #88000	Loss: 3.158931
Step #92000	Loss: 3.240836
Step #96000	Loss: 3.097502
Step #100000	Loss: 2.851786
Step #104000	Loss: 3.049103
Step #108000	Loss: 3.317156
Step #112000	Loss: 2.993259
Step #116000	Loss: 3.391615
Step #120000	Loss: 3.084471
Step #124000	Loss: 2.704730
Step #128000	Loss: 3.004427
Step #132000	Loss: 2.905769
Step #136000	Loss: 3.084471
Step #140000	Loss: 2.641439
Step #144000	Loss: 3.034211
Step #148000	Loss: 3.196160
Step #152000	Loss: 2.911354
Step #156000	Loss: 3.412092
Step #160000	Loss: 2.829449
Step #164000	Loss: 2.473906
Step #168000	Loss: 3.114255
Step #172000	Loss: 3.071441
Step #176000	Loss: 3.075164
Step #180000	Loss: 2.684253
Step #184000	Loss: 2.786634
Step #188000	Loss: 3.131008
Step #192000	Loss: 3.166376
Step #196000	Loss: 3.225944
Step #200000	Loss: 3.019319
Step #204000	Loss: 2.849925
Step #208000	Loss: 2.946722
Step #212000	Loss: 2.896462
Step #216000	Loss: 3.084471
Step #220000	Loss: 3.346940
Code block 'train epoch=3' took: 1664501.95918 ms
train loss 3.012592315673828
Code block 'val epoch=3' took: 90174.80956 ms
validation loss 3.013434648513794
Step #0	Loss: 3.240836
Step #4000	Loss: 2.701006
Step #8000	Loss: 2.931830
Step #12000	Loss: 2.619102
Step #16000	Loss: 2.823864
Step #20000	Loss: 2.905769
Step #24000	Loss: 3.054688
Step #28000	Loss: 2.978367
Step #32000	Loss: 2.781050
Step #36000	Loss: 2.831310
Step #40000	Loss: 3.088194
Step #44000	Loss: 2.382694
Step #48000	Loss: 2.823864
Step #52000	Loss: 2.849925
Step #56000	Loss: 3.291096
Step #60000	Loss: 3.015596
Step #64000	Loss: 2.835033
Step #68000	Loss: 3.426983
Step #72000	Loss: 2.637716
Step #76000	Loss: 2.678669
Step #80000	Loss: 3.149623
Step #84000	Loss: 3.322741
Step #88000	Loss: 3.192437
Step #92000	Loss: 3.332048
Step #96000	Loss: 3.157069
Step #100000	Loss: 2.680530
Step #104000	Loss: 2.952306
Step #108000	Loss: 3.345078
Step #112000	Loss: 2.827587
Step #116000	Loss: 3.279927
Step #120000	Loss: 2.969059
Step #124000	Loss: 2.678669
Step #128000	Loss: 3.058411
Step #132000	Loss: 2.965337
Step #136000	Loss: 3.071441
Step #140000	Loss: 2.656331
Step #144000	Loss: 3.080748
Step #148000	Loss: 3.229667
Step #152000	Loss: 3.063995
Step #156000	Loss: 3.376724
Step #160000	Loss: 2.916938
Step #164000	Loss: 2.505551
Step #168000	Loss: 3.186852
Step #172000	Loss: 3.227805
Step #176000	Loss: 3.015596
Step #180000	Loss: 2.866678
Step #184000	Loss: 2.697284
Step #188000	Loss: 3.153346
Step #192000	Loss: 3.171961
Step #196000	Loss: 3.365555
Step #200000	Loss: 3.237113
Step #204000	Loss: 2.957891
Step #208000	Loss: 3.013735
Step #212000	Loss: 3.034211
Step #216000	Loss: 3.069579
Step #220000	Loss: 3.265035
Code block 'train epoch=4' took: 1663117.79467 ms
train loss 3.0126240253448486
Code block 'val epoch=4' took: 90999.40480 ms
validation loss 3.013434648513794
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --cufile-thread-count 8 --batch-size 8192 --epochs 5'
[WARN  tini (980017)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-21 12:17:18.779156: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 12:17:22.781362: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-21 12:18:00.287674: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-21 12:22:04.206647: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-21 12:22:04.894199: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f143795eb30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-21 12:22:04.894262: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-21 12:22:05.058815: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-21 12:22:06.271415: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-21 12:22:06.622475: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.659230
Step #4000	Loss: 0.397941
Step #8000	Loss: 0.310567
Step #12000	Loss: 0.320901
Step #16000	Loss: 0.334698
Step #20000	Loss: 0.370304
Step #24000	Loss: 0.445673
Step #28000	Loss: 0.328198
Step #32000	Loss: 0.346942
Step #36000	Loss: 0.431222
Step #40000	Loss: 0.335413
Step #44000	Loss: 0.398817
Step #48000	Loss: 0.310786
Step #52000	Loss: 0.353947
Step #56000	Loss: 0.418043
Step #60000	Loss: 0.326942
Step #64000	Loss: 0.339881
Step #68000	Loss: 0.425094
Step #72000	Loss: 0.397361
Step #76000	Loss: 0.431846
Step #80000	Loss: 0.331443
Step #84000	Loss: 0.357265
Step #88000	Loss: 0.355698
Step #92000	Loss: 0.420528
Step #96000	Loss: 0.378379
Step #100000	Loss: 0.375841
Step #104000	Loss: 0.316597
Step #108000	Loss: 0.345793
Step #112000	Loss: 0.331446
Step #116000	Loss: 0.351045
Step #120000	Loss: 0.348756
Step #124000	Loss: 0.330564
Step #128000	Loss: 0.366298
Step #132000	Loss: 0.373897
Step #136000	Loss: 0.447912
Step #140000	Loss: 0.351678
Step #144000	Loss: 0.331709
Step #148000	Loss: 0.370940
Step #152000	Loss: 0.418497
Step #156000	Loss: 0.328611
Step #160000	Loss: 0.342010
Step #164000	Loss: 0.330870
Step #168000	Loss: 0.356635
Step #172000	Loss: 0.366694
Step #176000	Loss: 0.336499
Step #180000	Loss: 0.341268
Step #184000	Loss: 0.358154
Step #188000	Loss: 0.482989
Step #192000	Loss: 0.352855
Step #196000	Loss: 0.394017
Step #200000	Loss: 0.326079
Step #204000	Loss: 0.328536
Step #208000	Loss: 0.314284
Step #212000	Loss: 0.341523
Step #216000	Loss: 0.352226
Step #220000	Loss: 0.342746
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 1697880.17407 ms
train loss 0.3589070439338684
Code block 'val epoch=0' took: 90922.65215 ms
validation loss 0.6416075825691223
Step #0	Loss: 0.451163
Step #4000	Loss: 0.323217
Step #8000	Loss: 0.292809
Step #12000	Loss: 0.320352
Step #16000	Loss: 0.324677
Step #20000	Loss: 0.335730
Step #24000	Loss: 0.363157
Step #28000	Loss: 0.323494
Step #32000	Loss: 0.304148
Step #36000	Loss: 0.360680
Step #40000	Loss: 0.303933
Step #44000	Loss: 0.338774
Step #48000	Loss: 0.295116
Step #52000	Loss: 0.322627
Step #56000	Loss: 0.347353
Step #60000	Loss: 0.312183
Step #64000	Loss: 0.308164
Step #68000	Loss: 0.351533
Step #72000	Loss: 0.336543
Step #76000	Loss: 0.338711
Step #80000	Loss: 0.319326
Step #84000	Loss: 0.329440
Step #88000	Loss: 0.315900
Step #92000	Loss: 0.346743
Step #96000	Loss: 0.330527
Step #100000	Loss: 0.323899
Step #104000	Loss: 0.307218
Step #108000	Loss: 0.321706
Step #112000	Loss: 0.318578
Step #116000	Loss: 0.318232
Step #120000	Loss: 0.320266
Step #124000	Loss: 0.308854
Step #128000	Loss: 0.317616
Step #132000	Loss: 0.334123
Step #136000	Loss: 0.360680
Step #140000	Loss: 0.334428
Step #144000	Loss: 0.305056
Step #148000	Loss: 0.313633
Step #152000	Loss: 0.333045
Step #156000	Loss: 0.315620
Step #160000	Loss: 0.310421
Step #164000	Loss: 0.314740
Step #168000	Loss: 0.322943
Step #172000	Loss: 0.310941
Step #176000	Loss: 0.295096
Step #180000	Loss: 0.305970
Step #184000	Loss: 0.322176
Step #188000	Loss: 0.370616
Step #192000	Loss: 0.328317
Step #196000	Loss: 0.335031
Step #200000	Loss: 0.322343
Step #204000	Loss: 0.304477
Step #208000	Loss: 0.305820
Step #212000	Loss: 0.305574
Step #216000	Loss: 0.323109
Step #220000	Loss: 0.306866
Code block 'train epoch=1' took: 1676024.28826 ms
train loss 0.3216002881526947
Code block 'val epoch=1' took: 90771.64120 ms
validation loss 0.6452057957649231
Step #0	Loss: 0.345382
Step #4000	Loss: 0.299363
Step #8000	Loss: 0.297771
Step #12000	Loss: 0.309176
Step #16000	Loss: 0.302159
Step #20000	Loss: 0.307546
Step #24000	Loss: 0.323479
Step #28000	Loss: 0.307735
Step #32000	Loss: 0.303781
Step #36000	Loss: 0.332262
Step #40000	Loss: 0.309870
Step #44000	Loss: 0.305419
Step #48000	Loss: 0.290747
Step #52000	Loss: 0.290698
Step #56000	Loss: 0.314956
Step #60000	Loss: 0.303676
Step #64000	Loss: 0.287669
Step #68000	Loss: 0.325726
Step #72000	Loss: 0.293364
Step #76000	Loss: 0.316493
Step #80000	Loss: 0.300825
Step #84000	Loss: 0.315846
Step #88000	Loss: 0.309805
Step #92000	Loss: 0.324676
Step #96000	Loss: 0.311531
Step #100000	Loss: 0.307843
Step #104000	Loss: 0.302020
Step #108000	Loss: 0.318209
Step #112000	Loss: 0.311728
Step #116000	Loss: 0.304371
Step #120000	Loss: 0.319806
Step #124000	Loss: 0.299430
Step #128000	Loss: 0.319427
Step #132000	Loss: 0.320472
Step #136000	Loss: 0.332213
Step #140000	Loss: 0.312441
Step #144000	Loss: 0.298214
Step #148000	Loss: 0.297152
Step #152000	Loss: 0.323388
Step #156000	Loss: 0.310941
Step #160000	Loss: 0.317771
Step #164000	Loss: 0.297138
Step #168000	Loss: 0.325057
Step #172000	Loss: 0.304635
Step #176000	Loss: 0.289807
Step #180000	Loss: 0.296619
Step #184000	Loss: 0.305823
Step #188000	Loss: 0.320101
Step #192000	Loss: 0.327207
Step #196000	Loss: 0.320046
Step #200000	Loss: 0.312354
Step #204000	Loss: 0.288125
Step #208000	Loss: 0.301898
Step #212000	Loss: 0.297922
Step #216000	Loss: 0.304033
Step #220000	Loss: 0.313395
Code block 'train epoch=2' took: 1672075.44968 ms
train loss 0.3095794916152954
Code block 'val epoch=2' took: 91340.64128 ms
validation loss 0.6462116241455078
Step #0	Loss: 0.313662
Step #4000	Loss: 0.296210
Step #8000	Loss: 0.296213
Step #12000	Loss: 0.309106
Step #16000	Loss: 0.300678
Step #20000	Loss: 0.295459
Step #24000	Loss: 0.320237
Step #28000	Loss: 0.302280
Step #32000	Loss: 0.299795
Step #36000	Loss: 0.321718
Step #40000	Loss: 0.305476
Step #44000	Loss: 0.283938
Step #48000	Loss: 0.283637
Step #52000	Loss: 0.308507
Step #56000	Loss: 0.312876
Step #60000	Loss: 0.291782
Step #64000	Loss: 0.291071
Step #68000	Loss: 0.303981
Step #72000	Loss: 0.296434
Step #76000	Loss: 0.304048
Step #80000	Loss: 0.301416
Step #84000	Loss: 0.318643
Step #88000	Loss: 0.296456
Step #92000	Loss: 0.306271
Step #96000	Loss: 0.322455
Step #100000	Loss: 0.295518
Step #104000	Loss: 0.296437
Step #108000	Loss: 0.306993
Step #112000	Loss: 0.311370
Step #116000	Loss: 0.299223
Step #120000	Loss: 0.304945
Step #124000	Loss: 0.294571
Step #128000	Loss: 0.315480
Step #132000	Loss: 0.310366
Step #136000	Loss: 0.312818
Step #140000	Loss: 0.311287
Step #144000	Loss: 0.297635
Step #148000	Loss: 0.291112
Step #152000	Loss: 0.307926
Step #156000	Loss: 0.309148
Step #160000	Loss: 0.304620
Step #164000	Loss: 0.293259
Step #168000	Loss: 0.298986
Step #172000	Loss: 0.307476
Step #176000	Loss: 0.292556
Step #180000	Loss: 0.293178
Step #184000	Loss: 0.304875
Step #188000	Loss: 0.311537
Step #192000	Loss: 0.319770
Step #196000	Loss: 0.313465
Step #200000	Loss: 0.307692
Step #204000	Loss: 0.298905
Step #208000	Loss: 0.291161
Step #212000	Loss: 0.307655
Step #216000	Loss: 0.311163
Step #220000	Loss: 0.298255
Code block 'train epoch=3' took: 1674385.43032 ms
train loss 0.3047518730163574
Code block 'val epoch=3' took: 90363.56291 ms
validation loss 0.6995049715042114
Step #0	Loss: 0.320221
Step #4000	Loss: 0.292535
Step #8000	Loss: 0.295087
Step #12000	Loss: 0.299831
Step #16000	Loss: 0.299697
Step #20000	Loss: 0.300766
Step #24000	Loss: 0.309622
Step #28000	Loss: 0.299086
Step #32000	Loss: 0.284879
Step #36000	Loss: 0.304672
Step #40000	Loss: 0.308288
Step #44000	Loss: 0.289679
Step #48000	Loss: 0.288167
Step #52000	Loss: 0.301194
Step #56000	Loss: 0.299130
Step #60000	Loss: 0.290750
Step #64000	Loss: 0.289106
Step #68000	Loss: 0.311591
Step #72000	Loss: 0.291220
Step #76000	Loss: 0.295350
Step #80000	Loss: 0.298247
Step #84000	Loss: 0.314998
Step #88000	Loss: 0.305770
Step #92000	Loss: 0.310321
Step #96000	Loss: 0.307215
Step #100000	Loss: 0.312707
Step #104000	Loss: 0.299546
Step #108000	Loss: 0.307485
Step #112000	Loss: 0.296985
Step #116000	Loss: 0.303623
Step #120000	Loss: 0.303607
Step #124000	Loss: 0.291242
Step #128000	Loss: 0.305582
Step #132000	Loss: 0.327782
Step #136000	Loss: 0.316282
Step #140000	Loss: 0.315469
Step #144000	Loss: 0.283129
Step #148000	Loss: 0.299695
Step #152000	Loss: 0.304479
Step #156000	Loss: 0.304461
Step #160000	Loss: 0.309166
Step #164000	Loss: 0.300838
Step #168000	Loss: 0.306430
Step #172000	Loss: 0.302872
Step #176000	Loss: 0.280905
Step #180000	Loss: 0.297600
Step #184000	Loss: 0.305891
Step #188000	Loss: 0.312688
Step #192000	Loss: 0.296443
Step #196000	Loss: 0.309854
Step #200000	Loss: 0.301050
Step #204000	Loss: 0.283490
Step #208000	Loss: 0.291784
Step #212000	Loss: 0.300935
Step #216000	Loss: 0.309201
Step #220000	Loss: 0.296705
Code block 'train epoch=4' took: 1674322.26651 ms
train loss 0.30231982469558716
Code block 'val epoch=4' took: 91698.50318 ms
validation loss 0.7345894575119019
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --cufile-thread-count 8 --batch-size 8192 --epochs 5'
[WARN  tini (1101637)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-21 14:49:25.911686: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 14:49:29.466302: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-21 14:49:58.786396: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-21 14:53:46.405809: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-21 14:53:46.893292: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f23aad1f4c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-21 14:53:46.893361: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-21 14:53:47.055423: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-21 14:53:48.063093: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-21 14:53:48.379934: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.954671
Step #4000	Loss: 0.372049
Step #8000	Loss: 0.371278
terminate called after throwing an instance of 'rmm::out_of_memory'
  what():  std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp
[dgx-2:1101664] *** Process received signal ***
[dgx-2:1101664] Signal: Aborted (6)
[dgx-2:1101664] Signal code:  (-6)
[dgx-2:1101664] [ 0] /lib/x86_64-linux-gnu/libc.so.6(+0x42520)[0x7f2dfd65b520]
[dgx-2:1101664] [ 1] /lib/x86_64-linux-gnu/libc.so.6(pthread_kill+0x12c)[0x7f2dfd6afa7c]
[dgx-2:1101664] [ 2] /lib/x86_64-linux-gnu/libc.so.6(raise+0x16)[0x7f2dfd65b476]
[dgx-2:1101664] [ 3] /lib/x86_64-linux-gnu/libc.so.6(abort+0xd3)[0x7f2dfd6417f3]
[dgx-2:1101664] [ 4] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(_ZN9__gnu_cxx27__verbose_terminate_handlerEv+0xc0)[0x7f2dfa7c9026]
[dgx-2:1101664] [ 5] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(+0xb0514)[0x7f2dfa7c7514]
[dgx-2:1101664] [ 6] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(+0xb0566)[0x7f2dfa7c7566]
[dgx-2:1101664] [ 7] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(__cxa_rethrow+0x0)[0x7f2dfa7c7758]
[dgx-2:1101664] [ 8] /opt/conda/envs/rapids/lib/python3.10/site-packages/rmm/_lib/device_buffer.cpython-310-x86_64-linux-gnu.so(+0x4b67d)[0x7f2cbc08067d]
[dgx-2:1101664] [ 9] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf6columnC2ERKS0_N3rmm16cuda_stream_viewEPNS3_2mr22device_memory_resourceE+0x6d)[0x7f2bc3ad6add]
[dgx-2:1101664] [10] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf6columnC2ERKS0_N3rmm16cuda_stream_viewEPNS3_2mr22device_memory_resourceE+0x20c)[0x7f2bc3ad6c7c]
[dgx-2:1101664] [11] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf5tableC1ERKS0_+0x263)[0x7f2bc5210ec3]
[dgx-2:1101664] [12] /home2/faculty/pwesolowski/praca-mgr/parser-repo/build/libmeta-cudf-parser-1.so(_Z25generate_example_metadataPKcmmi11end_of_linebb+0x87d)[0x7f262686d27d]
[dgx-2:1101664] [13] /home2/faculty/pwesolowski/praca-mgr/parser-repo/python_binding/metajsonparser/_lib/json_cudf.cpython-310-x86_64-linux-gnu.so(+0x4b344)[0x7f2b4805a344]
[dgx-2:1101664] [14] python(+0x13fb27)[0x5629eed00b27]
[dgx-2:1101664] [15] python(PyObject_Call+0x209)[0x5629eed0d139]
[dgx-2:1101664] [16] python(_PyEval_EvalFrameDefault+0x5d8c)[0x5629eecf6b7c]
[dgx-2:1101664] [17] python(_PyFunction_Vectorcall+0x6f)[0x5629eed00f8f]
[dgx-2:1101664] [18] python(_PyEval_EvalFrameDefault+0x2ec2)[0x5629eecf3cb2]
[dgx-2:1101664] [19] python(_PyFunction_Vectorcall+0x6f)[0x5629eed00f8f]
[dgx-2:1101664] [20] python(_PyEval_EvalFrameDefault+0x332)[0x5629eecf1122]
[dgx-2:1101664] [21] python(_PyFunction_Vectorcall+0x6f)[0x5629eed00f8f]
[dgx-2:1101664] [22] python(_PyEval_EvalFrameDefault+0x2ec2)[0x5629eecf3cb2]
[dgx-2:1101664] [23] python(_PyFunction_Vectorcall+0x6f)[0x5629eed00f8f]
[dgx-2:1101664] [24] python(_PyEval_EvalFrameDefault+0x332)[0x5629eecf1122]
[dgx-2:1101664] [25] python(_PyFunction_Vectorcall+0x6f)[0x5629eed00f8f]
[dgx-2:1101664] [26] python(_PyEval_EvalFrameDefault+0x2ec2)[0x5629eecf3cb2]
[dgx-2:1101664] [27] python(+0x14b641)[0x5629eed0c641]
[dgx-2:1101664] [28] python(_PyEval_EvalFrameDefault+0x332)[0x5629eecf1122]
[dgx-2:1101664] [29] python(_PyFunction_Vectorcall+0x6f)[0x5629eed00f8f]
[dgx-2:1101664] *** End of error message ***
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --cufile-thread-count 8 --batch-size 8192 --epochs 5'
[WARN  tini (1107714)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-21 14:55:21.196961: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 14:55:24.946708: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-21 14:55:57.858993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
Failed to transform operator <nvtabular.ops.categorify.Categorify object at 0x7fcc7268fac0>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1780, in _encode
    ).sort_values("order")["labels"]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 2214, in sort_values
    out = self._gather(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-21 14:59:52.196132: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-21 14:59:52.714675: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fc4b7884980 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-21 14:59:52.714745: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-21 14:59:52.864113: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-21 14:59:53.978276: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-21 14:59:54.276992: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 4.676898
Code block 'train epoch=0' took: 58088.86564 ms
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 332, in _get_next_batch
    batch = next(self._batch_itr)
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home2/faculty/pwesolowski/praca-mgr/pipelines-repo/2_merlin/run_merlin.py", line 155, in <module>
    for batch, (examples, labels) in enumerate(train_tf_ds):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/tensorflow.py", line 97, in __next__
    converted_batch = self.convert_batch(super().__next__())
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 261, in __next__
    return self._get_next_batch()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 344, in _get_next_batch
    batch = next(self._batch_itr)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 369, in make_tensors
    tensors_by_name = self._convert_df_to_tensors(gdf)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 520, in _convert_df_to_tensors
    tensors_by_name[column_name] = self._to_tensor(gdf_i[[column_name]])
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 450, in _to_tensor
    tensor = df_or_series.to_cupy()
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/single_column_frame.py", line 131, in to_cupy
    return super().to_cupy(dtype, copy, na_value).flatten()
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 533, in to_cupy
    return self._to_array(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 498, in _to_array
    matrix[:, i] = get_column_values_na(col)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 477, in get_column_values_na
    return get_column_values(col)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 534, in <lambda>
    (lambda col: col.values.copy())
  File "cupy/_core/core.pyx", line 590, in cupy._core.core._ndarray_base.copy
  File "cupy/_core/core.pyx", line 616, in cupy._core.core._ndarray_base.copy
  File "cupy/_core/core.pyx", line 575, in cupy._core.core._ndarray_base.astype
  File "cupy/_core/core.pyx", line 136, in cupy._core.core.ndarray.__new__
  File "cupy/_core/core.pyx", line 224, in cupy._core.core._ndarray_base._init
  File "cupy/cuda/memory.pyx", line 742, in cupy.cuda.memory.alloc
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/rmm/rmm.py", line 230, in rmm_cupy_allocator
    buf = librmm.device_buffer.DeviceBuffer(size=nbytes, stream=stream)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --cufile-thread-count 8 --batch-size 8192 --epochs 5'
[WARN  tini (1113108)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-21 15:00:40.300646: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 15:00:43.619900: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-21 15:01:09.943084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
Failed to transform operator <nvtabular.ops.categorify.Categorify object at 0x7fdebf9f7ac0>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1778, in _encode
    labels = codes.merge(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/dataframe.py", line 4004, in merge
    ).perform_merge()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/join/join.py", line 203, in perform_merge
    self.rhs._gather(gather_map=right_rows, **gather_kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-21 15:05:05.236922: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-21 15:05:05.765616: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fdc0f4483a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-21 15:05:05.765727: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-21 15:05:05.940385: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-21 15:05:07.156767: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-21 15:05:07.564941: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 2.012680
Step #4000	Loss: 0.347426
Code block 'train epoch=0' took: 86399.17521 ms
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1778, in _encode
    labels = codes.merge(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/dataframe.py", line 4004, in merge
    ).perform_merge()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/join/join.py", line 203, in perform_merge
    self.rhs._gather(gather_map=right_rows, **gather_kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home2/faculty/pwesolowski/praca-mgr/pipelines-repo/2_merlin/run_merlin.py", line 155, in <module>
    for batch, (examples, labels) in enumerate(train_tf_ds):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/tensorflow.py", line 97, in __next__
    converted_batch = self.convert_batch(super().__next__())
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 261, in __next__
    return self._get_next_batch()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 343, in _get_next_batch
    self._fetch_chunk()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 277, in _fetch_chunk
    raise chunks
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 791, in load_chunks
    self.chunk_logic(itr)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 759, in chunk_logic
    for chunks in self.batch(itr):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 745, in batch
    value = next(itr)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/io/dataframe_iter.py", line 44, in __iter__
    yield part.compute(scheduler="synchronous")
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/base.py", line 314, in compute
    (result,) = compute(self, traverse=False, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/base.py", line 599, in compute
    results = schedule(dsk, keys, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 557, in get_sync
    return get_async(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 500, in get_async
    for key, res_info, failed in queue_get(queue).result():
  File "/opt/conda/envs/rapids/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/opt/conda/envs/rapids/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 542, in submit
    fut.set_result(fn(*args, **kwargs))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 238, in batch_execute_tasks
    return [execute_task(*a) for a in it]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 238, in <listcomp>
    return [execute_task(*a) for a in it]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 229, in execute_task
    result = pack_exception(e, dumps)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 224, in execute_task
    result = _execute_task(task, data)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/optimization.py", line 990, in __call__
    return core.get(self.dsk, self.outkey, dict(zip(self.inkeys, args)))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 149, in get
    result = _execute_task(task, cache)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in <genexpr>
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/utils.py", line 72, in apply
    return func(*args, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 87, in transform
    transformed_data = self._execute_node(node, transformable, capture_dtypes, strict)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 101, in _execute_node
    upstream_outputs = self._run_upstream_transforms(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 114, in _run_upstream_transforms
    node_output = self._execute_node(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 107, in _execute_node
    transform_output = self._run_node_transform(node, transform_input, capture_dtypes, strict)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 227, in _run_node_transform
    raise exc
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
+ for CUFILE_THREAD_COUNT in 4 8 16 32 64
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --cufile-thread-count 16 --batch-size 8192 --epochs 5'
[WARN  tini (1118755)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-21 15:06:21.992063: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 15:06:25.688971: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-21 15:06:54.163310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-21 15:10:48.684209: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-21 15:10:49.127713: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f03ccedf650 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-21 15:10:49.127777: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-21 15:10:49.295177: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-21 15:10:50.435634: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-21 15:10:50.806426: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 2.832108
Step #4000	Loss: 0.296995
Step #8000	Loss: 0.322413
Step #12000	Loss: 0.312960
Step #16000	Loss: 0.339613
Step #20000	Loss: 0.327968
Step #24000	Loss: 0.428175
Step #28000	Loss: 0.416714
Step #32000	Loss: 0.425912
Step #36000	Loss: 0.380008
Step #40000	Loss: 0.324696
Step #44000	Loss: 0.339674
Step #48000	Loss: 0.331478
Step #52000	Loss: 0.333418
Step #56000	Loss: 0.354579
Step #60000	Loss: 0.395520
Step #64000	Loss: 0.314454
Step #68000	Loss: 0.327967
Step #72000	Loss: 0.364211
Step #76000	Loss: 0.351895
Step #80000	Loss: 0.373678
Step #84000	Loss: 0.371222
Step #88000	Loss: 0.367386
Step #92000	Loss: 0.376135
Step #96000	Loss: 0.319688
Step #100000	Loss: 0.438369
Step #104000	Loss: 0.326990
Step #108000	Loss: 0.347818
Step #112000	Loss: 0.340925
Step #116000	Loss: 0.395890
Step #120000	Loss: 0.326183
Step #124000	Loss: 0.332771
Step #128000	Loss: 0.378449
Step #132000	Loss: 0.339216
Step #136000	Loss: 0.433601
Step #140000	Loss: 0.412208
Step #144000	Loss: 0.419610
Step #148000	Loss: 0.320699
Step #152000	Loss: 0.430933
Step #156000	Loss: 0.327156
Step #160000	Loss: 0.337303
Step #164000	Loss: 0.299752
Step #168000	Loss: 0.418421
Step #172000	Loss: 0.413719
Step #176000	Loss: 0.318215
Step #180000	Loss: 0.350936
Step #184000	Loss: 0.316670
Step #188000	Loss: 0.469542
Step #192000	Loss: 0.435751
Step #196000	Loss: 0.451416
Step #200000	Loss: 0.336155
Step #204000	Loss: 0.307046
Step #208000	Loss: 0.332810
Step #212000	Loss: 0.339573
Step #216000	Loss: 0.391069
Step #220000	Loss: 0.427311
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 1715336.77864 ms
train loss 0.3615851402282715
Code block 'val epoch=0' took: 96190.52735 ms
validation loss 0.5897881388664246
Step #0	Loss: 0.443578
Step #4000	Loss: 0.279901
Step #8000	Loss: 0.297111
Step #12000	Loss: 0.306264
Step #16000	Loss: 0.311621
Step #20000	Loss: 0.308445
Step #24000	Loss: 0.353037
Step #28000	Loss: 0.342066
Step #32000	Loss: 0.347963
Step #36000	Loss: 0.326906
Step #40000	Loss: 0.315494
Step #44000	Loss: 0.311195
Step #48000	Loss: 0.308552
Step #52000	Loss: 0.320911
Step #56000	Loss: 0.318059
Step #60000	Loss: 0.329208
Step #64000	Loss: 0.293406
Step #68000	Loss: 0.316329
Step #72000	Loss: 0.331680
Step #76000	Loss: 0.315500
Step #80000	Loss: 0.317224
Step #84000	Loss: 0.335387
Step #88000	Loss: 0.313889
Step #92000	Loss: 0.340153
Step #96000	Loss: 0.295442
Step #100000	Loss: 0.353742
Step #104000	Loss: 0.313774
Step #108000	Loss: 0.322285
Step #112000	Loss: 0.318283
Step #116000	Loss: 0.345269
Step #120000	Loss: 0.307865
Step #124000	Loss: 0.299618
Step #128000	Loss: 0.335776
Step #132000	Loss: 0.318414
Step #136000	Loss: 0.363522
Step #140000	Loss: 0.366009
Step #144000	Loss: 0.353875
Step #148000	Loss: 0.306989
Step #152000	Loss: 0.355552
Step #156000	Loss: 0.317770
Step #160000	Loss: 0.309223
Step #164000	Loss: 0.286304
Step #168000	Loss: 0.347930
Step #172000	Loss: 0.334152
Step #176000	Loss: 0.291082
Step #180000	Loss: 0.300137
Step #184000	Loss: 0.306527
Step #188000	Loss: 0.381707
Step #192000	Loss: 0.354186
Step #196000	Loss: 0.376052
Step #200000	Loss: 0.319082
Step #204000	Loss: 0.271538
Step #208000	Loss: 0.312991
Step #212000	Loss: 0.311844
Step #216000	Loss: 0.345318
Step #220000	Loss: 0.337841
Code block 'train epoch=1' took: 1687278.16641 ms
train loss 0.3252706825733185
Code block 'val epoch=1' took: 95765.48837 ms
validation loss 0.6215053200721741
Step #0	Loss: 0.339595
Step #4000	Loss: 0.279600
Step #8000	Loss: 0.301803
Step #12000	Loss: 0.289634
Step #16000	Loss: 0.301046
Step #20000	Loss: 0.302886
Step #24000	Loss: 0.323116
Step #28000	Loss: 0.314684
Step #32000	Loss: 0.312653
Step #36000	Loss: 0.306424
Step #40000	Loss: 0.315216
Step #44000	Loss: 0.295867
Step #48000	Loss: 0.297640
Step #52000	Loss: 0.317142
Step #56000	Loss: 0.313165
Step #60000	Loss: 0.303136
Step #64000	Loss: 0.295603
Step #68000	Loss: 0.315230
Step #72000	Loss: 0.304890
Step #76000	Loss: 0.309638
Step #80000	Loss: 0.302383
Step #84000	Loss: 0.328583
Step #88000	Loss: 0.303012
Step #92000	Loss: 0.319382
Step #96000	Loss: 0.294150
Step #100000	Loss: 0.330683
Step #104000	Loss: 0.314720
Step #108000	Loss: 0.321000
Step #112000	Loss: 0.311975
Step #116000	Loss: 0.306275
Step #120000	Loss: 0.305372
Step #124000	Loss: 0.297982
Step #128000	Loss: 0.318467
Step #132000	Loss: 0.317900
Step #136000	Loss: 0.333907
Step #140000	Loss: 0.337563
Step #144000	Loss: 0.320712
Step #148000	Loss: 0.302340
Step #152000	Loss: 0.316052
Step #156000	Loss: 0.300681
Step #160000	Loss: 0.294128
Step #164000	Loss: 0.293295
Step #168000	Loss: 0.320207
Step #172000	Loss: 0.326359
Step #176000	Loss: 0.276110
Step #180000	Loss: 0.303384
Step #184000	Loss: 0.295144
Step #188000	Loss: 0.338977
Step #192000	Loss: 0.341006
Step #196000	Loss: 0.344628
Step #200000	Loss: 0.321670
Step #204000	Loss: 0.273644
Step #208000	Loss: 0.310145
Step #212000	Loss: 0.312123
Step #216000	Loss: 0.324888
Step #220000	Loss: 0.318663
Code block 'train epoch=2' took: 1686917.06350 ms
train loss 0.31156301498413086
Code block 'val epoch=2' took: 95451.66346 ms
validation loss 0.6277772784233093
Step #0	Loss: 0.293362
Step #4000	Loss: 0.281315
Step #8000	Loss: 0.302022
Step #12000	Loss: 0.300134
Step #16000	Loss: 0.298186
Step #20000	Loss: 0.302469
Step #24000	Loss: 0.319944
Step #28000	Loss: 0.296505
Step #32000	Loss: 0.306470
Step #36000	Loss: 0.310989
Step #40000	Loss: 0.312521
Step #44000	Loss: 0.285273
Step #48000	Loss: 0.291136
Step #52000	Loss: 0.301976
Step #56000	Loss: 0.298781
Step #60000	Loss: 0.311335
Step #64000	Loss: 0.289385
Step #68000	Loss: 0.321844
Step #72000	Loss: 0.297176
Step #76000	Loss: 0.303599
Step #80000	Loss: 0.300862
Step #84000	Loss: 0.310946
Step #88000	Loss: 0.305374
Step #92000	Loss: 0.321305
Step #96000	Loss: 0.298394
Step #100000	Loss: 0.326051
Step #104000	Loss: 0.305520
Step #108000	Loss: 0.314400
Step #112000	Loss: 0.299016
Step #116000	Loss: 0.298767
Step #120000	Loss: 0.296611
Step #124000	Loss: 0.289644
Step #128000	Loss: 0.318453
Step #132000	Loss: 0.311581
Step #136000	Loss: 0.324079
Step #140000	Loss: 0.318149
Step #144000	Loss: 0.312005
Step #148000	Loss: 0.292706
Step #152000	Loss: 0.306594
Step #156000	Loss: 0.306426
Step #160000	Loss: 0.281038
Step #164000	Loss: 0.297601
Step #168000	Loss: 0.316683
Step #172000	Loss: 0.316810
Step #176000	Loss: 0.275499
Step #180000	Loss: 0.298639
Step #184000	Loss: 0.289555
Step #188000	Loss: 0.325340
Step #192000	Loss: 0.316997
Step #196000	Loss: 0.319221
Step #200000	Loss: 0.300936
Step #204000	Loss: 0.265672
Step #208000	Loss: 0.308983
Step #212000	Loss: 0.304953
Step #216000	Loss: 0.316317
Step #220000	Loss: 0.312480
Code block 'train epoch=3' took: 1691123.36099 ms
train loss 0.3058059513568878
Code block 'val epoch=3' took: 94532.47884 ms
validation loss 0.6868957281112671
Step #0	Loss: 0.303636
Step #4000	Loss: 0.269405
Step #8000	Loss: 0.298702
Step #12000	Loss: 0.294798
Step #16000	Loss: 0.289456
Step #20000	Loss: 0.307830
Step #24000	Loss: 0.315350
Step #28000	Loss: 0.300761
Step #32000	Loss: 0.301447
Step #36000	Loss: 0.309889
Step #40000	Loss: 0.315533
Step #44000	Loss: 0.283689
Step #48000	Loss: 0.290642
Step #52000	Loss: 0.305559
Step #56000	Loss: 0.296841
Step #60000	Loss: 0.288027
Step #64000	Loss: 0.287532
Step #68000	Loss: 0.306414
Step #72000	Loss: 0.292986
Step #76000	Loss: 0.292242
Step #80000	Loss: 0.290890
Step #84000	Loss: 0.316976
Step #88000	Loss: 0.305772
Step #92000	Loss: 0.308296
Step #96000	Loss: 0.284157
Step #100000	Loss: 0.315355
Step #104000	Loss: 0.304525
Step #108000	Loss: 0.311177
Step #112000	Loss: 0.299895
Step #116000	Loss: 0.300106
Step #120000	Loss: 0.292492
Step #124000	Loss: 0.287235
Step #128000	Loss: 0.310668
Step #132000	Loss: 0.315416
Step #136000	Loss: 0.326491
Step #140000	Loss: 0.318972
Step #144000	Loss: 0.307484
Step #148000	Loss: 0.295777
Step #152000	Loss: 0.292997
Step #156000	Loss: 0.295255
Step #160000	Loss: 0.284464
Step #164000	Loss: 0.286152
Step #168000	Loss: 0.312599
Step #172000	Loss: 0.309910
Step #176000	Loss: 0.272500
Step #180000	Loss: 0.292035
Step #184000	Loss: 0.292072
Step #188000	Loss: 0.323364
Step #192000	Loss: 0.316881
Step #196000	Loss: 0.307621
Step #200000	Loss: 0.308511
Step #204000	Loss: 0.268902
Step #208000	Loss: 0.291184
Step #212000	Loss: 0.313819
Step #216000	Loss: 0.319227
Step #220000	Loss: 0.311311
Code block 'train epoch=4' took: 1688135.29552 ms
train loss 0.30302929878234863
Code block 'val epoch=4' took: 94207.94983 ms
validation loss 0.7225126028060913
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --cufile-thread-count 16 --batch-size 8192 --epochs 5'
[WARN  tini (1235880)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-21 17:39:56.281776: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 17:40:00.277618: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-21 17:40:29.983342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-21 17:44:28.719963: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-21 17:44:29.409422: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fcbc02f0b30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-21 17:44:29.409545: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-21 17:44:29.581796: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-21 17:44:30.658511: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-21 17:44:30.963736: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.551920
Step #4000	Loss: 0.313642
Step #8000	Loss: 0.319900
Step #12000	Loss: 0.337033
Step #16000	Loss: 0.316534
Step #20000	Loss: 0.334587
Step #24000	Loss: 0.434057
Step #28000	Loss: 0.422632
Step #32000	Loss: 0.417801
Step #36000	Loss: 0.414344
Step #40000	Loss: 0.356679
Step #44000	Loss: 0.353828
Step #48000	Loss: 0.361846
Step #52000	Loss: 0.366496
Step #56000	Loss: 0.378388
Step #60000	Loss: 0.426045
Step #64000	Loss: 0.332147
Step #68000	Loss: 0.376678
Step #72000	Loss: 0.347577
Step #76000	Loss: 0.318464
Step #80000	Loss: 0.337237
Step #84000	Loss: 0.357502
Step #88000	Loss: 0.406380
Step #92000	Loss: 0.398668
Step #96000	Loss: 0.319567
Step #100000	Loss: 0.441808
Step #104000	Loss: 0.370495
Step #108000	Loss: 0.364103
Step #112000	Loss: 0.319975
Step #116000	Loss: 0.338106
Step #120000	Loss: 0.321308
Step #124000	Loss: 0.376949
Step #128000	Loss: 0.398831
Step #132000	Loss: 0.326007
Step #136000	Loss: 0.444792
Step #140000	Loss: 0.414665
Step #144000	Loss: 0.333850
Step #148000	Loss: 0.350872
Step #152000	Loss: 0.453617
Step #156000	Loss: 0.330558
Step #160000	Loss: 0.382505
Step #164000	Loss: 0.300316
Step #168000	Loss: 0.441231
Step #172000	Loss: 0.321399
Step #176000	Loss: 0.344284
Step #180000	Loss: 0.368324
Step #184000	Loss: 0.318094
Step #188000	Loss: 0.473770
Step #192000	Loss: 0.447028
Step #196000	Loss: 0.452841
Step #200000	Loss: 0.331936
Step #204000	Loss: 0.309318
Step #208000	Loss: 0.319796
Step #212000	Loss: 0.316777
Step #216000	Loss: 0.397337
Step #220000	Loss: 0.343408
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 1711772.13439 ms
train loss 0.35865360498428345
Code block 'val epoch=0' took: 94356.89459 ms
validation loss 0.6134907603263855
Step #0	Loss: 0.481220
Step #4000	Loss: 0.301242
Step #8000	Loss: 0.295219
Step #12000	Loss: 0.304570
Step #16000	Loss: 0.307050
Step #20000	Loss: 0.316719
Step #24000	Loss: 0.368856
Step #28000	Loss: 0.360579
Step #32000	Loss: 0.342187
Step #36000	Loss: 0.335425
Step #40000	Loss: 0.328823
Step #44000	Loss: 0.315072
Step #48000	Loss: 0.325172
Step #52000	Loss: 0.327636
Step #56000	Loss: 0.333900
Step #60000	Loss: 0.343597
Step #64000	Loss: 0.301644
Step #68000	Loss: 0.328560
Step #72000	Loss: 0.315610
Step #76000	Loss: 0.314610
Step #80000	Loss: 0.306653
Step #84000	Loss: 0.328032
Step #88000	Loss: 0.344284
Step #92000	Loss: 0.323548
Step #96000	Loss: 0.301872
Step #100000	Loss: 0.353106
Step #104000	Loss: 0.317088
Step #108000	Loss: 0.325912
Step #112000	Loss: 0.305600
Step #116000	Loss: 0.317933
Step #120000	Loss: 0.307001
Step #124000	Loss: 0.322867
Step #128000	Loss: 0.339534
Step #132000	Loss: 0.314759
Step #136000	Loss: 0.369024
Step #140000	Loss: 0.352949
Step #144000	Loss: 0.312317
Step #148000	Loss: 0.318405
Step #152000	Loss: 0.354282
Step #156000	Loss: 0.319003
Step #160000	Loss: 0.321726
Step #164000	Loss: 0.296535
Step #168000	Loss: 0.352885
Step #172000	Loss: 0.309821
Step #176000	Loss: 0.307041
Step #180000	Loss: 0.324346
Step #184000	Loss: 0.309740
Step #188000	Loss: 0.373514
Step #192000	Loss: 0.377142
Step #196000	Loss: 0.369414
Step #200000	Loss: 0.305174
Step #204000	Loss: 0.293751
Step #208000	Loss: 0.305438
Step #212000	Loss: 0.319376
Step #216000	Loss: 0.359060
Step #220000	Loss: 0.316625
Code block 'train epoch=1' took: 1683304.90649 ms
train loss 0.32290440797805786
Code block 'val epoch=1' took: 95768.41185 ms
validation loss 0.6891475915908813
Step #0	Loss: 0.359758
Step #4000	Loss: 0.280546
Step #8000	Loss: 0.306803
Step #12000	Loss: 0.307861
Step #16000	Loss: 0.311093
Step #20000	Loss: 0.304468
Step #24000	Loss: 0.335363
Step #28000	Loss: 0.315470
Step #32000	Loss: 0.318058
Step #36000	Loss: 0.314848
Step #40000	Loss: 0.311263
Step #44000	Loss: 0.291906
Step #48000	Loss: 0.312370
Step #52000	Loss: 0.311062
Step #56000	Loss: 0.324424
Step #60000	Loss: 0.317456
Step #64000	Loss: 0.302465
Step #68000	Loss: 0.323660
Step #72000	Loss: 0.298343
Step #76000	Loss: 0.298938
Step #80000	Loss: 0.299240
Step #84000	Loss: 0.329952
Step #88000	Loss: 0.306126
Step #92000	Loss: 0.318775
Step #96000	Loss: 0.296023
Step #100000	Loss: 0.323885
Step #104000	Loss: 0.314105
Step #108000	Loss: 0.320537
Step #112000	Loss: 0.300670
Step #116000	Loss: 0.307125
Step #120000	Loss: 0.304114
Step #124000	Loss: 0.305877
Step #128000	Loss: 0.315844
Step #132000	Loss: 0.309416
Step #136000	Loss: 0.343614
Step #140000	Loss: 0.336148
Step #144000	Loss: 0.304539
Step #148000	Loss: 0.295633
Step #152000	Loss: 0.327945
Step #156000	Loss: 0.299017
Step #160000	Loss: 0.299599
Step #164000	Loss: 0.298674
Step #168000	Loss: 0.330713
Step #172000	Loss: 0.291618
Step #176000	Loss: 0.295567
Step #180000	Loss: 0.293895
Step #184000	Loss: 0.295251
Step #188000	Loss: 0.329407
Step #192000	Loss: 0.329033
Step #196000	Loss: 0.339842
Step #200000	Loss: 0.309727
Step #204000	Loss: 0.292870
Step #208000	Loss: 0.297011
Step #212000	Loss: 0.303234
Step #216000	Loss: 0.327324
Step #220000	Loss: 0.301714
Code block 'train epoch=2' took: 1681054.29559 ms
train loss 0.31010982394218445
Code block 'val epoch=2' took: 93931.27956 ms
validation loss 0.7630401849746704
Step #0	Loss: 0.350956
Step #4000	Loss: 0.292471
Step #8000	Loss: 0.298509
Step #12000	Loss: 0.295390
Step #16000	Loss: 0.298484
Step #20000	Loss: 0.307032
Step #24000	Loss: 0.303157
Step #28000	Loss: 0.304257
Step #32000	Loss: 0.303623
Step #36000	Loss: 0.300358
Step #40000	Loss: 0.318780
Step #44000	Loss: 0.280658
Step #48000	Loss: 0.303409
Step #52000	Loss: 0.302902
Step #56000	Loss: 0.317058
Step #60000	Loss: 0.311426
Step #64000	Loss: 0.285019
Step #68000	Loss: 0.319525
Step #72000	Loss: 0.310753
Step #76000	Loss: 0.295035
Step #80000	Loss: 0.301530
Step #84000	Loss: 0.319721
Step #88000	Loss: 0.303201
Step #92000	Loss: 0.314946
Step #96000	Loss: 0.296386
Step #100000	Loss: 0.314605
Step #104000	Loss: 0.301063
Step #108000	Loss: 0.309792
Step #112000	Loss: 0.307113
Step #116000	Loss: 0.308100
Step #120000	Loss: 0.300227
Step #124000	Loss: 0.289870
Step #128000	Loss: 0.316471
Step #132000	Loss: 0.313189
Step #136000	Loss: 0.332869
Step #140000	Loss: 0.320230
Step #144000	Loss: 0.297870
Step #148000	Loss: 0.294331
Step #152000	Loss: 0.314501
Step #156000	Loss: 0.301757
Step #160000	Loss: 0.295065
Step #164000	Loss: 0.289526
Step #168000	Loss: 0.315126
Step #172000	Loss: 0.297242
Step #176000	Loss: 0.298687
Step #180000	Loss: 0.307658
Step #184000	Loss: 0.296288
Step #188000	Loss: 0.321154
Step #192000	Loss: 0.320606
Step #196000	Loss: 0.311175
Step #200000	Loss: 0.303365
Step #204000	Loss: 0.285623
Step #208000	Loss: 0.300103
Step #212000	Loss: 0.293710
Step #216000	Loss: 0.317417
Step #220000	Loss: 0.302011
Code block 'train epoch=3' took: 1683860.57833 ms
train loss 0.3047802746295929
Code block 'val epoch=3' took: 94216.57100 ms
validation loss 0.7480446100234985
Step #0	Loss: 0.328086
Step #4000	Loss: 0.275660
Step #8000	Loss: 0.289654
Step #12000	Loss: 0.293709
Step #16000	Loss: 0.294372
Step #20000	Loss: 0.301869
Step #24000	Loss: 0.311885
Step #28000	Loss: 0.309000
Step #32000	Loss: 0.286992
Step #36000	Loss: 0.303033
Step #40000	Loss: 0.317105
Step #44000	Loss: 0.291401
Step #48000	Loss: 0.304122
Step #52000	Loss: 0.300965
Step #56000	Loss: 0.296884
Step #60000	Loss: 0.303632
Step #64000	Loss: 0.290386
Step #68000	Loss: 0.310770
Step #72000	Loss: 0.293664
Step #76000	Loss: 0.300104
Step #80000	Loss: 0.302257
Step #84000	Loss: 0.320548
Step #88000	Loss: 0.291886
Step #92000	Loss: 0.309215
Step #96000	Loss: 0.302390
Step #100000	Loss: 0.321297
Step #104000	Loss: 0.303798
Step #108000	Loss: 0.310481
Step #112000	Loss: 0.303841
Step #116000	Loss: 0.302767
Step #120000	Loss: 0.302352
Step #124000	Loss: 0.302777
Step #128000	Loss: 0.310024
Step #132000	Loss: 0.315886
Step #136000	Loss: 0.317671
Step #140000	Loss: 0.314306
Step #144000	Loss: 0.298212
Step #148000	Loss: 0.290214
Step #152000	Loss: 0.299243
Step #156000	Loss: 0.304331
Step #160000	Loss: 0.288530
Step #164000	Loss: 0.291990
Step #168000	Loss: 0.307255
Step #172000	Loss: 0.297507
Step #176000	Loss: 0.281166
Step #180000	Loss: 0.301519
Step #184000	Loss: 0.297583
Step #188000	Loss: 0.324329
Step #192000	Loss: 0.315893
Step #196000	Loss: 0.314317
Step #200000	Loss: 0.301439
Step #204000	Loss: 0.297040
Step #208000	Loss: 0.291182
Step #212000	Loss: 0.301110
Step #216000	Loss: 0.314580
Step #220000	Loss: 0.309121
Code block 'train epoch=4' took: 1684185.88624 ms
train loss 0.302937388420105
Code block 'val epoch=4' took: 94316.00167 ms
validation loss 0.8415231704711914
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --cufile-thread-count 16 --batch-size 8192 --epochs 5'
[WARN  tini (1352803)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-21 20:13:02.544978: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 20:13:06.141099: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-21 20:13:35.817981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-21 20:17:35.681245: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-21 20:17:36.237216: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fbb24480b20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-21 20:17:36.237319: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-21 20:17:36.399471: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-21 20:17:37.630682: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-21 20:17:38.015018: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.880613
Step #4000	Loss: 0.314679
Step #8000	Loss: 0.372701
Step #12000	Loss: 0.330305
Step #16000	Loss: 0.336175
Step #20000	Loss: 0.327645
Step #24000	Loss: 0.366153
Step #28000	Loss: 0.332844
Step #32000	Loss: 0.429598
Step #36000	Loss: 0.354820
Step #40000	Loss: 0.329472
Step #44000	Loss: 0.278068
Step #48000	Loss: 0.382193
Step #52000	Loss: 0.330740
Step #56000	Loss: 0.312862
Step #60000	Loss: 0.420718
Step #64000	Loss: 0.332807
Step #68000	Loss: 0.324938
Step #72000	Loss: 0.357184
Step #76000	Loss: 0.347040
Step #80000	Loss: 0.329135
Step #84000	Loss: 0.418432
Step #88000	Loss: 0.331895
Step #92000	Loss: 0.419722
Step #96000	Loss: 0.327359
Step #100000	Loss: 0.362576
Step #104000	Loss: 0.310043
Step #108000	Loss: 0.376871
Step #112000	Loss: 0.316445
Step #116000	Loss: 0.322842
Step #120000	Loss: 0.343502
Step #124000	Loss: 0.334098
Step #128000	Loss: 0.338662
Step #132000	Loss: 0.348507
Step #136000	Loss: 0.455520
Step #140000	Loss: 0.376342
Step #144000	Loss: 0.444473
Step #148000	Loss: 0.359195
Step #152000	Loss: 0.459768
Step #156000	Loss: 0.374279
Step #160000	Loss: 0.347563
Step #164000	Loss: 0.324862
Step #168000	Loss: 0.445333
Step #172000	Loss: 0.319595
Step #176000	Loss: 0.328366
Step #180000	Loss: 0.326607
Step #184000	Loss: 0.327789
Step #188000	Loss: 0.482042
Step #192000	Loss: 0.359353
Step #196000	Loss: 0.349869
Step #200000	Loss: 0.326191
Step #204000	Loss: 0.370494
Step #208000	Loss: 0.404991
Step #212000	Loss: 0.333839
Step #216000	Loss: 0.421068
Step #220000	Loss: 0.330946
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 1709356.57974 ms
train loss 0.35913220047950745
Code block 'val epoch=0' took: 93960.90873 ms
validation loss 0.6603927612304688
Step #0	Loss: 0.462385
Step #4000	Loss: 0.298302
Step #8000	Loss: 0.323567
Step #12000	Loss: 0.322897
Step #16000	Loss: 0.310167
Step #20000	Loss: 0.306882
Step #24000	Loss: 0.320871
Step #28000	Loss: 0.305427
Step #32000	Loss: 0.349336
Step #36000	Loss: 0.313206
Step #40000	Loss: 0.307607
Step #44000	Loss: 0.299609
Step #48000	Loss: 0.319217
Step #52000	Loss: 0.308448
Step #56000	Loss: 0.304728
Step #60000	Loss: 0.370949
Step #64000	Loss: 0.304538
Step #68000	Loss: 0.318100
Step #72000	Loss: 0.322077
Step #76000	Loss: 0.311589
Step #80000	Loss: 0.308111
Step #84000	Loss: 0.356367
Step #88000	Loss: 0.305963
Step #92000	Loss: 0.343193
Step #96000	Loss: 0.306375
Step #100000	Loss: 0.329622
Step #104000	Loss: 0.308922
Step #108000	Loss: 0.332980
Step #112000	Loss: 0.299200
Step #116000	Loss: 0.303709
Step #120000	Loss: 0.319716
Step #124000	Loss: 0.306836
Step #128000	Loss: 0.320865
Step #132000	Loss: 0.319059
Step #136000	Loss: 0.374578
Step #140000	Loss: 0.322301
Step #144000	Loss: 0.351985
Step #148000	Loss: 0.319463
Step #152000	Loss: 0.374090
Step #156000	Loss: 0.319464
Step #160000	Loss: 0.322876
Step #164000	Loss: 0.314014
Step #168000	Loss: 0.369517
Step #172000	Loss: 0.305760
Step #176000	Loss: 0.294175
Step #180000	Loss: 0.308682
Step #184000	Loss: 0.301523
Step #188000	Loss: 0.363246
Step #192000	Loss: 0.337188
Step #196000	Loss: 0.330026
Step #200000	Loss: 0.305074
Step #204000	Loss: 0.326580
Step #208000	Loss: 0.329589
Step #212000	Loss: 0.305307
Step #216000	Loss: 0.355586
Step #220000	Loss: 0.304369
Code block 'train epoch=1' took: 1679507.07811 ms
train loss 0.322603315114975
Code block 'val epoch=1' took: 94163.83695 ms
validation loss 0.7148826122283936
Step #0	Loss: 0.362029
Step #4000	Loss: 0.293417
Step #8000	Loss: 0.305032
Step #12000	Loss: 0.327139
Step #16000	Loss: 0.320015
Step #20000	Loss: 0.305551
Step #24000	Loss: 0.306780
Step #28000	Loss: 0.305489
Step #32000	Loss: 0.322419
Step #36000	Loss: 0.307270
Step #40000	Loss: 0.296358
Step #44000	Loss: 0.280025
Step #48000	Loss: 0.304942
Step #52000	Loss: 0.301270
Step #56000	Loss: 0.314215
Step #60000	Loss: 0.319895
Step #64000	Loss: 0.295764
Step #68000	Loss: 0.321515
Step #72000	Loss: 0.301874
Step #76000	Loss: 0.306971
Step #80000	Loss: 0.300421
Step #84000	Loss: 0.331208
Step #88000	Loss: 0.300835
Step #92000	Loss: 0.325210
Step #96000	Loss: 0.315877
Step #100000	Loss: 0.305604
Step #104000	Loss: 0.297868
Step #108000	Loss: 0.313405
Step #112000	Loss: 0.291429
Step #116000	Loss: 0.295707
Step #120000	Loss: 0.302372
Step #124000	Loss: 0.304664
Step #128000	Loss: 0.311275
Step #132000	Loss: 0.305378
Step #136000	Loss: 0.345688
Step #140000	Loss: 0.320283
Step #144000	Loss: 0.317567
Step #148000	Loss: 0.321282
Step #152000	Loss: 0.331732
Step #156000	Loss: 0.319563
Step #160000	Loss: 0.318695
Step #164000	Loss: 0.298884
Step #168000	Loss: 0.321774
Step #172000	Loss: 0.297699
Step #176000	Loss: 0.294200
Step #180000	Loss: 0.299591
Step #184000	Loss: 0.295686
Step #188000	Loss: 0.328208
Step #192000	Loss: 0.317009
Step #196000	Loss: 0.325104
Step #200000	Loss: 0.299365
Step #204000	Loss: 0.289211
Step #208000	Loss: 0.336573
Step #212000	Loss: 0.302638
Step #216000	Loss: 0.331211
Step #220000	Loss: 0.291683
Code block 'train epoch=2' took: 1680231.99783 ms
train loss 0.3102062940597534
Code block 'val epoch=2' took: 94565.26278 ms
validation loss 0.7544435262680054
Step #0	Loss: 0.350437
Step #4000	Loss: 0.299332
Step #8000	Loss: 0.301204
Step #12000	Loss: 0.313726
Step #16000	Loss: 0.300737
Step #20000	Loss: 0.298375
Step #24000	Loss: 0.313518
Step #28000	Loss: 0.297388
Step #32000	Loss: 0.303160
Step #36000	Loss: 0.310313
Step #40000	Loss: 0.299058
Step #44000	Loss: 0.282256
Step #48000	Loss: 0.303609
Step #52000	Loss: 0.295565
Step #56000	Loss: 0.310163
Step #60000	Loss: 0.314405
Step #64000	Loss: 0.290356
Step #68000	Loss: 0.311327
Step #72000	Loss: 0.308753
Step #76000	Loss: 0.296553
Step #80000	Loss: 0.306661
Step #84000	Loss: 0.320183
Step #88000	Loss: 0.307048
Step #92000	Loss: 0.312118
Step #96000	Loss: 0.304965
Step #100000	Loss: 0.311879
Step #104000	Loss: 0.297265
Step #108000	Loss: 0.308865
Step #112000	Loss: 0.288492
Step #116000	Loss: 0.294169
Step #120000	Loss: 0.296889
Step #124000	Loss: 0.288320
Step #128000	Loss: 0.312961
Step #132000	Loss: 0.308002
Step #136000	Loss: 0.321332
Step #140000	Loss: 0.312378
Step #144000	Loss: 0.311354
Step #148000	Loss: 0.301881
Step #152000	Loss: 0.321439
Step #156000	Loss: 0.305421
Step #160000	Loss: 0.312921
Step #164000	Loss: 0.294668
Step #168000	Loss: 0.322581
Step #172000	Loss: 0.293911
Step #176000	Loss: 0.287422
Step #180000	Loss: 0.294918
Step #184000	Loss: 0.297435
Step #188000	Loss: 0.326168
Step #192000	Loss: 0.320764
Step #196000	Loss: 0.311537
Step #200000	Loss: 0.303954
Step #204000	Loss: 0.298012
Step #208000	Loss: 0.308146
Step #212000	Loss: 0.302014
Step #216000	Loss: 0.328432
Step #220000	Loss: 0.303789
Code block 'train epoch=3' took: 1681098.74720 ms
train loss 0.30506306886672974
Code block 'val epoch=3' took: 94178.04356 ms
validation loss 0.7826653718948364
Step #0	Loss: 0.328532
Step #4000	Loss: 0.292676
Step #8000	Loss: 0.284605
Step #12000	Loss: 0.317626
Step #16000	Loss: 0.308018
Step #20000	Loss: 0.298590
Step #24000	Loss: 0.301985
Step #28000	Loss: 0.301458
Step #32000	Loss: 0.288653
Step #36000	Loss: 0.295573
Step #40000	Loss: 0.309991
Step #44000	Loss: 0.271631
Step #48000	Loss: 0.296972
Step #52000	Loss: 0.297957
Step #56000	Loss: 0.300727
Step #60000	Loss: 0.298103
Step #64000	Loss: 0.286517
Step #68000	Loss: 0.300218
Step #72000	Loss: 0.305230
Step #76000	Loss: 0.287013
Step #80000	Loss: 0.296853
Step #84000	Loss: 0.324776
Step #88000	Loss: 0.305360
Step #92000	Loss: 0.317488
Step #96000	Loss: 0.304154
Step #100000	Loss: 0.309258
Step #104000	Loss: 0.299693
Step #108000	Loss: 0.303961
Step #112000	Loss: 0.297805
Step #116000	Loss: 0.289374
Step #120000	Loss: 0.295832
Step #124000	Loss: 0.287268
Step #128000	Loss: 0.310944
Step #132000	Loss: 0.305656
Step #136000	Loss: 0.325966
Step #140000	Loss: 0.317549
Step #144000	Loss: 0.310017
Step #148000	Loss: 0.298412
Step #152000	Loss: 0.305824
Step #156000	Loss: 0.305888
Step #160000	Loss: 0.311757
Step #164000	Loss: 0.292487
Step #168000	Loss: 0.316014
Step #172000	Loss: 0.287177
Step #176000	Loss: 0.281125
Step #180000	Loss: 0.304848
Step #184000	Loss: 0.291208
Step #188000	Loss: 0.316480
Step #192000	Loss: 0.321470
Step #196000	Loss: 0.316725
Step #200000	Loss: 0.304624
Step #204000	Loss: 0.287867
Step #208000	Loss: 0.314521
Step #212000	Loss: 0.302237
Step #216000	Loss: 0.315211
Step #220000	Loss: 0.295058
Code block 'train epoch=4' took: 1681068.64818 ms
train loss 0.3025496006011963
Code block 'val epoch=4' took: 93871.80163 ms
validation loss 0.8006008863449097
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --cufile-thread-count 16 --batch-size 8192 --epochs 5'
[WARN  tini (1466358)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-21 22:45:53.503344: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 22:45:57.286702: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-21 22:46:28.339543: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-21 22:50:19.177991: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-21 22:50:19.843370: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fe162acb770 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-21 22:50:19.843455: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-21 22:50:20.014496: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-21 22:50:21.276816: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-21 22:50:21.621863: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.840841
Step #4000	Loss: 0.323987
Step #8000	Loss: 0.367522
Step #12000	Loss: 0.350910
Step #16000	Loss: 0.319304
Step #20000	Loss: 0.319257
Step #24000	Loss: 0.436600
Step #28000	Loss: 0.430877
Step #32000	Loss: 0.441050
Step #36000	Loss: 0.418155
Step #40000	Loss: 0.333940
Step #44000	Loss: 0.359295
Step #48000	Loss: 0.364794
Step #52000	Loss: 0.372544
Step #56000	Loss: 0.393918
Step #60000	Loss: 0.427527
Step #64000	Loss: 0.336979
Step #68000	Loss: 0.381434
Step #72000	Loss: 0.369844
Step #76000	Loss: 0.398394
Step #80000	Loss: 0.406741
Step #84000	Loss: 0.424652
Step #88000	Loss: 0.405866
Step #92000	Loss: 0.371559
Step #96000	Loss: 0.361900
Step #100000	Loss: 0.340651
Step #104000	Loss: 0.310278
Step #108000	Loss: 0.338844
Step #112000	Loss: 0.337748
Step #116000	Loss: 0.418071
Step #120000	Loss: 0.321377
Step #124000	Loss: 0.392515
Step #128000	Loss: 0.381512
Step #132000	Loss: 0.323954
Step #136000	Loss: 0.451419
Step #140000	Loss: 0.421837
Step #144000	Loss: 0.344475
Step #148000	Loss: 0.353285
Step #152000	Loss: 0.347115
Step #156000	Loss: 0.366600
Step #160000	Loss: 0.398428
Step #164000	Loss: 0.340927
Step #168000	Loss: 0.357562
Step #172000	Loss: 0.329321
Step #176000	Loss: 0.355514
Step #180000	Loss: 0.372779
Step #184000	Loss: 0.313584
Step #188000	Loss: 0.478311
Step #192000	Loss: 0.456533
Step #196000	Loss: 0.469179
Step #200000	Loss: 0.328394
Step #204000	Loss: 0.345671
Step #208000	Loss: 0.313720
Step #212000	Loss: 0.331170
Step #216000	Loss: 0.411086
Step #220000	Loss: 0.430289
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 1693506.48346 ms
train loss 0.3613544702529907
Code block 'val epoch=0' took: 91746.65244 ms
validation loss 0.5713747143745422
Step #0	Loss: 0.466171
Step #4000	Loss: 0.308059
Step #8000	Loss: 0.320510
Step #12000	Loss: 0.311909
Step #16000	Loss: 0.307198
Step #20000	Loss: 0.318916
Step #24000	Loss: 0.362437
Step #28000	Loss: 0.365758
Step #32000	Loss: 0.363645
Step #36000	Loss: 0.341535
Step #40000	Loss: 0.336487
Step #44000	Loss: 0.315240
Step #48000	Loss: 0.331101
Step #52000	Loss: 0.330630
Step #56000	Loss: 0.346868
Step #60000	Loss: 0.356422
Step #64000	Loss: 0.313513
Step #68000	Loss: 0.349335
Step #72000	Loss: 0.327933
Step #76000	Loss: 0.327987
Step #80000	Loss: 0.349231
Step #84000	Loss: 0.364263
Step #88000	Loss: 0.342453
Step #92000	Loss: 0.344280
Step #96000	Loss: 0.334034
Step #100000	Loss: 0.314266
Step #104000	Loss: 0.316328
Step #108000	Loss: 0.341323
Step #112000	Loss: 0.320772
Step #116000	Loss: 0.361389
Step #120000	Loss: 0.316609
Step #124000	Loss: 0.328726
Step #128000	Loss: 0.341860
Step #132000	Loss: 0.316352
Step #136000	Loss: 0.360073
Step #140000	Loss: 0.371931
Step #144000	Loss: 0.317661
Step #148000	Loss: 0.313321
Step #152000	Loss: 0.317746
Step #156000	Loss: 0.332659
Step #160000	Loss: 0.337952
Step #164000	Loss: 0.314492
Step #168000	Loss: 0.340966
Step #172000	Loss: 0.310763
Step #176000	Loss: 0.308620
Step #180000	Loss: 0.332899
Step #184000	Loss: 0.311624
Step #188000	Loss: 0.377205
Step #192000	Loss: 0.384356
Step #196000	Loss: 0.382055
Step #200000	Loss: 0.321181
Step #204000	Loss: 0.310503
Step #208000	Loss: 0.298577
Step #212000	Loss: 0.318647
Step #216000	Loss: 0.347592
Step #220000	Loss: 0.348849
Code block 'train epoch=1' took: 1666766.31011 ms
train loss 0.3279719352722168
Code block 'val epoch=1' took: 92499.97574 ms
validation loss 0.5874770879745483
Step #0	Loss: 0.349458
Step #4000	Loss: 0.283697
Step #8000	Loss: 0.308851
Step #12000	Loss: 0.308408
Step #16000	Loss: 0.305151
Step #20000	Loss: 0.320210
Step #24000	Loss: 0.326331
Step #28000	Loss: 0.334664
Step #32000	Loss: 0.330739
Step #36000	Loss: 0.326075
Step #40000	Loss: 0.317674
Step #44000	Loss: 0.297584
Step #48000	Loss: 0.311789
Step #52000	Loss: 0.305298
Step #56000	Loss: 0.325844
Step #60000	Loss: 0.325978
Step #64000	Loss: 0.291542
Step #68000	Loss: 0.323986
Step #72000	Loss: 0.311480
Step #76000	Loss: 0.325299
Step #80000	Loss: 0.326538
Step #84000	Loss: 0.343340
Step #88000	Loss: 0.320255
Step #92000	Loss: 0.331843
Step #96000	Loss: 0.315528
Step #100000	Loss: 0.307660
Step #104000	Loss: 0.290020
Step #108000	Loss: 0.320020
Step #112000	Loss: 0.306443
Step #116000	Loss: 0.325253
Step #120000	Loss: 0.309516
Step #124000	Loss: 0.289669
Step #128000	Loss: 0.310919
Step #132000	Loss: 0.316024
Step #136000	Loss: 0.336671
Step #140000	Loss: 0.339103
Step #144000	Loss: 0.310418
Step #148000	Loss: 0.304045
Step #152000	Loss: 0.316174
Step #156000	Loss: 0.318341
Step #160000	Loss: 0.313072
Step #164000	Loss: 0.291463
Step #168000	Loss: 0.325202
Step #172000	Loss: 0.285052
Step #176000	Loss: 0.284072
Step #180000	Loss: 0.302929
Step #184000	Loss: 0.296586
Step #188000	Loss: 0.343276
Step #192000	Loss: 0.342986
Step #196000	Loss: 0.334131
Step #200000	Loss: 0.308174
Step #204000	Loss: 0.294548
Step #208000	Loss: 0.297171
Step #212000	Loss: 0.316281
Step #216000	Loss: 0.325572
Step #220000	Loss: 0.327051
Code block 'train epoch=2' took: 1670224.41548 ms
train loss 0.3134031295776367
Code block 'val epoch=2' took: 92558.03016 ms
validation loss 0.6308864951133728
Step #0	Loss: 0.349158
Step #4000	Loss: 0.293880
Step #8000	Loss: 0.302606
Step #12000	Loss: 0.309774
Step #16000	Loss: 0.297142
Step #20000	Loss: 0.305952
Step #24000	Loss: 0.325592
Step #28000	Loss: 0.323673
Step #32000	Loss: 0.310935
Step #36000	Loss: 0.314867
Step #40000	Loss: 0.311145
Step #44000	Loss: 0.280099
Step #48000	Loss: 0.300409
Step #52000	Loss: 0.308074
Step #56000	Loss: 0.307442
Step #60000	Loss: 0.309595
Step #64000	Loss: 0.293104
Step #68000	Loss: 0.304002
Step #72000	Loss: 0.309660
Step #76000	Loss: 0.302813
Step #80000	Loss: 0.306207
Step #84000	Loss: 0.328355
Step #88000	Loss: 0.313592
Step #92000	Loss: 0.319156
Step #96000	Loss: 0.300270
Step #100000	Loss: 0.308675
Step #104000	Loss: 0.306250
Step #108000	Loss: 0.313598
Step #112000	Loss: 0.288251
Step #116000	Loss: 0.312717
Step #120000	Loss: 0.298782
Step #124000	Loss: 0.293695
Step #128000	Loss: 0.309855
Step #132000	Loss: 0.300699
Step #136000	Loss: 0.328629
Step #140000	Loss: 0.325939
Step #144000	Loss: 0.308323
Step #148000	Loss: 0.297195
Step #152000	Loss: 0.300912
Step #156000	Loss: 0.308251
Step #160000	Loss: 0.302155
Step #164000	Loss: 0.301564
Step #168000	Loss: 0.317380
Step #172000	Loss: 0.289756
Step #176000	Loss: 0.283395
Step #180000	Loss: 0.305824
Step #184000	Loss: 0.292654
Step #188000	Loss: 0.323774
Step #192000	Loss: 0.338484
Step #196000	Loss: 0.311544
Step #200000	Loss: 0.301691
Step #204000	Loss: 0.298081
Step #208000	Loss: 0.297142
Step #212000	Loss: 0.304720
Step #216000	Loss: 0.323963
Step #220000	Loss: 0.318654
Code block 'train epoch=3' took: 1665987.01024 ms
train loss 0.30650919675827026
Code block 'val epoch=3' took: 92406.74362 ms
validation loss 0.6708582043647766
Step #0	Loss: 0.338684
Step #4000	Loss: 0.285109
Step #8000	Loss: 0.295732
Step #12000	Loss: 0.301793
Step #16000	Loss: 0.291058
Step #20000	Loss: 0.302857
Step #24000	Loss: 0.312012
Step #28000	Loss: 0.311940
Step #32000	Loss: 0.291542
Step #36000	Loss: 0.295833
Step #40000	Loss: 0.312761
Step #44000	Loss: 0.283727
Step #48000	Loss: 0.294232
Step #52000	Loss: 0.294303
Step #56000	Loss: 0.304899
Step #60000	Loss: 0.295519
Step #64000	Loss: 0.300004
Step #68000	Loss: 0.309124
Step #72000	Loss: 0.304474
Step #76000	Loss: 0.303998
Step #80000	Loss: 0.304369
Step #84000	Loss: 0.324897
Step #88000	Loss: 0.308882
Step #92000	Loss: 0.313088
Step #96000	Loss: 0.303280
Step #100000	Loss: 0.292560
Step #104000	Loss: 0.303374
Step #108000	Loss: 0.301175
Step #112000	Loss: 0.292755
Step #116000	Loss: 0.309664
Step #120000	Loss: 0.299933
Step #124000	Loss: 0.296791
Step #128000	Loss: 0.326782
Step #132000	Loss: 0.304490
Step #136000	Loss: 0.326720
Step #140000	Loss: 0.319406
Step #144000	Loss: 0.301738
Step #148000	Loss: 0.298284
Step #152000	Loss: 0.299005
Step #156000	Loss: 0.295594
Step #160000	Loss: 0.289846
Step #164000	Loss: 0.296899
Step #168000	Loss: 0.303354
Step #172000	Loss: 0.298662
Step #176000	Loss: 0.287264
Step #180000	Loss: 0.295800
Step #184000	Loss: 0.289076
Step #188000	Loss: 0.325755
Step #192000	Loss: 0.324769
Step #196000	Loss: 0.304047
Step #200000	Loss: 0.301682
Step #204000	Loss: 0.273116
Step #208000	Loss: 0.308610
Step #212000	Loss: 0.306238
Step #216000	Loss: 0.299600
Step #220000	Loss: 0.306360
Code block 'train epoch=4' took: 1668118.09768 ms
train loss 0.30337750911712646
Code block 'val epoch=4' took: 92614.53668 ms
validation loss 0.7312243580818176
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --cufile-thread-count 16 --batch-size 8192 --epochs 5'
[WARN  tini (1579901)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-22 01:17:24.288207: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-22 01:17:27.945021: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-22 01:17:57.974670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-22 01:21:51.529652: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-22 01:21:52.074680: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f6c78792420 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-22 01:21:52.074742: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-22 01:21:52.233655: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-22 01:21:53.304556: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-22 01:21:53.652801: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.974702
Step #4000	Loss: 0.334856
Step #8000	Loss: 0.328178
Step #12000	Loss: 0.357975
Step #16000	Loss: 0.363860
Step #20000	Loss: 0.346942
Step #24000	Loss: 0.357598
Step #28000	Loss: 0.341666
Step #32000	Loss: 0.337187
Step #36000	Loss: 0.331075
Step #40000	Loss: 0.336241
Step #44000	Loss: 0.298317
Step #48000	Loss: 0.325266
Step #52000	Loss: 0.322616
Step #56000	Loss: 0.338137
Step #60000	Loss: 0.347099
Step #64000	Loss: 0.326640
Step #68000	Loss: 0.356354
Step #72000	Loss: 0.392341
Step #76000	Loss: 0.323027
Step #80000	Loss: 0.338660
Step #84000	Loss: 0.355153
Step #88000	Loss: 0.413368
Step #92000	Loss: 0.431660
Step #96000	Loss: 0.403207
Step #100000	Loss: 0.359245
Step #104000	Loss: 0.348481
Step #108000	Loss: 0.354173
Step #112000	Loss: 0.326793
Step #116000	Loss: 0.432790
Step #120000	Loss: 0.316405
Step #124000	Loss: 0.351048
Step #128000	Loss: 0.332380
Step #132000	Loss: 0.340868
Step #136000	Loss: 0.455011
Step #140000	Loss: 0.403003
Step #144000	Loss: 0.370526
Step #148000	Loss: 0.365337
Step #152000	Loss: 0.325911
Step #156000	Loss: 0.324702
Step #160000	Loss: 0.412985
Step #164000	Loss: 0.338734
Step #168000	Loss: 0.340763
Step #172000	Loss: 0.375164
Step #176000	Loss: 0.408724
Step #180000	Loss: 0.372362
Step #184000	Loss: 0.339577
Step #188000	Loss: 0.355888
Step #192000	Loss: 0.367132
Step #196000	Loss: 0.367444
Step #200000	Loss: 0.361867
Step #204000	Loss: 0.347355
Step #208000	Loss: 0.353877
Step #212000	Loss: 0.341979
Step #216000	Loss: 0.345842
Step #220000	Loss: 0.432625
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 1691448.42973 ms
train loss 0.35906514525413513
Code block 'val epoch=0' took: 90663.24403 ms
validation loss 0.6466643810272217
Step #0	Loss: 0.469553
Step #4000	Loss: 0.313533
Step #8000	Loss: 0.311095
Step #12000	Loss: 0.307729
Step #16000	Loss: 0.311332
Step #20000	Loss: 0.311734
Step #24000	Loss: 0.317228
Step #28000	Loss: 0.319407
Step #32000	Loss: 0.299119
Step #36000	Loss: 0.316027
Step #40000	Loss: 0.323947
Step #44000	Loss: 0.291874
Step #48000	Loss: 0.302333
Step #52000	Loss: 0.309002
Step #56000	Loss: 0.313098
Step #60000	Loss: 0.307186
Step #64000	Loss: 0.303549
Step #68000	Loss: 0.315329
Step #72000	Loss: 0.336608
Step #76000	Loss: 0.297032
Step #80000	Loss: 0.306056
Step #84000	Loss: 0.335568
Step #88000	Loss: 0.340462
Step #92000	Loss: 0.353711
Step #96000	Loss: 0.341920
Step #100000	Loss: 0.332237
Step #104000	Loss: 0.303307
Step #108000	Loss: 0.322424
Step #112000	Loss: 0.304079
Step #116000	Loss: 0.352662
Step #120000	Loss: 0.316996
Step #124000	Loss: 0.315519
Step #128000	Loss: 0.326661
Step #132000	Loss: 0.313264
Step #136000	Loss: 0.368837
Step #140000	Loss: 0.329244
Step #144000	Loss: 0.337866
Step #148000	Loss: 0.313596
Step #152000	Loss: 0.307016
Step #156000	Loss: 0.309813
Step #160000	Loss: 0.337530
Step #164000	Loss: 0.302218
Step #168000	Loss: 0.318749
Step #172000	Loss: 0.309485
Step #176000	Loss: 0.326304
Step #180000	Loss: 0.319827
Step #184000	Loss: 0.315690
Step #188000	Loss: 0.334020
Step #192000	Loss: 0.335962
Step #196000	Loss: 0.313425
Step #200000	Loss: 0.322610
Step #204000	Loss: 0.304469
Step #208000	Loss: 0.320899
Step #212000	Loss: 0.326109
Step #216000	Loss: 0.321201
Step #220000	Loss: 0.340704
Code block 'train epoch=1' took: 1668074.82042 ms
train loss 0.3222348988056183
Code block 'val epoch=1' took: 91747.20011 ms
validation loss 0.6854006052017212
Step #0	Loss: 0.360330
Step #4000	Loss: 0.290719
Step #8000	Loss: 0.305848
Step #12000	Loss: 0.307272
Step #16000	Loss: 0.310550
Step #20000	Loss: 0.308418
Step #24000	Loss: 0.320316
Step #28000	Loss: 0.294209
Step #32000	Loss: 0.307742
Step #36000	Loss: 0.296589
Step #40000	Loss: 0.301670
Step #44000	Loss: 0.280772
Step #48000	Loss: 0.292194
Step #52000	Loss: 0.297592
Step #56000	Loss: 0.304096
Step #60000	Loss: 0.296350
Step #64000	Loss: 0.298025
Step #68000	Loss: 0.324268
Step #72000	Loss: 0.305953
Step #76000	Loss: 0.295355
Step #80000	Loss: 0.302123
Step #84000	Loss: 0.333493
Step #88000	Loss: 0.320717
Step #92000	Loss: 0.320217
Step #96000	Loss: 0.321711
Step #100000	Loss: 0.300769
Step #104000	Loss: 0.313283
Step #108000	Loss: 0.315323
Step #112000	Loss: 0.293081
Step #116000	Loss: 0.323552
Step #120000	Loss: 0.296845
Step #124000	Loss: 0.304302
Step #128000	Loss: 0.313597
Step #132000	Loss: 0.316866
Step #136000	Loss: 0.340322
Step #140000	Loss: 0.308844
Step #144000	Loss: 0.307790
Step #148000	Loss: 0.312861
Step #152000	Loss: 0.302772
Step #156000	Loss: 0.321309
Step #160000	Loss: 0.300206
Step #164000	Loss: 0.301519
Step #168000	Loss: 0.310887
Step #172000	Loss: 0.305766
Step #176000	Loss: 0.311985
Step #180000	Loss: 0.299816
Step #184000	Loss: 0.306195
Step #188000	Loss: 0.320874
Step #192000	Loss: 0.320909
Step #196000	Loss: 0.322947
Step #200000	Loss: 0.313515
Step #204000	Loss: 0.300067
Step #208000	Loss: 0.307268
Step #212000	Loss: 0.310806
Step #216000	Loss: 0.306638
Step #220000	Loss: 0.334367
Code block 'train epoch=2' took: 1664723.57592 ms
train loss 0.3100370466709137
Code block 'val epoch=2' took: 90212.69649 ms
validation loss 0.6898893713951111
Step #0	Loss: 0.334742
Step #4000	Loss: 0.295079
Step #8000	Loss: 0.288511
Step #12000	Loss: 0.298340
Step #16000	Loss: 0.294783
Step #20000	Loss: 0.310437
Step #24000	Loss: 0.306030
Step #28000	Loss: 0.302931
Step #32000	Loss: 0.293415
Step #36000	Loss: 0.303798
Step #40000	Loss: 0.300802
Step #44000	Loss: 0.281371
Step #48000	Loss: 0.291766
Step #52000	Loss: 0.298280
Step #56000	Loss: 0.303883
Step #60000	Loss: 0.306310
Step #64000	Loss: 0.282776
Step #68000	Loss: 0.313089
Step #72000	Loss: 0.309755
Step #76000	Loss: 0.290971
Step #80000	Loss: 0.304018
Step #84000	Loss: 0.311318
Step #88000	Loss: 0.311829
Step #92000	Loss: 0.314190
Step #96000	Loss: 0.316614
Step #100000	Loss: 0.320457
Step #104000	Loss: 0.296188
Step #108000	Loss: 0.310968
Step #112000	Loss: 0.293799
Step #116000	Loss: 0.310598
Step #120000	Loss: 0.289478
Step #124000	Loss: 0.299763
Step #128000	Loss: 0.301082
Step #132000	Loss: 0.326114
Step #136000	Loss: 0.329546
Step #140000	Loss: 0.302581
Step #144000	Loss: 0.315525
Step #148000	Loss: 0.307129
Step #152000	Loss: 0.289326
Step #156000	Loss: 0.311102
Step #160000	Loss: 0.298536
Step #164000	Loss: 0.295352
Step #168000	Loss: 0.304721
Step #172000	Loss: 0.292095
Step #176000	Loss: 0.291234
Step #180000	Loss: 0.288027
Step #184000	Loss: 0.288353
Step #188000	Loss: 0.320313
Step #192000	Loss: 0.321148
Step #196000	Loss: 0.314780
Step #200000	Loss: 0.308328
Step #204000	Loss: 0.286660
Step #208000	Loss: 0.312176
Step #212000	Loss: 0.303104
Step #216000	Loss: 0.297186
Step #220000	Loss: 0.310417
Code block 'train epoch=3' took: 1666385.95027 ms
train loss 0.304602712392807
Code block 'val epoch=3' took: 90391.81910 ms
validation loss 0.6656850576400757
Step #0	Loss: 0.331388
Step #4000	Loss: 0.302582
Step #8000	Loss: 0.299775
Step #12000	Loss: 0.301385
Step #16000	Loss: 0.302298
Step #20000	Loss: 0.308886
Step #24000	Loss: 0.306312
Step #28000	Loss: 0.311763
Step #32000	Loss: 0.295852
Step #36000	Loss: 0.291434
Step #40000	Loss: 0.300679
Step #44000	Loss: 0.272423
Step #48000	Loss: 0.287560
Step #52000	Loss: 0.286043
Step #56000	Loss: 0.309777
Step #60000	Loss: 0.293925
Step #64000	Loss: 0.286209
Step #68000	Loss: 0.305105
Step #72000	Loss: 0.298981
Step #76000	Loss: 0.289113
Step #80000	Loss: 0.301538
Step #84000	Loss: 0.310756
Step #88000	Loss: 0.304139
Step #92000	Loss: 0.312478
Step #96000	Loss: 0.307695
Step #100000	Loss: 0.297916
Step #104000	Loss: 0.295605
Step #108000	Loss: 0.316511
Step #112000	Loss: 0.287207
Step #116000	Loss: 0.295984
Step #120000	Loss: 0.303183
Step #124000	Loss: 0.289513
Step #128000	Loss: 0.306507
Step #132000	Loss: 0.313998
Step #136000	Loss: 0.332407
Step #140000	Loss: 0.289158
Step #144000	Loss: 0.301808
Step #148000	Loss: 0.295608
Step #152000	Loss: 0.305587
Step #156000	Loss: 0.304588
Step #160000	Loss: 0.296642
Step #164000	Loss: 0.304546
Step #168000	Loss: 0.304979
Step #172000	Loss: 0.293101
Step #176000	Loss: 0.299912
Step #180000	Loss: 0.289981
Step #184000	Loss: 0.301265
Step #188000	Loss: 0.322007
Step #192000	Loss: 0.304403
Step #196000	Loss: 0.302325
Step #200000	Loss: 0.302381
Step #204000	Loss: 0.278862
Step #208000	Loss: 0.302117
Step #212000	Loss: 0.301808
Step #216000	Loss: 0.297206
Step #220000	Loss: 0.306468
Code block 'train epoch=4' took: 1666447.40938 ms
train loss 0.30191847681999207
Code block 'val epoch=4' took: 91825.17120 ms
validation loss 0.6815307140350342
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --cufile-thread-count 16 --batch-size 8192 --epochs 5'
[WARN  tini (1696644)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-22 03:48:39.874701: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-22 03:48:44.027667: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-22 03:49:14.576966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-22 03:53:14.013216: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-22 03:53:14.657968: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f31446b4a40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-22 03:53:14.658114: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-22 03:53:14.828912: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-22 03:53:16.039866: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-22 03:53:16.381557: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.929456
Step #4000	Loss: 0.400840
Step #8000	Loss: 0.321578
Step #12000	Loss: 0.323917
Step #16000	Loss: 0.319228
Step #20000	Loss: 0.373702
Step #24000	Loss: 0.444795
Step #28000	Loss: 0.337509
Step #32000	Loss: 0.339636
Step #36000	Loss: 0.425528
Step #40000	Loss: 0.325781
Step #44000	Loss: 0.407750
Step #48000	Loss: 0.320806
Step #52000	Loss: 0.353193
Step #56000	Loss: 0.431829
Step #60000	Loss: 0.326068
Step #64000	Loss: 0.351936
Step #68000	Loss: 0.420332
Step #72000	Loss: 0.406129
Step #76000	Loss: 0.438370
Step #80000	Loss: 0.326776
Step #84000	Loss: 0.360628
Step #88000	Loss: 0.361755
Step #92000	Loss: 0.430723
Step #96000	Loss: 0.366517
Step #100000	Loss: 0.378771
Step #104000	Loss: 0.308363
Step #108000	Loss: 0.354598
Step #112000	Loss: 0.347215
Step #116000	Loss: 0.372734
Step #120000	Loss: 0.359122
Step #124000	Loss: 0.331120
Step #128000	Loss: 0.362588
Step #132000	Loss: 0.385317
Step #136000	Loss: 0.445330
Step #140000	Loss: 0.341906
Step #144000	Loss: 0.334095
Step #148000	Loss: 0.371559
Step #152000	Loss: 0.423008
Step #156000	Loss: 0.340401
Step #160000	Loss: 0.337275
Step #164000	Loss: 0.322580
Step #168000	Loss: 0.343847
Step #172000	Loss: 0.368958
Step #176000	Loss: 0.330785
Step #180000	Loss: 0.338539
Step #184000	Loss: 0.364457
Step #188000	Loss: 0.478478
Step #192000	Loss: 0.357540
Step #196000	Loss: 0.373035
Step #200000	Loss: 0.325728
Step #204000	Loss: 0.328677
Step #208000	Loss: 0.322498
Step #212000	Loss: 0.336109
Step #216000	Loss: 0.366151
Step #220000	Loss: 0.348970
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 1702034.30599 ms
train loss 0.3593835234642029
Code block 'val epoch=0' took: 90942.22547 ms
validation loss 0.7364935874938965
Step #0	Loss: 0.450393
Step #4000	Loss: 0.341721
Step #8000	Loss: 0.304795
Step #12000	Loss: 0.316826
Step #16000	Loss: 0.309920
Step #20000	Loss: 0.332219
Step #24000	Loss: 0.353222
Step #28000	Loss: 0.308542
Step #32000	Loss: 0.311221
Step #36000	Loss: 0.349545
Step #40000	Loss: 0.307023
Step #44000	Loss: 0.343035
Step #48000	Loss: 0.303880
Step #52000	Loss: 0.316888
Step #56000	Loss: 0.337569
Step #60000	Loss: 0.314217
Step #64000	Loss: 0.304006
Step #68000	Loss: 0.359960
Step #72000	Loss: 0.324506
Step #76000	Loss: 0.347848
Step #80000	Loss: 0.303605
Step #84000	Loss: 0.331883
Step #88000	Loss: 0.320695
Step #92000	Loss: 0.354942
Step #96000	Loss: 0.331518
Step #100000	Loss: 0.314421
Step #104000	Loss: 0.309331
Step #108000	Loss: 0.322563
Step #112000	Loss: 0.317798
Step #116000	Loss: 0.309070
Step #120000	Loss: 0.314250
Step #124000	Loss: 0.309047
Step #128000	Loss: 0.330193
Step #132000	Loss: 0.344778
Step #136000	Loss: 0.372442
Step #140000	Loss: 0.330587
Step #144000	Loss: 0.312175
Step #148000	Loss: 0.309114
Step #152000	Loss: 0.321933
Step #156000	Loss: 0.314341
Step #160000	Loss: 0.321445
Step #164000	Loss: 0.298045
Step #168000	Loss: 0.323437
Step #172000	Loss: 0.318872
Step #176000	Loss: 0.309384
Step #180000	Loss: 0.299851
Step #184000	Loss: 0.326051
Step #188000	Loss: 0.363042
Step #192000	Loss: 0.335018
Step #196000	Loss: 0.333878
Step #200000	Loss: 0.303684
Step #204000	Loss: 0.303304
Step #208000	Loss: 0.311605
Step #212000	Loss: 0.322185
Step #216000	Loss: 0.326277
Step #220000	Loss: 0.309472
Code block 'train epoch=1' took: 1674408.46797 ms
train loss 0.3215827941894531
Code block 'val epoch=1' took: 91973.95424 ms
validation loss 0.7905237078666687
Step #0	Loss: 0.378759
Step #4000	Loss: 0.319889
Step #8000	Loss: 0.288894
Step #12000	Loss: 0.323042
Step #16000	Loss: 0.299923
Step #20000	Loss: 0.314447
Step #24000	Loss: 0.316920
Step #28000	Loss: 0.320045
Step #32000	Loss: 0.307770
Step #36000	Loss: 0.324384
Step #40000	Loss: 0.307686
Step #44000	Loss: 0.301183
Step #48000	Loss: 0.278946
Step #52000	Loss: 0.308498
Step #56000	Loss: 0.319572
Step #60000	Loss: 0.296688
Step #64000	Loss: 0.305050
Step #68000	Loss: 0.326756
Step #72000	Loss: 0.300466
Step #76000	Loss: 0.312333
Step #80000	Loss: 0.311728
Step #84000	Loss: 0.318958
Step #88000	Loss: 0.303848
Step #92000	Loss: 0.326400
Step #96000	Loss: 0.322298
Step #100000	Loss: 0.309458
Step #104000	Loss: 0.298399
Step #108000	Loss: 0.310421
Step #112000	Loss: 0.314502
Step #116000	Loss: 0.300288
Step #120000	Loss: 0.311461
Step #124000	Loss: 0.299257
Step #128000	Loss: 0.313007
Step #132000	Loss: 0.329949
Step #136000	Loss: 0.332433
Step #140000	Loss: 0.322860
Step #144000	Loss: 0.301933
Step #148000	Loss: 0.299033
Step #152000	Loss: 0.316004
Step #156000	Loss: 0.318438
Step #160000	Loss: 0.312850
Step #164000	Loss: 0.295224
Step #168000	Loss: 0.329434
Step #172000	Loss: 0.307579
Step #176000	Loss: 0.290982
Step #180000	Loss: 0.291190
Step #184000	Loss: 0.316108
Step #188000	Loss: 0.328653
Step #192000	Loss: 0.319127
Step #196000	Loss: 0.319315
Step #200000	Loss: 0.318924
Step #204000	Loss: 0.297246
Step #208000	Loss: 0.303947
Step #212000	Loss: 0.316024
Step #216000	Loss: 0.306894
Step #220000	Loss: 0.308472
Code block 'train epoch=2' took: 1674808.21090 ms
train loss 0.3095936179161072
Code block 'val epoch=2' took: 91793.77190 ms
validation loss 0.8261034488677979
Step #0	Loss: 0.350790
Step #4000	Loss: 0.303079
Step #8000	Loss: 0.287401
Step #12000	Loss: 0.311401
Step #16000	Loss: 0.299079
Step #20000	Loss: 0.310808
Step #24000	Loss: 0.312270
Step #28000	Loss: 0.304081
Step #32000	Loss: 0.299853
Step #36000	Loss: 0.312392
Step #40000	Loss: 0.308192
Step #44000	Loss: 0.296771
Step #48000	Loss: 0.288374
Step #52000	Loss: 0.293646
Step #56000	Loss: 0.303017
Step #60000	Loss: 0.289571
Step #64000	Loss: 0.297270
Step #68000	Loss: 0.318314
Step #72000	Loss: 0.302381
Step #76000	Loss: 0.315106
Step #80000	Loss: 0.306840
Step #84000	Loss: 0.317957
Step #88000	Loss: 0.305478
Step #92000	Loss: 0.326085
Step #96000	Loss: 0.323223
Step #100000	Loss: 0.309049
Step #104000	Loss: 0.293968
Step #108000	Loss: 0.309326
Step #112000	Loss: 0.302940
Step #116000	Loss: 0.303802
Step #120000	Loss: 0.311051
Step #124000	Loss: 0.304020
Step #128000	Loss: 0.319255
Step #132000	Loss: 0.319696
Step #136000	Loss: 0.324883
Step #140000	Loss: 0.317185
Step #144000	Loss: 0.289390
Step #148000	Loss: 0.293901
Step #152000	Loss: 0.317223
Step #156000	Loss: 0.290510
Step #160000	Loss: 0.305509
Step #164000	Loss: 0.300873
Step #168000	Loss: 0.310118
Step #172000	Loss: 0.306658
Step #176000	Loss: 0.287920
Step #180000	Loss: 0.294866
Step #184000	Loss: 0.297483
Step #188000	Loss: 0.330656
Step #192000	Loss: 0.320645
Step #196000	Loss: 0.314087
Step #200000	Loss: 0.308334
Step #204000	Loss: 0.292123
Step #208000	Loss: 0.286285
Step #212000	Loss: 0.310096
Step #216000	Loss: 0.325670
Step #220000	Loss: 0.306536
Code block 'train epoch=3' took: 1671976.47445 ms
train loss 0.30442729592323303
Code block 'val epoch=3' took: 92053.88286 ms
validation loss 0.8345743417739868
Step #0	Loss: 0.340421
Step #4000	Loss: 0.306954
Step #8000	Loss: 0.276474
Step #12000	Loss: 0.302735
Step #16000	Loss: 0.292772
Step #20000	Loss: 0.300985
Step #24000	Loss: 0.314683
Step #28000	Loss: 0.307981
Step #32000	Loss: 0.295243
Step #36000	Loss: 0.302751
Step #40000	Loss: 0.309290
Step #44000	Loss: 0.293416
Step #48000	Loss: 0.282641
Step #52000	Loss: 0.292730
Step #56000	Loss: 0.286769
Step #60000	Loss: 0.293883
Step #64000	Loss: 0.286759
Step #68000	Loss: 0.317875
Step #72000	Loss: 0.291299
Step #76000	Loss: 0.292373
Step #80000	Loss: 0.298642
Step #84000	Loss: 0.311233
Step #88000	Loss: 0.305058
Step #92000	Loss: 0.317374
Step #96000	Loss: 0.313881
Step #100000	Loss: 0.313321
Step #104000	Loss: 0.296822
Step #108000	Loss: 0.311275
Step #112000	Loss: 0.308323
Step #116000	Loss: 0.307855
Step #120000	Loss: 0.298757
Step #124000	Loss: 0.287568
Step #128000	Loss: 0.320339
Step #132000	Loss: 0.319366
Step #136000	Loss: 0.314488
Step #140000	Loss: 0.312251
Step #144000	Loss: 0.304053
Step #148000	Loss: 0.296317
Step #152000	Loss: 0.305272
Step #156000	Loss: 0.307034
Step #160000	Loss: 0.308614
Step #164000	Loss: 0.299758
Step #168000	Loss: 0.304028
Step #172000	Loss: 0.298785
Step #176000	Loss: 0.293837
Step #180000	Loss: 0.289153
Step #184000	Loss: 0.297618
Step #188000	Loss: 0.313207
Step #192000	Loss: 0.312844
Step #196000	Loss: 0.309359
Step #200000	Loss: 0.307027
Step #204000	Loss: 0.293294
Step #208000	Loss: 0.284546
Step #212000	Loss: 0.306726
Step #216000	Loss: 0.311595
Step #220000	Loss: 0.295613
Code block 'train epoch=4' took: 1676391.92019 ms
train loss 0.30173495411872864
Code block 'val epoch=4' took: 90990.86720 ms
validation loss 0.9866400957107544
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --cufile-thread-count 16 --batch-size 8192 --epochs 5'
[WARN  tini (1809637)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-22 06:20:41.241433: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-22 06:20:44.834314: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-22 06:21:13.359789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-22 06:25:02.634089: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-22 06:25:03.222453: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f2d22f012b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-22 06:25:03.222530: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-22 06:25:03.415221: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-22 06:25:04.649067: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-22 06:25:05.032889: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 1.055621
Step #4000	Loss: 0.381625
Step #8000	Loss: 0.380766
Failed to transform operator <nvtabular.ops.categorify.Categorify object at 0x7f348e92faf0>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1778, in _encode
    labels = codes.merge(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/dataframe.py", line 4004, in merge
    ).perform_merge()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/join/join.py", line 203, in perform_merge
    self.rhs._gather(gather_map=right_rows, **gather_kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
Step #12000	Loss: 0.346424
Code block 'train epoch=0' took: 139719.30399 ms
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1778, in _encode
    labels = codes.merge(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/dataframe.py", line 4004, in merge
    ).perform_merge()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/join/join.py", line 203, in perform_merge
    self.rhs._gather(gather_map=right_rows, **gather_kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home2/faculty/pwesolowski/praca-mgr/pipelines-repo/2_merlin/run_merlin.py", line 155, in <module>
    for batch, (examples, labels) in enumerate(train_tf_ds):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/tensorflow.py", line 97, in __next__
    converted_batch = self.convert_batch(super().__next__())
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 261, in __next__
    return self._get_next_batch()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 343, in _get_next_batch
    self._fetch_chunk()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 277, in _fetch_chunk
    raise chunks
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 791, in load_chunks
    self.chunk_logic(itr)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 759, in chunk_logic
    for chunks in self.batch(itr):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 745, in batch
    value = next(itr)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/io/dataframe_iter.py", line 44, in __iter__
    yield part.compute(scheduler="synchronous")
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/base.py", line 314, in compute
    (result,) = compute(self, traverse=False, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/base.py", line 599, in compute
    results = schedule(dsk, keys, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 557, in get_sync
    return get_async(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 500, in get_async
    for key, res_info, failed in queue_get(queue).result():
  File "/opt/conda/envs/rapids/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/opt/conda/envs/rapids/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 542, in submit
    fut.set_result(fn(*args, **kwargs))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 238, in batch_execute_tasks
    return [execute_task(*a) for a in it]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 238, in <listcomp>
    return [execute_task(*a) for a in it]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 229, in execute_task
    result = pack_exception(e, dumps)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 224, in execute_task
    result = _execute_task(task, data)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/optimization.py", line 990, in __call__
    return core.get(self.dsk, self.outkey, dict(zip(self.inkeys, args)))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 149, in get
    result = _execute_task(task, cache)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in <genexpr>
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/utils.py", line 72, in apply
    return func(*args, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 87, in transform
    transformed_data = self._execute_node(node, transformable, capture_dtypes, strict)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 101, in _execute_node
    upstream_outputs = self._run_upstream_transforms(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 114, in _run_upstream_transforms
    node_output = self._execute_node(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 107, in _execute_node
    transform_output = self._run_node_transform(node, transform_input, capture_dtypes, strict)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 227, in _run_node_transform
    raise exc
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --cufile-thread-count 16 --batch-size 8192 --epochs 5'
[WARN  tini (1815827)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-22 06:27:17.002354: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-22 06:27:20.538499: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-22 06:27:48.650614: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
Failed to transform operator <nvtabular.ops.categorify.Categorify object at 0x7f6cfc29fb20>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1780, in _encode
    ).sort_values("order")["labels"]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 2214, in sort_values
    out = self._gather(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-22 06:31:39.821412: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-22 06:31:40.429005: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f6966e0cfd0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-22 06:31:40.429073: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-22 06:31:40.575258: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-22 06:31:41.584938: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-22 06:31:41.922351: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.614145
Code block 'train epoch=0' took: 57718.64148 ms
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 332, in _get_next_batch
    batch = next(self._batch_itr)
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home2/faculty/pwesolowski/praca-mgr/pipelines-repo/2_merlin/run_merlin.py", line 155, in <module>
    for batch, (examples, labels) in enumerate(train_tf_ds):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/tensorflow.py", line 97, in __next__
    converted_batch = self.convert_batch(super().__next__())
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 261, in __next__
    return self._get_next_batch()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 344, in _get_next_batch
    batch = next(self._batch_itr)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 369, in make_tensors
    tensors_by_name = self._convert_df_to_tensors(gdf)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 520, in _convert_df_to_tensors
    tensors_by_name[column_name] = self._to_tensor(gdf_i[[column_name]])
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 450, in _to_tensor
    tensor = df_or_series.to_cupy()
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/single_column_frame.py", line 131, in to_cupy
    return super().to_cupy(dtype, copy, na_value).flatten()
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 533, in to_cupy
    return self._to_array(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 498, in _to_array
    matrix[:, i] = get_column_values_na(col)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 477, in get_column_values_na
    return get_column_values(col)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 534, in <lambda>
    (lambda col: col.values.copy())
  File "cupy/_core/core.pyx", line 590, in cupy._core.core._ndarray_base.copy
  File "cupy/_core/core.pyx", line 616, in cupy._core.core._ndarray_base.copy
  File "cupy/_core/core.pyx", line 575, in cupy._core.core._ndarray_base.astype
  File "cupy/_core/core.pyx", line 136, in cupy._core.core.ndarray.__new__
  File "cupy/_core/core.pyx", line 224, in cupy._core.core._ndarray_base._init
  File "cupy/cuda/memory.pyx", line 742, in cupy.cuda.memory.alloc
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/rmm/rmm.py", line 230, in rmm_cupy_allocator
    buf = librmm.device_buffer.DeviceBuffer(size=nbytes, stream=stream)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --cufile-thread-count 16 --batch-size 8192 --epochs 5'
[WARN  tini (1820877)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-22 06:32:28.746749: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-22 06:32:32.398977: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-22 06:33:00.988710: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
Failed to transform operator <nvtabular.ops.categorify.Categorify object at 0x7f4f0ad1bb20>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1780, in _encode
    ).sort_values("order")["labels"]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 2214, in sort_values
    out = self._gather(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-22 06:36:54.473265: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-22 06:36:54.985314: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f46bbd780a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-22 06:36:54.985401: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-22 06:36:55.144502: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-22 06:36:56.244307: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-22 06:36:56.595317: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.824800
Step #4000	Loss: 0.349905
Code block 'train epoch=0' took: 85011.43451 ms
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1780, in _encode
    ).sort_values("order")["labels"]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 2214, in sort_values
    out = self._gather(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home2/faculty/pwesolowski/praca-mgr/pipelines-repo/2_merlin/run_merlin.py", line 155, in <module>
    for batch, (examples, labels) in enumerate(train_tf_ds):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/tensorflow.py", line 97, in __next__
    converted_batch = self.convert_batch(super().__next__())
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 261, in __next__
    return self._get_next_batch()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 343, in _get_next_batch
    self._fetch_chunk()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 277, in _fetch_chunk
    raise chunks
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 791, in load_chunks
    self.chunk_logic(itr)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 759, in chunk_logic
    for chunks in self.batch(itr):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 745, in batch
    value = next(itr)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/io/dataframe_iter.py", line 44, in __iter__
    yield part.compute(scheduler="synchronous")
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/base.py", line 314, in compute
    (result,) = compute(self, traverse=False, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/base.py", line 599, in compute
    results = schedule(dsk, keys, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 557, in get_sync
    return get_async(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 500, in get_async
    for key, res_info, failed in queue_get(queue).result():
  File "/opt/conda/envs/rapids/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/opt/conda/envs/rapids/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 542, in submit
    fut.set_result(fn(*args, **kwargs))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 238, in batch_execute_tasks
    return [execute_task(*a) for a in it]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 238, in <listcomp>
    return [execute_task(*a) for a in it]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 229, in execute_task
    result = pack_exception(e, dumps)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 224, in execute_task
    result = _execute_task(task, data)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/optimization.py", line 990, in __call__
    return core.get(self.dsk, self.outkey, dict(zip(self.inkeys, args)))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 149, in get
    result = _execute_task(task, cache)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in <genexpr>
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/utils.py", line 72, in apply
    return func(*args, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 87, in transform
    transformed_data = self._execute_node(node, transformable, capture_dtypes, strict)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 101, in _execute_node
    upstream_outputs = self._run_upstream_transforms(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 114, in _run_upstream_transforms
    node_output = self._execute_node(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 107, in _execute_node
    transform_output = self._run_node_transform(node, transform_input, capture_dtypes, strict)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 227, in _run_node_transform
    raise exc
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
+ for CUFILE_THREAD_COUNT in 4 8 16 32 64
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --cufile-thread-count 32 --batch-size 8192 --epochs 5'
[WARN  tini (1826288)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-22 06:38:11.996523: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-22 06:38:16.054311: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-22 06:38:47.937286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-22 06:42:43.571636: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-22 06:42:44.140433: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f902f7067b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-22 06:42:44.140507: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-22 06:42:44.305740: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-22 06:42:45.462060: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-22 06:42:45.794347: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.582146
Step #4000	Loss: 0.295989
Step #8000	Loss: 0.327298
Step #12000	Loss: 0.303889
Step #16000	Loss: 0.336460
Step #20000	Loss: 0.334350
Step #24000	Loss: 0.419401
Step #28000	Loss: 0.407085
Step #32000	Loss: 0.431034
Step #36000	Loss: 0.379020
Step #40000	Loss: 0.320662
Step #44000	Loss: 0.356555
Step #48000	Loss: 0.324364
Step #52000	Loss: 0.327481
Step #56000	Loss: 0.348877
Step #60000	Loss: 0.393731
Step #64000	Loss: 0.312809
Step #68000	Loss: 0.330944
Step #72000	Loss: 0.385194
Step #76000	Loss: 0.360021
Step #80000	Loss: 0.381046
Step #84000	Loss: 0.370099
Step #88000	Loss: 0.360993
Step #92000	Loss: 0.371342
Step #96000	Loss: 0.318979
Step #100000	Loss: 0.446984
Step #104000	Loss: 0.324144
Step #108000	Loss: 0.333044
Step #112000	Loss: 0.326386
Step #116000	Loss: 0.377536
Step #120000	Loss: 0.332350
Step #124000	Loss: 0.339641
Step #128000	Loss: 0.383598
Step #132000	Loss: 0.333552
Step #136000	Loss: 0.428553
Step #140000	Loss: 0.411247
Step #144000	Loss: 0.431199
Step #148000	Loss: 0.305486
Step #152000	Loss: 0.422771
Step #156000	Loss: 0.326066
Step #160000	Loss: 0.334698
Step #164000	Loss: 0.312699
Step #168000	Loss: 0.436897
Step #172000	Loss: 0.409145
Step #176000	Loss: 0.316817
Step #180000	Loss: 0.353628
Step #184000	Loss: 0.316874
Step #188000	Loss: 0.460661
Step #192000	Loss: 0.428953
Step #196000	Loss: 0.467609
Step #200000	Loss: 0.345234
Step #204000	Loss: 0.300145
Step #208000	Loss: 0.341886
Step #212000	Loss: 0.334353
Step #216000	Loss: 0.386360
Step #220000	Loss: 0.429159
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 1711072.23202 ms
train loss 0.36036625504493713
Code block 'val epoch=0' took: 94416.65687 ms
validation loss 0.6281232237815857
Step #0	Loss: 0.700369
Step #4000	Loss: 0.296845
Step #8000	Loss: 0.307029
Step #12000	Loss: 0.307890
Step #16000	Loss: 0.313283
Step #20000	Loss: 0.308646
Step #24000	Loss: 0.364669
Step #28000	Loss: 0.345830
Step #32000	Loss: 0.367826
Step #36000	Loss: 0.339815
Step #40000	Loss: 0.326861
Step #44000	Loss: 0.316585
Step #48000	Loss: 0.312779
Step #52000	Loss: 0.316370
Step #56000	Loss: 0.314446
Step #60000	Loss: 0.331417
Step #64000	Loss: 0.305463
Step #68000	Loss: 0.320935
Step #72000	Loss: 0.333703
Step #76000	Loss: 0.313469
Step #80000	Loss: 0.325849
Step #84000	Loss: 0.330534
Step #88000	Loss: 0.318984
Step #92000	Loss: 0.337700
Step #96000	Loss: 0.306865
Step #100000	Loss: 0.357668
Step #104000	Loss: 0.320433
Step #108000	Loss: 0.325237
Step #112000	Loss: 0.306667
Step #116000	Loss: 0.316824
Step #120000	Loss: 0.304642
Step #124000	Loss: 0.288719
Step #128000	Loss: 0.323295
Step #132000	Loss: 0.311583
Step #136000	Loss: 0.354013
Step #140000	Loss: 0.359124
Step #144000	Loss: 0.356243
Step #148000	Loss: 0.303298
Step #152000	Loss: 0.346488
Step #156000	Loss: 0.316769
Step #160000	Loss: 0.319713
Step #164000	Loss: 0.301701
Step #168000	Loss: 0.344841
Step #172000	Loss: 0.350526
Step #176000	Loss: 0.291152
Step #180000	Loss: 0.311168
Step #184000	Loss: 0.302113
Step #188000	Loss: 0.380260
Step #192000	Loss: 0.346593
Step #196000	Loss: 0.369216
Step #200000	Loss: 0.321736
Step #204000	Loss: 0.280504
Step #208000	Loss: 0.311897
Step #212000	Loss: 0.317015
Step #216000	Loss: 0.336305
Step #220000	Loss: 0.350263
Code block 'train epoch=1' took: 1682400.90868 ms
train loss 0.326261430978775
Code block 'val epoch=1' took: 94824.46571 ms
validation loss 0.7075867056846619
Step #0	Loss: 0.924084
Step #4000	Loss: 0.283619
Step #8000	Loss: 0.300738
Step #12000	Loss: 0.308079
Step #16000	Loss: 0.306748
Step #20000	Loss: 0.307405
Step #24000	Loss: 0.330129
Step #28000	Loss: 0.325808
Step #32000	Loss: 0.320837
Step #36000	Loss: 0.312776
Step #40000	Loss: 0.321087
Step #44000	Loss: 0.297338
Step #48000	Loss: 0.290758
Step #52000	Loss: 0.304234
Step #56000	Loss: 0.314324
Step #60000	Loss: 0.299912
Step #64000	Loss: 0.294678
Step #68000	Loss: 0.310184
Step #72000	Loss: 0.314326
Step #76000	Loss: 0.305744
Step #80000	Loss: 0.300865
Step #84000	Loss: 0.326153
Step #88000	Loss: 0.310303
Step #92000	Loss: 0.325270
Step #96000	Loss: 0.295616
Step #100000	Loss: 0.323653
Step #104000	Loss: 0.315990
Step #108000	Loss: 0.312272
Step #112000	Loss: 0.300463
Step #116000	Loss: 0.323478
Step #120000	Loss: 0.297431
Step #124000	Loss: 0.294132
Step #128000	Loss: 0.328978
Step #132000	Loss: 0.313993
Step #136000	Loss: 0.338265
Step #140000	Loss: 0.332262
Step #144000	Loss: 0.321948
Step #148000	Loss: 0.296873
Step #152000	Loss: 0.333055
Step #156000	Loss: 0.303288
Step #160000	Loss: 0.303347
Step #164000	Loss: 0.298616
Step #168000	Loss: 0.325253
Step #172000	Loss: 0.320925
Step #176000	Loss: 0.267091
Step #180000	Loss: 0.304311
Step #184000	Loss: 0.290888
Step #188000	Loss: 0.336951
Step #192000	Loss: 0.345456
Step #196000	Loss: 0.324999
Step #200000	Loss: 0.313958
Step #204000	Loss: 0.269908
Step #208000	Loss: 0.314538
Step #212000	Loss: 0.318540
Step #216000	Loss: 0.320425
Step #220000	Loss: 0.316294
Code block 'train epoch=2' took: 1687198.89358 ms
train loss 0.3120937943458557
Code block 'val epoch=2' took: 94334.92252 ms
validation loss 0.7382641434669495
Step #0	Loss: 0.729269
Step #4000	Loss: 0.268677
Step #8000	Loss: 0.286549
Step #12000	Loss: 0.297339
Step #16000	Loss: 0.293925
Step #20000	Loss: 0.308610
Step #24000	Loss: 0.318942
Step #28000	Loss: 0.304698
Step #32000	Loss: 0.308645
Step #36000	Loss: 0.312567
Step #40000	Loss: 0.314664
Step #44000	Loss: 0.290442
Step #48000	Loss: 0.297801
Step #52000	Loss: 0.300405
Step #56000	Loss: 0.300416
Step #60000	Loss: 0.305559
Step #64000	Loss: 0.286368
Step #68000	Loss: 0.309089
Step #72000	Loss: 0.296831
Step #76000	Loss: 0.295667
Step #80000	Loss: 0.310806
Step #84000	Loss: 0.320319
Step #88000	Loss: 0.301697
Step #92000	Loss: 0.313594
Step #96000	Loss: 0.276677
Step #100000	Loss: 0.313972
Step #104000	Loss: 0.310686
Step #108000	Loss: 0.314920
Step #112000	Loss: 0.299303
Step #116000	Loss: 0.309628
Step #120000	Loss: 0.296915
Step #124000	Loss: 0.284367
Step #128000	Loss: 0.312911
Step #132000	Loss: 0.313745
Step #136000	Loss: 0.313672
Step #140000	Loss: 0.328215
Step #144000	Loss: 0.310103
Step #148000	Loss: 0.297920
Step #152000	Loss: 0.316231
Step #156000	Loss: 0.307495
Step #160000	Loss: 0.289212
Step #164000	Loss: 0.289557
Step #168000	Loss: 0.308412
Step #172000	Loss: 0.305901
Step #176000	Loss: 0.272102
Step #180000	Loss: 0.295738
Step #184000	Loss: 0.290973
Step #188000	Loss: 0.330712
Step #192000	Loss: 0.316303
Step #196000	Loss: 0.322456
Step #200000	Loss: 0.308037
Step #204000	Loss: 0.270465
Step #208000	Loss: 0.297289
Step #212000	Loss: 0.311598
Step #216000	Loss: 0.308718
Step #220000	Loss: 0.317498
Code block 'train epoch=3' took: 1685785.47489 ms
train loss 0.3060056269168854
Code block 'val epoch=3' took: 93880.80345 ms
validation loss 0.7929591536521912
Step #0	Loss: 0.673595
Step #4000	Loss: 0.281553
Step #8000	Loss: 0.277803
Step #12000	Loss: 0.302347
Step #16000	Loss: 0.294419
Step #20000	Loss: 0.301049
Step #24000	Loss: 0.316847
Step #28000	Loss: 0.302477
Step #32000	Loss: 0.302790
Step #36000	Loss: 0.304689
Step #40000	Loss: 0.313189
Step #44000	Loss: 0.285054
Step #48000	Loss: 0.285569
Step #52000	Loss: 0.306842
Step #56000	Loss: 0.289530
Step #60000	Loss: 0.314084
Step #64000	Loss: 0.291327
Step #68000	Loss: 0.311911
Step #72000	Loss: 0.302038
Step #76000	Loss: 0.299190
Step #80000	Loss: 0.294713
Step #84000	Loss: 0.323231
Step #88000	Loss: 0.307294
Step #92000	Loss: 0.323431
Step #96000	Loss: 0.285230
Step #100000	Loss: 0.309882
Step #104000	Loss: 0.302708
Step #108000	Loss: 0.317248
Step #112000	Loss: 0.301691
Step #116000	Loss: 0.297118
Step #120000	Loss: 0.293140
Step #124000	Loss: 0.289753
Step #128000	Loss: 0.317133
Step #132000	Loss: 0.315029
Step #136000	Loss: 0.306012
Step #140000	Loss: 0.320100
Step #144000	Loss: 0.309887
Step #148000	Loss: 0.299655
Step #152000	Loss: 0.310667
Step #156000	Loss: 0.296794
Step #160000	Loss: 0.269255
Step #164000	Loss: 0.299377
Step #168000	Loss: 0.309158
Step #172000	Loss: 0.308467
Step #176000	Loss: 0.279059
Step #180000	Loss: 0.291709
Step #184000	Loss: 0.294994
Step #188000	Loss: 0.319489
Step #192000	Loss: 0.321625
Step #196000	Loss: 0.311676
Step #200000	Loss: 0.309345
Step #204000	Loss: 0.267208
Step #208000	Loss: 0.298258
Step #212000	Loss: 0.291625
Step #216000	Loss: 0.318919
Step #220000	Loss: 0.307748
Code block 'train epoch=4' took: 1684584.02790 ms
train loss 0.303594172000885
Code block 'val epoch=4' took: 95300.39126 ms
validation loss 0.7448805570602417
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --cufile-thread-count 32 --batch-size 8192 --epochs 5'
[WARN  tini (1940397)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-22 09:11:25.316718: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-22 09:11:28.984832: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-22 09:11:56.053486: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-22 09:15:51.699570: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-22 09:15:52.163123: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f70d06e2fe0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-22 09:15:52.163190: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-22 09:15:52.305202: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-22 09:15:53.318106: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-22 09:15:53.622359: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.770248
Step #4000	Loss: 0.303159
Step #8000	Loss: 0.320297
Step #12000	Loss: 0.328332
Step #16000	Loss: 0.327318
Step #20000	Loss: 0.316680
Step #24000	Loss: 0.457850
Step #28000	Loss: 0.443549
Step #32000	Loss: 0.429471
Step #36000	Loss: 0.414476
Step #40000	Loss: 0.351207
Step #44000	Loss: 0.375247
Step #48000	Loss: 0.371419
Step #52000	Loss: 0.380524
Step #56000	Loss: 0.393005
Step #60000	Loss: 0.432104
Step #64000	Loss: 0.341359
Step #68000	Loss: 0.390694
Step #72000	Loss: 0.347350
Step #76000	Loss: 0.322413
Step #80000	Loss: 0.327378
Step #84000	Loss: 0.357435
Step #88000	Loss: 0.394026
Step #92000	Loss: 0.389158
Step #96000	Loss: 0.322155
Step #100000	Loss: 0.434101
Step #104000	Loss: 0.371455
Step #108000	Loss: 0.377940
Step #112000	Loss: 0.326639
Step #116000	Loss: 0.337258
Step #120000	Loss: 0.317476
Step #124000	Loss: 0.378627
Step #128000	Loss: 0.386633
Step #132000	Loss: 0.328189
Step #136000	Loss: 0.450387
Step #140000	Loss: 0.432606
Step #144000	Loss: 0.320821
Step #148000	Loss: 0.348794
Step #152000	Loss: 0.443566
Step #156000	Loss: 0.333199
Step #160000	Loss: 0.392758
Step #164000	Loss: 0.293334
Step #168000	Loss: 0.424224
Step #172000	Loss: 0.329637
Step #176000	Loss: 0.364034
Step #180000	Loss: 0.379481
Step #184000	Loss: 0.303173
Step #188000	Loss: 0.487402
Step #192000	Loss: 0.449353
Step #196000	Loss: 0.447915
Step #200000	Loss: 0.325662
Step #204000	Loss: 0.304638
Step #208000	Loss: 0.320930
Step #212000	Loss: 0.328330
Step #216000	Loss: 0.418851
Step #220000	Loss: 0.345167
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 1709021.74464 ms
train loss 0.35922446846961975
Code block 'val epoch=0' took: 94801.27538 ms
validation loss 0.6355280876159668
Step #0	Loss: 0.465730
Step #4000	Loss: 0.293507
Step #8000	Loss: 0.302865
Step #12000	Loss: 0.311501
Step #16000	Loss: 0.312970
Step #20000	Loss: 0.308515
Step #24000	Loss: 0.362997
Step #28000	Loss: 0.347579
Step #32000	Loss: 0.365268
Step #36000	Loss: 0.350897
Step #40000	Loss: 0.322116
Step #44000	Loss: 0.310335
Step #48000	Loss: 0.327878
Step #52000	Loss: 0.325661
Step #56000	Loss: 0.338979
Step #60000	Loss: 0.354284
Step #64000	Loss: 0.303347
Step #68000	Loss: 0.339363
Step #72000	Loss: 0.327468
Step #76000	Loss: 0.303973
Step #80000	Loss: 0.328975
Step #84000	Loss: 0.332138
Step #88000	Loss: 0.336067
Step #92000	Loss: 0.341716
Step #96000	Loss: 0.307092
Step #100000	Loss: 0.348266
Step #104000	Loss: 0.327013
Step #108000	Loss: 0.325716
Step #112000	Loss: 0.312355
Step #116000	Loss: 0.314329
Step #120000	Loss: 0.302450
Step #124000	Loss: 0.329886
Step #128000	Loss: 0.340663
Step #132000	Loss: 0.315946
Step #136000	Loss: 0.380602
Step #140000	Loss: 0.358059
Step #144000	Loss: 0.312280
Step #148000	Loss: 0.314960
Step #152000	Loss: 0.360729
Step #156000	Loss: 0.314373
Step #160000	Loss: 0.317967
Step #164000	Loss: 0.291992
Step #168000	Loss: 0.365290
Step #172000	Loss: 0.308729
Step #176000	Loss: 0.292148
Step #180000	Loss: 0.310949
Step #184000	Loss: 0.305280
Step #188000	Loss: 0.367119
Step #192000	Loss: 0.361476
Step #196000	Loss: 0.375239
Step #200000	Loss: 0.306676
Step #204000	Loss: 0.302058
Step #208000	Loss: 0.306493
Step #212000	Loss: 0.320455
Step #216000	Loss: 0.338739
Step #220000	Loss: 0.316662
Code block 'train epoch=1' took: 1688082.53293 ms
train loss 0.32343238592147827
Code block 'val epoch=1' took: 95285.14932 ms
validation loss 0.6600512266159058
Step #0	Loss: 0.352000
Step #4000	Loss: 0.289259
Step #8000	Loss: 0.296197
Step #12000	Loss: 0.305601
Step #16000	Loss: 0.306058
Step #20000	Loss: 0.317803
Step #24000	Loss: 0.318531
Step #28000	Loss: 0.335006
Step #32000	Loss: 0.309728
Step #36000	Loss: 0.318685
Step #40000	Loss: 0.313811
Step #44000	Loss: 0.290790
Step #48000	Loss: 0.310982
Step #52000	Loss: 0.315063
Step #56000	Loss: 0.308849
Step #60000	Loss: 0.333598
Step #64000	Loss: 0.283573
Step #68000	Loss: 0.322287
Step #72000	Loss: 0.316925
Step #76000	Loss: 0.299548
Step #80000	Loss: 0.314404
Step #84000	Loss: 0.311518
Step #88000	Loss: 0.316235
Step #92000	Loss: 0.320651
Step #96000	Loss: 0.301784
Step #100000	Loss: 0.335010
Step #104000	Loss: 0.321054
Step #108000	Loss: 0.326614
Step #112000	Loss: 0.303809
Step #116000	Loss: 0.301796
Step #120000	Loss: 0.305801
Step #124000	Loss: 0.304557
Step #128000	Loss: 0.321351
Step #132000	Loss: 0.300257
Step #136000	Loss: 0.343222
Step #140000	Loss: 0.333428
Step #144000	Loss: 0.302548
Step #148000	Loss: 0.302119
Step #152000	Loss: 0.335906
Step #156000	Loss: 0.307093
Step #160000	Loss: 0.302701
Step #164000	Loss: 0.289908
Step #168000	Loss: 0.330823
Step #172000	Loss: 0.302178
Step #176000	Loss: 0.287590
Step #180000	Loss: 0.300825
Step #184000	Loss: 0.294967
Step #188000	Loss: 0.340933
Step #192000	Loss: 0.324582
Step #196000	Loss: 0.327380
Step #200000	Loss: 0.304504
Step #204000	Loss: 0.298063
Step #208000	Loss: 0.301341
Step #212000	Loss: 0.310459
Step #216000	Loss: 0.321804
Step #220000	Loss: 0.318675
Code block 'train epoch=2' took: 1684769.63983 ms
train loss 0.31057122349739075
Code block 'val epoch=2' took: 95092.22257 ms
validation loss 0.6976907849311829
Step #0	Loss: 0.336544
Step #4000	Loss: 0.288696
Step #8000	Loss: 0.281601
Step #12000	Loss: 0.300324
Step #16000	Loss: 0.309926
Step #20000	Loss: 0.299722
Step #24000	Loss: 0.307508
Step #28000	Loss: 0.315139
Step #32000	Loss: 0.302183
Step #36000	Loss: 0.301910
Step #40000	Loss: 0.322577
Step #44000	Loss: 0.283078
Step #48000	Loss: 0.291020
Step #52000	Loss: 0.306563
Step #56000	Loss: 0.313483
Step #60000	Loss: 0.313951
Step #64000	Loss: 0.284068
Step #68000	Loss: 0.310588
Step #72000	Loss: 0.299620
Step #76000	Loss: 0.299540
Step #80000	Loss: 0.306813
Step #84000	Loss: 0.322476
Step #88000	Loss: 0.309186
Step #92000	Loss: 0.307671
Step #96000	Loss: 0.302924
Step #100000	Loss: 0.321580
Step #104000	Loss: 0.307063
Step #108000	Loss: 0.302308
Step #112000	Loss: 0.296163
Step #116000	Loss: 0.305473
Step #120000	Loss: 0.306926
Step #124000	Loss: 0.305876
Step #128000	Loss: 0.311036
Step #132000	Loss: 0.308664
Step #136000	Loss: 0.330218
Step #140000	Loss: 0.313466
Step #144000	Loss: 0.304948
Step #148000	Loss: 0.290016
Step #152000	Loss: 0.311280
Step #156000	Loss: 0.293947
Step #160000	Loss: 0.303591
Step #164000	Loss: 0.285793
Step #168000	Loss: 0.323761
Step #172000	Loss: 0.291494
Step #176000	Loss: 0.288095
Step #180000	Loss: 0.288506
Step #184000	Loss: 0.297919
Step #188000	Loss: 0.323090
Step #192000	Loss: 0.321857
Step #196000	Loss: 0.313058
Step #200000	Loss: 0.305768
Step #204000	Loss: 0.295297
Step #208000	Loss: 0.299371
Step #212000	Loss: 0.300596
Step #216000	Loss: 0.312055
Step #220000	Loss: 0.301940
Code block 'train epoch=3' took: 1685387.53617 ms
train loss 0.30500370264053345
Code block 'val epoch=3' took: 94507.05932 ms
validation loss 0.736977219581604
Step #0	Loss: 0.322157
Step #4000	Loss: 0.288651
Step #8000	Loss: 0.296099
Step #12000	Loss: 0.294585
Step #16000	Loss: 0.293620
Step #20000	Loss: 0.307961
Step #24000	Loss: 0.304190
Step #28000	Loss: 0.311822
Step #32000	Loss: 0.304253
Step #36000	Loss: 0.297671
Step #40000	Loss: 0.305873
Step #44000	Loss: 0.290765
Step #48000	Loss: 0.297759
Step #52000	Loss: 0.299557
Step #56000	Loss: 0.298350
Step #60000	Loss: 0.296600
Step #64000	Loss: 0.288676
Step #68000	Loss: 0.313446
Step #72000	Loss: 0.298742
Step #76000	Loss: 0.291863
Step #80000	Loss: 0.302031
Step #84000	Loss: 0.322751
Step #88000	Loss: 0.300564
Step #92000	Loss: 0.307055
Step #96000	Loss: 0.297296
Step #100000	Loss: 0.304347
Step #104000	Loss: 0.314590
Step #108000	Loss: 0.312098
Step #112000	Loss: 0.291283
Step #116000	Loss: 0.300236
Step #120000	Loss: 0.304864
Step #124000	Loss: 0.294027
Step #128000	Loss: 0.312772
Step #132000	Loss: 0.300840
Step #136000	Loss: 0.324402
Step #140000	Loss: 0.308007
Step #144000	Loss: 0.300195
Step #148000	Loss: 0.292030
Step #152000	Loss: 0.305291
Step #156000	Loss: 0.300549
Step #160000	Loss: 0.281609
Step #164000	Loss: 0.285793
Step #168000	Loss: 0.320388
Step #172000	Loss: 0.290069
Step #176000	Loss: 0.281896
Step #180000	Loss: 0.304631
Step #184000	Loss: 0.290299
Step #188000	Loss: 0.315992
Step #192000	Loss: 0.321541
Step #196000	Loss: 0.304322
Step #200000	Loss: 0.300085
Step #204000	Loss: 0.289583
Step #208000	Loss: 0.288063
Step #212000	Loss: 0.310246
Step #216000	Loss: 0.312407
Step #220000	Loss: 0.307569
Code block 'train epoch=4' took: 1684070.79322 ms
train loss 0.3025171458721161
Code block 'val epoch=4' took: 96000.94018 ms
validation loss 0.8053778409957886
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --cufile-thread-count 32 --batch-size 8192 --epochs 5'
[WARN  tini (2054500)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-22 11:44:37.355437: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-22 11:44:40.981163: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-22 11:45:09.636231: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-22 11:49:08.627465: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-22 11:49:09.211657: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fe9e6190b30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-22 11:49:09.211724: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-22 11:49:09.384470: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-22 11:49:10.495650: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-22 11:49:10.875077: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 1.230194
Step #4000	Loss: 0.304055
Step #8000	Loss: 0.371268
Step #12000	Loss: 0.317442
Step #16000	Loss: 0.340905
Step #20000	Loss: 0.311628
Step #24000	Loss: 0.369760
Step #28000	Loss: 0.327897
Step #32000	Loss: 0.434109
Step #36000	Loss: 0.349480
Step #40000	Loss: 0.326665
Step #44000	Loss: 0.293482
Step #48000	Loss: 0.385321
Step #52000	Loss: 0.329212
Step #56000	Loss: 0.311368
Step #60000	Loss: 0.424362
Step #64000	Loss: 0.336909
Step #68000	Loss: 0.331234
Step #72000	Loss: 0.344323
Step #76000	Loss: 0.343331
Step #80000	Loss: 0.322509
Step #84000	Loss: 0.431509
Step #88000	Loss: 0.341179
Step #92000	Loss: 0.407074
Step #96000	Loss: 0.325388
Step #100000	Loss: 0.363240
Step #104000	Loss: 0.321425
Step #108000	Loss: 0.362680
Step #112000	Loss: 0.332497
Step #116000	Loss: 0.312532
Step #120000	Loss: 0.339476
Step #124000	Loss: 0.337775
Step #128000	Loss: 0.340052
Step #132000	Loss: 0.345932
Step #136000	Loss: 0.442156
Step #140000	Loss: 0.376928
Step #144000	Loss: 0.451880
Step #148000	Loss: 0.346405
Step #152000	Loss: 0.466218
Step #156000	Loss: 0.381563
Step #160000	Loss: 0.347314
Step #164000	Loss: 0.332974
Step #168000	Loss: 0.441924
Step #172000	Loss: 0.333184
Step #176000	Loss: 0.342186
Step #180000	Loss: 0.331553
Step #184000	Loss: 0.322832
Step #188000	Loss: 0.474697
Step #192000	Loss: 0.377703
Step #196000	Loss: 0.349842
Step #200000	Loss: 0.313764
Step #204000	Loss: 0.366487
Step #208000	Loss: 0.415653
Step #212000	Loss: 0.332440
Step #216000	Loss: 0.426605
Step #220000	Loss: 0.327384
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 1706710.90043 ms
train loss 0.35911521315574646
Code block 'val epoch=0' took: 94575.35934 ms
validation loss 0.6407749056816101
Step #0	Loss: 0.498164
Step #4000	Loss: 0.300916
Step #8000	Loss: 0.317927
Step #12000	Loss: 0.328759
Step #16000	Loss: 0.322495
Step #20000	Loss: 0.311959
Step #24000	Loss: 0.333968
Step #28000	Loss: 0.306851
Step #32000	Loss: 0.343934
Step #36000	Loss: 0.319089
Step #40000	Loss: 0.310928
Step #44000	Loss: 0.283489
Step #48000	Loss: 0.337455
Step #52000	Loss: 0.318443
Step #56000	Loss: 0.317757
Step #60000	Loss: 0.343752
Step #64000	Loss: 0.299433
Step #68000	Loss: 0.312386
Step #72000	Loss: 0.313316
Step #76000	Loss: 0.316202
Step #80000	Loss: 0.320039
Step #84000	Loss: 0.369209
Step #88000	Loss: 0.308827
Step #92000	Loss: 0.342341
Step #96000	Loss: 0.302250
Step #100000	Loss: 0.314726
Step #104000	Loss: 0.302104
Step #108000	Loss: 0.331715
Step #112000	Loss: 0.310668
Step #116000	Loss: 0.305059
Step #120000	Loss: 0.293548
Step #124000	Loss: 0.300198
Step #128000	Loss: 0.316230
Step #132000	Loss: 0.324826
Step #136000	Loss: 0.372422
Step #140000	Loss: 0.318796
Step #144000	Loss: 0.357798
Step #148000	Loss: 0.323261
Step #152000	Loss: 0.363947
Step #156000	Loss: 0.330457
Step #160000	Loss: 0.321143
Step #164000	Loss: 0.304622
Step #168000	Loss: 0.350598
Step #172000	Loss: 0.304533
Step #176000	Loss: 0.294497
Step #180000	Loss: 0.305810
Step #184000	Loss: 0.313199
Step #188000	Loss: 0.375435
Step #192000	Loss: 0.326593
Step #196000	Loss: 0.319744
Step #200000	Loss: 0.315717
Step #204000	Loss: 0.308327
Step #208000	Loss: 0.339589
Step #212000	Loss: 0.311938
Step #216000	Loss: 0.359774
Step #220000	Loss: 0.309030
Code block 'train epoch=1' took: 1677464.19147 ms
train loss 0.32253915071487427
Code block 'val epoch=1' took: 94027.98935 ms
validation loss 0.7067251801490784
Step #0	Loss: 0.384407
Step #4000	Loss: 0.294205
Step #8000	Loss: 0.314237
Step #12000	Loss: 0.311685
Step #16000	Loss: 0.308575
Step #20000	Loss: 0.307569
Step #24000	Loss: 0.319281
Step #28000	Loss: 0.302366
Step #32000	Loss: 0.292318
Step #36000	Loss: 0.304467
Step #40000	Loss: 0.307730
Step #44000	Loss: 0.278923
Step #48000	Loss: 0.314382
Step #52000	Loss: 0.303470
Step #56000	Loss: 0.299130
Step #60000	Loss: 0.317742
Step #64000	Loss: 0.300200
Step #68000	Loss: 0.299934
Step #72000	Loss: 0.305663
Step #76000	Loss: 0.289560
Step #80000	Loss: 0.298994
Step #84000	Loss: 0.364574
Step #88000	Loss: 0.307333
Step #92000	Loss: 0.324367
Step #96000	Loss: 0.304662
Step #100000	Loss: 0.320425
Step #104000	Loss: 0.296236
Step #108000	Loss: 0.311028
Step #112000	Loss: 0.300715
Step #116000	Loss: 0.300557
Step #120000	Loss: 0.302153
Step #124000	Loss: 0.290089
Step #128000	Loss: 0.316317
Step #132000	Loss: 0.305960
Step #136000	Loss: 0.336131
Step #140000	Loss: 0.318914
Step #144000	Loss: 0.321659
Step #148000	Loss: 0.306892
Step #152000	Loss: 0.328611
Step #156000	Loss: 0.303817
Step #160000	Loss: 0.308862
Step #164000	Loss: 0.287191
Step #168000	Loss: 0.331749
Step #172000	Loss: 0.296493
Step #176000	Loss: 0.291833
Step #180000	Loss: 0.307395
Step #184000	Loss: 0.301841
Step #188000	Loss: 0.327392
Step #192000	Loss: 0.330028
Step #196000	Loss: 0.317786
Step #200000	Loss: 0.316899
Step #204000	Loss: 0.300781
Step #208000	Loss: 0.323073
Step #212000	Loss: 0.304251
Step #216000	Loss: 0.321595
Step #220000	Loss: 0.291123
Code block 'train epoch=2' took: 1673899.86000 ms
train loss 0.30991923809051514
Code block 'val epoch=2' took: 88142.17590 ms
validation loss 0.7420273423194885
Step #0	Loss: 0.352256
Step #4000	Loss: 0.288437
Step #8000	Loss: 0.312758
Step #12000	Loss: 0.319600
Step #16000	Loss: 0.313011
Step #20000	Loss: 0.302483
Step #24000	Loss: 0.311506
Step #28000	Loss: 0.295304
Step #32000	Loss: 0.303008
Step #36000	Loss: 0.304869
Step #40000	Loss: 0.303361
Step #44000	Loss: 0.273130
Step #48000	Loss: 0.299353
Step #52000	Loss: 0.300920
Step #56000	Loss: 0.303982
Step #60000	Loss: 0.299030
Step #64000	Loss: 0.292598
Step #68000	Loss: 0.309362
Step #72000	Loss: 0.303774
Step #76000	Loss: 0.295441
Step #80000	Loss: 0.304998
Step #84000	Loss: 0.336660
Step #88000	Loss: 0.310943
Step #92000	Loss: 0.315860
Step #96000	Loss: 0.310365
Step #100000	Loss: 0.301873
Step #104000	Loss: 0.294466
Step #108000	Loss: 0.297201
Step #112000	Loss: 0.300216
Step #116000	Loss: 0.297053
Step #120000	Loss: 0.288621
Step #124000	Loss: 0.294274
Step #128000	Loss: 0.305704
Step #132000	Loss: 0.306150
Step #136000	Loss: 0.325406
Step #140000	Loss: 0.321677
Step #144000	Loss: 0.308750
Step #148000	Loss: 0.299618
Step #152000	Loss: 0.323319
Step #156000	Loss: 0.307221
Step #160000	Loss: 0.320070
Step #164000	Loss: 0.288549
Step #168000	Loss: 0.318340
Step #172000	Loss: 0.296444
Step #176000	Loss: 0.280008
Step #180000	Loss: 0.297111
Step #184000	Loss: 0.290391
Step #188000	Loss: 0.319147
Step #192000	Loss: 0.317727
Step #196000	Loss: 0.323942
Step #200000	Loss: 0.303612
Step #204000	Loss: 0.290325
Step #208000	Loss: 0.323076
Step #212000	Loss: 0.289047
Step #216000	Loss: 0.319943
Step #220000	Loss: 0.295849
Code block 'train epoch=3' took: 1662604.89928 ms
train loss 0.30484282970428467
Code block 'val epoch=3' took: 88008.61734 ms
validation loss 0.7766454815864563
Step #0	Loss: 0.337853
Step #4000	Loss: 0.286682
Step #8000	Loss: 0.292597
Step #12000	Loss: 0.308086
Step #16000	Loss: 0.300100
Step #20000	Loss: 0.302917
Step #24000	Loss: 0.307443
Step #28000	Loss: 0.303292
Step #32000	Loss: 0.302746
Step #36000	Loss: 0.307760
Step #40000	Loss: 0.302630
Step #44000	Loss: 0.280442
Step #48000	Loss: 0.287379
Step #52000	Loss: 0.298002
Step #56000	Loss: 0.297417
Step #60000	Loss: 0.306601
Step #64000	Loss: 0.281179
Step #68000	Loss: 0.311531
Step #72000	Loss: 0.286978
Step #76000	Loss: 0.294092
Step #80000	Loss: 0.300295
Step #84000	Loss: 0.323724
Step #88000	Loss: 0.299088
Step #92000	Loss: 0.308684
Step #96000	Loss: 0.302468
Step #100000	Loss: 0.305292
Step #104000	Loss: 0.294068
Step #108000	Loss: 0.301713
Step #112000	Loss: 0.301338
Step #116000	Loss: 0.297599
Step #120000	Loss: 0.293660
Step #124000	Loss: 0.297716
Step #128000	Loss: 0.314808
Step #132000	Loss: 0.307450
Step #136000	Loss: 0.313621
Step #140000	Loss: 0.314751
Step #144000	Loss: 0.303386
Step #148000	Loss: 0.300214
Step #152000	Loss: 0.299742
Step #156000	Loss: 0.305182
Step #160000	Loss: 0.326600
Step #164000	Loss: 0.289724
Step #168000	Loss: 0.314097
Step #172000	Loss: 0.295710
Step #176000	Loss: 0.302664
Step #180000	Loss: 0.301870
Step #184000	Loss: 0.291754
Step #188000	Loss: 0.335747
Step #192000	Loss: 0.313597
Step #196000	Loss: 0.305436
Step #200000	Loss: 0.299076
Step #204000	Loss: 0.292538
Step #208000	Loss: 0.318960
Step #212000	Loss: 0.305682
Step #216000	Loss: 0.313920
Step #220000	Loss: 0.295017
Code block 'train epoch=4' took: 1663456.14508 ms
train loss 0.3022538721561432
Code block 'val epoch=4' took: 87868.48968 ms
validation loss 0.7727314829826355
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --cufile-thread-count 32 --batch-size 8192 --epochs 5'
[WARN  tini (2174381)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-22 14:16:20.658696: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-22 14:16:25.117732: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-22 14:16:53.822374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-22 14:20:39.469633: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-22 14:20:40.179516: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fc3713986d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-22 14:20:40.179595: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-22 14:20:40.385139: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-22 14:20:41.564338: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-22 14:20:41.947723: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 1.204742
Step #4000	Loss: 0.332591
Step #8000	Loss: 0.370330
Step #12000	Loss: 0.318372
Step #16000	Loss: 0.323945
Step #20000	Loss: 0.326546
Step #24000	Loss: 0.445475
Step #28000	Loss: 0.439506
Step #32000	Loss: 0.425122
Step #36000	Loss: 0.407859
Step #40000	Loss: 0.346730
Step #44000	Loss: 0.369735
Step #48000	Loss: 0.360176
Step #52000	Loss: 0.376632
Step #56000	Loss: 0.398608
Step #60000	Loss: 0.425491
Step #64000	Loss: 0.343113
Step #68000	Loss: 0.381029
Step #72000	Loss: 0.371418
Step #76000	Loss: 0.386894
Step #80000	Loss: 0.413617
Step #84000	Loss: 0.423414
Step #88000	Loss: 0.404412
Step #92000	Loss: 0.360335
Step #96000	Loss: 0.375722
Step #100000	Loss: 0.335227
Step #104000	Loss: 0.313506
Step #108000	Loss: 0.337410
Step #112000	Loss: 0.334302
Step #116000	Loss: 0.426167
Step #120000	Loss: 0.318981
Step #124000	Loss: 0.374728
Step #128000	Loss: 0.384285
Step #132000	Loss: 0.321979
Step #136000	Loss: 0.437778
Step #140000	Loss: 0.430920
Step #144000	Loss: 0.330272
Step #148000	Loss: 0.337060
Step #152000	Loss: 0.343637
Step #156000	Loss: 0.353966
Step #160000	Loss: 0.377008
Step #164000	Loss: 0.324885
Step #168000	Loss: 0.339873
Step #172000	Loss: 0.332155
Step #176000	Loss: 0.358973
Step #180000	Loss: 0.374446
Step #184000	Loss: 0.304178
Step #188000	Loss: 0.465014
Step #192000	Loss: 0.449835
Step #196000	Loss: 0.463135
Step #200000	Loss: 0.322463
Step #204000	Loss: 0.339698
Step #208000	Loss: 0.323105
Step #212000	Loss: 0.325394
Step #216000	Loss: 0.412624
Step #220000	Loss: 0.438158
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 1676253.99760 ms
train loss 0.3593507707118988
Code block 'val epoch=0' took: 85761.33541 ms
validation loss 0.6338471174240112
Step #0	Loss: 0.442922
Step #4000	Loss: 0.305398
Step #8000	Loss: 0.308105
Step #12000	Loss: 0.309322
Step #16000	Loss: 0.314584
Step #20000	Loss: 0.309051
Step #24000	Loss: 0.367677
Step #28000	Loss: 0.360031
Step #32000	Loss: 0.346093
Step #36000	Loss: 0.344277
Step #40000	Loss: 0.324565
Step #44000	Loss: 0.321511
Step #48000	Loss: 0.328785
Step #52000	Loss: 0.311249
Step #56000	Loss: 0.339357
Step #60000	Loss: 0.355666
Step #64000	Loss: 0.292388
Step #68000	Loss: 0.350274
Step #72000	Loss: 0.317179
Step #76000	Loss: 0.331471
Step #80000	Loss: 0.347244
Step #84000	Loss: 0.360638
Step #88000	Loss: 0.333744
Step #92000	Loss: 0.336877
Step #96000	Loss: 0.319241
Step #100000	Loss: 0.310392
Step #104000	Loss: 0.314349
Step #108000	Loss: 0.323155
Step #112000	Loss: 0.304753
Step #116000	Loss: 0.341782
Step #120000	Loss: 0.300091
Step #124000	Loss: 0.323108
Step #128000	Loss: 0.334985
Step #132000	Loss: 0.317670
Step #136000	Loss: 0.366199
Step #140000	Loss: 0.356474
Step #144000	Loss: 0.320407
Step #148000	Loss: 0.307279
Step #152000	Loss: 0.311323
Step #156000	Loss: 0.330457
Step #160000	Loss: 0.321527
Step #164000	Loss: 0.304319
Step #168000	Loss: 0.328293
Step #172000	Loss: 0.306561
Step #176000	Loss: 0.315704
Step #180000	Loss: 0.325243
Step #184000	Loss: 0.301808
Step #188000	Loss: 0.371307
Step #192000	Loss: 0.370492
Step #196000	Loss: 0.382649
Step #200000	Loss: 0.318618
Step #204000	Loss: 0.305988
Step #208000	Loss: 0.305938
Step #212000	Loss: 0.313394
Step #216000	Loss: 0.349584
Step #220000	Loss: 0.346763
Code block 'train epoch=1' took: 1648406.07666 ms
train loss 0.32375285029411316
Code block 'val epoch=1' took: 85438.52024 ms
validation loss 0.6427374482154846
Step #0	Loss: 0.332318
Step #4000	Loss: 0.296598
Step #8000	Loss: 0.297823
Step #12000	Loss: 0.307871
Step #16000	Loss: 0.299622
Step #20000	Loss: 0.302385
Step #24000	Loss: 0.335226
Step #28000	Loss: 0.332540
Step #32000	Loss: 0.315151
Step #36000	Loss: 0.320410
Step #40000	Loss: 0.306306
Step #44000	Loss: 0.279955
Step #48000	Loss: 0.299502
Step #52000	Loss: 0.309491
Step #56000	Loss: 0.315975
Step #60000	Loss: 0.331428
Step #64000	Loss: 0.290579
Step #68000	Loss: 0.318153
Step #72000	Loss: 0.307057
Step #76000	Loss: 0.311934
Step #80000	Loss: 0.320597
Step #84000	Loss: 0.341338
Step #88000	Loss: 0.308330
Step #92000	Loss: 0.317439
Step #96000	Loss: 0.312343
Step #100000	Loss: 0.314677
Step #104000	Loss: 0.299146
Step #108000	Loss: 0.315303
Step #112000	Loss: 0.305008
Step #116000	Loss: 0.315735
Step #120000	Loss: 0.300996
Step #124000	Loss: 0.305408
Step #128000	Loss: 0.321137
Step #132000	Loss: 0.306467
Step #136000	Loss: 0.349184
Step #140000	Loss: 0.340332
Step #144000	Loss: 0.299106
Step #148000	Loss: 0.305506
Step #152000	Loss: 0.308879
Step #156000	Loss: 0.315251
Step #160000	Loss: 0.301456
Step #164000	Loss: 0.293772
Step #168000	Loss: 0.311884
Step #172000	Loss: 0.301403
Step #176000	Loss: 0.283614
Step #180000	Loss: 0.310881
Step #184000	Loss: 0.300984
Step #188000	Loss: 0.339537
Step #192000	Loss: 0.340806
Step #196000	Loss: 0.340601
Step #200000	Loss: 0.308800
Step #204000	Loss: 0.293342
Step #208000	Loss: 0.295643
Step #212000	Loss: 0.298946
Step #216000	Loss: 0.337893
Step #220000	Loss: 0.336001
Code block 'train epoch=2' took: 1647955.94656 ms
train loss 0.3109566271305084
Code block 'val epoch=2' took: 85087.54347 ms
validation loss 0.666836678981781
Step #0	Loss: 0.325694
Step #4000	Loss: 0.284508
Step #8000	Loss: 0.294808
Step #12000	Loss: 0.310890
Step #16000	Loss: 0.292240
Step #20000	Loss: 0.306452
Step #24000	Loss: 0.305409
Step #28000	Loss: 0.307667
Step #32000	Loss: 0.299555
Step #36000	Loss: 0.318426
Step #40000	Loss: 0.312678
Step #44000	Loss: 0.279164
Step #48000	Loss: 0.296526
Step #52000	Loss: 0.285138
Step #56000	Loss: 0.298304
Step #60000	Loss: 0.307884
Step #64000	Loss: 0.293618
Step #68000	Loss: 0.307924
Step #72000	Loss: 0.294879
Step #76000	Loss: 0.310006
Step #80000	Loss: 0.304694
Step #84000	Loss: 0.330262
Step #88000	Loss: 0.309132
Step #92000	Loss: 0.310240
Step #96000	Loss: 0.313977
Step #100000	Loss: 0.318035
Step #104000	Loss: 0.301494
Step #108000	Loss: 0.311449
Step #112000	Loss: 0.299234
Step #116000	Loss: 0.306761
Step #120000	Loss: 0.297602
Step #124000	Loss: 0.297059
Step #128000	Loss: 0.316872
Step #132000	Loss: 0.303512
Step #136000	Loss: 0.335547
Step #140000	Loss: 0.328175
Step #144000	Loss: 0.299314
Step #148000	Loss: 0.299688
Step #152000	Loss: 0.301553
Step #156000	Loss: 0.304833
Step #160000	Loss: 0.290918
Step #164000	Loss: 0.311867
Step #168000	Loss: 0.298282
Step #172000	Loss: 0.299009
Step #176000	Loss: 0.290483
Step #180000	Loss: 0.297259
Step #184000	Loss: 0.302057
Step #188000	Loss: 0.316580
Step #192000	Loss: 0.327907
Step #196000	Loss: 0.318539
Step #200000	Loss: 0.302954
Step #204000	Loss: 0.275806
Step #208000	Loss: 0.292507
Step #212000	Loss: 0.313052
Step #216000	Loss: 0.308625
Step #220000	Loss: 0.298636
Code block 'train epoch=3' took: 1648216.10091 ms
train loss 0.30535218119621277
Code block 'val epoch=3' took: 84925.49814 ms
validation loss 0.6953606605529785
Step #0	Loss: 0.316484
Step #4000	Loss: 0.286881
Step #8000	Loss: 0.292684
Step #12000	Loss: 0.289119
Step #16000	Loss: 0.302806
Step #20000	Loss: 0.291899
Step #24000	Loss: 0.315658
Step #28000	Loss: 0.300377
Step #32000	Loss: 0.298717
Step #36000	Loss: 0.299537
Step #40000	Loss: 0.313884
Step #44000	Loss: 0.285537
Step #48000	Loss: 0.282293
Step #52000	Loss: 0.303138
Step #56000	Loss: 0.304310
Step #60000	Loss: 0.294796
Step #64000	Loss: 0.294078
Step #68000	Loss: 0.309543
Step #72000	Loss: 0.296140
Step #76000	Loss: 0.293581
Step #80000	Loss: 0.299913
Step #84000	Loss: 0.327658
Step #88000	Loss: 0.293411
Step #92000	Loss: 0.320542
Step #96000	Loss: 0.302978
Step #100000	Loss: 0.304353
Step #104000	Loss: 0.305967
Step #108000	Loss: 0.312560
Step #112000	Loss: 0.295044
Step #116000	Loss: 0.311325
Step #120000	Loss: 0.299459
Step #124000	Loss: 0.292248
Step #128000	Loss: 0.303786
Step #132000	Loss: 0.296628
Step #136000	Loss: 0.327676
Step #140000	Loss: 0.317219
Step #144000	Loss: 0.303356
Step #148000	Loss: 0.295073
Step #152000	Loss: 0.308171
Step #156000	Loss: 0.294133
Step #160000	Loss: 0.287455
Step #164000	Loss: 0.302351
Step #168000	Loss: 0.305153
Step #172000	Loss: 0.285741
Step #176000	Loss: 0.290640
Step #180000	Loss: 0.295760
Step #184000	Loss: 0.295333
Step #188000	Loss: 0.321766
Step #192000	Loss: 0.321679
Step #196000	Loss: 0.312814
Step #200000	Loss: 0.300970
Step #204000	Loss: 0.273271
Step #208000	Loss: 0.288320
Step #212000	Loss: 0.304238
Step #216000	Loss: 0.309211
Step #220000	Loss: 0.303434
Code block 'train epoch=4' took: 1648818.49520 ms
train loss 0.3026520013809204
Code block 'val epoch=4' took: 84171.21438 ms
validation loss 0.720698893070221
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --cufile-thread-count 32 --batch-size 8192 --epochs 5'
[WARN  tini (2291228)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-22 16:45:31.557957: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-22 16:45:35.175898: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-22 16:46:02.084459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-22 16:49:50.031762: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-22 16:49:50.580938: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f8b534a0420 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-22 16:49:50.580999: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-22 16:49:50.791277: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-22 16:49:52.117556: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-22 16:49:52.489772: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.527128
Step #4000	Loss: 0.321916
Step #8000	Loss: 0.331864
Step #12000	Loss: 0.347923
Step #16000	Loss: 0.364119
Step #20000	Loss: 0.350721
Step #24000	Loss: 0.354346
Step #28000	Loss: 0.359706
Step #32000	Loss: 0.337649
Step #36000	Loss: 0.341950
Step #40000	Loss: 0.324091
Step #44000	Loss: 0.299336
Step #48000	Loss: 0.312971
Step #52000	Loss: 0.325956
Step #56000	Loss: 0.338081
Step #60000	Loss: 0.346036
Step #64000	Loss: 0.316929
Step #68000	Loss: 0.340191
Step #72000	Loss: 0.390774
Step #76000	Loss: 0.326662
Step #80000	Loss: 0.344159
Step #84000	Loss: 0.335906
Step #88000	Loss: 0.416803
Step #92000	Loss: 0.417991
Step #96000	Loss: 0.397871
Step #100000	Loss: 0.353718
Step #104000	Loss: 0.352462
Step #108000	Loss: 0.362295
Step #112000	Loss: 0.308030
Step #116000	Loss: 0.434845
Step #120000	Loss: 0.328449
Step #124000	Loss: 0.337190
Step #128000	Loss: 0.334792
Step #132000	Loss: 0.328340
Step #136000	Loss: 0.454333
Step #140000	Loss: 0.419322
Step #144000	Loss: 0.376891
Step #148000	Loss: 0.358583
Step #152000	Loss: 0.318329
Step #156000	Loss: 0.336849
Step #160000	Loss: 0.416405
Step #164000	Loss: 0.327387
Step #168000	Loss: 0.328710
Step #172000	Loss: 0.382089
Step #176000	Loss: 0.414852
Step #180000	Loss: 0.371044
Step #184000	Loss: 0.342136
Step #188000	Loss: 0.351742
Step #192000	Loss: 0.355486
Step #196000	Loss: 0.363744
Step #200000	Loss: 0.369330
Step #204000	Loss: 0.335770
Step #208000	Loss: 0.361470
Step #212000	Loss: 0.345754
Step #216000	Loss: 0.348662
Step #220000	Loss: 0.421288
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 1674262.37042 ms
train loss 0.35935813188552856
Code block 'val epoch=0' took: 84459.90312 ms
validation loss 0.6091486215591431
Step #0	Loss: 0.424501
Step #4000	Loss: 0.303102
Step #8000	Loss: 0.314079
Step #12000	Loss: 0.309193
Step #16000	Loss: 0.321105
Step #20000	Loss: 0.328431
Step #24000	Loss: 0.317537
Step #28000	Loss: 0.314314
Step #32000	Loss: 0.302844
Step #36000	Loss: 0.319041
Step #40000	Loss: 0.311068
Step #44000	Loss: 0.281572
Step #48000	Loss: 0.291679
Step #52000	Loss: 0.311326
Step #56000	Loss: 0.314744
Step #60000	Loss: 0.308122
Step #64000	Loss: 0.298692
Step #68000	Loss: 0.321826
Step #72000	Loss: 0.330732
Step #76000	Loss: 0.301350
Step #80000	Loss: 0.316516
Step #84000	Loss: 0.332970
Step #88000	Loss: 0.336109
Step #92000	Loss: 0.356789
Step #96000	Loss: 0.347358
Step #100000	Loss: 0.324763
Step #104000	Loss: 0.318058
Step #108000	Loss: 0.327134
Step #112000	Loss: 0.306921
Step #116000	Loss: 0.341788
Step #120000	Loss: 0.311256
Step #124000	Loss: 0.313472
Step #128000	Loss: 0.327507
Step #132000	Loss: 0.336080
Step #136000	Loss: 0.369297
Step #140000	Loss: 0.342164
Step #144000	Loss: 0.332368
Step #148000	Loss: 0.318874
Step #152000	Loss: 0.304340
Step #156000	Loss: 0.317997
Step #160000	Loss: 0.323347
Step #164000	Loss: 0.302104
Step #168000	Loss: 0.320149
Step #172000	Loss: 0.316946
Step #176000	Loss: 0.335182
Step #180000	Loss: 0.316879
Step #184000	Loss: 0.310274
Step #188000	Loss: 0.341836
Step #192000	Loss: 0.327537
Step #196000	Loss: 0.318328
Step #200000	Loss: 0.319350
Step #204000	Loss: 0.296678
Step #208000	Loss: 0.320583
Step #212000	Loss: 0.320040
Step #216000	Loss: 0.316252
Step #220000	Loss: 0.351094
Code block 'train epoch=1' took: 1646153.04266 ms
train loss 0.3223201334476471
Code block 'val epoch=1' took: 84292.83370 ms
validation loss 0.6947321891784668
Step #0	Loss: 0.337669
Step #4000	Loss: 0.295049
Step #8000	Loss: 0.301168
Step #12000	Loss: 0.301541
Step #16000	Loss: 0.306261
Step #20000	Loss: 0.321286
Step #24000	Loss: 0.313441
Step #28000	Loss: 0.309022
Step #32000	Loss: 0.301098
Step #36000	Loss: 0.312211
Step #40000	Loss: 0.303297
Step #44000	Loss: 0.272435
Step #48000	Loss: 0.298030
Step #52000	Loss: 0.314123
Step #56000	Loss: 0.305821
Step #60000	Loss: 0.297996
Step #64000	Loss: 0.289664
Step #68000	Loss: 0.313496
Step #72000	Loss: 0.314658
Step #76000	Loss: 0.291696
Step #80000	Loss: 0.312819
Step #84000	Loss: 0.308719
Step #88000	Loss: 0.317747
Step #92000	Loss: 0.324311
Step #96000	Loss: 0.325478
Step #100000	Loss: 0.311469
Step #104000	Loss: 0.310687
Step #108000	Loss: 0.320513
Step #112000	Loss: 0.288189
Step #116000	Loss: 0.322118
Step #120000	Loss: 0.311987
Step #124000	Loss: 0.296450
Step #128000	Loss: 0.316296
Step #132000	Loss: 0.319721
Step #136000	Loss: 0.331510
Step #140000	Loss: 0.307619
Step #144000	Loss: 0.317473
Step #148000	Loss: 0.303519
Step #152000	Loss: 0.305582
Step #156000	Loss: 0.312384
Step #160000	Loss: 0.308526
Step #164000	Loss: 0.307673
Step #168000	Loss: 0.320276
Step #172000	Loss: 0.308821
Step #176000	Loss: 0.310457
Step #180000	Loss: 0.302074
Step #184000	Loss: 0.305324
Step #188000	Loss: 0.319781
Step #192000	Loss: 0.332170
Step #196000	Loss: 0.323443
Step #200000	Loss: 0.317167
Step #204000	Loss: 0.280682
Step #208000	Loss: 0.315400
Step #212000	Loss: 0.311152
Step #216000	Loss: 0.305710
Step #220000	Loss: 0.323922
Code block 'train epoch=2' took: 1644845.57894 ms
train loss 0.3098907172679901
Code block 'val epoch=2' took: 84281.09542 ms
validation loss 0.729344367980957
Step #0	Loss: 0.317927
Step #4000	Loss: 0.295551
Step #8000	Loss: 0.298288
Step #12000	Loss: 0.309173
Step #16000	Loss: 0.299427
Step #20000	Loss: 0.302611
Step #24000	Loss: 0.298214
Step #28000	Loss: 0.310353
Step #32000	Loss: 0.295266
Step #36000	Loss: 0.298039
Step #40000	Loss: 0.302879
Step #44000	Loss: 0.281200
Step #48000	Loss: 0.295773
Step #52000	Loss: 0.299424
Step #56000	Loss: 0.300447
Step #60000	Loss: 0.297744
Step #64000	Loss: 0.286049
Step #68000	Loss: 0.316333
Step #72000	Loss: 0.298137
Step #76000	Loss: 0.308445
Step #80000	Loss: 0.293486
Step #84000	Loss: 0.309254
Step #88000	Loss: 0.311756
Step #92000	Loss: 0.305950
Step #96000	Loss: 0.320664
Step #100000	Loss: 0.296423
Step #104000	Loss: 0.305034
Step #108000	Loss: 0.321324
Step #112000	Loss: 0.290942
Step #116000	Loss: 0.299182
Step #120000	Loss: 0.291266
Step #124000	Loss: 0.297350
Step #128000	Loss: 0.308047
Step #132000	Loss: 0.305407
Step #136000	Loss: 0.327962
Step #140000	Loss: 0.291342
Step #144000	Loss: 0.299435
Step #148000	Loss: 0.301443
Step #152000	Loss: 0.302024
Step #156000	Loss: 0.299316
Step #160000	Loss: 0.299400
Step #164000	Loss: 0.307499
Step #168000	Loss: 0.307401
Step #172000	Loss: 0.297309
Step #176000	Loss: 0.296093
Step #180000	Loss: 0.289055
Step #184000	Loss: 0.300716
Step #188000	Loss: 0.312481
Step #192000	Loss: 0.309587
Step #196000	Loss: 0.309123
Step #200000	Loss: 0.303504
Step #204000	Loss: 0.290981
Step #208000	Loss: 0.300663
Step #212000	Loss: 0.303250
Step #216000	Loss: 0.310655
Step #220000	Loss: 0.309114
Code block 'train epoch=3' took: 1645889.94499 ms
train loss 0.30487632751464844
Code block 'val epoch=3' took: 84659.18318 ms
validation loss 0.7606406211853027
Step #0	Loss: 0.315881
Step #4000	Loss: 0.291931
Step #8000	Loss: 0.291607
Step #12000	Loss: 0.297543
Step #16000	Loss: 0.302780
Step #20000	Loss: 0.289720
Step #24000	Loss: 0.314700
Step #28000	Loss: 0.301891
Step #32000	Loss: 0.291855
Step #36000	Loss: 0.295605
Step #40000	Loss: 0.313271
Step #44000	Loss: 0.289370
Step #48000	Loss: 0.290942
Step #52000	Loss: 0.298242
Step #56000	Loss: 0.306085
Step #60000	Loss: 0.288350
Step #64000	Loss: 0.288197
Step #68000	Loss: 0.302226
Step #72000	Loss: 0.297856
Step #76000	Loss: 0.310191
Step #80000	Loss: 0.293960
Step #84000	Loss: 0.314826
Step #88000	Loss: 0.302675
Step #92000	Loss: 0.306755
Step #96000	Loss: 0.303642
Step #100000	Loss: 0.298777
Step #104000	Loss: 0.307821
Step #108000	Loss: 0.301519
Step #112000	Loss: 0.295354
Step #116000	Loss: 0.309045
Step #120000	Loss: 0.300948
Step #124000	Loss: 0.298281
Step #128000	Loss: 0.304897
Step #132000	Loss: 0.316489
Step #136000	Loss: 0.319448
Step #140000	Loss: 0.298108
Step #144000	Loss: 0.294582
Step #148000	Loss: 0.301536
Step #152000	Loss: 0.298770
Step #156000	Loss: 0.293797
Step #160000	Loss: 0.296664
Step #164000	Loss: 0.293062
Step #168000	Loss: 0.313395
Step #172000	Loss: 0.300142
Step #176000	Loss: 0.299136
Step #180000	Loss: 0.284706
Step #184000	Loss: 0.299861
Step #188000	Loss: 0.318475
Step #192000	Loss: 0.309327
Step #196000	Loss: 0.299094
Step #200000	Loss: 0.299915
Step #204000	Loss: 0.280801
Step #208000	Loss: 0.310819
Step #212000	Loss: 0.300160
Step #216000	Loss: 0.296762
Step #220000	Loss: 0.300449
Code block 'train epoch=4' took: 1645789.93175 ms
train loss 0.30255556106567383
Code block 'val epoch=4' took: 84688.52909 ms
validation loss 0.7705589532852173
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --cufile-thread-count 32 --batch-size 8192 --epochs 5'
[WARN  tini (2408240)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-22 19:14:24.539429: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-22 19:14:28.107992: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-22 19:14:55.913197: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-22 19:18:45.215237: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-22 19:18:45.966654: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fe43f12b0a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-22 19:18:45.966727: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-22 19:18:46.132093: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-22 19:18:47.302093: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-22 19:18:47.648714: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 2.614012
Step #4000	Loss: 0.402380
Step #8000	Loss: 0.310588
Step #12000	Loss: 0.337928
Step #16000	Loss: 0.330493
Step #20000	Loss: 0.368280
Step #24000	Loss: 0.444625
Step #28000	Loss: 0.335538
Step #32000	Loss: 0.353742
Step #36000	Loss: 0.442183
Step #40000	Loss: 0.329052
Step #44000	Loss: 0.421229
Step #48000	Loss: 0.313073
Step #52000	Loss: 0.345676
Step #56000	Loss: 0.418154
Step #60000	Loss: 0.320869
Step #64000	Loss: 0.346548
Step #68000	Loss: 0.423301
Step #72000	Loss: 0.392520
Step #76000	Loss: 0.439922
Step #80000	Loss: 0.323803
Step #84000	Loss: 0.358037
Step #88000	Loss: 0.369450
Step #92000	Loss: 0.421647
Step #96000	Loss: 0.382420
Step #100000	Loss: 0.379723
Step #104000	Loss: 0.325623
Step #108000	Loss: 0.333779
Step #112000	Loss: 0.334837
Step #116000	Loss: 0.341331
Step #120000	Loss: 0.354315
Step #124000	Loss: 0.336377
Step #128000	Loss: 0.351410
Step #132000	Loss: 0.375748
Step #136000	Loss: 0.447136
Step #140000	Loss: 0.341552
Step #144000	Loss: 0.350389
Step #148000	Loss: 0.376859
Step #152000	Loss: 0.423595
Step #156000	Loss: 0.342057
Step #160000	Loss: 0.344943
Step #164000	Loss: 0.319684
Step #168000	Loss: 0.354894
Step #172000	Loss: 0.363065
Step #176000	Loss: 0.330206
Step #180000	Loss: 0.352833
Step #184000	Loss: 0.352795
Step #188000	Loss: 0.472714
Step #192000	Loss: 0.342383
Step #196000	Loss: 0.386763
Step #200000	Loss: 0.343889
Step #204000	Loss: 0.334829
Step #208000	Loss: 0.322330
Step #212000	Loss: 0.343943
Step #216000	Loss: 0.363189
Step #220000	Loss: 0.346294
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 1679904.06466 ms
train loss 0.35952961444854736
Code block 'val epoch=0' took: 84661.87197 ms
validation loss 0.5914487242698669
Step #0	Loss: 0.481129
Step #4000	Loss: 0.330289
Step #8000	Loss: 0.292257
Step #12000	Loss: 0.310427
Step #16000	Loss: 0.310361
Step #20000	Loss: 0.323460
Step #24000	Loss: 0.356513
Step #28000	Loss: 0.309883
Step #32000	Loss: 0.307709
Step #36000	Loss: 0.360519
Step #40000	Loss: 0.323693
Step #44000	Loss: 0.322219
Step #48000	Loss: 0.297275
Step #52000	Loss: 0.307978
Step #56000	Loss: 0.341560
Step #60000	Loss: 0.304107
Step #64000	Loss: 0.299968
Step #68000	Loss: 0.351362
Step #72000	Loss: 0.335351
Step #76000	Loss: 0.341600
Step #80000	Loss: 0.304976
Step #84000	Loss: 0.331983
Step #88000	Loss: 0.324779
Step #92000	Loss: 0.349168
Step #96000	Loss: 0.330339
Step #100000	Loss: 0.331232
Step #104000	Loss: 0.310065
Step #108000	Loss: 0.322121
Step #112000	Loss: 0.323199
Step #116000	Loss: 0.309426
Step #120000	Loss: 0.314924
Step #124000	Loss: 0.305856
Step #128000	Loss: 0.320657
Step #132000	Loss: 0.323718
Step #136000	Loss: 0.362409
Step #140000	Loss: 0.330359
Step #144000	Loss: 0.311182
Step #148000	Loss: 0.316888
Step #152000	Loss: 0.336991
Step #156000	Loss: 0.323354
Step #160000	Loss: 0.303936
Step #164000	Loss: 0.298511
Step #168000	Loss: 0.321625
Step #172000	Loss: 0.304906
Step #176000	Loss: 0.296730
Step #180000	Loss: 0.305108
Step #184000	Loss: 0.312596
Step #188000	Loss: 0.347078
Step #192000	Loss: 0.325163
Step #196000	Loss: 0.331229
Step #200000	Loss: 0.322526
Step #204000	Loss: 0.313940
Step #208000	Loss: 0.306549
Step #212000	Loss: 0.308822
Step #216000	Loss: 0.329488
Step #220000	Loss: 0.312969
Code block 'train epoch=1' took: 1653027.72893 ms
train loss 0.3218116760253906
Code block 'val epoch=1' took: 84116.90835 ms
validation loss 0.6425576210021973
Step #0	Loss: 0.389008
Step #4000	Loss: 0.308001
Step #8000	Loss: 0.294988
Step #12000	Loss: 0.316871
Step #16000	Loss: 0.293602
Step #20000	Loss: 0.307867
Step #24000	Loss: 0.312515
Step #28000	Loss: 0.301284
Step #32000	Loss: 0.309588
Step #36000	Loss: 0.326639
Step #40000	Loss: 0.296918
Step #44000	Loss: 0.305902
Step #48000	Loss: 0.295505
Step #52000	Loss: 0.307422
Step #56000	Loss: 0.314006
Step #60000	Loss: 0.311184
Step #64000	Loss: 0.298314
Step #68000	Loss: 0.335078
Step #72000	Loss: 0.311322
Step #76000	Loss: 0.307630
Step #80000	Loss: 0.300879
Step #84000	Loss: 0.314156
Step #88000	Loss: 0.320707
Step #92000	Loss: 0.315778
Step #96000	Loss: 0.318339
Step #100000	Loss: 0.316338
Step #104000	Loss: 0.299289
Step #108000	Loss: 0.316210
Step #112000	Loss: 0.310483
Step #116000	Loss: 0.293324
Step #120000	Loss: 0.319204
Step #124000	Loss: 0.299279
Step #128000	Loss: 0.324398
Step #132000	Loss: 0.319256
Step #136000	Loss: 0.328638
Step #140000	Loss: 0.322418
Step #144000	Loss: 0.293073
Step #148000	Loss: 0.304967
Step #152000	Loss: 0.324063
Step #156000	Loss: 0.311440
Step #160000	Loss: 0.314612
Step #164000	Loss: 0.296878
Step #168000	Loss: 0.313716
Step #172000	Loss: 0.297428
Step #176000	Loss: 0.294951
Step #180000	Loss: 0.297256
Step #184000	Loss: 0.321269
Step #188000	Loss: 0.334659
Step #192000	Loss: 0.325128
Step #196000	Loss: 0.313549
Step #200000	Loss: 0.310250
Step #204000	Loss: 0.298689
Step #208000	Loss: 0.294272
Step #212000	Loss: 0.319900
Step #216000	Loss: 0.322451
Step #220000	Loss: 0.316406
Code block 'train epoch=2' took: 1654827.06343 ms
train loss 0.3098016083240509
Code block 'val epoch=2' took: 84021.03754 ms
validation loss 0.6855970621109009
Step #0	Loss: 0.364030
Step #4000	Loss: 0.284034
Step #8000	Loss: 0.300750
Step #12000	Loss: 0.305093
Step #16000	Loss: 0.304275
Step #20000	Loss: 0.307237
Step #24000	Loss: 0.311417
Step #28000	Loss: 0.302529
Step #32000	Loss: 0.293002
Step #36000	Loss: 0.313249
Step #40000	Loss: 0.316228
Step #44000	Loss: 0.296193
Step #48000	Loss: 0.288445
Step #52000	Loss: 0.306961
Step #56000	Loss: 0.298783
Step #60000	Loss: 0.303340
Step #64000	Loss: 0.288216
Step #68000	Loss: 0.323380
Step #72000	Loss: 0.300522
Step #76000	Loss: 0.301783
Step #80000	Loss: 0.299360
Step #84000	Loss: 0.309165
Step #88000	Loss: 0.307757
Step #92000	Loss: 0.323920
Step #96000	Loss: 0.310939
Step #100000	Loss: 0.298934
Step #104000	Loss: 0.301631
Step #108000	Loss: 0.316086
Step #112000	Loss: 0.305206
Step #116000	Loss: 0.288444
Step #120000	Loss: 0.302239
Step #124000	Loss: 0.294937
Step #128000	Loss: 0.314600
Step #132000	Loss: 0.304308
Step #136000	Loss: 0.329672
Step #140000	Loss: 0.323672
Step #144000	Loss: 0.306624
Step #148000	Loss: 0.296223
Step #152000	Loss: 0.301172
Step #156000	Loss: 0.319049
Step #160000	Loss: 0.303369
Step #164000	Loss: 0.297387
Step #168000	Loss: 0.307020
Step #172000	Loss: 0.296369
Step #176000	Loss: 0.294133
Step #180000	Loss: 0.292122
Step #184000	Loss: 0.308688
Step #188000	Loss: 0.316171
Step #192000	Loss: 0.311969
Step #196000	Loss: 0.317095
Step #200000	Loss: 0.308172
Step #204000	Loss: 0.303031
Step #208000	Loss: 0.291453
Step #212000	Loss: 0.298618
Step #216000	Loss: 0.317219
Step #220000	Loss: 0.300499
Code block 'train epoch=3' took: 1653972.03577 ms
train loss 0.305169939994812
Code block 'val epoch=3' took: 84657.56491 ms
validation loss 0.7233250141143799
Step #0	Loss: 0.349606
Step #4000	Loss: 0.299921
Step #8000	Loss: 0.284333
Step #12000	Loss: 0.311541
Step #16000	Loss: 0.307312
Step #20000	Loss: 0.310670
Step #24000	Loss: 0.300254
Step #28000	Loss: 0.308855
Step #32000	Loss: 0.293727
Step #36000	Loss: 0.308252
Step #40000	Loss: 0.299960
Step #44000	Loss: 0.291478
Step #48000	Loss: 0.295157
Step #52000	Loss: 0.299400
Step #56000	Loss: 0.289879
Step #60000	Loss: 0.298098
Step #64000	Loss: 0.287824
Step #68000	Loss: 0.313406
Step #72000	Loss: 0.294666
Step #76000	Loss: 0.291727
Step #80000	Loss: 0.298586
Step #84000	Loss: 0.323299
Step #88000	Loss: 0.312133
Step #92000	Loss: 0.317100
Step #96000	Loss: 0.318081
Step #100000	Loss: 0.295300
Step #104000	Loss: 0.296647
Step #108000	Loss: 0.312383
Step #112000	Loss: 0.307369
Step #116000	Loss: 0.289977
Step #120000	Loss: 0.303957
Step #124000	Loss: 0.296087
Step #128000	Loss: 0.313692
Step #132000	Loss: 0.317171
Step #136000	Loss: 0.325895
Step #140000	Loss: 0.317107
Step #144000	Loss: 0.295766
Step #148000	Loss: 0.306840
Step #152000	Loss: 0.303624
Step #156000	Loss: 0.304595
Step #160000	Loss: 0.310714
Step #164000	Loss: 0.297545
Step #168000	Loss: 0.314844
Step #172000	Loss: 0.297845
Step #176000	Loss: 0.294154
Step #180000	Loss: 0.296646
Step #184000	Loss: 0.302017
Step #188000	Loss: 0.319762
Step #192000	Loss: 0.320831
Step #196000	Loss: 0.316053
Step #200000	Loss: 0.314438
Step #204000	Loss: 0.303256
Step #208000	Loss: 0.293493
Step #212000	Loss: 0.299815
Step #216000	Loss: 0.308221
Step #220000	Loss: 0.297173
Code block 'train epoch=4' took: 1652870.46578 ms
train loss 0.30305615067481995
Code block 'val epoch=4' took: 84585.17745 ms
validation loss 0.7084433436393738
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --cufile-thread-count 32 --batch-size 8192 --epochs 5'
[WARN  tini (2525682)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-22 21:43:55.503953: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-22 21:43:59.084370: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-22 21:44:27.639369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-22 21:48:10.105186: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-22 21:48:10.759075: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fbc69103af0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-22 21:48:10.759160: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-22 21:48:10.911129: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-22 21:48:11.931296: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-22 21:48:12.309608: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.644216
Step #4000	Loss: 0.374951
Step #8000	Loss: 0.367257
terminate called after throwing an instance of 'rmm::out_of_memory'
  what():  std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp
[dgx-2:2525708] *** Process received signal ***
[dgx-2:2525708] Signal: Aborted (6)
[dgx-2:2525708] Signal code:  (-6)
[dgx-2:2525708] [ 0] /lib/x86_64-linux-gnu/libc.so.6(+0x42520)[0x7fc6739c3520]
[dgx-2:2525708] [ 1] /lib/x86_64-linux-gnu/libc.so.6(pthread_kill+0x12c)[0x7fc673a17a7c]
[dgx-2:2525708] [ 2] /lib/x86_64-linux-gnu/libc.so.6(raise+0x16)[0x7fc6739c3476]
[dgx-2:2525708] [ 3] /lib/x86_64-linux-gnu/libc.so.6(abort+0xd3)[0x7fc6739a97f3]
[dgx-2:2525708] [ 4] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(_ZN9__gnu_cxx27__verbose_terminate_handlerEv+0xc0)[0x7fc670b31026]
[dgx-2:2525708] [ 5] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(+0xb0514)[0x7fc670b2f514]
[dgx-2:2525708] [ 6] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(+0xb0566)[0x7fc670b2f566]
[dgx-2:2525708] [ 7] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(__cxa_rethrow+0x0)[0x7fc670b2f758]
[dgx-2:2525708] [ 8] /opt/conda/envs/rapids/lib/python3.10/site-packages/rmm/_lib/device_buffer.cpython-310-x86_64-linux-gnu.so(+0x4b67d)[0x7fc54017967d]
[dgx-2:2525708] [ 9] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf6columnC2ERKS0_N3rmm16cuda_stream_viewEPNS3_2mr22device_memory_resourceE+0x6d)[0x7fc433ad6add]
[dgx-2:2525708] [10] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf6columnC2ERKS0_N3rmm16cuda_stream_viewEPNS3_2mr22device_memory_resourceE+0x20c)[0x7fc433ad6c7c]
[dgx-2:2525708] [11] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf5tableC1ERKS0_+0x263)[0x7fc435210ec3]
[dgx-2:2525708] [12] /home2/faculty/pwesolowski/praca-mgr/parser-repo/build/libmeta-cudf-parser-1.so(_Z25generate_example_metadataPKcmmi11end_of_linebb+0x87d)[0x7fc3b421827d]
[dgx-2:2525708] [13] /home2/faculty/pwesolowski/praca-mgr/parser-repo/python_binding/metajsonparser/_lib/json_cudf.cpython-310-x86_64-linux-gnu.so(+0x4b344)[0x7fc3b42ef344]
[dgx-2:2525708] [14] python(+0x13fb27)[0x5643dd78db27]
[dgx-2:2525708] [15] python(PyObject_Call+0x209)[0x5643dd79a139]
[dgx-2:2525708] [16] python(_PyEval_EvalFrameDefault+0x5d8c)[0x5643dd783b7c]
[dgx-2:2525708] [17] python(_PyFunction_Vectorcall+0x6f)[0x5643dd78df8f]
[dgx-2:2525708] [18] python(_PyEval_EvalFrameDefault+0x2ec2)[0x5643dd780cb2]
[dgx-2:2525708] [19] python(_PyFunction_Vectorcall+0x6f)[0x5643dd78df8f]
[dgx-2:2525708] [20] python(_PyEval_EvalFrameDefault+0x332)[0x5643dd77e122]
[dgx-2:2525708] [21] python(_PyFunction_Vectorcall+0x6f)[0x5643dd78df8f]
[dgx-2:2525708] [22] python(_PyEval_EvalFrameDefault+0x2ec2)[0x5643dd780cb2]
[dgx-2:2525708] [23] python(_PyFunction_Vectorcall+0x6f)[0x5643dd78df8f]
[dgx-2:2525708] [24] python(_PyEval_EvalFrameDefault+0x332)[0x5643dd77e122]
[dgx-2:2525708] [25] python(_PyFunction_Vectorcall+0x6f)[0x5643dd78df8f]
[dgx-2:2525708] [26] python(_PyEval_EvalFrameDefault+0x2ec2)[0x5643dd780cb2]
[dgx-2:2525708] [27] python(+0x14b641)[0x5643dd799641]
[dgx-2:2525708] [28] python(_PyEval_EvalFrameDefault+0x332)[0x5643dd77e122]
[dgx-2:2525708] [29] python(_PyFunction_Vectorcall+0x6f)[0x5643dd78df8f]
[dgx-2:2525708] *** End of error message ***
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --cufile-thread-count 32 --batch-size 8192 --epochs 5'
[WARN  tini (2531513)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-22 21:49:41.635590: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-22 21:49:45.110168: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-22 21:50:10.804688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
Failed to transform operator <nvtabular.ops.categorify.Categorify object at 0x7f8378f9bb50>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1780, in _encode
    ).sort_values("order")["labels"]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 2214, in sort_values
    out = self._gather(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-22 21:53:54.062384: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-22 21:53:54.394464: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f7b6c989520 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-22 21:53:54.394541: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-22 21:53:54.539563: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-22 21:53:55.573502: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-22 21:53:55.974619: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 2.753712
Code block 'train epoch=0' took: 54360.62801 ms
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 332, in _get_next_batch
    batch = next(self._batch_itr)
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home2/faculty/pwesolowski/praca-mgr/pipelines-repo/2_merlin/run_merlin.py", line 155, in <module>
    for batch, (examples, labels) in enumerate(train_tf_ds):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/tensorflow.py", line 97, in __next__
    converted_batch = self.convert_batch(super().__next__())
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 261, in __next__
    return self._get_next_batch()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 344, in _get_next_batch
    batch = next(self._batch_itr)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 369, in make_tensors
    tensors_by_name = self._convert_df_to_tensors(gdf)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 520, in _convert_df_to_tensors
    tensors_by_name[column_name] = self._to_tensor(gdf_i[[column_name]])
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 450, in _to_tensor
    tensor = df_or_series.to_cupy()
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/single_column_frame.py", line 131, in to_cupy
    return super().to_cupy(dtype, copy, na_value).flatten()
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 533, in to_cupy
    return self._to_array(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 498, in _to_array
    matrix[:, i] = get_column_values_na(col)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 477, in get_column_values_na
    return get_column_values(col)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 534, in <lambda>
    (lambda col: col.values.copy())
  File "cupy/_core/core.pyx", line 590, in cupy._core.core._ndarray_base.copy
  File "cupy/_core/core.pyx", line 616, in cupy._core.core._ndarray_base.copy
  File "cupy/_core/core.pyx", line 575, in cupy._core.core._ndarray_base.astype
  File "cupy/_core/core.pyx", line 136, in cupy._core.core.ndarray.__new__
  File "cupy/_core/core.pyx", line 224, in cupy._core.core._ndarray_base._init
  File "cupy/cuda/memory.pyx", line 742, in cupy.cuda.memory.alloc
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/rmm/rmm.py", line 230, in rmm_cupy_allocator
    buf = librmm.device_buffer.DeviceBuffer(size=nbytes, stream=stream)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --cufile-thread-count 32 --batch-size 8192 --epochs 5'
[WARN  tini (2536708)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-22 21:54:41.587693: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-22 21:54:44.828322: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-22 21:55:09.872370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
terminate called after throwing an instance of 'rmm::out_of_memory'
  what():  std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp
[dgx-2:2536734] *** Process received signal ***
[dgx-2:2536734] Signal: Aborted (6)
[dgx-2:2536734] Signal code:  (-6)
[dgx-2:2536734] [ 0] /lib/x86_64-linux-gnu/libc.so.6(+0x42520)[0x7f2265f71520]
[dgx-2:2536734] [ 1] /lib/x86_64-linux-gnu/libc.so.6(pthread_kill+0x12c)[0x7f2265fc5a7c]
[dgx-2:2536734] [ 2] /lib/x86_64-linux-gnu/libc.so.6(raise+0x16)[0x7f2265f71476]
[dgx-2:2536734] [ 3] /lib/x86_64-linux-gnu/libc.so.6(abort+0xd3)[0x7f2265f577f3]
[dgx-2:2536734] [ 4] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(_ZN9__gnu_cxx27__verbose_terminate_handlerEv+0xc0)[0x7f22630df026]
[dgx-2:2536734] [ 5] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(+0xb0514)[0x7f22630dd514]
[dgx-2:2536734] [ 6] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(+0xb0566)[0x7f22630dd566]
[dgx-2:2536734] [ 7] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(__cxa_rethrow+0x0)[0x7f22630dd758]
[dgx-2:2536734] [ 8] /opt/conda/envs/rapids/lib/python3.10/site-packages/rmm/_lib/device_buffer.cpython-310-x86_64-linux-gnu.so(+0x4b67d)[0x7f212018067d]
[dgx-2:2536734] [ 9] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf6columnC2ERKS0_N3rmm16cuda_stream_viewEPNS3_2mr22device_memory_resourceE+0x6d)[0x7f2023ad6add]
[dgx-2:2536734] [10] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf6columnC2ERKS0_N3rmm16cuda_stream_viewEPNS3_2mr22device_memory_resourceE+0x20c)[0x7f2023ad6c7c]
[dgx-2:2536734] [11] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf5tableC1ERKS0_+0x263)[0x7f2025210ec3]
[dgx-2:2536734] [12] /home2/faculty/pwesolowski/praca-mgr/parser-repo/build/libmeta-cudf-parser-1.so(_Z25generate_example_metadataPKcmmi11end_of_linebb+0x87d)[0x7f1a8fa7027d]
[dgx-2:2536734] [13] /home2/faculty/pwesolowski/praca-mgr/parser-repo/python_binding/metajsonparser/_lib/json_cudf.cpython-310-x86_64-linux-gnu.so(+0x4b344)[0x7f1a8fb47344]
[dgx-2:2536734] [14] python(+0x13fb27)[0x55d0be91fb27]
[dgx-2:2536734] [15] python(PyObject_Call+0x209)[0x55d0be92c139]
[dgx-2:2536734] [16] python(_PyEval_EvalFrameDefault+0x5d8c)[0x55d0be915b7c]
[dgx-2:2536734] [17] python(_PyFunction_Vectorcall+0x6f)[0x55d0be91ff8f]
[dgx-2:2536734] [18] python(_PyEval_EvalFrameDefault+0x2ec2)[0x55d0be912cb2]
[dgx-2:2536734] [19] python(_PyFunction_Vectorcall+0x6f)[0x55d0be91ff8f]
[dgx-2:2536734] [20] python(_PyEval_EvalFrameDefault+0x332)[0x55d0be910122]
[dgx-2:2536734] [21] python(_PyFunction_Vectorcall+0x6f)[0x55d0be91ff8f]
[dgx-2:2536734] [22] python(_PyEval_EvalFrameDefault+0x2ec2)[0x55d0be912cb2]
[dgx-2:2536734] [23] python(_PyFunction_Vectorcall+0x6f)[0x55d0be91ff8f]
[dgx-2:2536734] [24] python(_PyEval_EvalFrameDefault+0x332)[0x55d0be910122]
[dgx-2:2536734] [25] python(_PyFunction_Vectorcall+0x6f)[0x55d0be91ff8f]
[dgx-2:2536734] [26] python(_PyEval_EvalFrameDefault+0x2ec2)[0x55d0be912cb2]
[dgx-2:2536734] [27] python(+0x14b641)[0x55d0be92b641]
[dgx-2:2536734] [28] python(_PyEval_EvalFrameDefault+0x332)[0x55d0be910122]
[dgx-2:2536734] [29] python(_PyFunction_Vectorcall+0x6f)[0x55d0be91ff8f]
[dgx-2:2536734] *** End of error message ***
+ for CUFILE_THREAD_COUNT in 4 8 16 32 64
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --cufile-thread-count 64 --batch-size 8192 --epochs 5'
[WARN  tini (2540876)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-22 21:58:54.610840: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-22 21:58:57.895142: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-22 21:59:24.207132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-22 22:03:12.735318: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-22 22:03:13.200304: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fbfc87a4440 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-22 22:03:13.200368: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-22 22:03:13.355429: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-22 22:03:14.442479: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-22 22:03:14.844284: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.519897
Step #4000	Loss: 0.289457
Step #8000	Loss: 0.323678
Step #12000	Loss: 0.318299
Step #16000	Loss: 0.334391
Step #20000	Loss: 0.319829
Step #24000	Loss: 0.419347
Step #28000	Loss: 0.420694
Step #32000	Loss: 0.432330
Step #36000	Loss: 0.381397
Step #40000	Loss: 0.330734
Step #44000	Loss: 0.355313
Step #48000	Loss: 0.335034
Step #52000	Loss: 0.338340
Step #56000	Loss: 0.343439
Step #60000	Loss: 0.399962
Step #64000	Loss: 0.312471
Step #68000	Loss: 0.333893
Step #72000	Loss: 0.364598
Step #76000	Loss: 0.350151
Step #80000	Loss: 0.377334
Step #84000	Loss: 0.371086
Step #88000	Loss: 0.366612
Step #92000	Loss: 0.373826
Step #96000	Loss: 0.316625
Step #100000	Loss: 0.439955
Step #104000	Loss: 0.325013
Step #108000	Loss: 0.347118
Step #112000	Loss: 0.318753
Step #116000	Loss: 0.375150
Step #120000	Loss: 0.328266
Step #124000	Loss: 0.334137
Step #128000	Loss: 0.362297
Step #132000	Loss: 0.332925
Step #136000	Loss: 0.424231
Step #140000	Loss: 0.408529
Step #144000	Loss: 0.426561
Step #148000	Loss: 0.306790
Step #152000	Loss: 0.425509
Step #156000	Loss: 0.315493
Step #160000	Loss: 0.342485
Step #164000	Loss: 0.306877
Step #168000	Loss: 0.414823
Step #172000	Loss: 0.402831
Step #176000	Loss: 0.307865
Step #180000	Loss: 0.348240
Step #184000	Loss: 0.326611
Step #188000	Loss: 0.460557
Step #192000	Loss: 0.416563
Step #196000	Loss: 0.461790
Step #200000	Loss: 0.327717
Step #204000	Loss: 0.294505
Step #208000	Loss: 0.332019
Step #212000	Loss: 0.337549
Step #216000	Loss: 0.391467
Step #220000	Loss: 0.424509
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 1698271.52899 ms
train loss 0.3598467707633972
Code block 'val epoch=0' took: 88116.18709 ms
validation loss 0.616331160068512
Step #0	Loss: 0.422797
Step #4000	Loss: 0.277398
Step #8000	Loss: 0.300678
Step #12000	Loss: 0.300318
Step #16000	Loss: 0.312665
Step #20000	Loss: 0.314788
Step #24000	Loss: 0.356217
Step #28000	Loss: 0.332511
Step #32000	Loss: 0.367308
Step #36000	Loss: 0.329417
Step #40000	Loss: 0.312645
Step #44000	Loss: 0.306593
Step #48000	Loss: 0.299664
Step #52000	Loss: 0.313929
Step #56000	Loss: 0.302585
Step #60000	Loss: 0.329554
Step #64000	Loss: 0.295772
Step #68000	Loss: 0.318322
Step #72000	Loss: 0.325086
Step #76000	Loss: 0.327925
Step #80000	Loss: 0.330592
Step #84000	Loss: 0.331908
Step #88000	Loss: 0.320629
Step #92000	Loss: 0.326899
Step #96000	Loss: 0.297077
Step #100000	Loss: 0.354002
Step #104000	Loss: 0.318625
Step #108000	Loss: 0.325863
Step #112000	Loss: 0.307708
Step #116000	Loss: 0.330177
Step #120000	Loss: 0.298566
Step #124000	Loss: 0.290403
Step #128000	Loss: 0.349356
Step #132000	Loss: 0.323927
Step #136000	Loss: 0.360237
Step #140000	Loss: 0.354708
Step #144000	Loss: 0.350960
Step #148000	Loss: 0.293429
Step #152000	Loss: 0.347701
Step #156000	Loss: 0.319197
Step #160000	Loss: 0.307034
Step #164000	Loss: 0.312184
Step #168000	Loss: 0.343970
Step #172000	Loss: 0.331401
Step #176000	Loss: 0.278323
Step #180000	Loss: 0.304909
Step #184000	Loss: 0.296054
Step #188000	Loss: 0.378916
Step #192000	Loss: 0.359125
Step #196000	Loss: 0.377724
Step #200000	Loss: 0.326762
Step #204000	Loss: 0.290383
Step #208000	Loss: 0.307216
Step #212000	Loss: 0.307273
Step #216000	Loss: 0.346486
Step #220000	Loss: 0.360113
Code block 'train epoch=1' took: 1669578.68062 ms
train loss 0.32464835047721863
Code block 'val epoch=1' took: 87945.66943 ms
validation loss 0.6572622656822205
Step #0	Loss: 0.319142
Step #4000	Loss: 0.279075
Step #8000	Loss: 0.300031
Step #12000	Loss: 0.302643
Step #16000	Loss: 0.294102
Step #20000	Loss: 0.301310
Step #24000	Loss: 0.334762
Step #28000	Loss: 0.311332
Step #32000	Loss: 0.313877
Step #36000	Loss: 0.310972
Step #40000	Loss: 0.305822
Step #44000	Loss: 0.300289
Step #48000	Loss: 0.297194
Step #52000	Loss: 0.296596
Step #56000	Loss: 0.306682
Step #60000	Loss: 0.305721
Step #64000	Loss: 0.295527
Step #68000	Loss: 0.312529
Step #72000	Loss: 0.307746
Step #76000	Loss: 0.315969
Step #80000	Loss: 0.300352
Step #84000	Loss: 0.323578
Step #88000	Loss: 0.306697
Step #92000	Loss: 0.318202
Step #96000	Loss: 0.300908
Step #100000	Loss: 0.320913
Step #104000	Loss: 0.321176
Step #108000	Loss: 0.315099
Step #112000	Loss: 0.306860
Step #116000	Loss: 0.313599
Step #120000	Loss: 0.299602
Step #124000	Loss: 0.294975
Step #128000	Loss: 0.315575
Step #132000	Loss: 0.309765
Step #136000	Loss: 0.341777
Step #140000	Loss: 0.327766
Step #144000	Loss: 0.322144
Step #148000	Loss: 0.286560
Step #152000	Loss: 0.323410
Step #156000	Loss: 0.307257
Step #160000	Loss: 0.290845
Step #164000	Loss: 0.305564
Step #168000	Loss: 0.322586
Step #172000	Loss: 0.324299
Step #176000	Loss: 0.287845
Step #180000	Loss: 0.298812
Step #184000	Loss: 0.295331
Step #188000	Loss: 0.342340
Step #192000	Loss: 0.322549
Step #196000	Loss: 0.333793
Step #200000	Loss: 0.304229
Step #204000	Loss: 0.271340
Step #208000	Loss: 0.315363
Step #212000	Loss: 0.306341
Step #216000	Loss: 0.326525
Step #220000	Loss: 0.319440
Code block 'train epoch=2' took: 1670673.23933 ms
train loss 0.31122517585754395
Code block 'val epoch=2' took: 88302.76212 ms
validation loss 0.686428427696228
Step #0	Loss: 0.299296
Step #4000	Loss: 0.287144
Step #8000	Loss: 0.292846
Step #12000	Loss: 0.297278
Step #16000	Loss: 0.290574
Step #20000	Loss: 0.309401
Step #24000	Loss: 0.313032
Step #28000	Loss: 0.310465
Step #32000	Loss: 0.304570
Step #36000	Loss: 0.302919
Step #40000	Loss: 0.313351
Step #44000	Loss: 0.289462
Step #48000	Loss: 0.300853
Step #52000	Loss: 0.305204
Step #56000	Loss: 0.297377
Step #60000	Loss: 0.299884
Step #64000	Loss: 0.291108
Step #68000	Loss: 0.318744
Step #72000	Loss: 0.297123
Step #76000	Loss: 0.297842
Step #80000	Loss: 0.300890
Step #84000	Loss: 0.324282
Step #88000	Loss: 0.311917
Step #92000	Loss: 0.313649
Step #96000	Loss: 0.304658
Step #100000	Loss: 0.319789
Step #104000	Loss: 0.311096
Step #108000	Loss: 0.329963
Step #112000	Loss: 0.295674
Step #116000	Loss: 0.313846
Step #120000	Loss: 0.293315
Step #124000	Loss: 0.280790
Step #128000	Loss: 0.308275
Step #132000	Loss: 0.310262
Step #136000	Loss: 0.325181
Step #140000	Loss: 0.320277
Step #144000	Loss: 0.308892
Step #148000	Loss: 0.288252
Step #152000	Loss: 0.312685
Step #156000	Loss: 0.292469
Step #160000	Loss: 0.284300
Step #164000	Loss: 0.308095
Step #168000	Loss: 0.320954
Step #172000	Loss: 0.312558
Step #176000	Loss: 0.278064
Step #180000	Loss: 0.307287
Step #184000	Loss: 0.297938
Step #188000	Loss: 0.329375
Step #192000	Loss: 0.306089
Step #196000	Loss: 0.325821
Step #200000	Loss: 0.311081
Step #204000	Loss: 0.264147
Step #208000	Loss: 0.306936
Step #212000	Loss: 0.295292
Step #216000	Loss: 0.320959
Step #220000	Loss: 0.310337
Code block 'train epoch=3' took: 1668846.59567 ms
train loss 0.30565205216407776
Code block 'val epoch=3' took: 87863.59656 ms
validation loss 0.7499929070472717
Step #0	Loss: 0.306247
Step #4000	Loss: 0.272314
Step #8000	Loss: 0.293184
Step #12000	Loss: 0.289102
Step #16000	Loss: 0.312281
Step #20000	Loss: 0.310125
Step #24000	Loss: 0.296893
Step #28000	Loss: 0.297896
Step #32000	Loss: 0.294978
Step #36000	Loss: 0.298903
Step #40000	Loss: 0.299749
Step #44000	Loss: 0.300365
Step #48000	Loss: 0.290317
Step #52000	Loss: 0.301900
Step #56000	Loss: 0.296442
Step #60000	Loss: 0.298790
Step #64000	Loss: 0.298235
Step #68000	Loss: 0.312083
Step #72000	Loss: 0.291307
Step #76000	Loss: 0.300651
Step #80000	Loss: 0.303372
Step #84000	Loss: 0.309991
Step #88000	Loss: 0.296742
Step #92000	Loss: 0.307449
Step #96000	Loss: 0.292070
Step #100000	Loss: 0.312024
Step #104000	Loss: 0.306643
Step #108000	Loss: 0.320838
Step #112000	Loss: 0.305446
Step #116000	Loss: 0.300862
Step #120000	Loss: 0.295010
Step #124000	Loss: 0.272442
Step #128000	Loss: 0.299929
Step #132000	Loss: 0.310454
Step #136000	Loss: 0.317896
Step #140000	Loss: 0.307096
Step #144000	Loss: 0.304953
Step #148000	Loss: 0.290790
Step #152000	Loss: 0.308028
Step #156000	Loss: 0.297592
Step #160000	Loss: 0.286297
Step #164000	Loss: 0.297081
Step #168000	Loss: 0.315034
Step #172000	Loss: 0.309109
Step #176000	Loss: 0.274171
Step #180000	Loss: 0.293965
Step #184000	Loss: 0.280393
Step #188000	Loss: 0.307188
Step #192000	Loss: 0.309560
Step #196000	Loss: 0.303083
Step #200000	Loss: 0.306764
Step #204000	Loss: 0.270095
Step #208000	Loss: 0.306615
Step #212000	Loss: 0.303668
Step #216000	Loss: 0.327026
Step #220000	Loss: 0.309965
Code block 'train epoch=4' took: 1669382.40281 ms
train loss 0.3028765618801117
Code block 'val epoch=4' took: 88081.25419 ms
validation loss 0.7852725982666016
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --cufile-thread-count 64 --batch-size 8192 --epochs 5'
[WARN  tini (2660542)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-23 00:30:09.879858: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-23 00:30:13.646405: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-23 00:30:43.234764: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-23 00:34:32.341472: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-23 00:34:32.770220: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f525ce867a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-23 00:34:32.770302: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-23 00:34:32.914787: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-23 00:34:33.842916: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-23 00:34:34.164088: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 2.177950
Step #4000	Loss: 0.291820
Step #8000	Loss: 0.313612
Step #12000	Loss: 0.332186
Step #16000	Loss: 0.318595
Step #20000	Loss: 0.314804
Step #24000	Loss: 0.438594
Step #28000	Loss: 0.431721
Step #32000	Loss: 0.431891
Step #36000	Loss: 0.423458
Step #40000	Loss: 0.358536
Step #44000	Loss: 0.351291
Step #48000	Loss: 0.365338
Step #52000	Loss: 0.372300
Step #56000	Loss: 0.388277
Step #60000	Loss: 0.419494
Step #64000	Loss: 0.333317
Step #68000	Loss: 0.378697
Step #72000	Loss: 0.359771
Step #76000	Loss: 0.318111
Step #80000	Loss: 0.341320
Step #84000	Loss: 0.366433
Step #88000	Loss: 0.401088
Step #92000	Loss: 0.399742
Step #96000	Loss: 0.328159
Step #100000	Loss: 0.428398
Step #104000	Loss: 0.362161
Step #108000	Loss: 0.374665
Step #112000	Loss: 0.319315
Step #116000	Loss: 0.341344
Step #120000	Loss: 0.309663
Step #124000	Loss: 0.377226
Step #128000	Loss: 0.388218
Step #132000	Loss: 0.315911
Step #136000	Loss: 0.449401
Step #140000	Loss: 0.422696
Step #144000	Loss: 0.325651
Step #148000	Loss: 0.335577
Step #152000	Loss: 0.450562
Step #156000	Loss: 0.327328
Step #160000	Loss: 0.394408
Step #164000	Loss: 0.306143
Step #168000	Loss: 0.433334
Step #172000	Loss: 0.326888
Step #176000	Loss: 0.353992
Step #180000	Loss: 0.363494
Step #184000	Loss: 0.319145
Step #188000	Loss: 0.473528
Step #192000	Loss: 0.449676
Step #196000	Loss: 0.459600
Step #200000	Loss: 0.327878
Step #204000	Loss: 0.314201
Step #208000	Loss: 0.313187
Step #212000	Loss: 0.327165
Step #216000	Loss: 0.406627
Step #220000	Loss: 0.347194
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 1687045.76205 ms
train loss 0.35958725214004517
Code block 'val epoch=0' took: 88105.54879 ms
validation loss 0.5956393480300903
Step #0	Loss: 0.459145
Step #4000	Loss: 0.295581
Step #8000	Loss: 0.299268
Step #12000	Loss: 0.304505
Step #16000	Loss: 0.310425
Step #20000	Loss: 0.309398
Step #24000	Loss: 0.352705
Step #28000	Loss: 0.350038
Step #32000	Loss: 0.365196
Step #36000	Loss: 0.344699
Step #40000	Loss: 0.338761
Step #44000	Loss: 0.322329
Step #48000	Loss: 0.320697
Step #52000	Loss: 0.319842
Step #56000	Loss: 0.337463
Step #60000	Loss: 0.350284
Step #64000	Loss: 0.305245
Step #68000	Loss: 0.334757
Step #72000	Loss: 0.319758
Step #76000	Loss: 0.313993
Step #80000	Loss: 0.314395
Step #84000	Loss: 0.335945
Step #88000	Loss: 0.329639
Step #92000	Loss: 0.335318
Step #96000	Loss: 0.312451
Step #100000	Loss: 0.356416
Step #104000	Loss: 0.314668
Step #108000	Loss: 0.332410
Step #112000	Loss: 0.305572
Step #116000	Loss: 0.317191
Step #120000	Loss: 0.315711
Step #124000	Loss: 0.322803
Step #128000	Loss: 0.336939
Step #132000	Loss: 0.331796
Step #136000	Loss: 0.379313
Step #140000	Loss: 0.361239
Step #144000	Loss: 0.315872
Step #148000	Loss: 0.312272
Step #152000	Loss: 0.362941
Step #156000	Loss: 0.309260
Step #160000	Loss: 0.317351
Step #164000	Loss: 0.297857
Step #168000	Loss: 0.360010
Step #172000	Loss: 0.301192
Step #176000	Loss: 0.313570
Step #180000	Loss: 0.329227
Step #184000	Loss: 0.302345
Step #188000	Loss: 0.370526
Step #192000	Loss: 0.376052
Step #196000	Loss: 0.386394
Step #200000	Loss: 0.317212
Step #204000	Loss: 0.305261
Step #208000	Loss: 0.310680
Step #212000	Loss: 0.302313
Step #216000	Loss: 0.347736
Step #220000	Loss: 0.310115
Code block 'train epoch=1' took: 1662020.60771 ms
train loss 0.3237731456756592
Code block 'val epoch=1' took: 87374.78906 ms
validation loss 0.6652565598487854
Step #0	Loss: 0.359515
Step #4000	Loss: 0.274267
Step #8000	Loss: 0.293508
Step #12000	Loss: 0.308050
Step #16000	Loss: 0.305905
Step #20000	Loss: 0.307886
Step #24000	Loss: 0.333586
Step #28000	Loss: 0.336077
Step #32000	Loss: 0.317764
Step #36000	Loss: 0.325790
Step #40000	Loss: 0.320256
Step #44000	Loss: 0.293925
Step #48000	Loss: 0.298329
Step #52000	Loss: 0.306495
Step #56000	Loss: 0.318187
Step #60000	Loss: 0.333554
Step #64000	Loss: 0.302581
Step #68000	Loss: 0.318296
Step #72000	Loss: 0.320389
Step #76000	Loss: 0.288256
Step #80000	Loss: 0.309823
Step #84000	Loss: 0.315688
Step #88000	Loss: 0.310906
Step #92000	Loss: 0.317682
Step #96000	Loss: 0.301875
Step #100000	Loss: 0.316651
Step #104000	Loss: 0.314414
Step #108000	Loss: 0.315357
Step #112000	Loss: 0.300246
Step #116000	Loss: 0.320646
Step #120000	Loss: 0.306043
Step #124000	Loss: 0.299441
Step #128000	Loss: 0.320086
Step #132000	Loss: 0.322673
Step #136000	Loss: 0.347111
Step #140000	Loss: 0.350231
Step #144000	Loss: 0.305231
Step #148000	Loss: 0.307735
Step #152000	Loss: 0.325691
Step #156000	Loss: 0.311420
Step #160000	Loss: 0.293450
Step #164000	Loss: 0.279934
Step #168000	Loss: 0.326747
Step #172000	Loss: 0.291645
Step #176000	Loss: 0.294625
Step #180000	Loss: 0.299939
Step #184000	Loss: 0.312636
Step #188000	Loss: 0.341408
Step #192000	Loss: 0.340135
Step #196000	Loss: 0.329734
Step #200000	Loss: 0.307407
Step #204000	Loss: 0.291472
Step #208000	Loss: 0.305482
Step #212000	Loss: 0.317091
Step #216000	Loss: 0.324868
Step #220000	Loss: 0.295804
Code block 'train epoch=2' took: 1661939.29977 ms
train loss 0.3110824227333069
Code block 'val epoch=2' took: 87628.74451 ms
validation loss 0.7329546213150024
Step #0	Loss: 0.337434
Step #4000	Loss: 0.287010
Step #8000	Loss: 0.290669
Step #12000	Loss: 0.311938
Step #16000	Loss: 0.288973
Step #20000	Loss: 0.306210
Step #24000	Loss: 0.310106
Step #28000	Loss: 0.308283
Step #32000	Loss: 0.310551
Step #36000	Loss: 0.313161
Step #40000	Loss: 0.308803
Step #44000	Loss: 0.285106
Step #48000	Loss: 0.287246
Step #52000	Loss: 0.313558
Step #56000	Loss: 0.305382
Step #60000	Loss: 0.310950
Step #64000	Loss: 0.288506
Step #68000	Loss: 0.315247
Step #72000	Loss: 0.302528
Step #76000	Loss: 0.290602
Step #80000	Loss: 0.307966
Step #84000	Loss: 0.321474
Step #88000	Loss: 0.297808
Step #92000	Loss: 0.304985
Step #96000	Loss: 0.306671
Step #100000	Loss: 0.308775
Step #104000	Loss: 0.307899
Step #108000	Loss: 0.313659
Step #112000	Loss: 0.309556
Step #116000	Loss: 0.300366
Step #120000	Loss: 0.298968
Step #124000	Loss: 0.293767
Step #128000	Loss: 0.302644
Step #132000	Loss: 0.312681
Step #136000	Loss: 0.330391
Step #140000	Loss: 0.311620
Step #144000	Loss: 0.297600
Step #148000	Loss: 0.301788
Step #152000	Loss: 0.315843
Step #156000	Loss: 0.304923
Step #160000	Loss: 0.286189
Step #164000	Loss: 0.295740
Step #168000	Loss: 0.319604
Step #172000	Loss: 0.280869
Step #176000	Loss: 0.297843
Step #180000	Loss: 0.288270
Step #184000	Loss: 0.291721
Step #188000	Loss: 0.329811
Step #192000	Loss: 0.326041
Step #196000	Loss: 0.313146
Step #200000	Loss: 0.302853
Step #204000	Loss: 0.286009
Step #208000	Loss: 0.294329
Step #212000	Loss: 0.301550
Step #216000	Loss: 0.311480
Step #220000	Loss: 0.295350
Code block 'train epoch=3' took: 1665171.68137 ms
train loss 0.3054216504096985
Code block 'val epoch=3' took: 88035.93993 ms
validation loss 0.7828455567359924
Step #0	Loss: 0.334309
Step #4000	Loss: 0.295846
Step #8000	Loss: 0.297774
Step #12000	Loss: 0.293199
Step #16000	Loss: 0.290184
Step #20000	Loss: 0.290468
Step #24000	Loss: 0.310484
Step #28000	Loss: 0.308667
Step #32000	Loss: 0.295101
Step #36000	Loss: 0.310261
Step #40000	Loss: 0.317087
Step #44000	Loss: 0.278610
Step #48000	Loss: 0.294002
Step #52000	Loss: 0.308452
Step #56000	Loss: 0.306671
Step #60000	Loss: 0.301953
Step #64000	Loss: 0.296330
Step #68000	Loss: 0.312684
Step #72000	Loss: 0.306095
Step #76000	Loss: 0.284666
Step #80000	Loss: 0.303562
Step #84000	Loss: 0.308010
Step #88000	Loss: 0.309272
Step #92000	Loss: 0.291217
Step #96000	Loss: 0.299091
Step #100000	Loss: 0.311356
Step #104000	Loss: 0.310390
Step #108000	Loss: 0.307433
Step #112000	Loss: 0.290936
Step #116000	Loss: 0.307234
Step #120000	Loss: 0.306483
Step #124000	Loss: 0.295596
Step #128000	Loss: 0.321930
Step #132000	Loss: 0.300339
Step #136000	Loss: 0.333357
Step #140000	Loss: 0.315802
Step #144000	Loss: 0.308765
Step #148000	Loss: 0.293492
Step #152000	Loss: 0.300716
Step #156000	Loss: 0.307043
Step #160000	Loss: 0.293673
Step #164000	Loss: 0.284093
Step #168000	Loss: 0.309574
Step #172000	Loss: 0.286780
Step #176000	Loss: 0.283527
Step #180000	Loss: 0.300785
Step #184000	Loss: 0.289416
Step #188000	Loss: 0.320372
Step #192000	Loss: 0.320404
Step #196000	Loss: 0.305284
Step #200000	Loss: 0.295110
Step #204000	Loss: 0.292849
Step #208000	Loss: 0.305921
Step #212000	Loss: 0.293290
Step #216000	Loss: 0.312152
Step #220000	Loss: 0.305806
Code block 'train epoch=4' took: 1660879.89881 ms
train loss 0.30241644382476807
Code block 'val epoch=4' took: 87794.24084 ms
validation loss 0.8341456651687622
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --cufile-thread-count 64 --batch-size 8192 --epochs 5'
[WARN  tini (2784252)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-23 03:00:45.953370: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-23 03:00:50.160743: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-23 03:01:19.165348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-23 03:05:10.791323: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-23 03:05:11.338127: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f80fa01cde0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-23 03:05:11.338200: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-23 03:05:11.506269: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-23 03:05:12.592575: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-23 03:05:12.941478: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.553551
Step #4000	Loss: 0.309187
Step #8000	Loss: 0.377035
Step #12000	Loss: 0.337313
Step #16000	Loss: 0.341798
Step #20000	Loss: 0.323754
Step #24000	Loss: 0.384052
Step #28000	Loss: 0.334236
Step #32000	Loss: 0.435348
Step #36000	Loss: 0.347177
Step #40000	Loss: 0.329291
Step #44000	Loss: 0.291592
Step #48000	Loss: 0.370240
Step #52000	Loss: 0.337123
Step #56000	Loss: 0.328231
Step #60000	Loss: 0.423030
Step #64000	Loss: 0.339921
Step #68000	Loss: 0.314202
Step #72000	Loss: 0.342086
Step #76000	Loss: 0.344881
Step #80000	Loss: 0.331386
Step #84000	Loss: 0.425534
Step #88000	Loss: 0.332164
Step #92000	Loss: 0.416508
Step #96000	Loss: 0.325997
Step #100000	Loss: 0.361117
Step #104000	Loss: 0.322196
Step #108000	Loss: 0.361246
Step #112000	Loss: 0.321168
Step #116000	Loss: 0.321365
Step #120000	Loss: 0.342913
Step #124000	Loss: 0.342987
Step #128000	Loss: 0.335337
Step #132000	Loss: 0.332216
Step #136000	Loss: 0.453220
Step #140000	Loss: 0.366406
Step #144000	Loss: 0.457824
Step #148000	Loss: 0.356695
Step #152000	Loss: 0.466176
Step #156000	Loss: 0.388837
Step #160000	Loss: 0.339371
Step #164000	Loss: 0.326009
Step #168000	Loss: 0.438652
Step #172000	Loss: 0.312576
Step #176000	Loss: 0.328399
Step #180000	Loss: 0.321056
Step #184000	Loss: 0.326780
Step #188000	Loss: 0.474039
Step #192000	Loss: 0.377598
Step #196000	Loss: 0.337724
Step #200000	Loss: 0.329892
Step #204000	Loss: 0.368201
Step #208000	Loss: 0.404326
Step #212000	Loss: 0.339271
Step #216000	Loss: 0.419155
Step #220000	Loss: 0.326283
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 1684913.68008 ms
train loss 0.3581751883029938
Code block 'val epoch=0' took: 87932.10084 ms
validation loss 0.6490892171859741
Step #0	Loss: 0.476996
Step #4000	Loss: 0.298905
Step #8000	Loss: 0.324382
Step #12000	Loss: 0.336045
Step #16000	Loss: 0.323615
Step #20000	Loss: 0.316775
Step #24000	Loss: 0.325434
Step #28000	Loss: 0.305025
Step #32000	Loss: 0.342993
Step #36000	Loss: 0.308908
Step #40000	Loss: 0.303915
Step #44000	Loss: 0.285010
Step #48000	Loss: 0.322556
Step #52000	Loss: 0.307678
Step #56000	Loss: 0.311353
Step #60000	Loss: 0.347133
Step #64000	Loss: 0.297983
Step #68000	Loss: 0.308841
Step #72000	Loss: 0.318621
Step #76000	Loss: 0.319000
Step #80000	Loss: 0.311980
Step #84000	Loss: 0.355041
Step #88000	Loss: 0.308568
Step #92000	Loss: 0.344506
Step #96000	Loss: 0.312274
Step #100000	Loss: 0.309012
Step #104000	Loss: 0.305773
Step #108000	Loss: 0.325939
Step #112000	Loss: 0.304649
Step #116000	Loss: 0.308564
Step #120000	Loss: 0.304768
Step #124000	Loss: 0.312656
Step #128000	Loss: 0.315613
Step #132000	Loss: 0.317288
Step #136000	Loss: 0.365771
Step #140000	Loss: 0.324432
Step #144000	Loss: 0.342097
Step #148000	Loss: 0.309871
Step #152000	Loss: 0.358885
Step #156000	Loss: 0.330181
Step #160000	Loss: 0.316873
Step #164000	Loss: 0.299951
Step #168000	Loss: 0.359481
Step #172000	Loss: 0.302505
Step #176000	Loss: 0.294560
Step #180000	Loss: 0.306822
Step #184000	Loss: 0.301880
Step #188000	Loss: 0.372875
Step #192000	Loss: 0.330407
Step #196000	Loss: 0.326899
Step #200000	Loss: 0.312852
Step #204000	Loss: 0.311653
Step #208000	Loss: 0.328105
Step #212000	Loss: 0.303777
Step #216000	Loss: 0.352546
Step #220000	Loss: 0.307827
Code block 'train epoch=1' took: 1659444.46357 ms
train loss 0.3223801553249359
Code block 'val epoch=1' took: 87784.87133 ms
validation loss 0.6964681148529053
Step #0	Loss: 0.358052
Step #4000	Loss: 0.303589
Step #8000	Loss: 0.305531
Step #12000	Loss: 0.315610
Step #16000	Loss: 0.308752
Step #20000	Loss: 0.314789
Step #24000	Loss: 0.312027
Step #28000	Loss: 0.296210
Step #32000	Loss: 0.302473
Step #36000	Loss: 0.301658
Step #40000	Loss: 0.306492
Step #44000	Loss: 0.297816
Step #48000	Loss: 0.303115
Step #52000	Loss: 0.305754
Step #56000	Loss: 0.290257
Step #60000	Loss: 0.324368
Step #64000	Loss: 0.301494
Step #68000	Loss: 0.325993
Step #72000	Loss: 0.302068
Step #76000	Loss: 0.299106
Step #80000	Loss: 0.295416
Step #84000	Loss: 0.335740
Step #88000	Loss: 0.309539
Step #92000	Loss: 0.336919
Step #96000	Loss: 0.300810
Step #100000	Loss: 0.317695
Step #104000	Loss: 0.301427
Step #108000	Loss: 0.318888
Step #112000	Loss: 0.287838
Step #116000	Loss: 0.301558
Step #120000	Loss: 0.303402
Step #124000	Loss: 0.298537
Step #128000	Loss: 0.309164
Step #132000	Loss: 0.306799
Step #136000	Loss: 0.324736
Step #140000	Loss: 0.322390
Step #144000	Loss: 0.322732
Step #148000	Loss: 0.310531
Step #152000	Loss: 0.324494
Step #156000	Loss: 0.308743
Step #160000	Loss: 0.320461
Step #164000	Loss: 0.290428
Step #168000	Loss: 0.328842
Step #172000	Loss: 0.295536
Step #176000	Loss: 0.288315
Step #180000	Loss: 0.291487
Step #184000	Loss: 0.283984
Step #188000	Loss: 0.334016
Step #192000	Loss: 0.314910
Step #196000	Loss: 0.307941
Step #200000	Loss: 0.308841
Step #204000	Loss: 0.303838
Step #208000	Loss: 0.326051
Step #212000	Loss: 0.308730
Step #216000	Loss: 0.325475
Step #220000	Loss: 0.291426
Code block 'train epoch=2' took: 1661133.23447 ms
train loss 0.3100816607475281
Code block 'val epoch=2' took: 88476.08415 ms
validation loss 0.7300222516059875
Step #0	Loss: 0.343295
Step #4000	Loss: 0.282607
Step #8000	Loss: 0.287826
Step #12000	Loss: 0.316783
Step #16000	Loss: 0.301930
Step #20000	Loss: 0.299506
Step #24000	Loss: 0.310482
Step #28000	Loss: 0.301533
Step #32000	Loss: 0.303818
Step #36000	Loss: 0.297024
Step #40000	Loss: 0.305257
Step #44000	Loss: 0.288476
Step #48000	Loss: 0.288469
Step #52000	Loss: 0.309004
Step #56000	Loss: 0.302882
Step #60000	Loss: 0.312841
Step #64000	Loss: 0.295607
Step #68000	Loss: 0.310967
Step #72000	Loss: 0.299776
Step #76000	Loss: 0.294296
Step #80000	Loss: 0.297389
Step #84000	Loss: 0.324820
Step #88000	Loss: 0.300944
Step #92000	Loss: 0.320066
Step #96000	Loss: 0.294378
Step #100000	Loss: 0.303587
Step #104000	Loss: 0.301300
Step #108000	Loss: 0.316468
Step #112000	Loss: 0.291946
Step #116000	Loss: 0.287378
Step #120000	Loss: 0.296258
Step #124000	Loss: 0.299531
Step #128000	Loss: 0.311474
Step #132000	Loss: 0.310939
Step #136000	Loss: 0.311179
Step #140000	Loss: 0.307333
Step #144000	Loss: 0.306005
Step #148000	Loss: 0.308223
Step #152000	Loss: 0.323670
Step #156000	Loss: 0.301003
Step #160000	Loss: 0.309274
Step #164000	Loss: 0.292238
Step #168000	Loss: 0.322574
Step #172000	Loss: 0.292757
Step #176000	Loss: 0.282039
Step #180000	Loss: 0.306149
Step #184000	Loss: 0.292240
Step #188000	Loss: 0.326151
Step #192000	Loss: 0.313590
Step #196000	Loss: 0.317631
Step #200000	Loss: 0.305807
Step #204000	Loss: 0.297293
Step #208000	Loss: 0.319187
Step #212000	Loss: 0.303514
Step #216000	Loss: 0.323146
Step #220000	Loss: 0.294884
Code block 'train epoch=3' took: 1659960.20854 ms
train loss 0.30523645877838135
Code block 'val epoch=3' took: 87949.60177 ms
validation loss 0.770842432975769
Step #0	Loss: 0.332266
Step #4000	Loss: 0.292154
Step #8000	Loss: 0.284698
Step #12000	Loss: 0.308409
Step #16000	Loss: 0.300674
Step #20000	Loss: 0.301134
Step #24000	Loss: 0.311331
Step #28000	Loss: 0.298213
Step #32000	Loss: 0.295772
Step #36000	Loss: 0.293232
Step #40000	Loss: 0.313476
Step #44000	Loss: 0.285944
Step #48000	Loss: 0.299235
Step #52000	Loss: 0.294783
Step #56000	Loss: 0.295317
Step #60000	Loss: 0.300723
Step #64000	Loss: 0.293865
Step #68000	Loss: 0.308776
Step #72000	Loss: 0.293705
Step #76000	Loss: 0.296502
Step #80000	Loss: 0.295156
Step #84000	Loss: 0.321648
Step #88000	Loss: 0.297511
Step #92000	Loss: 0.310757
Step #96000	Loss: 0.299317
Step #100000	Loss: 0.302728
Step #104000	Loss: 0.302978
Step #108000	Loss: 0.313357
Step #112000	Loss: 0.297517
Step #116000	Loss: 0.299962
Step #120000	Loss: 0.286152
Step #124000	Loss: 0.298689
Step #128000	Loss: 0.305796
Step #132000	Loss: 0.310781
Step #136000	Loss: 0.327291
Step #140000	Loss: 0.314351
Step #144000	Loss: 0.303571
Step #148000	Loss: 0.295461
Step #152000	Loss: 0.305007
Step #156000	Loss: 0.304394
Step #160000	Loss: 0.313996
Step #164000	Loss: 0.286316
Step #168000	Loss: 0.308659
Step #172000	Loss: 0.294935
Step #176000	Loss: 0.297526
Step #180000	Loss: 0.308670
Step #184000	Loss: 0.291718
Step #188000	Loss: 0.313598
Step #192000	Loss: 0.308346
Step #196000	Loss: 0.318424
Step #200000	Loss: 0.310173
Step #204000	Loss: 0.278089
Step #208000	Loss: 0.309073
Step #212000	Loss: 0.301390
Step #216000	Loss: 0.319472
Step #220000	Loss: 0.293840
Code block 'train epoch=4' took: 1662989.23143 ms
train loss 0.3028595745563507
Code block 'val epoch=4' took: 87318.44799 ms
validation loss 0.7866643667221069
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --cufile-thread-count 64 --batch-size 8192 --epochs 5'
[WARN  tini (2904466)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-23 05:31:14.570836: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-23 05:31:17.916367: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-23 05:31:44.666250: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-23 05:35:26.113356: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-23 05:35:26.505699: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f08e24686e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-23 05:35:26.505781: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-23 05:35:26.668929: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-23 05:35:27.688182: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-23 05:35:28.007065: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.563362
Step #4000	Loss: 0.351662
Step #8000	Loss: 0.361755
Step #12000	Loss: 0.322374
Step #16000	Loss: 0.315115
Step #20000	Loss: 0.327029
Step #24000	Loss: 0.441088
Step #28000	Loss: 0.451059
Step #32000	Loss: 0.427895
Step #36000	Loss: 0.418962
Step #40000	Loss: 0.353772
Step #44000	Loss: 0.361149
Step #48000	Loss: 0.360470
Step #52000	Loss: 0.365333
Step #56000	Loss: 0.402135
Step #60000	Loss: 0.415227
Step #64000	Loss: 0.327590
Step #68000	Loss: 0.380800
Step #72000	Loss: 0.353871
Step #76000	Loss: 0.384361
Step #80000	Loss: 0.405122
Step #84000	Loss: 0.416113
Step #88000	Loss: 0.386766
Step #92000	Loss: 0.373073
Step #96000	Loss: 0.361793
Step #100000	Loss: 0.336870
Step #104000	Loss: 0.312767
Step #108000	Loss: 0.332152
Step #112000	Loss: 0.344133
Step #116000	Loss: 0.424751
Step #120000	Loss: 0.335230
Step #124000	Loss: 0.385410
Step #128000	Loss: 0.401369
Step #132000	Loss: 0.320506
Step #136000	Loss: 0.442724
Step #140000	Loss: 0.417248
Step #144000	Loss: 0.355044
Step #148000	Loss: 0.342466
Step #152000	Loss: 0.348076
Step #156000	Loss: 0.364802
Step #160000	Loss: 0.384695
Step #164000	Loss: 0.340380
Step #168000	Loss: 0.366243
Step #172000	Loss: 0.326880
Step #176000	Loss: 0.352660
Step #180000	Loss: 0.366962
Step #184000	Loss: 0.306476
Step #188000	Loss: 0.473843
Step #192000	Loss: 0.441566
Step #196000	Loss: 0.456066
Step #200000	Loss: 0.336224
Step #204000	Loss: 0.331531
Step #208000	Loss: 0.318756
Step #212000	Loss: 0.318741
Step #216000	Loss: 0.410732
Step #220000	Loss: 0.418478
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 1671377.52717 ms
train loss 0.35918036103248596
Code block 'val epoch=0' took: 85422.98014 ms
validation loss 0.6459074020385742
Step #0	Loss: 0.451172
Step #4000	Loss: 0.307862
Step #8000	Loss: 0.315954
Step #12000	Loss: 0.313517
Step #16000	Loss: 0.312093
Step #20000	Loss: 0.313243
Step #24000	Loss: 0.345838
Step #28000	Loss: 0.365003
Step #32000	Loss: 0.349858
Step #36000	Loss: 0.338602
Step #40000	Loss: 0.326964
Step #44000	Loss: 0.323308
Step #48000	Loss: 0.313426
Step #52000	Loss: 0.335262
Step #56000	Loss: 0.332433
Step #60000	Loss: 0.340035
Step #64000	Loss: 0.296127
Step #68000	Loss: 0.334239
Step #72000	Loss: 0.319076
Step #76000	Loss: 0.332050
Step #80000	Loss: 0.343763
Step #84000	Loss: 0.349665
Step #88000	Loss: 0.336440
Step #92000	Loss: 0.322114
Step #96000	Loss: 0.315343
Step #100000	Loss: 0.318210
Step #104000	Loss: 0.299100
Step #108000	Loss: 0.328234
Step #112000	Loss: 0.316177
Step #116000	Loss: 0.343995
Step #120000	Loss: 0.313314
Step #124000	Loss: 0.313614
Step #128000	Loss: 0.338948
Step #132000	Loss: 0.305633
Step #136000	Loss: 0.367271
Step #140000	Loss: 0.362018
Step #144000	Loss: 0.315918
Step #148000	Loss: 0.314691
Step #152000	Loss: 0.321591
Step #156000	Loss: 0.322320
Step #160000	Loss: 0.320491
Step #164000	Loss: 0.308649
Step #168000	Loss: 0.329328
Step #172000	Loss: 0.307597
Step #176000	Loss: 0.302469
Step #180000	Loss: 0.325592
Step #184000	Loss: 0.302667
Step #188000	Loss: 0.388279
Step #192000	Loss: 0.360830
Step #196000	Loss: 0.375357
Step #200000	Loss: 0.308130
Step #204000	Loss: 0.296401
Step #208000	Loss: 0.310954
Step #212000	Loss: 0.314005
Step #216000	Loss: 0.331966
Step #220000	Loss: 0.343974
Code block 'train epoch=1' took: 1648070.64803 ms
train loss 0.322998970746994
Code block 'val epoch=1' took: 85522.67615 ms
validation loss 0.6541905403137207
Step #0	Loss: 0.349198
Step #4000	Loss: 0.295752
Step #8000	Loss: 0.299415
Step #12000	Loss: 0.307875
Step #16000	Loss: 0.292872
Step #20000	Loss: 0.308673
Step #24000	Loss: 0.329085
Step #28000	Loss: 0.320790
Step #32000	Loss: 0.313746
Step #36000	Loss: 0.312587
Step #40000	Loss: 0.317536
Step #44000	Loss: 0.297324
Step #48000	Loss: 0.296633
Step #52000	Loss: 0.316262
Step #56000	Loss: 0.315224
Step #60000	Loss: 0.315793
Step #64000	Loss: 0.296189
Step #68000	Loss: 0.319110
Step #72000	Loss: 0.302527
Step #76000	Loss: 0.308412
Step #80000	Loss: 0.319510
Step #84000	Loss: 0.334842
Step #88000	Loss: 0.310718
Step #92000	Loss: 0.317385
Step #96000	Loss: 0.300878
Step #100000	Loss: 0.309294
Step #104000	Loss: 0.294001
Step #108000	Loss: 0.320670
Step #112000	Loss: 0.296530
Step #116000	Loss: 0.322739
Step #120000	Loss: 0.307231
Step #124000	Loss: 0.308704
Step #128000	Loss: 0.321088
Step #132000	Loss: 0.312936
Step #136000	Loss: 0.352231
Step #140000	Loss: 0.319160
Step #144000	Loss: 0.314852
Step #148000	Loss: 0.304439
Step #152000	Loss: 0.311335
Step #156000	Loss: 0.310640
Step #160000	Loss: 0.307881
Step #164000	Loss: 0.287378
Step #168000	Loss: 0.321978
Step #172000	Loss: 0.291727
Step #176000	Loss: 0.298999
Step #180000	Loss: 0.298535
Step #184000	Loss: 0.289237
Step #188000	Loss: 0.335676
Step #192000	Loss: 0.330380
Step #196000	Loss: 0.335574
Step #200000	Loss: 0.316799
Step #204000	Loss: 0.292214
Step #208000	Loss: 0.302977
Step #212000	Loss: 0.309754
Step #216000	Loss: 0.320998
Step #220000	Loss: 0.326545
Code block 'train epoch=2' took: 1647762.26292 ms
train loss 0.310451865196228
Code block 'val epoch=2' took: 85848.74559 ms
validation loss 0.6953576803207397
Step #0	Loss: 0.325418
Step #4000	Loss: 0.292081
Step #8000	Loss: 0.291828
Step #12000	Loss: 0.289899
Step #16000	Loss: 0.301113
Step #20000	Loss: 0.299350
Step #24000	Loss: 0.317371
Step #28000	Loss: 0.302833
Step #32000	Loss: 0.305491
Step #36000	Loss: 0.305937
Step #40000	Loss: 0.314758
Step #44000	Loss: 0.288605
Step #48000	Loss: 0.302700
Step #52000	Loss: 0.300922
Step #56000	Loss: 0.314042
Step #60000	Loss: 0.309363
Step #64000	Loss: 0.291711
Step #68000	Loss: 0.312071
Step #72000	Loss: 0.304757
Step #76000	Loss: 0.300222
Step #80000	Loss: 0.299646
Step #84000	Loss: 0.329788
Step #88000	Loss: 0.293008
Step #92000	Loss: 0.309605
Step #96000	Loss: 0.311299
Step #100000	Loss: 0.302897
Step #104000	Loss: 0.291782
Step #108000	Loss: 0.323527
Step #112000	Loss: 0.300462
Step #116000	Loss: 0.308870
Step #120000	Loss: 0.297934
Step #124000	Loss: 0.298753
Step #128000	Loss: 0.307311
Step #132000	Loss: 0.306032
Step #136000	Loss: 0.329863
Step #140000	Loss: 0.324910
Step #144000	Loss: 0.300593
Step #148000	Loss: 0.302847
Step #152000	Loss: 0.298491
Step #156000	Loss: 0.308599
Step #160000	Loss: 0.280025
Step #164000	Loss: 0.298772
Step #168000	Loss: 0.317946
Step #172000	Loss: 0.296370
Step #176000	Loss: 0.294882
Step #180000	Loss: 0.295157
Step #184000	Loss: 0.291665
Step #188000	Loss: 0.335392
Step #192000	Loss: 0.323496
Step #196000	Loss: 0.312071
Step #200000	Loss: 0.312612
Step #204000	Loss: 0.286620
Step #208000	Loss: 0.285418
Step #212000	Loss: 0.301119
Step #216000	Loss: 0.314782
Step #220000	Loss: 0.311195
Code block 'train epoch=3' took: 1646371.03590 ms
train loss 0.3053432106971741
Code block 'val epoch=3' took: 84799.33861 ms
validation loss 0.7173976302146912
Step #0	Loss: 0.321173
Step #4000	Loss: 0.289947
Step #8000	Loss: 0.288652
Step #12000	Loss: 0.295034
Step #16000	Loss: 0.303968
Step #20000	Loss: 0.304153
Step #24000	Loss: 0.317572
Step #28000	Loss: 0.313489
Step #32000	Loss: 0.300633
Step #36000	Loss: 0.299856
Step #40000	Loss: 0.313232
Step #44000	Loss: 0.271316
Step #48000	Loss: 0.290694
Step #52000	Loss: 0.303189
Step #56000	Loss: 0.295380
Step #60000	Loss: 0.300164
Step #64000	Loss: 0.292315
Step #68000	Loss: 0.309481
Step #72000	Loss: 0.293033
Step #76000	Loss: 0.298488
Step #80000	Loss: 0.296157
Step #84000	Loss: 0.317945
Step #88000	Loss: 0.293584
Step #92000	Loss: 0.310283
Step #96000	Loss: 0.314322
Step #100000	Loss: 0.307031
Step #104000	Loss: 0.298387
Step #108000	Loss: 0.313180
Step #112000	Loss: 0.302411
Step #116000	Loss: 0.312460
Step #120000	Loss: 0.303629
Step #124000	Loss: 0.290382
Step #128000	Loss: 0.310074
Step #132000	Loss: 0.308360
Step #136000	Loss: 0.322666
Step #140000	Loss: 0.313288
Step #144000	Loss: 0.299551
Step #148000	Loss: 0.297821
Step #152000	Loss: 0.300630
Step #156000	Loss: 0.300452
Step #160000	Loss: 0.288280
Step #164000	Loss: 0.298550
Step #168000	Loss: 0.306741
Step #172000	Loss: 0.287397
Step #176000	Loss: 0.294277
Step #180000	Loss: 0.292477
Step #184000	Loss: 0.290016
Step #188000	Loss: 0.319580
Step #192000	Loss: 0.321356
Step #196000	Loss: 0.319563
Step #200000	Loss: 0.306326
Step #204000	Loss: 0.282459
Step #208000	Loss: 0.284953
Step #212000	Loss: 0.301355
Step #216000	Loss: 0.307171
Step #220000	Loss: 0.295740
Code block 'train epoch=4' took: 1647313.76706 ms
train loss 0.30258819460868835
Code block 'val epoch=4' took: 85207.77215 ms
validation loss 0.7477625012397766
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --cufile-thread-count 64 --batch-size 8192 --epochs 5'
[WARN  tini (3025883)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-23 08:00:11.170695: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-23 08:00:14.566488: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-23 08:00:40.188337: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-23 08:04:23.444891: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-23 08:04:23.831442: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f5551d7bd30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-23 08:04:23.831516: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-23 08:04:23.962880: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-23 08:04:24.930906: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-23 08:04:25.221385: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 1.761211
Step #4000	Loss: 0.341750
Step #8000	Loss: 0.331070
Step #12000	Loss: 0.349938
Step #16000	Loss: 0.344455
Step #20000	Loss: 0.351703
Step #24000	Loss: 0.356279
Step #28000	Loss: 0.342609
Step #32000	Loss: 0.334356
Step #36000	Loss: 0.328495
Step #40000	Loss: 0.339168
Step #44000	Loss: 0.300375
Step #48000	Loss: 0.312329
Step #52000	Loss: 0.331930
Step #56000	Loss: 0.334553
Step #60000	Loss: 0.329938
Step #64000	Loss: 0.314997
Step #68000	Loss: 0.336279
Step #72000	Loss: 0.389905
Step #76000	Loss: 0.322069
Step #80000	Loss: 0.355742
Step #84000	Loss: 0.360425
Step #88000	Loss: 0.421575
Step #92000	Loss: 0.413315
Step #96000	Loss: 0.417762
Step #100000	Loss: 0.368453
Step #104000	Loss: 0.347771
Step #108000	Loss: 0.360733
Step #112000	Loss: 0.307781
Step #116000	Loss: 0.429112
Step #120000	Loss: 0.319695
Step #124000	Loss: 0.331193
Step #128000	Loss: 0.339398
Step #132000	Loss: 0.335602
Step #136000	Loss: 0.449105
Step #140000	Loss: 0.407440
Step #144000	Loss: 0.373161
Step #148000	Loss: 0.359051
Step #152000	Loss: 0.327863
Step #156000	Loss: 0.342076
Step #160000	Loss: 0.405772
Step #164000	Loss: 0.324414
Step #168000	Loss: 0.339287
Step #172000	Loss: 0.379246
Step #176000	Loss: 0.409542
Step #180000	Loss: 0.368507
Step #184000	Loss: 0.328176
Step #188000	Loss: 0.358994
Step #192000	Loss: 0.358016
Step #196000	Loss: 0.353545
Step #200000	Loss: 0.360457
Step #204000	Loss: 0.332306
Step #208000	Loss: 0.348769
Step #212000	Loss: 0.344092
Step #216000	Loss: 0.353686
Step #220000	Loss: 0.428613
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 1670254.09605 ms
train loss 0.35847049951553345
Code block 'val epoch=0' took: 84878.86043 ms
validation loss 0.6500347852706909
Step #0	Loss: 0.505210
Step #4000	Loss: 0.291423
Step #8000	Loss: 0.301184
Step #12000	Loss: 0.320497
Step #16000	Loss: 0.315324
Step #20000	Loss: 0.316721
Step #24000	Loss: 0.320819
Step #28000	Loss: 0.310842
Step #32000	Loss: 0.313314
Step #36000	Loss: 0.306577
Step #40000	Loss: 0.314741
Step #44000	Loss: 0.293742
Step #48000	Loss: 0.300191
Step #52000	Loss: 0.316529
Step #56000	Loss: 0.308594
Step #60000	Loss: 0.308535
Step #64000	Loss: 0.313545
Step #68000	Loss: 0.325368
Step #72000	Loss: 0.336211
Step #76000	Loss: 0.301555
Step #80000	Loss: 0.318190
Step #84000	Loss: 0.332814
Step #88000	Loss: 0.351246
Step #92000	Loss: 0.341108
Step #96000	Loss: 0.341625
Step #100000	Loss: 0.323594
Step #104000	Loss: 0.319577
Step #108000	Loss: 0.333661
Step #112000	Loss: 0.301970
Step #116000	Loss: 0.342927
Step #120000	Loss: 0.315552
Step #124000	Loss: 0.304098
Step #128000	Loss: 0.311253
Step #132000	Loss: 0.320139
Step #136000	Loss: 0.368082
Step #140000	Loss: 0.330419
Step #144000	Loss: 0.322103
Step #148000	Loss: 0.311224
Step #152000	Loss: 0.305890
Step #156000	Loss: 0.321385
Step #160000	Loss: 0.335155
Step #164000	Loss: 0.306312
Step #168000	Loss: 0.313188
Step #172000	Loss: 0.319989
Step #176000	Loss: 0.333987
Step #180000	Loss: 0.319876
Step #184000	Loss: 0.313378
Step #188000	Loss: 0.334546
Step #192000	Loss: 0.333507
Step #196000	Loss: 0.322595
Step #200000	Loss: 0.323559
Step #204000	Loss: 0.313956
Step #208000	Loss: 0.318484
Step #212000	Loss: 0.316414
Step #216000	Loss: 0.314613
Step #220000	Loss: 0.344678
Code block 'train epoch=1' took: 1645680.34441 ms
train loss 0.3220134377479553
Code block 'val epoch=1' took: 84477.13293 ms
validation loss 0.6818743348121643
Step #0	Loss: 0.391203
Step #4000	Loss: 0.299808
Step #8000	Loss: 0.305219
Step #12000	Loss: 0.305644
Step #16000	Loss: 0.305678
Step #20000	Loss: 0.315665
Step #24000	Loss: 0.311612
Step #28000	Loss: 0.312545
Step #32000	Loss: 0.305571
Step #36000	Loss: 0.302353
Step #40000	Loss: 0.304965
Step #44000	Loss: 0.285468
Step #48000	Loss: 0.303252
Step #52000	Loss: 0.307183
Step #56000	Loss: 0.314877
Step #60000	Loss: 0.305299
Step #64000	Loss: 0.291150
Step #68000	Loss: 0.314114
Step #72000	Loss: 0.310820
Step #76000	Loss: 0.297364
Step #80000	Loss: 0.309933
Step #84000	Loss: 0.330732
Step #88000	Loss: 0.319133
Step #92000	Loss: 0.323853
Step #96000	Loss: 0.327055
Step #100000	Loss: 0.313730
Step #104000	Loss: 0.312145
Step #108000	Loss: 0.315604
Step #112000	Loss: 0.294185
Step #116000	Loss: 0.323097
Step #120000	Loss: 0.298570
Step #124000	Loss: 0.300439
Step #128000	Loss: 0.311896
Step #132000	Loss: 0.320450
Step #136000	Loss: 0.335956
Step #140000	Loss: 0.305489
Step #144000	Loss: 0.312238
Step #148000	Loss: 0.301866
Step #152000	Loss: 0.310593
Step #156000	Loss: 0.301449
Step #160000	Loss: 0.309140
Step #164000	Loss: 0.295323
Step #168000	Loss: 0.310974
Step #172000	Loss: 0.300910
Step #176000	Loss: 0.305385
Step #180000	Loss: 0.289725
Step #184000	Loss: 0.300041
Step #188000	Loss: 0.321107
Step #192000	Loss: 0.318941
Step #196000	Loss: 0.318588
Step #200000	Loss: 0.317004
Step #204000	Loss: 0.289410
Step #208000	Loss: 0.318754
Step #212000	Loss: 0.306514
Step #216000	Loss: 0.310759
Step #220000	Loss: 0.312346
Code block 'train epoch=2' took: 1647478.40055 ms
train loss 0.3094440698623657
Code block 'val epoch=2' took: 85092.76417 ms
validation loss 0.6848015189170837
Step #0	Loss: 0.347610
Step #4000	Loss: 0.295548
Step #8000	Loss: 0.277095
Step #12000	Loss: 0.301769
Step #16000	Loss: 0.299240
Step #20000	Loss: 0.298118
Step #24000	Loss: 0.313285
Step #28000	Loss: 0.312649
Step #32000	Loss: 0.292785
Step #36000	Loss: 0.296151
Step #40000	Loss: 0.307936
Step #44000	Loss: 0.276845
Step #48000	Loss: 0.289577
Step #52000	Loss: 0.283980
Step #56000	Loss: 0.296701
Step #60000	Loss: 0.293695
Step #64000	Loss: 0.277897
Step #68000	Loss: 0.312503
Step #72000	Loss: 0.303352
Step #76000	Loss: 0.290557
Step #80000	Loss: 0.296282
Step #84000	Loss: 0.307298
Step #88000	Loss: 0.313349
Step #92000	Loss: 0.318703
Step #96000	Loss: 0.309855
Step #100000	Loss: 0.293257
Step #104000	Loss: 0.304531
Step #108000	Loss: 0.312440
Step #112000	Loss: 0.302994
Step #116000	Loss: 0.313585
Step #120000	Loss: 0.303440
Step #124000	Loss: 0.299215
Step #128000	Loss: 0.302169
Step #132000	Loss: 0.315240
Step #136000	Loss: 0.323319
Step #140000	Loss: 0.292055
Step #144000	Loss: 0.304843
Step #148000	Loss: 0.298116
Step #152000	Loss: 0.290545
Step #156000	Loss: 0.304823
Step #160000	Loss: 0.294774
Step #164000	Loss: 0.301352
Step #168000	Loss: 0.315103
Step #172000	Loss: 0.304219
Step #176000	Loss: 0.295805
Step #180000	Loss: 0.300194
Step #184000	Loss: 0.288446
Step #188000	Loss: 0.322947
Step #192000	Loss: 0.314360
Step #196000	Loss: 0.308878
Step #200000	Loss: 0.310547
Step #204000	Loss: 0.284400
Step #208000	Loss: 0.304013
Step #212000	Loss: 0.312808
Step #216000	Loss: 0.310027
Step #220000	Loss: 0.299235
Code block 'train epoch=3' took: 1646890.44235 ms
train loss 0.3044338822364807
Code block 'val epoch=3' took: 85411.33863 ms
validation loss 0.7183983325958252
Step #0	Loss: 0.337561
Step #4000	Loss: 0.284503
Step #8000	Loss: 0.288274
Step #12000	Loss: 0.302005
Step #16000	Loss: 0.294246
Step #20000	Loss: 0.312934
Step #24000	Loss: 0.308532
Step #28000	Loss: 0.302119
Step #32000	Loss: 0.289828
Step #36000	Loss: 0.295022
Step #40000	Loss: 0.304327
Step #44000	Loss: 0.284521
Step #48000	Loss: 0.300654
Step #52000	Loss: 0.290861
Step #56000	Loss: 0.297853
Step #60000	Loss: 0.297423
Step #64000	Loss: 0.290128
Step #68000	Loss: 0.303856
Step #72000	Loss: 0.301517
Step #76000	Loss: 0.285364
Step #80000	Loss: 0.309442
Step #84000	Loss: 0.306243
Step #88000	Loss: 0.306764
Step #92000	Loss: 0.307650
Step #96000	Loss: 0.301258
Step #100000	Loss: 0.301755
Step #104000	Loss: 0.289828
Step #108000	Loss: 0.314780
Step #112000	Loss: 0.293158
Step #116000	Loss: 0.310938
Step #120000	Loss: 0.301813
Step #124000	Loss: 0.291749
Step #128000	Loss: 0.305356
Step #132000	Loss: 0.303615
Step #136000	Loss: 0.326038
Step #140000	Loss: 0.302342
Step #144000	Loss: 0.300387
Step #148000	Loss: 0.302732
Step #152000	Loss: 0.305745
Step #156000	Loss: 0.310288
Step #160000	Loss: 0.288797
Step #164000	Loss: 0.288552
Step #168000	Loss: 0.307224
Step #172000	Loss: 0.297865
Step #176000	Loss: 0.300316
Step #180000	Loss: 0.289245
Step #184000	Loss: 0.293194
Step #188000	Loss: 0.316737
Step #192000	Loss: 0.318526
Step #196000	Loss: 0.309765
Step #200000	Loss: 0.307711
Step #204000	Loss: 0.287835
Step #208000	Loss: 0.302884
Step #212000	Loss: 0.291864
Step #216000	Loss: 0.313630
Step #220000	Loss: 0.304737
Code block 'train epoch=4' took: 1650006.06695 ms
train loss 0.3019193410873413
Code block 'val epoch=4' took: 84720.38654 ms
validation loss 0.7454853057861328
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --cufile-thread-count 64 --batch-size 8192 --epochs 5'
[WARN  tini (3147223)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-23 10:29:06.923520: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-23 10:29:10.459274: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-23 10:29:38.590944: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-23 10:33:24.788130: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-23 10:33:25.154886: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f98c8befc40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-23 10:33:25.154955: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-23 10:33:25.305076: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-23 10:33:26.432918: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-23 10:33:26.804559: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 2.636547
Step #4000	Loss: 0.403048
Step #8000	Loss: 0.320283
Step #12000	Loss: 0.324142
Step #16000	Loss: 0.334530
Step #20000	Loss: 0.377371
Step #24000	Loss: 0.454346
Step #28000	Loss: 0.344855
Step #32000	Loss: 0.362236
Step #36000	Loss: 0.444342
Step #40000	Loss: 0.335203
Step #44000	Loss: 0.416611
Step #48000	Loss: 0.304442
Step #52000	Loss: 0.354096
Step #56000	Loss: 0.421116
Step #60000	Loss: 0.314503
Step #64000	Loss: 0.340374
Step #68000	Loss: 0.426498
Step #72000	Loss: 0.393498
Step #76000	Loss: 0.440272
Step #80000	Loss: 0.322035
Step #84000	Loss: 0.360743
Step #88000	Loss: 0.365930
Step #92000	Loss: 0.424095
Step #96000	Loss: 0.375331
Step #100000	Loss: 0.377529
Step #104000	Loss: 0.319280
Step #108000	Loss: 0.350835
Step #112000	Loss: 0.338646
Step #116000	Loss: 0.342940
Step #120000	Loss: 0.350436
Step #124000	Loss: 0.334653
Step #128000	Loss: 0.357145
Step #132000	Loss: 0.374027
Step #136000	Loss: 0.443793
Step #140000	Loss: 0.338290
Step #144000	Loss: 0.343315
Step #148000	Loss: 0.370281
Step #152000	Loss: 0.417693
Step #156000	Loss: 0.343445
Step #160000	Loss: 0.332449
Step #164000	Loss: 0.313965
Step #168000	Loss: 0.366761
Step #172000	Loss: 0.365135
Step #176000	Loss: 0.344667
Step #180000	Loss: 0.339977
Step #184000	Loss: 0.357857
Step #188000	Loss: 0.477318
Step #192000	Loss: 0.339383
Step #196000	Loss: 0.383223
Step #200000	Loss: 0.330057
Step #204000	Loss: 0.328440
Step #208000	Loss: 0.317842
Step #212000	Loss: 0.351312
Step #216000	Loss: 0.361674
Step #220000	Loss: 0.345359
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 1675554.54652 ms
train loss 0.35919061303138733
Code block 'val epoch=0' took: 84795.62913 ms
validation loss 0.6295465230941772
Step #0	Loss: 0.436508
Step #4000	Loss: 0.328056
Step #8000	Loss: 0.289119
Step #12000	Loss: 0.317712
Step #16000	Loss: 0.312887
Step #20000	Loss: 0.341955
Step #24000	Loss: 0.356824
Step #28000	Loss: 0.311770
Step #32000	Loss: 0.315244
Step #36000	Loss: 0.357996
Step #40000	Loss: 0.313252
Step #44000	Loss: 0.335001
Step #48000	Loss: 0.306921
Step #52000	Loss: 0.319524
Step #56000	Loss: 0.340597
Step #60000	Loss: 0.294465
Step #64000	Loss: 0.309501
Step #68000	Loss: 0.351482
Step #72000	Loss: 0.326219
Step #76000	Loss: 0.345865
Step #80000	Loss: 0.305528
Step #84000	Loss: 0.325143
Step #88000	Loss: 0.318989
Step #92000	Loss: 0.348831
Step #96000	Loss: 0.332431
Step #100000	Loss: 0.321141
Step #104000	Loss: 0.309613
Step #108000	Loss: 0.320450
Step #112000	Loss: 0.323858
Step #116000	Loss: 0.320067
Step #120000	Loss: 0.315614
Step #124000	Loss: 0.316789
Step #128000	Loss: 0.332270
Step #132000	Loss: 0.340296
Step #136000	Loss: 0.363285
Step #140000	Loss: 0.323494
Step #144000	Loss: 0.319362
Step #148000	Loss: 0.330853
Step #152000	Loss: 0.336642
Step #156000	Loss: 0.315573
Step #160000	Loss: 0.317976
Step #164000	Loss: 0.320967
Step #168000	Loss: 0.328964
Step #172000	Loss: 0.303272
Step #176000	Loss: 0.308751
Step #180000	Loss: 0.311448
Step #184000	Loss: 0.323117
Step #188000	Loss: 0.367409
Step #192000	Loss: 0.325756
Step #196000	Loss: 0.330364
Step #200000	Loss: 0.313945
Step #204000	Loss: 0.304888
Step #208000	Loss: 0.303961
Step #212000	Loss: 0.329995
Step #216000	Loss: 0.328670
Step #220000	Loss: 0.316509
Code block 'train epoch=1' took: 1651554.52902 ms
train loss 0.32192131876945496
Code block 'val epoch=1' took: 84824.23398 ms
validation loss 0.6484110355377197
Step #0	Loss: 0.358162
Step #4000	Loss: 0.306173
Step #8000	Loss: 0.295545
Step #12000	Loss: 0.315971
Step #16000	Loss: 0.305096
Step #20000	Loss: 0.319985
Step #24000	Loss: 0.322969
Step #28000	Loss: 0.305395
Step #32000	Loss: 0.297383
Step #36000	Loss: 0.329186
Step #40000	Loss: 0.308048
Step #44000	Loss: 0.307950
Step #48000	Loss: 0.294142
Step #52000	Loss: 0.308093
Step #56000	Loss: 0.330970
Step #60000	Loss: 0.309443
Step #64000	Loss: 0.308903
Step #68000	Loss: 0.312687
Step #72000	Loss: 0.301501
Step #76000	Loss: 0.316027
Step #80000	Loss: 0.297873
Step #84000	Loss: 0.321961
Step #88000	Loss: 0.310016
Step #92000	Loss: 0.319123
Step #96000	Loss: 0.317312
Step #100000	Loss: 0.308250
Step #104000	Loss: 0.315512
Step #108000	Loss: 0.312375
Step #112000	Loss: 0.319531
Step #116000	Loss: 0.310458
Step #120000	Loss: 0.302423
Step #124000	Loss: 0.314603
Step #128000	Loss: 0.314133
Step #132000	Loss: 0.317838
Step #136000	Loss: 0.325519
Step #140000	Loss: 0.314185
Step #144000	Loss: 0.299248
Step #148000	Loss: 0.310356
Step #152000	Loss: 0.317119
Step #156000	Loss: 0.305384
Step #160000	Loss: 0.312038
Step #164000	Loss: 0.290820
Step #168000	Loss: 0.321332
Step #172000	Loss: 0.304744
Step #176000	Loss: 0.298662
Step #180000	Loss: 0.297355
Step #184000	Loss: 0.307934
Step #188000	Loss: 0.338145
Step #192000	Loss: 0.317584
Step #196000	Loss: 0.314411
Step #200000	Loss: 0.316301
Step #204000	Loss: 0.303926
Step #208000	Loss: 0.290501
Step #212000	Loss: 0.307548
Step #216000	Loss: 0.323696
Step #220000	Loss: 0.301435
Code block 'train epoch=2' took: 1650841.78418 ms
train loss 0.30988937616348267
Code block 'val epoch=2' took: 84925.92720 ms
validation loss 0.677064836025238
Step #0	Loss: 0.337540
Step #4000	Loss: 0.298552
Step #8000	Loss: 0.291108
Step #12000	Loss: 0.305616
Step #16000	Loss: 0.302003
Step #20000	Loss: 0.309475
Step #24000	Loss: 0.311432
Step #28000	Loss: 0.302314
Step #32000	Loss: 0.292871
Step #36000	Loss: 0.305092
Step #40000	Loss: 0.305782
Step #44000	Loss: 0.291368
Step #48000	Loss: 0.288371
Step #52000	Loss: 0.304707
Step #56000	Loss: 0.293740
Step #60000	Loss: 0.299000
Step #64000	Loss: 0.304491
Step #68000	Loss: 0.311036
Step #72000	Loss: 0.305059
Step #76000	Loss: 0.305048
Step #80000	Loss: 0.297484
Step #84000	Loss: 0.321748
Step #88000	Loss: 0.299158
Step #92000	Loss: 0.323015
Step #96000	Loss: 0.313778
Step #100000	Loss: 0.300336
Step #104000	Loss: 0.306342
Step #108000	Loss: 0.302987
Step #112000	Loss: 0.311903
Step #116000	Loss: 0.298365
Step #120000	Loss: 0.314788
Step #124000	Loss: 0.295956
Step #128000	Loss: 0.313861
Step #132000	Loss: 0.315969
Step #136000	Loss: 0.317827
Step #140000	Loss: 0.317829
Step #144000	Loss: 0.291036
Step #148000	Loss: 0.303912
Step #152000	Loss: 0.310487
Step #156000	Loss: 0.317833
Step #160000	Loss: 0.303132
Step #164000	Loss: 0.295056
Step #168000	Loss: 0.314274
Step #172000	Loss: 0.295519
Step #176000	Loss: 0.294273
Step #180000	Loss: 0.299648
Step #184000	Loss: 0.304906
Step #188000	Loss: 0.322300
Step #192000	Loss: 0.312125
Step #196000	Loss: 0.307242
Step #200000	Loss: 0.305798
Step #204000	Loss: 0.295034
Step #208000	Loss: 0.306779
Step #212000	Loss: 0.307981
Step #216000	Loss: 0.315331
Step #220000	Loss: 0.301048
Code block 'train epoch=3' took: 1651172.95660 ms
train loss 0.3050786256790161
Code block 'val epoch=3' took: 85494.58127 ms
validation loss 0.7067635655403137
Step #0	Loss: 0.327533
Step #4000	Loss: 0.300152
Step #8000	Loss: 0.288099
Step #12000	Loss: 0.307740
Step #16000	Loss: 0.306275
Step #20000	Loss: 0.309048
Step #24000	Loss: 0.302832
Step #28000	Loss: 0.309727
Step #32000	Loss: 0.294610
Step #36000	Loss: 0.309057
Step #40000	Loss: 0.295602
Step #44000	Loss: 0.297600
Step #48000	Loss: 0.285163
Step #52000	Loss: 0.294089
Step #56000	Loss: 0.292780
Step #60000	Loss: 0.297143
Step #64000	Loss: 0.294155
Step #68000	Loss: 0.312854
Step #72000	Loss: 0.288290
Step #76000	Loss: 0.296676
Step #80000	Loss: 0.300576
Step #84000	Loss: 0.308005
Step #88000	Loss: 0.301968
Step #92000	Loss: 0.317216
Step #96000	Loss: 0.306090
Step #100000	Loss: 0.300380
Step #104000	Loss: 0.302926
Step #108000	Loss: 0.309565
Step #112000	Loss: 0.299442
Step #116000	Loss: 0.293309
Step #120000	Loss: 0.306849
Step #124000	Loss: 0.308542
Step #128000	Loss: 0.321093
Step #132000	Loss: 0.313233
Step #136000	Loss: 0.323225
Step #140000	Loss: 0.321098
Step #144000	Loss: 0.295968
Step #148000	Loss: 0.305501
Step #152000	Loss: 0.309389
Step #156000	Loss: 0.304394
Step #160000	Loss: 0.304667
Step #164000	Loss: 0.291052
Step #168000	Loss: 0.314946
Step #172000	Loss: 0.293223
Step #176000	Loss: 0.285617
Step #180000	Loss: 0.288528
Step #184000	Loss: 0.298059
Step #188000	Loss: 0.321346
Step #192000	Loss: 0.317676
Step #196000	Loss: 0.313186
Step #200000	Loss: 0.319801
Step #204000	Loss: 0.295103
Step #208000	Loss: 0.290766
Step #212000	Loss: 0.308443
Step #216000	Loss: 0.306255
Step #220000	Loss: 0.289915
Code block 'train epoch=4' took: 1652660.28033 ms
train loss 0.3028406500816345
Code block 'val epoch=4' took: 84466.24119 ms
validation loss 0.7246090769767761
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --cufile-thread-count 64 --batch-size 8192 --epochs 5'
[WARN  tini (3269728)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-23 12:58:27.563500: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-23 12:58:30.977557: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-23 12:59:00.341514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-23 13:02:41.768978: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-23 13:02:42.145657: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f802004a000 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-23 13:02:42.145730: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-23 13:02:42.294715: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-23 13:02:43.341859: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-23 13:02:43.651867: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.773117
Step #4000	Loss: 0.379578
Step #8000	Loss: 0.374879
Failed to transform operator <nvtabular.ops.categorify.Categorify object at 0x7f8794d1fb20>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1780, in _encode
    ).sort_values("order")["labels"]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 2214, in sort_values
    out = self._gather(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
Step #12000	Loss: 0.356851
Code block 'train epoch=0' took: 134795.67422 ms
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1780, in _encode
    ).sort_values("order")["labels"]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 2214, in sort_values
    out = self._gather(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home2/faculty/pwesolowski/praca-mgr/pipelines-repo/2_merlin/run_merlin.py", line 155, in <module>
    for batch, (examples, labels) in enumerate(train_tf_ds):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/tensorflow.py", line 97, in __next__
    converted_batch = self.convert_batch(super().__next__())
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 261, in __next__
    return self._get_next_batch()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 343, in _get_next_batch
    self._fetch_chunk()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 277, in _fetch_chunk
    raise chunks
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 791, in load_chunks
    self.chunk_logic(itr)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 759, in chunk_logic
    for chunks in self.batch(itr):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 745, in batch
    value = next(itr)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/io/dataframe_iter.py", line 44, in __iter__
    yield part.compute(scheduler="synchronous")
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/base.py", line 314, in compute
    (result,) = compute(self, traverse=False, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/base.py", line 599, in compute
    results = schedule(dsk, keys, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 557, in get_sync
    return get_async(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 500, in get_async
    for key, res_info, failed in queue_get(queue).result():
  File "/opt/conda/envs/rapids/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/opt/conda/envs/rapids/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 542, in submit
    fut.set_result(fn(*args, **kwargs))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 238, in batch_execute_tasks
    return [execute_task(*a) for a in it]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 238, in <listcomp>
    return [execute_task(*a) for a in it]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 229, in execute_task
    result = pack_exception(e, dumps)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 224, in execute_task
    result = _execute_task(task, data)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/optimization.py", line 990, in __call__
    return core.get(self.dsk, self.outkey, dict(zip(self.inkeys, args)))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 149, in get
    result = _execute_task(task, cache)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in <genexpr>
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/utils.py", line 72, in apply
    return func(*args, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 87, in transform
    transformed_data = self._execute_node(node, transformable, capture_dtypes, strict)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 101, in _execute_node
    upstream_outputs = self._run_upstream_transforms(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 114, in _run_upstream_transforms
    node_output = self._execute_node(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 107, in _execute_node
    transform_output = self._run_node_transform(node, transform_input, capture_dtypes, strict)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 227, in _run_node_transform
    raise exc
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --cufile-thread-count 64 --batch-size 8192 --epochs 5'
[WARN  tini (3276345)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-23 13:04:53.031876: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-23 13:04:56.761484: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-23 13:05:20.881717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
terminate called after throwing an instance of 'rmm::out_of_memory'
  what():  std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp
[dgx-2:3276373] *** Process received signal ***
[dgx-2:3276373] Signal: Aborted (6)
[dgx-2:3276373] Signal code:  (-6)
[dgx-2:3276373] [ 0] /lib/x86_64-linux-gnu/libc.so.6(+0x42520)[0x7fce48307520]
[dgx-2:3276373] [ 1] /lib/x86_64-linux-gnu/libc.so.6(pthread_kill+0x12c)[0x7fce4835ba7c]
[dgx-2:3276373] [ 2] /lib/x86_64-linux-gnu/libc.so.6(raise+0x16)[0x7fce48307476]
[dgx-2:3276373] [ 3] /lib/x86_64-linux-gnu/libc.so.6(abort+0xd3)[0x7fce482ed7f3]
[dgx-2:3276373] [ 4] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(_ZN9__gnu_cxx27__verbose_terminate_handlerEv+0xc0)[0x7fce45475026]
[dgx-2:3276373] [ 5] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(+0xb0514)[0x7fce45473514]
[dgx-2:3276373] [ 6] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(+0xb0566)[0x7fce45473566]
[dgx-2:3276373] [ 7] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(__cxa_rethrow+0x0)[0x7fce45473758]
[dgx-2:3276373] [ 8] /opt/conda/envs/rapids/lib/python3.10/site-packages/rmm/_lib/device_buffer.cpython-310-x86_64-linux-gnu.so(+0x4b67d)[0x7fcd142c467d]
[dgx-2:3276373] [ 9] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf6columnC2ERKS0_N3rmm16cuda_stream_viewEPNS3_2mr22device_memory_resourceE+0x6d)[0x7fcc13ad6add]
[dgx-2:3276373] [10] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf5tableC1ERKS0_+0x263)[0x7fcc15210ec3]
[dgx-2:3276373] [11] /home2/faculty/pwesolowski/praca-mgr/parser-repo/build/libmeta-cudf-parser-1.so(_Z25generate_example_metadataPKcmmi11end_of_linebb+0x87d)[0x7fc6726f827d]
[dgx-2:3276373] [12] /home2/faculty/pwesolowski/praca-mgr/parser-repo/python_binding/metajsonparser/_lib/json_cudf.cpython-310-x86_64-linux-gnu.so(+0x4b344)[0x7fc6727cf344]
[dgx-2:3276373] [13] python(+0x13fb27)[0x556babcbdb27]
[dgx-2:3276373] [14] python(PyObject_Call+0x209)[0x556babcca139]
[dgx-2:3276373] [15] python(_PyEval_EvalFrameDefault+0x5d8c)[0x556babcb3b7c]
[dgx-2:3276373] [16] python(_PyFunction_Vectorcall+0x6f)[0x556babcbdf8f]
[dgx-2:3276373] [17] python(_PyEval_EvalFrameDefault+0x2ec2)[0x556babcb0cb2]
[dgx-2:3276373] [18] python(_PyFunction_Vectorcall+0x6f)[0x556babcbdf8f]
[dgx-2:3276373] [19] python(_PyEval_EvalFrameDefault+0x332)[0x556babcae122]
[dgx-2:3276373] [20] python(_PyFunction_Vectorcall+0x6f)[0x556babcbdf8f]
[dgx-2:3276373] [21] python(_PyEval_EvalFrameDefault+0x2ec2)[0x556babcb0cb2]
[dgx-2:3276373] [22] python(_PyFunction_Vectorcall+0x6f)[0x556babcbdf8f]
[dgx-2:3276373] [23] python(_PyEval_EvalFrameDefault+0x332)[0x556babcae122]
[dgx-2:3276373] [24] python(_PyFunction_Vectorcall+0x6f)[0x556babcbdf8f]
[dgx-2:3276373] [25] python(_PyEval_EvalFrameDefault+0x2ec2)[0x556babcb0cb2]
[dgx-2:3276373] [26] python(+0x14b641)[0x556babcc9641]
[dgx-2:3276373] [27] python(_PyEval_EvalFrameDefault+0x332)[0x556babcae122]
[dgx-2:3276373] [28] python(_PyFunction_Vectorcall+0x6f)[0x556babcbdf8f]
[dgx-2:3276373] [29] python(_PyEval_EvalFrameDefault+0x332)[0x556babcae122]
[dgx-2:3276373] *** End of error message ***
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --cufile-thread-count 64 --batch-size 8192 --epochs 5'
[WARN  tini (3280949)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-23 13:09:02.374054: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-23 13:09:05.423258: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-23 13:09:28.376606: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
terminate called after throwing an instance of 'rmm::out_of_memory'
  what():  std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp
[dgx-2:3280979] *** Process received signal ***
[dgx-2:3280979] Signal: Aborted (6)
[dgx-2:3280979] Signal code:  (-6)
[dgx-2:3280979] [ 0] /lib/x86_64-linux-gnu/libc.so.6(+0x42520)[0x7f2d5f68d520]
[dgx-2:3280979] [ 1] /lib/x86_64-linux-gnu/libc.so.6(pthread_kill+0x12c)[0x7f2d5f6e1a7c]
[dgx-2:3280979] [ 2] /lib/x86_64-linux-gnu/libc.so.6(raise+0x16)[0x7f2d5f68d476]
[dgx-2:3280979] [ 3] /lib/x86_64-linux-gnu/libc.so.6(abort+0xd3)[0x7f2d5f6737f3]
[dgx-2:3280979] [ 4] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(_ZN9__gnu_cxx27__verbose_terminate_handlerEv+0xc0)[0x7f2d5c7fb026]
[dgx-2:3280979] [ 5] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(+0xb0514)[0x7f2d5c7f9514]
[dgx-2:3280979] [ 6] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(+0xb0566)[0x7f2d5c7f9566]
[dgx-2:3280979] [ 7] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(__cxa_rethrow+0x0)[0x7f2d5c7f9758]
[dgx-2:3280979] [ 8] /opt/conda/envs/rapids/lib/python3.10/site-packages/rmm/_lib/device_buffer.cpython-310-x86_64-linux-gnu.so(+0x4b67d)[0x7f2c0408767d]
[dgx-2:3280979] [ 9] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf6columnC2ERKS0_N3rmm16cuda_stream_viewEPNS3_2mr22device_memory_resourceE+0x6d)[0x7f2b23ad6add]
[dgx-2:3280979] [10] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf6columnC2ERKS0_N3rmm16cuda_stream_viewEPNS3_2mr22device_memory_resourceE+0x20c)[0x7f2b23ad6c7c]
[dgx-2:3280979] [11] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf5tableC1ERKS0_+0x263)[0x7f2b25210ec3]
[dgx-2:3280979] [12] /home2/faculty/pwesolowski/praca-mgr/parser-repo/build/libmeta-cudf-parser-1.so(_Z25generate_example_metadataPKcmmi11end_of_linebb+0x87d)[0x7f258a7f827d]
[dgx-2:3280979] [13] /home2/faculty/pwesolowski/praca-mgr/parser-repo/python_binding/metajsonparser/_lib/json_cudf.cpython-310-x86_64-linux-gnu.so(+0x4b344)[0x7f258a8cf344]
[dgx-2:3280979] [14] python(+0x13fb27)[0x5580b7cdbb27]
[dgx-2:3280979] [15] python(PyObject_Call+0x209)[0x5580b7ce8139]
[dgx-2:3280979] [16] python(_PyEval_EvalFrameDefault+0x5d8c)[0x5580b7cd1b7c]
[dgx-2:3280979] [17] python(_PyFunction_Vectorcall+0x6f)[0x5580b7cdbf8f]
[dgx-2:3280979] [18] python(_PyEval_EvalFrameDefault+0x2ec2)[0x5580b7ccecb2]
[dgx-2:3280979] [19] python(_PyFunction_Vectorcall+0x6f)[0x5580b7cdbf8f]
[dgx-2:3280979] [20] python(_PyEval_EvalFrameDefault+0x332)[0x5580b7ccc122]
[dgx-2:3280979] [21] python(_PyFunction_Vectorcall+0x6f)[0x5580b7cdbf8f]
[dgx-2:3280979] [22] python(_PyEval_EvalFrameDefault+0x2ec2)[0x5580b7ccecb2]
[dgx-2:3280979] [23] python(_PyFunction_Vectorcall+0x6f)[0x5580b7cdbf8f]
[dgx-2:3280979] [24] python(_PyEval_EvalFrameDefault+0x332)[0x5580b7ccc122]
[dgx-2:3280979] [25] python(_PyFunction_Vectorcall+0x6f)[0x5580b7cdbf8f]
[dgx-2:3280979] [26] python(_PyEval_EvalFrameDefault+0x2ec2)[0x5580b7ccecb2]
[dgx-2:3280979] [27] python(+0x14b641)[0x5580b7ce7641]
[dgx-2:3280979] [28] python(_PyEval_EvalFrameDefault+0x332)[0x5580b7ccc122]
[dgx-2:3280979] [29] python(_PyFunction_Vectorcall+0x6f)[0x5580b7cdbf8f]
[dgx-2:3280979] *** End of error message ***
+ for BATCH_SIZE in 8192 16384 32768
+ for CUFILE_THREAD_COUNT in 4 8 16 32 64
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --cufile-thread-count 4 --batch-size 16384 --epochs 5'
[WARN  tini (3285689)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-23 13:13:11.693158: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-23 13:13:15.057525: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-23 13:13:39.405652: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-23 13:17:26.765523: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-23 13:17:27.086630: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f94695fdee0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-23 13:17:27.086702: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-23 13:17:27.238428: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-23 13:17:28.260173: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-23 13:17:28.551098: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 3.475783
Step #4000	Loss: 0.324616
Step #8000	Loss: 0.344945
Step #12000	Loss: 0.425974
Step #16000	Loss: 0.425335
Step #20000	Loss: 0.332881
Step #24000	Loss: 0.320017
Step #28000	Loss: 0.346902
Step #32000	Loss: 0.308229
Step #36000	Loss: 0.367019
Step #40000	Loss: 0.379497
Step #44000	Loss: 0.364189
Step #48000	Loss: 0.315936
Step #52000	Loss: 0.337017
Step #56000	Loss: 0.323652
Step #60000	Loss: 0.321747
Step #64000	Loss: 0.372940
Step #68000	Loss: 0.427818
Step #72000	Loss: 0.440956
Step #76000	Loss: 0.436016
Step #80000	Loss: 0.356881
Step #84000	Loss: 0.431007
Step #88000	Loss: 0.311252
Step #92000	Loss: 0.322244
Step #96000	Loss: 0.427483
Step #100000	Loss: 0.334449
Step #104000	Loss: 0.341397
Step #108000	Loss: 0.391745
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 970511.91310 ms
train loss 0.363248735666275
Code block 'val epoch=0' took: 64363.13513 ms
validation loss 0.56520676612854
Step #0	Loss: 0.483560
Step #4000	Loss: 0.303566
Step #8000	Loss: 0.311162
Step #12000	Loss: 0.352705
Step #16000	Loss: 0.345951
Step #20000	Loss: 0.324078
Step #24000	Loss: 0.312424
Step #28000	Loss: 0.327077
Step #32000	Loss: 0.295256
Step #36000	Loss: 0.321072
Step #40000	Loss: 0.323339
Step #44000	Loss: 0.325856
Step #48000	Loss: 0.303271
Step #52000	Loss: 0.315558
Step #56000	Loss: 0.304069
Step #60000	Loss: 0.299960
Step #64000	Loss: 0.340632
Step #68000	Loss: 0.371166
Step #72000	Loss: 0.355941
Step #76000	Loss: 0.357102
Step #80000	Loss: 0.311266
Step #84000	Loss: 0.514905
Step #88000	Loss: 0.286941
Step #92000	Loss: 0.306365
Step #96000	Loss: 0.358578
Step #100000	Loss: 0.313494
Step #104000	Loss: 0.318443
Step #108000	Loss: 0.346149
Code block 'train epoch=1' took: 949187.31149 ms
train loss 0.32947489619255066
Code block 'val epoch=1' took: 64223.91362 ms
validation loss 0.6146833300590515
Step #0	Loss: 0.332860
Step #4000	Loss: 0.303025
Step #8000	Loss: 0.293429
Step #12000	Loss: 0.325202
Step #16000	Loss: 0.312636
Step #20000	Loss: 0.314404
Step #24000	Loss: 0.292428
Step #28000	Loss: 0.305532
Step #32000	Loss: 0.301652
Step #36000	Loss: 0.307983
Step #40000	Loss: 0.307959
Step #44000	Loss: 0.317741
Step #48000	Loss: 0.295198
Step #52000	Loss: 0.310104
Step #56000	Loss: 0.302448
Step #60000	Loss: 0.309159
Step #64000	Loss: 0.316779
Step #68000	Loss: 0.331574
Step #72000	Loss: 0.320687
Step #76000	Loss: 0.323187
Step #80000	Loss: 0.291489
Step #84000	Loss: 0.330675
Step #88000	Loss: 0.284754
Step #92000	Loss: 0.297303
Step #96000	Loss: 0.326132
Step #100000	Loss: 0.307356
Step #104000	Loss: 0.306375
Step #108000	Loss: 0.326633
Code block 'train epoch=2' took: 947556.69028 ms
train loss 0.3114525377750397
Code block 'val epoch=2' took: 63916.62089 ms
validation loss 0.6905984878540039
Step #0	Loss: 0.309877
Step #4000	Loss: 0.293946
Step #8000	Loss: 0.297502
Step #12000	Loss: 0.307185
Step #16000	Loss: 0.303502
Step #20000	Loss: 0.309220
Step #24000	Loss: 0.294791
Step #28000	Loss: 0.302096
Step #32000	Loss: 0.290489
Step #36000	Loss: 0.302656
Step #40000	Loss: 0.298468
Step #44000	Loss: 0.299157
Step #48000	Loss: 0.293955
Step #52000	Loss: 0.304647
Step #56000	Loss: 0.299546
Step #60000	Loss: 0.295698
Step #64000	Loss: 0.315041
Step #68000	Loss: 0.328632
Step #72000	Loss: 0.315451
Step #76000	Loss: 0.311807
Step #80000	Loss: 0.292161
Step #84000	Loss: 0.313400
Step #88000	Loss: 0.275511
Step #92000	Loss: 0.285769
Step #96000	Loss: 0.313852
Step #100000	Loss: 0.309642
Step #104000	Loss: 0.306068
Step #108000	Loss: 0.320554
Code block 'train epoch=3' took: 949316.99054 ms
train loss 0.3052968978881836
Code block 'val epoch=3' took: 64424.30910 ms
validation loss 0.694058358669281
Step #0	Loss: 0.305748
Step #4000	Loss: 0.296179
Step #8000	Loss: 0.294248
Step #12000	Loss: 0.299816
Step #16000	Loss: 0.293078
Step #20000	Loss: 0.306568
Step #24000	Loss: 0.291181
Step #28000	Loss: 0.297512
Step #32000	Loss: 0.295942
Step #36000	Loss: 0.284880
Step #40000	Loss: 0.298755
Step #44000	Loss: 0.300829
Step #48000	Loss: 0.291954
Step #52000	Loss: 0.302491
Step #56000	Loss: 0.297619
Step #60000	Loss: 0.292382
Step #64000	Loss: 0.303341
Step #68000	Loss: 0.321543
Step #72000	Loss: 0.296363
Step #76000	Loss: 0.306571
Step #80000	Loss: 0.278944
Step #84000	Loss: 0.306461
Step #88000	Loss: 0.275991
Step #92000	Loss: 0.290883
Step #96000	Loss: 0.313262
Step #100000	Loss: 0.308428
Step #104000	Loss: 0.304426
Step #108000	Loss: 0.319592
Code block 'train epoch=4' took: 947387.97605 ms
train loss 0.3024017810821533
Code block 'val epoch=4' took: 64113.59134 ms
validation loss 0.7449326515197754
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --cufile-thread-count 4 --batch-size 16384 --epochs 5'
[WARN  tini (3369236)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-23 14:42:09.270755: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-23 14:42:12.221499: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-23 14:42:36.606832: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-23 14:46:25.327073: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-23 14:46:25.669363: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f7866cb3fc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-23 14:46:25.669445: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-23 14:46:25.819031: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-23 14:46:26.997297: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-23 14:46:27.343586: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 1.092254
Step #4000	Loss: 0.311177
Step #8000	Loss: 0.332424
Step #12000	Loss: 0.445259
Step #16000	Loss: 0.442131
Step #20000	Loss: 0.346747
Step #24000	Loss: 0.357492
Step #28000	Loss: 0.396812
Step #32000	Loss: 0.334537
Step #36000	Loss: 0.341425
Step #40000	Loss: 0.340553
Step #44000	Loss: 0.393110
Step #48000	Loss: 0.320260
Step #52000	Loss: 0.361330
Step #56000	Loss: 0.317611
Step #60000	Loss: 0.319230
Step #64000	Loss: 0.399544
Step #68000	Loss: 0.446777
Step #72000	Loss: 0.340631
Step #76000	Loss: 0.452883
Step #80000	Loss: 0.393627
Step #84000	Loss: 0.435341
Step #88000	Loss: 0.350013
Step #92000	Loss: 0.308312
Step #96000	Loss: 0.447310
Step #100000	Loss: 0.327843
Step #104000	Loss: 0.306728
Step #108000	Loss: 0.403569
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 969257.84551 ms
train loss 0.3601941168308258
Code block 'val epoch=0' took: 63818.52037 ms
validation loss 0.5985066294670105
Step #0	Loss: 0.438567
Step #4000	Loss: 0.298236
Step #8000	Loss: 0.305006
Step #12000	Loss: 0.359691
Step #16000	Loss: 0.356111
Step #20000	Loss: 0.319425
Step #24000	Loss: 0.324691
Step #28000	Loss: 0.334923
Step #32000	Loss: 0.306020
Step #36000	Loss: 0.307556
Step #40000	Loss: 0.322693
Step #44000	Loss: 0.321472
Step #48000	Loss: 0.303961
Step #52000	Loss: 0.328410
Step #56000	Loss: 0.308316
Step #60000	Loss: 0.305023
Step #64000	Loss: 0.340453
Step #68000	Loss: 0.366768
Step #72000	Loss: 0.310358
Step #76000	Loss: 0.359552
Step #80000	Loss: 0.321053
Step #84000	Loss: 0.370377
Step #88000	Loss: 0.304555
Step #92000	Loss: 0.303629
Step #96000	Loss: 0.359447
Step #100000	Loss: 0.314629
Step #104000	Loss: 0.300871
Step #108000	Loss: 0.348537
Code block 'train epoch=1' took: 944471.92744 ms
train loss 0.32297608256340027
Code block 'val epoch=1' took: 63845.96001 ms
validation loss 0.6418722867965698
Step #0	Loss: 0.340331
Step #4000	Loss: 0.295374
Step #8000	Loss: 0.300798
Step #12000	Loss: 0.326706
Step #16000	Loss: 0.314301
Step #20000	Loss: 0.319517
Step #24000	Loss: 0.300456
Step #28000	Loss: 0.314771
Step #32000	Loss: 0.293585
Step #36000	Loss: 0.303978
Step #40000	Loss: 0.306253
Step #44000	Loss: 0.309717
Step #48000	Loss: 0.298130
Step #52000	Loss: 0.317359
Step #56000	Loss: 0.298490
Step #60000	Loss: 0.299361
Step #64000	Loss: 0.317312
Step #68000	Loss: 0.344381
Step #72000	Loss: 0.296718
Step #76000	Loss: 0.330509
Step #80000	Loss: 0.295485
Step #84000	Loss: 0.329019
Step #88000	Loss: 0.292338
Step #92000	Loss: 0.292594
Step #96000	Loss: 0.342500
Step #100000	Loss: 0.308531
Step #104000	Loss: 0.295890
Step #108000	Loss: 0.322446
Code block 'train epoch=2' took: 941901.27381 ms
train loss 0.30983301997184753
Code block 'val epoch=2' took: 63289.23241 ms
validation loss 0.7089611887931824
Step #0	Loss: 0.315754
Step #4000	Loss: 0.294935
Step #8000	Loss: 0.298513
Step #12000	Loss: 0.321329
Step #16000	Loss: 0.295172
Step #20000	Loss: 0.305783
Step #24000	Loss: 0.296473
Step #28000	Loss: 0.303650
Step #32000	Loss: 0.298823
Step #36000	Loss: 0.295068
Step #40000	Loss: 0.301051
Step #44000	Loss: 0.299329
Step #48000	Loss: 0.296337
Step #52000	Loss: 0.318660
Step #56000	Loss: 0.300179
Step #60000	Loss: 0.296416
Step #64000	Loss: 0.317783
Step #68000	Loss: 0.327021
Step #72000	Loss: 0.302839
Step #76000	Loss: 0.317564
Step #80000	Loss: 0.288904
Step #84000	Loss: 0.319599
Step #88000	Loss: 0.293479
Step #92000	Loss: 0.290381
Step #96000	Loss: 0.318681
Step #100000	Loss: 0.307618
Step #104000	Loss: 0.292139
Step #108000	Loss: 0.316806
Code block 'train epoch=3' took: 943545.94277 ms
train loss 0.30442291498184204
Code block 'val epoch=3' took: 63007.61139 ms
validation loss 0.7400117516517639
Step #0	Loss: 0.314956
Step #4000	Loss: 0.289972
Step #8000	Loss: 0.297523
Step #12000	Loss: 0.308625
Step #16000	Loss: 0.297482
Step #20000	Loss: 0.314089
Step #24000	Loss: 0.298589
Step #28000	Loss: 0.306436
Step #32000	Loss: 0.293910
Step #36000	Loss: 0.297223
Step #40000	Loss: 0.294821
Step #44000	Loss: 0.302949
Step #48000	Loss: 0.301821
Step #52000	Loss: 0.316893
Step #56000	Loss: 0.290169
Step #60000	Loss: 0.290807
Step #64000	Loss: 0.306768
Step #68000	Loss: 0.319732
Step #72000	Loss: 0.296377
Step #76000	Loss: 0.306593
Step #80000	Loss: 0.295095
Step #84000	Loss: 0.307383
Step #88000	Loss: 0.282587
Step #92000	Loss: 0.288826
Step #96000	Loss: 0.322969
Step #100000	Loss: 0.311991
Step #104000	Loss: 0.296535
Step #108000	Loss: 0.303882
Code block 'train epoch=4' took: 942819.54084 ms
train loss 0.3018524944782257
Code block 'val epoch=4' took: 63481.04810 ms
validation loss 0.8128905892372131
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --cufile-thread-count 4 --batch-size 16384 --epochs 5'
[WARN  tini (3448132)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-23 16:10:41.950146: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-23 16:10:45.361074: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-23 16:11:11.809186: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-23 16:15:02.344336: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-23 16:15:02.738705: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f75573d9440 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-23 16:15:02.738792: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-23 16:15:02.904724: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-23 16:15:04.045117: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-23 16:15:04.356735: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 2.369126
Step #4000	Loss: 0.376103
Step #8000	Loss: 0.346021
Step #12000	Loss: 0.370313
Step #16000	Loss: 0.427191
Step #20000	Loss: 0.322339
Step #24000	Loss: 0.383051
Step #28000	Loss: 0.324277
Step #32000	Loss: 0.333330
Step #36000	Loss: 0.352959
Step #40000	Loss: 0.329549
Step #44000	Loss: 0.336696
Step #48000	Loss: 0.321772
Step #52000	Loss: 0.308392
Step #56000	Loss: 0.308997
Step #60000	Loss: 0.346745
Step #64000	Loss: 0.342277
Step #68000	Loss: 0.450071
Step #72000	Loss: 0.446296
Step #76000	Loss: 0.460591
Step #80000	Loss: 0.341042
Step #84000	Loss: 0.449095
Step #88000	Loss: 0.333841
Step #92000	Loss: 0.324922
Step #96000	Loss: 0.376436
Step #100000	Loss: 0.325497
Step #104000	Loss: 0.397487
Step #108000	Loss: 0.425945
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 965600.16342 ms
train loss 0.3601421117782593
Code block 'val epoch=0' took: 63272.02529 ms
validation loss 0.5818256735801697
Step #0	Loss: 0.452947
Step #4000	Loss: 0.314003
Step #8000	Loss: 0.317081
Step #12000	Loss: 0.334389
Step #16000	Loss: 0.345577
Step #20000	Loss: 0.309227
Step #24000	Loss: 0.323346
Step #28000	Loss: 0.307440
Step #32000	Loss: 0.304074
Step #36000	Loss: 0.313404
Step #40000	Loss: 0.308088
Step #44000	Loss: 0.310984
Step #48000	Loss: 0.311961
Step #52000	Loss: 0.307152
Step #56000	Loss: 0.301314
Step #60000	Loss: 0.309403
Step #64000	Loss: 0.320109
Step #68000	Loss: 0.367994
Step #72000	Loss: 0.352701
Step #76000	Loss: 0.366940
Step #80000	Loss: 0.321941
Step #84000	Loss: 0.372575
Step #88000	Loss: 0.306049
Step #92000	Loss: 0.316459
Step #96000	Loss: 0.322301
Step #100000	Loss: 0.310688
Step #104000	Loss: 0.338857
Step #108000	Loss: 0.362722
Code block 'train epoch=1' took: 941162.69498 ms
train loss 0.32220807671546936
Code block 'val epoch=1' took: 63517.42751 ms
validation loss 0.6531368494033813
Step #0	Loss: 0.349249
Step #4000	Loss: 0.299166
Step #8000	Loss: 0.304652
Step #12000	Loss: 0.307080
Step #16000	Loss: 0.309405
Step #20000	Loss: 0.308083
Step #24000	Loss: 0.305332
Step #28000	Loss: 0.298637
Step #32000	Loss: 0.298551
Step #36000	Loss: 0.303670
Step #40000	Loss: 0.314340
Step #44000	Loss: 0.301882
Step #48000	Loss: 0.307298
Step #52000	Loss: 0.298135
Step #56000	Loss: 0.299804
Step #60000	Loss: 0.303434
Step #64000	Loss: 0.305367
Step #68000	Loss: 0.330911
Step #72000	Loss: 0.318969
Step #76000	Loss: 0.331384
Step #80000	Loss: 0.317899
Step #84000	Loss: 0.337561
Step #88000	Loss: 0.290171
Step #92000	Loss: 0.296930
Step #96000	Loss: 0.329985
Step #100000	Loss: 0.310136
Step #104000	Loss: 0.327098
Step #108000	Loss: 0.339894
Code block 'train epoch=2' took: 939108.30788 ms
train loss 0.30945250391960144
Code block 'val epoch=2' took: 62805.32270 ms
validation loss 0.6976385712623596
Step #0	Loss: 0.330343
Step #4000	Loss: 0.294996
Step #8000	Loss: 0.300068
Step #12000	Loss: 0.305489
Step #16000	Loss: 0.296503
Step #20000	Loss: 0.307892
Step #24000	Loss: 0.294516
Step #28000	Loss: 0.303257
Step #32000	Loss: 0.291389
Step #36000	Loss: 0.306365
Step #40000	Loss: 0.295213
Step #44000	Loss: 0.302744
Step #48000	Loss: 0.306355
Step #52000	Loss: 0.302947
Step #56000	Loss: 0.292646
Step #60000	Loss: 0.295022
Step #64000	Loss: 0.308519
Step #68000	Loss: 0.321035
Step #72000	Loss: 0.310289
Step #76000	Loss: 0.315175
Step #80000	Loss: 0.311552
Step #84000	Loss: 0.320925
Step #88000	Loss: 0.287221
Step #92000	Loss: 0.295652
Step #96000	Loss: 0.311452
Step #100000	Loss: 0.308192
Step #104000	Loss: 0.309876
Step #108000	Loss: 0.330305
Code block 'train epoch=3' took: 940539.58259 ms
train loss 0.30457258224487305
Code block 'val epoch=3' took: 62582.52519 ms
validation loss 0.710902214050293
Step #0	Loss: 0.336579
Step #4000	Loss: 0.290405
Step #8000	Loss: 0.297339
Step #12000	Loss: 0.307715
Step #16000	Loss: 0.294371
Step #20000	Loss: 0.301522
Step #24000	Loss: 0.296922
Step #28000	Loss: 0.293165
Step #32000	Loss: 0.281724
Step #36000	Loss: 0.300074
Step #40000	Loss: 0.307451
Step #44000	Loss: 0.293836
Step #48000	Loss: 0.307292
Step #52000	Loss: 0.296109
Step #56000	Loss: 0.289439
Step #60000	Loss: 0.295505
Step #64000	Loss: 0.307923
Step #68000	Loss: 0.320376
Step #72000	Loss: 0.302698
Step #76000	Loss: 0.313802
Step #80000	Loss: 0.310864
Step #84000	Loss: 0.314998
Step #88000	Loss: 0.282997
Step #92000	Loss: 0.299622
Step #96000	Loss: 0.312730
Step #100000	Loss: 0.297785
Step #104000	Loss: 0.313011
Step #108000	Loss: 0.320953
Code block 'train epoch=4' took: 939593.03230 ms
train loss 0.3018949627876282
Code block 'val epoch=4' took: 62880.69005 ms
validation loss 0.7006822228431702
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --cufile-thread-count 4 --batch-size 16384 --epochs 5'
[WARN  tini (3527094)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-23 17:38:56.634412: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-23 17:39:00.026228: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-23 17:39:22.884730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-23 17:43:06.148094: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-23 17:43:06.491514: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f3e86689ea0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-23 17:43:06.491599: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-23 17:43:06.633558: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-23 17:43:07.693150: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-23 17:43:07.978879: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.518297
Step #4000	Loss: 0.372541
Step #8000	Loss: 0.324378
Step #12000	Loss: 0.432635
Step #16000	Loss: 0.437800
Step #20000	Loss: 0.345229
Step #24000	Loss: 0.358385
Step #28000	Loss: 0.391026
Step #32000	Loss: 0.330068
Step #36000	Loss: 0.356091
Step #40000	Loss: 0.413988
Step #44000	Loss: 0.391559
Step #48000	Loss: 0.356600
Step #52000	Loss: 0.317345
Step #56000	Loss: 0.338116
Step #60000	Loss: 0.330392
Step #64000	Loss: 0.395436
Step #68000	Loss: 0.444256
Step #72000	Loss: 0.339546
Step #76000	Loss: 0.344847
Step #80000	Loss: 0.386541
Step #84000	Loss: 0.353754
Step #88000	Loss: 0.352447
Step #92000	Loss: 0.317872
Step #96000	Loss: 0.450087
Step #100000	Loss: 0.324529
Step #104000	Loss: 0.308521
Step #108000	Loss: 0.413024
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 952485.67376 ms
train loss 0.36047452688217163
Code block 'val epoch=0' took: 60252.54620 ms
validation loss 0.6509795784950256
Step #0	Loss: 0.449626
Step #4000	Loss: 0.322988
Step #8000	Loss: 0.316796
Step #12000	Loss: 0.373620
Step #16000	Loss: 0.347109
Step #20000	Loss: 0.319494
Step #24000	Loss: 0.313081
Step #28000	Loss: 0.331841
Step #32000	Loss: 0.302426
Step #36000	Loss: 0.315157
Step #40000	Loss: 0.342538
Step #44000	Loss: 0.332913
Step #48000	Loss: 0.325183
Step #52000	Loss: 0.297543
Step #56000	Loss: 0.315011
Step #60000	Loss: 0.309024
Step #64000	Loss: 0.336344
Step #68000	Loss: 0.369392
Step #72000	Loss: 0.310646
Step #76000	Loss: 0.315704
Step #80000	Loss: 0.319509
Step #84000	Loss: 0.322476
Step #88000	Loss: 0.318477
Step #92000	Loss: 0.296944
Step #96000	Loss: 0.372832
Step #100000	Loss: 0.319727
Step #104000	Loss: 0.298564
Step #108000	Loss: 0.348613
Code block 'train epoch=1' took: 925630.10042 ms
train loss 0.32256805896759033
Code block 'val epoch=1' took: 60378.47438 ms
validation loss 0.7006602883338928
Step #0	Loss: 0.335578
Step #4000	Loss: 0.305162
Step #8000	Loss: 0.303127
Step #12000	Loss: 0.322610
Step #16000	Loss: 0.315836
Step #20000	Loss: 0.316280
Step #24000	Loss: 0.301692
Step #28000	Loss: 0.309370
Step #32000	Loss: 0.296150
Step #36000	Loss: 0.310198
Step #40000	Loss: 0.315327
Step #44000	Loss: 0.319231
Step #48000	Loss: 0.318329
Step #52000	Loss: 0.304620
Step #56000	Loss: 0.295616
Step #60000	Loss: 0.304617
Step #64000	Loss: 0.326925
Step #68000	Loss: 0.343786
Step #72000	Loss: 0.304020
Step #76000	Loss: 0.299606
Step #80000	Loss: 0.298430
Step #84000	Loss: 0.316319
Step #88000	Loss: 0.291389
Step #92000	Loss: 0.297224
Step #96000	Loss: 0.341487
Step #100000	Loss: 0.306993
Step #104000	Loss: 0.297480
Step #108000	Loss: 0.327549
Code block 'train epoch=2' took: 925431.16037 ms
train loss 0.3097686767578125
Code block 'val epoch=2' took: 60861.32943 ms
validation loss 0.7322747111320496
Step #0	Loss: 0.325652
Step #4000	Loss: 0.301173
Step #8000	Loss: 0.296516
Step #12000	Loss: 0.318581
Step #16000	Loss: 0.289072
Step #20000	Loss: 0.307626
Step #24000	Loss: 0.299557
Step #28000	Loss: 0.307407
Step #32000	Loss: 0.293721
Step #36000	Loss: 0.296388
Step #40000	Loss: 0.304368
Step #44000	Loss: 0.300478
Step #48000	Loss: 0.306471
Step #52000	Loss: 0.294800
Step #56000	Loss: 0.297907
Step #60000	Loss: 0.305644
Step #64000	Loss: 0.310968
Step #68000	Loss: 0.322028
Step #72000	Loss: 0.297638
Step #76000	Loss: 0.301796
Step #80000	Loss: 0.300335
Step #84000	Loss: 0.309852
Step #88000	Loss: 0.288675
Step #92000	Loss: 0.287795
Step #96000	Loss: 0.324366
Step #100000	Loss: 0.306345
Step #104000	Loss: 0.296937
Step #108000	Loss: 0.316699
Code block 'train epoch=3' took: 926405.22203 ms
train loss 0.30452412366867065
Code block 'val epoch=3' took: 60994.41456 ms
validation loss 0.7979140281677246
Step #0	Loss: 0.309931
Step #4000	Loss: 0.288835
Step #8000	Loss: 0.301809
Step #12000	Loss: 0.300559
Step #16000	Loss: 0.301636
Step #20000	Loss: 0.317163
Step #24000	Loss: 0.301771
Step #28000	Loss: 0.300830
Step #32000	Loss: 0.292394
Step #36000	Loss: 0.293662
Step #40000	Loss: 0.302694
Step #44000	Loss: 0.298838
Step #48000	Loss: 0.308469
Step #52000	Loss: 0.295670
Step #56000	Loss: 0.295904
Step #60000	Loss: 0.295316
Step #64000	Loss: 0.303432
Step #68000	Loss: 0.324506
Step #72000	Loss: 0.297455
Step #76000	Loss: 0.299456
Step #80000	Loss: 0.287871
Step #84000	Loss: 0.313835
Step #88000	Loss: 0.293157
Step #92000	Loss: 0.288293
Step #96000	Loss: 0.315330
Step #100000	Loss: 0.309671
Step #104000	Loss: 0.291811
Step #108000	Loss: 0.312836
Code block 'train epoch=4' took: 925925.74549 ms
train loss 0.3018706738948822
Code block 'val epoch=4' took: 60591.15121 ms
validation loss 0.8389385342597961
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --cufile-thread-count 4 --batch-size 16384 --epochs 5'
[WARN  tini (3604839)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-23 19:05:40.365545: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-23 19:05:43.896029: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-23 19:06:10.499889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-23 19:09:54.962205: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-23 19:09:55.312956: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7ef5f03be4b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-23 19:09:55.313035: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-23 19:09:55.461148: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-23 19:09:56.549394: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-23 19:09:56.853949: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 1.521977
Step #4000	Loss: 0.324469
Step #8000	Loss: 0.349017
Step #12000	Loss: 0.360592
Step #16000	Loss: 0.330648
Step #20000	Loss: 0.343597
Step #24000	Loss: 0.311652
Step #28000	Loss: 0.333286
Step #32000	Loss: 0.320298
Step #36000	Loss: 0.400245
Step #40000	Loss: 0.338912
Step #44000	Loss: 0.419217
Step #48000	Loss: 0.403032
Step #52000	Loss: 0.345530
Step #56000	Loss: 0.323581
Step #60000	Loss: 0.331606
Step #64000	Loss: 0.346996
Step #68000	Loss: 0.459910
Step #72000	Loss: 0.378635
Step #76000	Loss: 0.336883
Step #80000	Loss: 0.419496
Step #84000	Loss: 0.344107
Step #88000	Loss: 0.399121
Step #92000	Loss: 0.338751
Step #96000	Loss: 0.377599
Step #100000	Loss: 0.373892
Step #104000	Loss: 0.360760
Step #108000	Loss: 0.361730
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 953764.67091 ms
train loss 0.36123552918434143
Code block 'val epoch=0' took: 60082.38824 ms
validation loss 0.6138184666633606
Step #0	Loss: 0.495153
Step #4000	Loss: 0.304482
Step #8000	Loss: 0.316386
Step #12000	Loss: 0.317148
Step #16000	Loss: 0.312921
Step #20000	Loss: 0.311590
Step #24000	Loss: 0.307469
Step #28000	Loss: 0.312878
Step #32000	Loss: 0.299874
Step #36000	Loss: 0.326675
Step #40000	Loss: 0.311760
Step #44000	Loss: 0.346929
Step #48000	Loss: 0.352168
Step #52000	Loss: 0.321799
Step #56000	Loss: 0.301635
Step #60000	Loss: 0.317885
Step #64000	Loss: 0.318594
Step #68000	Loss: 0.366044
Step #72000	Loss: 0.324606
Step #76000	Loss: 0.307679
Step #80000	Loss: 0.339270
Step #84000	Loss: 0.310071
Step #88000	Loss: 0.348055
Step #92000	Loss: 0.317301
Step #96000	Loss: 0.331535
Step #100000	Loss: 0.335748
Step #104000	Loss: 0.318933
Step #108000	Loss: 0.329393
Code block 'train epoch=1' took: 925603.72613 ms
train loss 0.32267847657203674
Code block 'val epoch=1' took: 60978.32576 ms
validation loss 0.676850438117981
Step #0	Loss: 0.364970
Step #4000	Loss: 0.305328
Step #8000	Loss: 0.306213
Step #12000	Loss: 0.306242
Step #16000	Loss: 0.296452
Step #20000	Loss: 0.312133
Step #24000	Loss: 0.293193
Step #28000	Loss: 0.310700
Step #32000	Loss: 0.290235
Step #36000	Loss: 0.307121
Step #40000	Loss: 0.301195
Step #44000	Loss: 0.325005
Step #48000	Loss: 0.323330
Step #52000	Loss: 0.309129
Step #56000	Loss: 0.295533
Step #60000	Loss: 0.304672
Step #64000	Loss: 0.316881
Step #68000	Loss: 0.329554
Step #72000	Loss: 0.314028
Step #76000	Loss: 0.301831
Step #80000	Loss: 0.301652
Step #84000	Loss: 0.313414
Step #88000	Loss: 0.308910
Step #92000	Loss: 0.300436
Step #96000	Loss: 0.312588
Step #100000	Loss: 0.312681
Step #104000	Loss: 0.309201
Step #108000	Loss: 0.316552
Code block 'train epoch=2' took: 924488.95400 ms
train loss 0.3102978765964508
Code block 'val epoch=2' took: 59810.82531 ms
validation loss 0.7186263799667358
Step #0	Loss: 0.344179
Step #4000	Loss: 0.292859
Step #8000	Loss: 0.302354
Step #12000	Loss: 0.305220
Step #16000	Loss: 0.288918
Step #20000	Loss: 0.306808
Step #24000	Loss: 0.293382
Step #28000	Loss: 0.297729
Step #32000	Loss: 0.286772
Step #36000	Loss: 0.304527
Step #40000	Loss: 0.306911
Step #44000	Loss: 0.312282
Step #48000	Loss: 0.313792
Step #52000	Loss: 0.309610
Step #56000	Loss: 0.301438
Step #60000	Loss: 0.302074
Step #64000	Loss: 0.308571
Step #68000	Loss: 0.327819
Step #72000	Loss: 0.301591
Step #76000	Loss: 0.297173
Step #80000	Loss: 0.296657
Step #84000	Loss: 0.314456
Step #88000	Loss: 0.295379
Step #92000	Loss: 0.300595
Step #96000	Loss: 0.314841
Step #100000	Loss: 0.299725
Step #104000	Loss: 0.309902
Step #108000	Loss: 0.307171
Code block 'train epoch=3' took: 926940.92253 ms
train loss 0.30493709444999695
Code block 'val epoch=3' took: 59900.77879 ms
validation loss 0.7224122881889343
Step #0	Loss: 0.335583
Step #4000	Loss: 0.291866
Step #8000	Loss: 0.298090
Step #12000	Loss: 0.306123
Step #16000	Loss: 0.292890
Step #20000	Loss: 0.305473
Step #24000	Loss: 0.287179
Step #28000	Loss: 0.296435
Step #32000	Loss: 0.289045
Step #36000	Loss: 0.302129
Step #40000	Loss: 0.305861
Step #44000	Loss: 0.302453
Step #48000	Loss: 0.321082
Step #52000	Loss: 0.303263
Step #56000	Loss: 0.288687
Step #60000	Loss: 0.305761
Step #64000	Loss: 0.313875
Step #68000	Loss: 0.314189
Step #72000	Loss: 0.298824
Step #76000	Loss: 0.301813
Step #80000	Loss: 0.294607
Step #84000	Loss: 0.309812
Step #88000	Loss: 0.287767
Step #92000	Loss: 0.304530
Step #96000	Loss: 0.318251
Step #100000	Loss: 0.303368
Step #104000	Loss: 0.309473
Step #108000	Loss: 0.307084
Code block 'train epoch=4' took: 924801.85290 ms
train loss 0.30241116881370544
Code block 'val epoch=4' took: 60206.37809 ms
validation loss 0.7721673846244812
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --cufile-thread-count 4 --batch-size 16384 --epochs 5'
[WARN  tini (3686230)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-23 20:32:26.437006: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-23 20:32:29.878759: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-23 20:32:54.826287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-23 20:36:41.039073: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-23 20:36:41.439007: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fea6e809f90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-23 20:36:41.439074: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-23 20:36:41.602567: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-23 20:36:42.678091: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-23 20:36:42.993028: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.646028
Step #4000	Loss: 0.319230
Step #8000	Loss: 0.335396
Step #12000	Loss: 0.447561
Step #16000	Loss: 0.350434
Step #20000	Loss: 0.320615
Step #24000	Loss: 0.312989
Step #28000	Loss: 0.428241
Step #32000	Loss: 0.345123
Step #36000	Loss: 0.391840
Step #40000	Loss: 0.332074
Step #44000	Loss: 0.365470
Step #48000	Loss: 0.372413
Step #52000	Loss: 0.314628
Step #56000	Loss: 0.334496
Step #60000	Loss: 0.347291
Step #64000	Loss: 0.370100
Step #68000	Loss: 0.446492
Step #72000	Loss: 0.334223
Step #76000	Loss: 0.402747
Step #80000	Loss: 0.340857
Step #84000	Loss: 0.354741
Step #88000	Loss: 0.339019
Step #92000	Loss: 0.366049
Step #96000	Loss: 0.346034
Step #100000	Loss: 0.332525
Step #104000	Loss: 0.318658
Step #108000	Loss: 0.357705
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 958430.86848 ms
train loss 0.3585737347602844
Code block 'val epoch=0' took: 60258.32229 ms
validation loss 0.5707868933677673
Step #0	Loss: 0.460524
Step #4000	Loss: 0.299823
Step #8000	Loss: 0.307890
Step #12000	Loss: 0.363373
Step #16000	Loss: 0.314767
Step #20000	Loss: 0.318065
Step #24000	Loss: 0.296952
Step #28000	Loss: 0.338983
Step #32000	Loss: 0.304470
Step #36000	Loss: 0.315688
Step #40000	Loss: 0.307764
Step #44000	Loss: 0.328442
Step #48000	Loss: 0.331912
Step #52000	Loss: 0.301438
Step #56000	Loss: 0.316551
Step #60000	Loss: 0.313002
Step #64000	Loss: 0.332469
Step #68000	Loss: 0.367586
Step #72000	Loss: 0.304078
Step #76000	Loss: 0.338638
Step #80000	Loss: 0.319686
Step #84000	Loss: 0.318111
Step #88000	Loss: 0.299705
Step #92000	Loss: 0.314579
Step #96000	Loss: 0.327261
Step #100000	Loss: 0.317436
Step #104000	Loss: 0.301892
Step #108000	Loss: 0.332051
Code block 'train epoch=1' took: 933842.89754 ms
train loss 0.3206252455711365
Code block 'val epoch=1' took: 60827.42746 ms
validation loss 0.6284483075141907
Step #0	Loss: 0.354533
Step #4000	Loss: 0.300173
Step #8000	Loss: 0.300701
Step #12000	Loss: 0.319522
Step #16000	Loss: 0.301618
Step #20000	Loss: 0.307893
Step #24000	Loss: 0.291009
Step #28000	Loss: 0.315000
Step #32000	Loss: 0.299054
Step #36000	Loss: 0.302304
Step #40000	Loss: 0.310922
Step #44000	Loss: 0.311655
Step #48000	Loss: 0.317586
Step #52000	Loss: 0.307328
Step #56000	Loss: 0.314682
Step #60000	Loss: 0.307596
Step #64000	Loss: 0.307920
Step #68000	Loss: 0.330051
Step #72000	Loss: 0.300453
Step #76000	Loss: 0.315827
Step #80000	Loss: 0.310331
Step #84000	Loss: 0.316157
Step #88000	Loss: 0.299828
Step #92000	Loss: 0.299704
Step #96000	Loss: 0.323755
Step #100000	Loss: 0.312198
Step #104000	Loss: 0.307139
Step #108000	Loss: 0.312934
Code block 'train epoch=2' took: 934002.11193 ms
train loss 0.3086611330509186
Code block 'val epoch=2' took: 60296.31383 ms
validation loss 0.6607512831687927
Step #0	Loss: 0.341144
Step #4000	Loss: 0.284379
Step #8000	Loss: 0.300745
Step #12000	Loss: 0.308348
Step #16000	Loss: 0.290552
Step #20000	Loss: 0.304889
Step #24000	Loss: 0.284108
Step #28000	Loss: 0.302368
Step #32000	Loss: 0.292715
Step #36000	Loss: 0.289934
Step #40000	Loss: 0.294582
Step #44000	Loss: 0.308908
Step #48000	Loss: 0.311621
Step #52000	Loss: 0.307992
Step #56000	Loss: 0.308392
Step #60000	Loss: 0.304295
Step #64000	Loss: 0.311980
Step #68000	Loss: 0.328877
Step #72000	Loss: 0.291931
Step #76000	Loss: 0.305094
Step #80000	Loss: 0.304325
Step #84000	Loss: 0.316047
Step #88000	Loss: 0.295622
Step #92000	Loss: 0.295943
Step #96000	Loss: 0.315039
Step #100000	Loss: 0.308796
Step #104000	Loss: 0.299686
Step #108000	Loss: 0.311901
Code block 'train epoch=3' took: 935280.78261 ms
train loss 0.30379101634025574
Code block 'val epoch=3' took: 61805.88383 ms
validation loss 0.7330614924430847
Step #0	Loss: 0.329793
Step #4000	Loss: 0.289740
Step #8000	Loss: 0.299770
Step #12000	Loss: 0.297023
Step #16000	Loss: 0.288660
Step #20000	Loss: 0.300907
Step #24000	Loss: 0.286430
Step #28000	Loss: 0.300132
Step #32000	Loss: 0.295941
Step #36000	Loss: 0.286319
Step #40000	Loss: 0.296666
Step #44000	Loss: 0.305862
Step #48000	Loss: 0.312562
Step #52000	Loss: 0.294893
Step #56000	Loss: 0.305674
Step #60000	Loss: 0.296287
Step #64000	Loss: 0.324253
Step #68000	Loss: 0.323693
Step #72000	Loss: 0.305901
Step #76000	Loss: 0.300209
Step #80000	Loss: 0.309039
Step #84000	Loss: 0.307477
Step #88000	Loss: 0.290431
Step #92000	Loss: 0.303210
Step #96000	Loss: 0.313069
Step #100000	Loss: 0.314219
Step #104000	Loss: 0.291245
Step #108000	Loss: 0.310124
Code block 'train epoch=4' took: 935586.38482 ms
train loss 0.30140748620033264
Code block 'val epoch=4' took: 60389.55899 ms
validation loss 0.7718586921691895
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --cufile-thread-count 4 --batch-size 16384 --epochs 5'
[WARN  tini (3765911)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-23 22:00:05.339920: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-23 22:00:08.935181: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-23 22:00:42.456634: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-23 22:04:30.259855: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-23 22:04:30.785905: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f3ffe2cc870 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-23 22:04:30.785976: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-23 22:04:30.932909: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-23 22:04:32.028467: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-23 22:04:32.340095: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 6.496207
Step #4000	Loss: 0.361528
terminate called after throwing an instance of 'rmm::out_of_memory'
  what():  std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp
[dgx-2:3765945] *** Process received signal ***
[dgx-2:3765945] Signal: Aborted (6)
[dgx-2:3765945] Signal code:  (-6)
[dgx-2:3765945] [ 0] /lib/x86_64-linux-gnu/libc.so.6(+0x42520)[0x7f4a0a8e9520]
[dgx-2:3765945] [ 1] /lib/x86_64-linux-gnu/libc.so.6(pthread_kill+0x12c)[0x7f4a0a93da7c]
[dgx-2:3765945] [ 2] /lib/x86_64-linux-gnu/libc.so.6(raise+0x16)[0x7f4a0a8e9476]
[dgx-2:3765945] [ 3] /lib/x86_64-linux-gnu/libc.so.6(abort+0xd3)[0x7f4a0a8cf7f3]
[dgx-2:3765945] [ 4] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(_ZN9__gnu_cxx27__verbose_terminate_handlerEv+0xc0)[0x7f4a07a57026]
[dgx-2:3765945] [ 5] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(+0xb0514)[0x7f4a07a55514]
[dgx-2:3765945] [ 6] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(+0xb0566)[0x7f4a07a55566]
[dgx-2:3765945] [ 7] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(__cxa_rethrow+0x0)[0x7f4a07a55758]
[dgx-2:3765945] [ 8] /opt/conda/envs/rapids/lib/python3.10/site-packages/rmm/_lib/device_buffer.cpython-310-x86_64-linux-gnu.so(+0x4b67d)[0x7f490008167d]
[dgx-2:3765945] [ 9] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf19make_numeric_columnENS_9data_typeEiNS_10mask_stateEN3rmm16cuda_stream_viewEPNS2_2mr22device_memory_resourceE+0x126)[0x7f47d3ae20c6]
[dgx-2:3765945] [10] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf7strings6detail25create_chars_child_columnEiN3rmm16cuda_stream_viewEPNS2_2mr22device_memory_resourceE+0x19)[0x7f47d51ffa29]
[dgx-2:3765945] [11] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf7strings6detail19make_strings_columnIPKN6thrust4pairIPKciEEEESt10unique_ptrINS_6columnESt14default_deleteISB_EET_SF_N3rmm16cuda_stream_viewEPNSG_2mr22device_memory_resourceE+0x47a)[0x7f47d51f937a]
[dgx-2:3765945] [12] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf19make_strings_columnENS_11device_spanIKN6thrust4pairIPKciEELm18446744073709551615EEEN3rmm16cuda_stream_viewEPNS8_2mr22device_memory_resourceE+0x83)[0x7f47d51f4603]
[dgx-2:3765945] [13] /home2/faculty/pwesolowski/praca-mgr/parser-repo/build/libmeta-cudf-parser-1.so(_ZNK18ParserOutputDeviceI5JDictIN5boost4mp117mp_listIJNS3_IJNS3_IJSt17integral_constantIiLi117EES4_IiLi115EES4_IiLi101EES4_IiLi114EES4_IiLi95EES4_IiLi105EES4_IiLi100EEEEE17JStringStaticCopyIS4_IiLi21EESC_NS3_IJEEEEEEENS3_IJNS3_IJS4_IiLi103EES4_IiLi109EES4_IiLi97EES4_IiLi112EES9_SA_SB_EEESD_IS4_IiLi37EESM_SF_EEEENS3_IJNS3_IJS8_SK_S4_IiLi116EESA_S4_IiLi110EESI_EEE7JNumberIhSS_SF_EEEENS3_IJNS3_IJS4_IiLi99EESK_SQ_S7_SI_S4_IiLi111EES8_S4_IiLi121EEEEESD_IS4_IiLi470EESZ_SF_EEEENS3_IJNS3_IJS4_IiLi108EESK_SQ_SA_SQ_S5_SB_S7_EEE11JRealNumberIfS14_SF_EEEENS3_IJNS3_IJS13_SX_SR_SI_SA_SQ_S5_SB_S7_EEES15_IfS18_SF_EEEEEEESF_EE6ToCudfEN3rmm16cuda_stream_viewEPNS1E_2mr22device_memory_resourceE+0x505)[0x7f4758b3a3a5]
[dgx-2:3765945] [14] /home2/faculty/pwesolowski/praca-mgr/parser-repo/build/libmeta-cudf-parser-1.so(_Z25generate_example_metadataPKcmmi11end_of_linebb+0x1cf)[0x7f4758b31bcf]
[dgx-2:3765945] [15] /home2/faculty/pwesolowski/praca-mgr/parser-repo/python_binding/metajsonparser/_lib/json_cudf.cpython-310-x86_64-linux-gnu.so(+0x4b344)[0x7f4758c09344]
[dgx-2:3765945] [16] python(+0x13fb27)[0x5557d28b4b27]
[dgx-2:3765945] [17] python(PyObject_Call+0x209)[0x5557d28c1139]
[dgx-2:3765945] [18] python(_PyEval_EvalFrameDefault+0x5d8c)[0x5557d28aab7c]
[dgx-2:3765945] [19] python(_PyFunction_Vectorcall+0x6f)[0x5557d28b4f8f]
[dgx-2:3765945] [20] python(_PyEval_EvalFrameDefault+0x2ec2)[0x5557d28a7cb2]
[dgx-2:3765945] [21] python(_PyFunction_Vectorcall+0x6f)[0x5557d28b4f8f]
[dgx-2:3765945] [22] python(_PyEval_EvalFrameDefault+0x332)[0x5557d28a5122]
[dgx-2:3765945] [23] python(_PyFunction_Vectorcall+0x6f)[0x5557d28b4f8f]
[dgx-2:3765945] [24] python(_PyEval_EvalFrameDefault+0x2ec2)[0x5557d28a7cb2]
[dgx-2:3765945] [25] python(_PyFunction_Vectorcall+0x6f)[0x5557d28b4f8f]
[dgx-2:3765945] [26] python(_PyEval_EvalFrameDefault+0x332)[0x5557d28a5122]
[dgx-2:3765945] [27] python(_PyFunction_Vectorcall+0x6f)[0x5557d28b4f8f]
[dgx-2:3765945] [28] python(_PyEval_EvalFrameDefault+0x2ec2)[0x5557d28a7cb2]
[dgx-2:3765945] [29] python(+0x14b641)[0x5557d28c0641]
[dgx-2:3765945] *** End of error message ***
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --cufile-thread-count 4 --batch-size 16384 --epochs 5'
[WARN  tini (3772072)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-23 22:05:30.959852: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-23 22:05:34.402904: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-23 22:06:02.703002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
Failed to transform operator <nvtabular.ops.categorify.Categorify object at 0x7f1912f6faf0>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1780, in _encode
    ).sort_values("order")["labels"]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 2214, in sort_values
    out = self._gather(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-23 22:09:47.224837: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-23 22:09:47.662094: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f108b65e000 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-23 22:09:47.662167: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-23 22:09:47.804926: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-23 22:09:48.831776: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-23 22:09:49.154554: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.596390
Code block 'train epoch=0' took: 43007.60995 ms
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 332, in _get_next_batch
    batch = next(self._batch_itr)
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home2/faculty/pwesolowski/praca-mgr/pipelines-repo/2_merlin/run_merlin.py", line 155, in <module>
    for batch, (examples, labels) in enumerate(train_tf_ds):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/tensorflow.py", line 97, in __next__
    converted_batch = self.convert_batch(super().__next__())
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 261, in __next__
    return self._get_next_batch()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 344, in _get_next_batch
    batch = next(self._batch_itr)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 369, in make_tensors
    tensors_by_name = self._convert_df_to_tensors(gdf)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 520, in _convert_df_to_tensors
    tensors_by_name[column_name] = self._to_tensor(gdf_i[[column_name]])
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 450, in _to_tensor
    tensor = df_or_series.to_cupy()
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/single_column_frame.py", line 131, in to_cupy
    return super().to_cupy(dtype, copy, na_value).flatten()
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 533, in to_cupy
    return self._to_array(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 498, in _to_array
    matrix[:, i] = get_column_values_na(col)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 477, in get_column_values_na
    return get_column_values(col)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 534, in <lambda>
    (lambda col: col.values.copy())
  File "cupy/_core/core.pyx", line 590, in cupy._core.core._ndarray_base.copy
  File "cupy/_core/core.pyx", line 616, in cupy._core.core._ndarray_base.copy
  File "cupy/_core/core.pyx", line 575, in cupy._core.core._ndarray_base.astype
  File "cupy/_core/core.pyx", line 136, in cupy._core.core.ndarray.__new__
  File "cupy/_core/core.pyx", line 224, in cupy._core.core._ndarray_base._init
  File "cupy/cuda/memory.pyx", line 742, in cupy.cuda.memory.alloc
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/rmm/rmm.py", line 230, in rmm_cupy_allocator
    buf = librmm.device_buffer.DeviceBuffer(size=nbytes, stream=stream)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --cufile-thread-count 4 --batch-size 16384 --epochs 5'
[WARN  tini (3803543)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-23 22:10:24.796992: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-23 22:10:28.370149: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-23 22:10:55.407751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
Failed to transform operator <nvtabular.ops.categorify.Categorify object at 0x7f4d91b83af0>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1778, in _encode
    labels = codes.merge(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/dataframe.py", line 4004, in merge
    ).perform_merge()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/join/join.py", line 198, in perform_merge
    self.lhs._gather(gather_map=left_rows, **gather_kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-23 22:14:45.070248: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-23 22:14:45.613555: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f4a8dbe21f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-23 22:14:45.613629: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-23 22:14:45.788749: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-23 22:14:46.981880: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-23 22:14:47.324445: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 1.219407
Code block 'train epoch=0' took: 59763.66613 ms
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1778, in _encode
    labels = codes.merge(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/dataframe.py", line 4004, in merge
    ).perform_merge()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/join/join.py", line 198, in perform_merge
    self.lhs._gather(gather_map=left_rows, **gather_kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home2/faculty/pwesolowski/praca-mgr/pipelines-repo/2_merlin/run_merlin.py", line 155, in <module>
    for batch, (examples, labels) in enumerate(train_tf_ds):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/tensorflow.py", line 97, in __next__
    converted_batch = self.convert_batch(super().__next__())
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 261, in __next__
    return self._get_next_batch()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 343, in _get_next_batch
    self._fetch_chunk()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 277, in _fetch_chunk
    raise chunks
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 791, in load_chunks
    self.chunk_logic(itr)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 759, in chunk_logic
    for chunks in self.batch(itr):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 745, in batch
    value = next(itr)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/io/dataframe_iter.py", line 44, in __iter__
    yield part.compute(scheduler="synchronous")
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/base.py", line 314, in compute
    (result,) = compute(self, traverse=False, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/base.py", line 599, in compute
    results = schedule(dsk, keys, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 557, in get_sync
    return get_async(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 500, in get_async
    for key, res_info, failed in queue_get(queue).result():
  File "/opt/conda/envs/rapids/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/opt/conda/envs/rapids/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 542, in submit
    fut.set_result(fn(*args, **kwargs))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 238, in batch_execute_tasks
    return [execute_task(*a) for a in it]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 238, in <listcomp>
    return [execute_task(*a) for a in it]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 229, in execute_task
    result = pack_exception(e, dumps)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 224, in execute_task
    result = _execute_task(task, data)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/optimization.py", line 990, in __call__
    return core.get(self.dsk, self.outkey, dict(zip(self.inkeys, args)))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 149, in get
    result = _execute_task(task, cache)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in <genexpr>
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/utils.py", line 72, in apply
    return func(*args, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 87, in transform
    transformed_data = self._execute_node(node, transformable, capture_dtypes, strict)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 101, in _execute_node
    upstream_outputs = self._run_upstream_transforms(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 114, in _run_upstream_transforms
    node_output = self._execute_node(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 107, in _execute_node
    transform_output = self._run_node_transform(node, transform_input, capture_dtypes, strict)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 227, in _run_node_transform
    raise exc
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
+ for CUFILE_THREAD_COUNT in 4 8 16 32 64
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --cufile-thread-count 8 --batch-size 16384 --epochs 5'
[WARN  tini (3838106)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-23 22:15:37.221259: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-23 22:15:40.748008: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-23 22:16:10.494541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-23 22:20:01.654919: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-23 22:20:02.160388: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f794d070c40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-23 22:20:02.160480: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-23 22:20:02.322038: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-23 22:20:03.408259: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-23 22:20:03.777365: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.551170
Step #4000	Loss: 0.327879
Step #8000	Loss: 0.333752
Step #12000	Loss: 0.429330
Step #16000	Loss: 0.421420
Step #20000	Loss: 0.330748
Step #24000	Loss: 0.327558
Step #28000	Loss: 0.348729
Step #32000	Loss: 0.317140
Step #36000	Loss: 0.365041
Step #40000	Loss: 0.372391
Step #44000	Loss: 0.368906
Step #48000	Loss: 0.321209
Step #52000	Loss: 0.329425
Step #56000	Loss: 0.330596
Step #60000	Loss: 0.308644
Step #64000	Loss: 0.377113
Step #68000	Loss: 0.432312
Step #72000	Loss: 0.428620
Step #76000	Loss: 0.438036
Step #80000	Loss: 0.352118
Step #84000	Loss: 0.430712
Step #88000	Loss: 0.297048
Step #92000	Loss: 0.317655
Step #96000	Loss: 0.425401
Step #100000	Loss: 0.340552
Step #104000	Loss: 0.337235
Step #108000	Loss: 0.399066
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 980641.59605 ms
train loss 0.3621813952922821
Code block 'val epoch=0' took: 65217.85105 ms
validation loss 0.6078893542289734
Step #0	Loss: 0.426115
Step #4000	Loss: 0.317729
Step #8000	Loss: 0.316002
Step #12000	Loss: 0.345103
Step #16000	Loss: 0.358884
Step #20000	Loss: 0.327075
Step #24000	Loss: 0.306123
Step #28000	Loss: 0.318974
Step #32000	Loss: 0.300510
Step #36000	Loss: 0.318420
Step #40000	Loss: 0.320633
Step #44000	Loss: 0.323573
Step #48000	Loss: 0.301349
Step #52000	Loss: 0.315400
Step #56000	Loss: 0.316605
Step #60000	Loss: 0.299893
Step #64000	Loss: 0.330078
Step #68000	Loss: 0.361985
Step #72000	Loss: 0.356037
Step #76000	Loss: 0.348106
Step #80000	Loss: 0.310045
Step #84000	Loss: 0.355720
Step #88000	Loss: 0.286310
Step #92000	Loss: 0.294659
Step #96000	Loss: 0.354386
Step #100000	Loss: 0.317269
Step #104000	Loss: 0.316846
Step #108000	Loss: 0.350743
Code block 'train epoch=1' took: 953544.17082 ms
train loss 0.32466962933540344
Code block 'val epoch=1' took: 64848.45031 ms
validation loss 0.6570161581039429
Step #0	Loss: 0.322301
Step #4000	Loss: 0.303713
Step #8000	Loss: 0.306849
Step #12000	Loss: 0.325323
Step #16000	Loss: 0.317107
Step #20000	Loss: 0.308572
Step #24000	Loss: 0.296988
Step #28000	Loss: 0.308923
Step #32000	Loss: 0.290359
Step #36000	Loss: 0.305709
Step #40000	Loss: 0.302734
Step #44000	Loss: 0.301879
Step #48000	Loss: 0.290194
Step #52000	Loss: 0.315645
Step #56000	Loss: 0.303162
Step #60000	Loss: 0.295374
Step #64000	Loss: 0.319604
Step #68000	Loss: 0.333791
Step #72000	Loss: 0.319394
Step #76000	Loss: 0.326271
Step #80000	Loss: 0.288985
Step #84000	Loss: 0.333830
Step #88000	Loss: 0.279808
Step #92000	Loss: 0.290122
Step #96000	Loss: 0.325246
Step #100000	Loss: 0.317742
Step #104000	Loss: 0.311244
Step #108000	Loss: 0.332199
Code block 'train epoch=2' took: 953904.20664 ms
train loss 0.31075048446655273
Code block 'val epoch=2' took: 65870.37930 ms
validation loss 0.7099087238311768
Step #0	Loss: 0.295800
Step #4000	Loss: 0.297910
Step #8000	Loss: 0.295146
Step #12000	Loss: 0.310852
Step #16000	Loss: 0.302833
Step #20000	Loss: 0.310297
Step #24000	Loss: 0.291062
Step #28000	Loss: 0.305398
Step #32000	Loss: 0.293805
Step #36000	Loss: 0.301711
Step #40000	Loss: 0.307057
Step #44000	Loss: 0.298585
Step #48000	Loss: 0.292624
Step #52000	Loss: 0.308643
Step #56000	Loss: 0.296812
Step #60000	Loss: 0.288795
Step #64000	Loss: 0.310385
Step #68000	Loss: 0.320338
Step #72000	Loss: 0.307178
Step #76000	Loss: 0.314618
Step #80000	Loss: 0.287461
Step #84000	Loss: 0.323898
Step #88000	Loss: 0.275386
Step #92000	Loss: 0.286695
Step #96000	Loss: 0.316033
Step #100000	Loss: 0.309164
Step #104000	Loss: 0.305541
Step #108000	Loss: 0.317603
Code block 'train epoch=3' took: 954314.18072 ms
train loss 0.30515944957733154
Code block 'val epoch=3' took: 65287.66796 ms
validation loss 0.7392135858535767
Step #0	Loss: 0.297313
Step #4000	Loss: 0.287535
Step #8000	Loss: 0.291852
Step #12000	Loss: 0.308367
Step #16000	Loss: 0.293970
Step #20000	Loss: 0.309995
Step #24000	Loss: 0.293645
Step #28000	Loss: 0.299575
Step #32000	Loss: 0.286415
Step #36000	Loss: 0.298638
Step #40000	Loss: 0.296006
Step #44000	Loss: 0.301396
Step #48000	Loss: 0.293246
Step #52000	Loss: 0.309829
Step #56000	Loss: 0.296330
Step #60000	Loss: 0.288592
Step #64000	Loss: 0.308181
Step #68000	Loss: 0.323266
Step #72000	Loss: 0.302141
Step #76000	Loss: 0.311511
Step #80000	Loss: 0.285857
Step #84000	Loss: 0.316537
Step #88000	Loss: 0.272504
Step #92000	Loss: 0.289726
Step #96000	Loss: 0.312815
Step #100000	Loss: 0.307766
Step #104000	Loss: 0.310935
Step #108000	Loss: 0.312288
Code block 'train epoch=4' took: 952962.48736 ms
train loss 0.3024163246154785
Code block 'val epoch=4' took: 65157.24430 ms
validation loss 0.801303505897522
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --cufile-thread-count 8 --batch-size 16384 --epochs 5'
[WARN  tini (272406)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-23 23:45:30.925081: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-23 23:45:34.949039: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-23 23:46:11.735604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-23 23:50:13.576232: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-23 23:50:14.201418: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7efcfa1a4d00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-23 23:50:14.201521: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-23 23:50:14.349889: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-23 23:50:15.431091: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-23 23:50:15.753972: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 5.796736
Step #4000	Loss: 0.322721
Step #8000	Loss: 0.319644
Step #12000	Loss: 0.439197
Step #16000	Loss: 0.437523
Step #20000	Loss: 0.347544
Step #24000	Loss: 0.367814
Step #28000	Loss: 0.393687
Step #32000	Loss: 0.341599
Step #36000	Loss: 0.345218
Step #40000	Loss: 0.335140
Step #44000	Loss: 0.392628
Step #48000	Loss: 0.321131
Step #52000	Loss: 0.366536
Step #56000	Loss: 0.320255
Step #60000	Loss: 0.315631
Step #64000	Loss: 0.404011
Step #68000	Loss: 0.450501
Step #72000	Loss: 0.335311
Step #76000	Loss: 0.451847
Step #80000	Loss: 0.388849
Step #84000	Loss: 0.447879
Step #88000	Loss: 0.356989
Step #92000	Loss: 0.307206
Step #96000	Loss: 0.441447
Step #100000	Loss: 0.329946
Step #104000	Loss: 0.307239
Step #108000	Loss: 0.409520
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 973689.04589 ms
train loss 0.3602539598941803
Code block 'val epoch=0' took: 64476.84423 ms
validation loss 0.600108802318573
Step #0	Loss: 0.503375
Step #4000	Loss: 0.307281
Step #8000	Loss: 0.309491
Step #12000	Loss: 0.369789
Step #16000	Loss: 0.346001
Step #20000	Loss: 0.319850
Step #24000	Loss: 0.327746
Step #28000	Loss: 0.335358
Step #32000	Loss: 0.309566
Step #36000	Loss: 0.313628
Step #40000	Loss: 0.310447
Step #44000	Loss: 0.327994
Step #48000	Loss: 0.309206
Step #52000	Loss: 0.337072
Step #56000	Loss: 0.301977
Step #60000	Loss: 0.310968
Step #64000	Loss: 0.335748
Step #68000	Loss: 0.365294
Step #72000	Loss: 0.315591
Step #76000	Loss: 0.360227
Step #80000	Loss: 0.314706
Step #84000	Loss: 0.363140
Step #88000	Loss: 0.297765
Step #92000	Loss: 0.300014
Step #96000	Loss: 0.367655
Step #100000	Loss: 0.318621
Step #104000	Loss: 0.299120
Step #108000	Loss: 0.343153
Code block 'train epoch=1' took: 946164.31043 ms
train loss 0.32271212339401245
Code block 'val epoch=1' took: 64304.93884 ms
validation loss 0.6371839046478271
Step #0	Loss: 0.347107
Step #4000	Loss: 0.291849
Step #8000	Loss: 0.292254
Step #12000	Loss: 0.335217
Step #16000	Loss: 0.312219
Step #20000	Loss: 0.315431
Step #24000	Loss: 0.301316
Step #28000	Loss: 0.314533
Step #32000	Loss: 0.289851
Step #36000	Loss: 0.304918
Step #40000	Loss: 0.303464
Step #44000	Loss: 0.312827
Step #48000	Loss: 0.299269
Step #52000	Loss: 0.315660
Step #56000	Loss: 0.297235
Step #60000	Loss: 0.301226
Step #64000	Loss: 0.321318
Step #68000	Loss: 0.349218
Step #72000	Loss: 0.308180
Step #76000	Loss: 0.324387
Step #80000	Loss: 0.308538
Step #84000	Loss: 0.329539
Step #88000	Loss: 0.299742
Step #92000	Loss: 0.299404
Step #96000	Loss: 0.339394
Step #100000	Loss: 0.309850
Step #104000	Loss: 0.297008
Step #108000	Loss: 0.331271
Code block 'train epoch=2' took: 946167.64888 ms
train loss 0.3098163604736328
Code block 'val epoch=2' took: 63748.84223 ms
validation loss 0.6570506691932678
Step #0	Loss: 0.322169
Step #4000	Loss: 0.291109
Step #8000	Loss: 0.308800
Step #12000	Loss: 0.315192
Step #16000	Loss: 0.295825
Step #20000	Loss: 0.306967
Step #24000	Loss: 0.293194
Step #28000	Loss: 0.307949
Step #32000	Loss: 0.297131
Step #36000	Loss: 0.296998
Step #40000	Loss: 0.309782
Step #44000	Loss: 0.304499
Step #48000	Loss: 0.294654
Step #52000	Loss: 0.314101
Step #56000	Loss: 0.292823
Step #60000	Loss: 0.298403
Step #64000	Loss: 0.314216
Step #68000	Loss: 0.330055
Step #72000	Loss: 0.301783
Step #76000	Loss: 0.321318
Step #80000	Loss: 0.299750
Step #84000	Loss: 0.323650
Step #88000	Loss: 0.290360
Step #92000	Loss: 0.299964
Step #96000	Loss: 0.323159
Step #100000	Loss: 0.304869
Step #104000	Loss: 0.290968
Step #108000	Loss: 0.312981
Code block 'train epoch=3' took: 943123.15718 ms
train loss 0.3044639527797699
Code block 'val epoch=3' took: 63589.19121 ms
validation loss 0.71614670753479
Step #0	Loss: 0.313014
Step #4000	Loss: 0.287552
Step #8000	Loss: 0.298387
Step #12000	Loss: 0.310809
Step #16000	Loss: 0.297333
Step #20000	Loss: 0.308400
Step #24000	Loss: 0.294016
Step #28000	Loss: 0.304396
Step #32000	Loss: 0.289941
Step #36000	Loss: 0.300724
Step #40000	Loss: 0.298237
Step #44000	Loss: 0.300467
Step #48000	Loss: 0.292265
Step #52000	Loss: 0.301642
Step #56000	Loss: 0.296992
Step #60000	Loss: 0.294343
Step #64000	Loss: 0.315670
Step #68000	Loss: 0.321375
Step #72000	Loss: 0.302559
Step #76000	Loss: 0.308646
Step #80000	Loss: 0.293231
Step #84000	Loss: 0.316949
Step #88000	Loss: 0.286942
Step #92000	Loss: 0.292205
Step #96000	Loss: 0.314821
Step #100000	Loss: 0.302411
Step #104000	Loss: 0.300861
Step #108000	Loss: 0.312499
Code block 'train epoch=4' took: 943846.13384 ms
train loss 0.30181780457496643
Code block 'val epoch=4' took: 63446.40346 ms
validation loss 0.763890266418457
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --cufile-thread-count 8 --batch-size 16384 --epochs 5'
[WARN  tini (489894)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-24 01:14:49.743995: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-24 01:14:52.929476: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-24 01:15:17.928286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-24 01:19:17.476534: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-24 01:19:18.006093: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f8f04197510 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-24 01:19:18.006171: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-24 01:19:18.170977: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-24 01:19:19.325291: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-24 01:19:19.635709: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.651501
Step #4000	Loss: 0.376094
Step #8000	Loss: 0.347553
Step #12000	Loss: 0.371203
Step #16000	Loss: 0.427751
Step #20000	Loss: 0.322865
Step #24000	Loss: 0.382101
Step #28000	Loss: 0.319074
Step #32000	Loss: 0.324294
Step #36000	Loss: 0.348865
Step #40000	Loss: 0.332528
Step #44000	Loss: 0.327295
Step #48000	Loss: 0.319401
Step #52000	Loss: 0.321316
Step #56000	Loss: 0.310715
Step #60000	Loss: 0.339288
Step #64000	Loss: 0.331425
Step #68000	Loss: 0.457287
Step #72000	Loss: 0.444759
Step #76000	Loss: 0.456446
Step #80000	Loss: 0.340492
Step #84000	Loss: 0.445009
Step #88000	Loss: 0.334948
Step #92000	Loss: 0.328374
Step #96000	Loss: 0.380567
Step #100000	Loss: 0.319999
Step #104000	Loss: 0.397795
Step #108000	Loss: 0.423807
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 966571.02849 ms
train loss 0.358859121799469
Code block 'val epoch=0' took: 63965.36051 ms
validation loss 0.6333625912666321
Step #0	Loss: 0.440855
Step #4000	Loss: 0.322185
Step #8000	Loss: 0.316223
Step #12000	Loss: 0.326115
Step #16000	Loss: 0.350083
Step #20000	Loss: 0.308348
Step #24000	Loss: 0.321748
Step #28000	Loss: 0.308829
Step #32000	Loss: 0.304225
Step #36000	Loss: 0.315970
Step #40000	Loss: 0.311362
Step #44000	Loss: 0.308070
Step #48000	Loss: 0.300974
Step #52000	Loss: 0.298353
Step #56000	Loss: 0.298048
Step #60000	Loss: 0.306086
Step #64000	Loss: 0.326299
Step #68000	Loss: 0.371969
Step #72000	Loss: 0.351628
Step #76000	Loss: 0.360925
Step #80000	Loss: 0.322387
Step #84000	Loss: 0.360115
Step #88000	Loss: 0.298557
Step #92000	Loss: 0.310340
Step #96000	Loss: 0.338076
Step #100000	Loss: 0.309335
Step #104000	Loss: 0.339120
Step #108000	Loss: 0.345664
Code block 'train epoch=1' took: 941022.94467 ms
train loss 0.3213239312171936
Code block 'val epoch=1' took: 63570.32188 ms
validation loss 0.7202109694480896
Step #0	Loss: 0.339965
Step #4000	Loss: 0.301862
Step #8000	Loss: 0.306740
Step #12000	Loss: 0.316303
Step #16000	Loss: 0.300798
Step #20000	Loss: 0.306177
Step #24000	Loss: 0.306148
Step #28000	Loss: 0.301518
Step #32000	Loss: 0.291563
Step #36000	Loss: 0.303775
Step #40000	Loss: 0.299215
Step #44000	Loss: 0.304748
Step #48000	Loss: 0.306089
Step #52000	Loss: 0.297115
Step #56000	Loss: 0.291791
Step #60000	Loss: 0.300681
Step #64000	Loss: 0.316998
Step #68000	Loss: 0.340715
Step #72000	Loss: 0.319720
Step #76000	Loss: 0.328035
Step #80000	Loss: 0.318372
Step #84000	Loss: 0.331791
Step #88000	Loss: 0.295413
Step #92000	Loss: 0.292944
Step #96000	Loss: 0.318685
Step #100000	Loss: 0.308821
Step #104000	Loss: 0.317220
Step #108000	Loss: 0.331351
Code block 'train epoch=2' took: 942534.12197 ms
train loss 0.30910372734069824
Code block 'val epoch=2' took: 63876.57683 ms
validation loss 0.7524384260177612
Step #0	Loss: 0.324131
Step #4000	Loss: 0.296065
Step #8000	Loss: 0.297610
Step #12000	Loss: 0.304906
Step #16000	Loss: 0.300123
Step #20000	Loss: 0.306040
Step #24000	Loss: 0.297568
Step #28000	Loss: 0.297565
Step #32000	Loss: 0.285643
Step #36000	Loss: 0.305107
Step #40000	Loss: 0.308698
Step #44000	Loss: 0.304300
Step #48000	Loss: 0.302417
Step #52000	Loss: 0.294564
Step #56000	Loss: 0.298846
Step #60000	Loss: 0.301552
Step #64000	Loss: 0.309180
Step #68000	Loss: 0.326809
Step #72000	Loss: 0.306181
Step #76000	Loss: 0.306253
Step #80000	Loss: 0.314587
Step #84000	Loss: 0.316858
Step #88000	Loss: 0.288696
Step #92000	Loss: 0.295316
Step #96000	Loss: 0.317680
Step #100000	Loss: 0.308899
Step #104000	Loss: 0.316905
Step #108000	Loss: 0.318530
Code block 'train epoch=3' took: 944678.89209 ms
train loss 0.3040676414966583
Code block 'val epoch=3' took: 63680.97962 ms
validation loss 0.8339065909385681
Step #0	Loss: 0.311580
Step #4000	Loss: 0.292764
Step #8000	Loss: 0.297138
Step #12000	Loss: 0.305434
Step #16000	Loss: 0.292353
Step #20000	Loss: 0.301467
Step #24000	Loss: 0.293570
Step #28000	Loss: 0.295225
Step #32000	Loss: 0.289293
Step #36000	Loss: 0.302528
Step #40000	Loss: 0.302249
Step #44000	Loss: 0.301252
Step #48000	Loss: 0.301297
Step #52000	Loss: 0.293997
Step #56000	Loss: 0.290748
Step #60000	Loss: 0.294367
Step #64000	Loss: 0.308825
Step #68000	Loss: 0.321134
Step #72000	Loss: 0.305224
Step #76000	Loss: 0.308770
Step #80000	Loss: 0.307250
Step #84000	Loss: 0.315233
Step #88000	Loss: 0.286501
Step #92000	Loss: 0.292491
Step #96000	Loss: 0.307948
Step #100000	Loss: 0.305566
Step #104000	Loss: 0.307555
Step #108000	Loss: 0.315496
Code block 'train epoch=4' took: 943182.49788 ms
train loss 0.3016528785228729
Code block 'val epoch=4' took: 64415.00953 ms
validation loss 0.8996585011482239
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --cufile-thread-count 8 --batch-size 16384 --epochs 5'
[WARN  tini (574195)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-24 02:43:32.023835: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-24 02:43:35.404493: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-24 02:44:04.652024: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-24 02:47:47.114366: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-24 02:47:47.503103: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f734cc29d80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-24 02:47:47.503198: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-24 02:47:47.667384: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-24 02:47:48.692969: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-24 02:47:49.002554: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.515732
Step #4000	Loss: 0.361414
Step #8000	Loss: 0.321579
Step #12000	Loss: 0.427646
Step #16000	Loss: 0.443790
Step #20000	Loss: 0.355801
Step #24000	Loss: 0.366086
Step #28000	Loss: 0.394766
Step #32000	Loss: 0.336385
Step #36000	Loss: 0.367831
Step #40000	Loss: 0.399794
Step #44000	Loss: 0.387912
Step #48000	Loss: 0.365831
Step #52000	Loss: 0.315981
Step #56000	Loss: 0.339953
Step #60000	Loss: 0.322593
Step #64000	Loss: 0.398368
Step #68000	Loss: 0.439975
Step #72000	Loss: 0.334819
Step #76000	Loss: 0.347921
Step #80000	Loss: 0.389913
Step #84000	Loss: 0.359254
Step #88000	Loss: 0.355212
Step #92000	Loss: 0.307554
Step #96000	Loss: 0.455321
Step #100000	Loss: 0.329639
Step #104000	Loss: 0.318261
Step #108000	Loss: 0.410388
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 952523.58027 ms
train loss 0.3604762852191925
Code block 'val epoch=0' took: 61463.57294 ms
validation loss 0.5939399600028992
Step #0	Loss: 0.442147
Step #4000	Loss: 0.311021
Step #8000	Loss: 0.315225
Step #12000	Loss: 0.364703
Step #16000	Loss: 0.358339
Step #20000	Loss: 0.325861
Step #24000	Loss: 0.325419
Step #28000	Loss: 0.333685
Step #32000	Loss: 0.295858
Step #36000	Loss: 0.326634
Step #40000	Loss: 0.325031
Step #44000	Loss: 0.331784
Step #48000	Loss: 0.324833
Step #52000	Loss: 0.306552
Step #56000	Loss: 0.314096
Step #60000	Loss: 0.308487
Step #64000	Loss: 0.334126
Step #68000	Loss: 0.369189
Step #72000	Loss: 0.313506
Step #76000	Loss: 0.317393
Step #80000	Loss: 0.315595
Step #84000	Loss: 0.318472
Step #88000	Loss: 0.305501
Step #92000	Loss: 0.294934
Step #96000	Loss: 0.371689
Step #100000	Loss: 0.313528
Step #104000	Loss: 0.302858
Step #108000	Loss: 0.347597
Code block 'train epoch=1' took: 930690.88185 ms
train loss 0.3231376111507416
Code block 'val epoch=1' took: 60741.54373 ms
validation loss 0.655845582485199
Step #0	Loss: 0.347361
Step #4000	Loss: 0.288475
Step #8000	Loss: 0.304356
Step #12000	Loss: 0.327996
Step #16000	Loss: 0.325589
Step #20000	Loss: 0.317229
Step #24000	Loss: 0.301010
Step #28000	Loss: 0.317153
Step #32000	Loss: 0.295218
Step #36000	Loss: 0.310236
Step #40000	Loss: 0.315423
Step #44000	Loss: 0.307075
Step #48000	Loss: 0.306016
Step #52000	Loss: 0.302776
Step #56000	Loss: 0.302180
Step #60000	Loss: 0.299078
Step #64000	Loss: 0.320126
Step #68000	Loss: 0.339701
Step #72000	Loss: 0.308736
Step #76000	Loss: 0.308482
Step #80000	Loss: 0.296312
Step #84000	Loss: 0.308973
Step #88000	Loss: 0.295993
Step #92000	Loss: 0.301927
Step #96000	Loss: 0.332377
Step #100000	Loss: 0.308203
Step #104000	Loss: 0.298127
Step #108000	Loss: 0.330618
Code block 'train epoch=2' took: 928793.53906 ms
train loss 0.31026723980903625
Code block 'val epoch=2' took: 60926.96659 ms
validation loss 0.7171722650527954
Step #0	Loss: 0.322157
Step #4000	Loss: 0.294154
Step #8000	Loss: 0.298088
Step #12000	Loss: 0.320987
Step #16000	Loss: 0.299294
Step #20000	Loss: 0.314270
Step #24000	Loss: 0.303068
Step #28000	Loss: 0.311667
Step #32000	Loss: 0.287759
Step #36000	Loss: 0.303333
Step #40000	Loss: 0.310273
Step #44000	Loss: 0.308581
Step #48000	Loss: 0.315561
Step #52000	Loss: 0.300870
Step #56000	Loss: 0.304634
Step #60000	Loss: 0.304268
Step #64000	Loss: 0.303528
Step #68000	Loss: 0.326350
Step #72000	Loss: 0.300672
Step #76000	Loss: 0.305398
Step #80000	Loss: 0.297019
Step #84000	Loss: 0.315529
Step #88000	Loss: 0.290104
Step #92000	Loss: 0.292485
Step #96000	Loss: 0.319379
Step #100000	Loss: 0.309358
Step #104000	Loss: 0.299061
Step #108000	Loss: 0.315483
Code block 'train epoch=3' took: 929991.66302 ms
train loss 0.30484291911125183
Code block 'val epoch=3' took: 61452.61759 ms
validation loss 0.7702244520187378
Step #0	Loss: 0.315497
Step #4000	Loss: 0.290104
Step #8000	Loss: 0.294418
Step #12000	Loss: 0.312491
Step #16000	Loss: 0.298430
Step #20000	Loss: 0.311314
Step #24000	Loss: 0.293373
Step #28000	Loss: 0.304068
Step #32000	Loss: 0.288005
Step #36000	Loss: 0.295046
Step #40000	Loss: 0.305366
Step #44000	Loss: 0.293581
Step #48000	Loss: 0.310814
Step #52000	Loss: 0.296474
Step #56000	Loss: 0.293144
Step #60000	Loss: 0.301332
Step #64000	Loss: 0.303972
Step #68000	Loss: 0.324322
Step #72000	Loss: 0.297345
Step #76000	Loss: 0.300940
Step #80000	Loss: 0.288783
Step #84000	Loss: 0.299124
Step #88000	Loss: 0.284809
Step #92000	Loss: 0.298312
Step #96000	Loss: 0.316159
Step #100000	Loss: 0.306016
Step #104000	Loss: 0.302621
Step #108000	Loss: 0.306215
Code block 'train epoch=4' took: 929243.75077 ms
train loss 0.3020508587360382
Code block 'val epoch=4' took: 60932.45625 ms
validation loss 0.7927689552307129
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --cufile-thread-count 8 --batch-size 16384 --epochs 5'
[WARN  tini (654225)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-24 04:10:42.594456: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-24 04:10:46.008591: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-24 04:11:11.209422: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-24 04:14:57.275341: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-24 04:14:57.615800: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f2be50063c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-24 04:14:57.615871: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-24 04:14:57.766148: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-24 04:14:58.834771: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-24 04:14:59.129373: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 1.047101
Step #4000	Loss: 0.322647
Step #8000	Loss: 0.350122
Step #12000	Loss: 0.349820
Step #16000	Loss: 0.342367
Step #20000	Loss: 0.328572
Step #24000	Loss: 0.318773
Step #28000	Loss: 0.332845
Step #32000	Loss: 0.315589
Step #36000	Loss: 0.396008
Step #40000	Loss: 0.350110
Step #44000	Loss: 0.433375
Step #48000	Loss: 0.399699
Step #52000	Loss: 0.352167
Step #56000	Loss: 0.317937
Step #60000	Loss: 0.332164
Step #64000	Loss: 0.343135
Step #68000	Loss: 0.448534
Step #72000	Loss: 0.377736
Step #76000	Loss: 0.320705
Step #80000	Loss: 0.415024
Step #84000	Loss: 0.338399
Step #88000	Loss: 0.410752
Step #92000	Loss: 0.337997
Step #96000	Loss: 0.353634
Step #100000	Loss: 0.367144
Step #104000	Loss: 0.351360
Step #108000	Loss: 0.354636
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 950526.34748 ms
train loss 0.3598240911960602
Code block 'val epoch=0' took: 60212.97160 ms
validation loss 0.647834300994873
Step #0	Loss: 0.500123
Step #4000	Loss: 0.305154
Step #8000	Loss: 0.313643
Step #12000	Loss: 0.325725
Step #16000	Loss: 0.310411
Step #20000	Loss: 0.309041
Step #24000	Loss: 0.301101
Step #28000	Loss: 0.304879
Step #32000	Loss: 0.295840
Step #36000	Loss: 0.330220
Step #40000	Loss: 0.317289
Step #44000	Loss: 0.351766
Step #48000	Loss: 0.344841
Step #52000	Loss: 0.324966
Step #56000	Loss: 0.310574
Step #60000	Loss: 0.311111
Step #64000	Loss: 0.313575
Step #68000	Loss: 0.368712
Step #72000	Loss: 0.329318
Step #76000	Loss: 0.305373
Step #80000	Loss: 0.338477
Step #84000	Loss: 0.313207
Step #88000	Loss: 0.330655
Step #92000	Loss: 0.313353
Step #96000	Loss: 0.324560
Step #100000	Loss: 0.323228
Step #104000	Loss: 0.320417
Step #108000	Loss: 0.321891
Code block 'train epoch=1' took: 925434.88798 ms
train loss 0.32198935747146606
Code block 'val epoch=1' took: 60470.74741 ms
validation loss 0.747551441192627
Step #0	Loss: 0.379075
Step #4000	Loss: 0.295721
Step #8000	Loss: 0.310774
Step #12000	Loss: 0.316435
Step #16000	Loss: 0.302604
Step #20000	Loss: 0.306336
Step #24000	Loss: 0.287705
Step #28000	Loss: 0.307768
Step #32000	Loss: 0.291226
Step #36000	Loss: 0.308184
Step #40000	Loss: 0.299995
Step #44000	Loss: 0.319916
Step #48000	Loss: 0.320717
Step #52000	Loss: 0.306485
Step #56000	Loss: 0.292622
Step #60000	Loss: 0.300867
Step #64000	Loss: 0.312381
Step #68000	Loss: 0.334637
Step #72000	Loss: 0.309784
Step #76000	Loss: 0.298734
Step #80000	Loss: 0.306264
Step #84000	Loss: 0.316177
Step #88000	Loss: 0.308425
Step #92000	Loss: 0.302740
Step #96000	Loss: 0.313881
Step #100000	Loss: 0.310060
Step #104000	Loss: 0.310357
Step #108000	Loss: 0.312568
Code block 'train epoch=2' took: 926476.47759 ms
train loss 0.309397429227829
Code block 'val epoch=2' took: 60413.02487 ms
validation loss 0.7650642395019531
Step #0	Loss: 0.345884
Step #4000	Loss: 0.300014
Step #8000	Loss: 0.299208
Step #12000	Loss: 0.311840
Step #16000	Loss: 0.286347
Step #20000	Loss: 0.305958
Step #24000	Loss: 0.296590
Step #28000	Loss: 0.296479
Step #32000	Loss: 0.284819
Step #36000	Loss: 0.295063
Step #40000	Loss: 0.301847
Step #44000	Loss: 0.304383
Step #48000	Loss: 0.321411
Step #52000	Loss: 0.306406
Step #56000	Loss: 0.298631
Step #60000	Loss: 0.301562
Step #64000	Loss: 0.315177
Step #68000	Loss: 0.329914
Step #72000	Loss: 0.306306
Step #76000	Loss: 0.297280
Step #80000	Loss: 0.297727
Step #84000	Loss: 0.304372
Step #88000	Loss: 0.303534
Step #92000	Loss: 0.296027
Step #96000	Loss: 0.305485
Step #100000	Loss: 0.304823
Step #104000	Loss: 0.299970
Step #108000	Loss: 0.308047
Code block 'train epoch=3' took: 926066.94441 ms
train loss 0.3043014705181122
Code block 'val epoch=3' took: 60821.70973 ms
validation loss 0.7720916867256165
Step #0	Loss: 0.336938
Step #4000	Loss: 0.288844
Step #8000	Loss: 0.294767
Step #12000	Loss: 0.311731
Step #16000	Loss: 0.293495
Step #20000	Loss: 0.303822
Step #24000	Loss: 0.292918
Step #28000	Loss: 0.297781
Step #32000	Loss: 0.283977
Step #36000	Loss: 0.295055
Step #40000	Loss: 0.298309
Step #44000	Loss: 0.307288
Step #48000	Loss: 0.305045
Step #52000	Loss: 0.302541
Step #56000	Loss: 0.292099
Step #60000	Loss: 0.298179
Step #64000	Loss: 0.305880
Step #68000	Loss: 0.321343
Step #72000	Loss: 0.297684
Step #76000	Loss: 0.300202
Step #80000	Loss: 0.291382
Step #84000	Loss: 0.306360
Step #88000	Loss: 0.306211
Step #92000	Loss: 0.295955
Step #96000	Loss: 0.313782
Step #100000	Loss: 0.298639
Step #104000	Loss: 0.306566
Step #108000	Loss: 0.306756
Code block 'train epoch=4' took: 926102.97432 ms
train loss 0.30179890990257263
Code block 'val epoch=4' took: 60214.05246 ms
validation loss 0.8108192682266235
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --cufile-thread-count 8 --batch-size 16384 --epochs 5'
[WARN  tini (732696)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-24 05:37:28.007244: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-24 05:37:31.464008: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-24 05:37:54.591786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-24 05:41:39.905040: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-24 05:41:40.218156: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f5264659ae0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-24 05:41:40.218237: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-24 05:41:40.356506: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-24 05:41:41.327704: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-24 05:41:41.609076: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 3.026367
Step #4000	Loss: 0.320669
Step #8000	Loss: 0.332643
Step #12000	Loss: 0.443040
Step #16000	Loss: 0.355636
Step #20000	Loss: 0.325521
Step #24000	Loss: 0.309770
Step #28000	Loss: 0.423953
Step #32000	Loss: 0.349635
Step #36000	Loss: 0.402163
Step #40000	Loss: 0.326955
Step #44000	Loss: 0.357981
Step #48000	Loss: 0.374037
Step #52000	Loss: 0.322739
Step #56000	Loss: 0.340013
Step #60000	Loss: 0.347552
Step #64000	Loss: 0.357033
Step #68000	Loss: 0.445744
Step #72000	Loss: 0.333880
Step #76000	Loss: 0.410257
Step #80000	Loss: 0.334759
Step #84000	Loss: 0.350023
Step #88000	Loss: 0.326372
Step #92000	Loss: 0.355363
Step #96000	Loss: 0.347040
Step #100000	Loss: 0.332525
Step #104000	Loss: 0.325373
Step #108000	Loss: 0.365145
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 955550.53994 ms
train loss 0.3591088056564331
Code block 'val epoch=0' took: 60666.69294 ms
validation loss 0.6645635366439819
Step #0	Loss: 0.463960
Step #4000	Loss: 0.299591
Step #8000	Loss: 0.313669
Step #12000	Loss: 0.359945
Step #16000	Loss: 0.313459
Step #20000	Loss: 0.315756
Step #24000	Loss: 0.294686
Step #28000	Loss: 0.340039
Step #32000	Loss: 0.305435
Step #36000	Loss: 0.325323
Step #40000	Loss: 0.313451
Step #44000	Loss: 0.320175
Step #48000	Loss: 0.332670
Step #52000	Loss: 0.316057
Step #56000	Loss: 0.308587
Step #60000	Loss: 0.318751
Step #64000	Loss: 0.329505
Step #68000	Loss: 0.351210
Step #72000	Loss: 0.310184
Step #76000	Loss: 0.340726
Step #80000	Loss: 0.321148
Step #84000	Loss: 0.323104
Step #88000	Loss: 0.299207
Step #92000	Loss: 0.323676
Step #96000	Loss: 0.325142
Step #100000	Loss: 0.322514
Step #104000	Loss: 0.298414
Step #108000	Loss: 0.328576
Code block 'train epoch=1' took: 933492.80639 ms
train loss 0.32031962275505066
Code block 'val epoch=1' took: 59688.47928 ms
validation loss 0.735690712928772
Step #0	Loss: 0.356356
Step #4000	Loss: 0.290290
Step #8000	Loss: 0.304035
Step #12000	Loss: 0.319651
Step #16000	Loss: 0.302130
Step #20000	Loss: 0.300437
Failed to transform operator <nvtabular.ops.categorify.Categorify object at 0x7f59a8ba3af0>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1780, in _encode
    ).sort_values("order")["labels"]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 2214, in sort_values
    out = self._gather(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
Step #24000	Loss: 0.289506
Code block 'train epoch=2' took: 214199.36408 ms
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 332, in _get_next_batch
    batch = next(self._batch_itr)
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home2/faculty/pwesolowski/praca-mgr/pipelines-repo/2_merlin/run_merlin.py", line 155, in <module>
    for batch, (examples, labels) in enumerate(train_tf_ds):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/tensorflow.py", line 97, in __next__
    converted_batch = self.convert_batch(super().__next__())
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 261, in __next__
    return self._get_next_batch()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 344, in _get_next_batch
    batch = next(self._batch_itr)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 369, in make_tensors
    tensors_by_name = self._convert_df_to_tensors(gdf)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 520, in _convert_df_to_tensors
    tensors_by_name[column_name] = self._to_tensor(gdf_i[[column_name]])
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 450, in _to_tensor
    tensor = df_or_series.to_cupy()
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/single_column_frame.py", line 131, in to_cupy
    return super().to_cupy(dtype, copy, na_value).flatten()
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 533, in to_cupy
    return self._to_array(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 498, in _to_array
    matrix[:, i] = get_column_values_na(col)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 477, in get_column_values_na
    return get_column_values(col)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 534, in <lambda>
    (lambda col: col.values.copy())
  File "cupy/_core/core.pyx", line 590, in cupy._core.core._ndarray_base.copy
  File "cupy/_core/core.pyx", line 616, in cupy._core.core._ndarray_base.copy
  File "cupy/_core/core.pyx", line 575, in cupy._core.core._ndarray_base.astype
  File "cupy/_core/core.pyx", line 136, in cupy._core.core.ndarray.__new__
  File "cupy/_core/core.pyx", line 224, in cupy._core.core._ndarray_base._init
  File "cupy/cuda/memory.pyx", line 742, in cupy.cuda.memory.alloc
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/rmm/rmm.py", line 230, in rmm_cupy_allocator
    buf = librmm.device_buffer.DeviceBuffer(size=nbytes, stream=stream)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --cufile-thread-count 8 --batch-size 16384 --epochs 5'
[WARN  tini (770529)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-24 06:18:35.602269: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-24 06:18:38.654182: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-24 06:19:00.588053: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-24 06:22:41.488588: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-24 06:22:41.854609: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f5f10553fe0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-24 06:22:41.854687: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-24 06:22:42.021127: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-24 06:22:43.199120: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-24 06:22:43.546196: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.548199
Step #4000	Loss: 0.375966
terminate called after throwing an instance of 'rmm::out_of_memory'
  what():  std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp
[dgx-2:770555] *** Process received signal ***
[dgx-2:770555] Signal: Aborted (6)
[dgx-2:770555] Signal code:  (-6)
[dgx-2:770555] [ 0] /lib/x86_64-linux-gnu/libc.so.6(+0x42520)[0x7f68a91f1520]
[dgx-2:770555] [ 1] /lib/x86_64-linux-gnu/libc.so.6(pthread_kill+0x12c)[0x7f68a9245a7c]
[dgx-2:770555] [ 2] /lib/x86_64-linux-gnu/libc.so.6(raise+0x16)[0x7f68a91f1476]
[dgx-2:770555] [ 3] /lib/x86_64-linux-gnu/libc.so.6(abort+0xd3)[0x7f68a91d77f3]
[dgx-2:770555] [ 4] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(_ZN9__gnu_cxx27__verbose_terminate_handlerEv+0xc0)[0x7f68a635f026]
[dgx-2:770555] [ 5] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(+0xb0514)[0x7f68a635d514]
[dgx-2:770555] [ 6] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(+0xb0566)[0x7f68a635d566]
[dgx-2:770555] [ 7] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(__cxa_rethrow+0x0)[0x7f68a635d758]
[dgx-2:770555] [ 8] /opt/conda/envs/rapids/lib/python3.10/site-packages/rmm/_lib/device_buffer.cpython-310-x86_64-linux-gnu.so(+0x4b67d)[0x7f678c1a767d]
[dgx-2:770555] [ 9] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf19make_numeric_columnENS_9data_typeEiNS_10mask_stateEN3rmm16cuda_stream_viewEPNS2_2mr22device_memory_resourceE+0x126)[0x7f6673ae20c6]
[dgx-2:770555] [10] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf7strings6detail25create_chars_child_columnEiN3rmm16cuda_stream_viewEPNS2_2mr22device_memory_resourceE+0x19)[0x7f66751ffa29]
[dgx-2:770555] [11] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf7strings6detail19make_strings_columnIPKN6thrust4pairIPKciEEEESt10unique_ptrINS_6columnESt14default_deleteISB_EET_SF_N3rmm16cuda_stream_viewEPNSG_2mr22device_memory_resourceE+0x47a)[0x7f66751f937a]
[dgx-2:770555] [12] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf19make_strings_columnENS_11device_spanIKN6thrust4pairIPKciEELm18446744073709551615EEEN3rmm16cuda_stream_viewEPNS8_2mr22device_memory_resourceE+0x83)[0x7f66751f4603]
[dgx-2:770555] [13] /home2/faculty/pwesolowski/praca-mgr/parser-repo/build/libmeta-cudf-parser-1.so(_ZNK18ParserOutputDeviceI5JDictIN5boost4mp117mp_listIJNS3_IJNS3_IJSt17integral_constantIiLi117EES4_IiLi115EES4_IiLi101EES4_IiLi114EES4_IiLi95EES4_IiLi105EES4_IiLi100EEEEE17JStringStaticCopyIS4_IiLi21EESC_NS3_IJEEEEEEENS3_IJNS3_IJS4_IiLi103EES4_IiLi109EES4_IiLi97EES4_IiLi112EES9_SA_SB_EEESD_IS4_IiLi37EESM_SF_EEEENS3_IJNS3_IJS8_SK_S4_IiLi116EESA_S4_IiLi110EESI_EEE7JNumberIhSS_SF_EEEENS3_IJNS3_IJS4_IiLi99EESK_SQ_S7_SI_S4_IiLi111EES8_S4_IiLi121EEEEESD_IS4_IiLi470EESZ_SF_EEEENS3_IJNS3_IJS4_IiLi108EESK_SQ_SA_SQ_S5_SB_S7_EEE11JRealNumberIfS14_SF_EEEENS3_IJNS3_IJS13_SX_SR_SI_SA_SQ_S5_SB_S7_EEES15_IfS18_SF_EEEEEEESF_EE6ToCudfEN3rmm16cuda_stream_viewEPNS1E_2mr22device_memory_resourceE+0x505)[0x7f65ea50d3a5]
[dgx-2:770555] [14] /home2/faculty/pwesolowski/praca-mgr/parser-repo/build/libmeta-cudf-parser-1.so(_Z25generate_example_metadataPKcmmi11end_of_linebb+0x1cf)[0x7f65ea504bcf]
[dgx-2:770555] [15] /home2/faculty/pwesolowski/praca-mgr/parser-repo/python_binding/metajsonparser/_lib/json_cudf.cpython-310-x86_64-linux-gnu.so(+0x4b344)[0x7f65ea5dc344]
[dgx-2:770555] [16] python(+0x13fb27)[0x557524ab4b27]
[dgx-2:770555] [17] python(PyObject_Call+0x209)[0x557524ac1139]
[dgx-2:770555] [18] python(_PyEval_EvalFrameDefault+0x5d8c)[0x557524aaab7c]
[dgx-2:770555] [19] python(_PyFunction_Vectorcall+0x6f)[0x557524ab4f8f]
[dgx-2:770555] [20] python(_PyEval_EvalFrameDefault+0x2ec2)[0x557524aa7cb2]
[dgx-2:770555] [21] python(_PyFunction_Vectorcall+0x6f)[0x557524ab4f8f]
[dgx-2:770555] [22] python(_PyEval_EvalFrameDefault+0x332)[0x557524aa5122]
[dgx-2:770555] [23] python(_PyFunction_Vectorcall+0x6f)[0x557524ab4f8f]
[dgx-2:770555] [24] python(_PyEval_EvalFrameDefault+0x2ec2)[0x557524aa7cb2]
[dgx-2:770555] [25] python(_PyFunction_Vectorcall+0x6f)[0x557524ab4f8f]
[dgx-2:770555] [26] python(_PyEval_EvalFrameDefault+0x332)[0x557524aa5122]
[dgx-2:770555] [27] python(_PyFunction_Vectorcall+0x6f)[0x557524ab4f8f]
[dgx-2:770555] [28] python(_PyEval_EvalFrameDefault+0x2ec2)[0x557524aa7cb2]
[dgx-2:770555] [29] python(+0x14b641)[0x557524ac0641]
[dgx-2:770555] *** End of error message ***
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --cufile-thread-count 8 --batch-size 16384 --epochs 5'
[WARN  tini (776580)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-24 06:23:39.490097: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-24 06:23:42.404608: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-24 06:24:05.209165: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
Failed to transform operator <nvtabular.ops.categorify.Categorify object at 0x7fc2521d7b20>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1778, in _encode
    labels = codes.merge(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/dataframe.py", line 4004, in merge
    ).perform_merge()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/join/join.py", line 203, in perform_merge
    self.rhs._gather(gather_map=right_rows, **gather_kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-24 06:27:50.297475: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-24 06:27:50.683474: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fba9a87a730 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-24 06:27:50.683549: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-24 06:27:50.828350: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-24 06:27:51.824829: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-24 06:27:52.137399: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 1.561725
Code block 'train epoch=0' took: 42428.50412 ms
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 332, in _get_next_batch
    batch = next(self._batch_itr)
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home2/faculty/pwesolowski/praca-mgr/pipelines-repo/2_merlin/run_merlin.py", line 155, in <module>
    for batch, (examples, labels) in enumerate(train_tf_ds):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/tensorflow.py", line 97, in __next__
    converted_batch = self.convert_batch(super().__next__())
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 261, in __next__
    return self._get_next_batch()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 344, in _get_next_batch
    batch = next(self._batch_itr)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 369, in make_tensors
    tensors_by_name = self._convert_df_to_tensors(gdf)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 520, in _convert_df_to_tensors
    tensors_by_name[column_name] = self._to_tensor(gdf_i[[column_name]])
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 450, in _to_tensor
    tensor = df_or_series.to_cupy()
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/single_column_frame.py", line 131, in to_cupy
    return super().to_cupy(dtype, copy, na_value).flatten()
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 533, in to_cupy
    return self._to_array(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 498, in _to_array
    matrix[:, i] = get_column_values_na(col)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 477, in get_column_values_na
    return get_column_values(col)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 534, in <lambda>
    (lambda col: col.values.copy())
  File "cupy/_core/core.pyx", line 590, in cupy._core.core._ndarray_base.copy
  File "cupy/_core/core.pyx", line 616, in cupy._core.core._ndarray_base.copy
  File "cupy/_core/core.pyx", line 575, in cupy._core.core._ndarray_base.astype
  File "cupy/_core/core.pyx", line 136, in cupy._core.core.ndarray.__new__
  File "cupy/_core/core.pyx", line 224, in cupy._core.core._ndarray_base._init
  File "cupy/cuda/memory.pyx", line 742, in cupy.cuda.memory.alloc
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/rmm/rmm.py", line 230, in rmm_cupy_allocator
    buf = librmm.device_buffer.DeviceBuffer(size=nbytes, stream=stream)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --cufile-thread-count 8 --batch-size 16384 --epochs 5'
[WARN  tini (782096)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-24 06:28:26.033724: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-24 06:28:28.981522: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-24 06:28:53.566847: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
Failed to transform operator <nvtabular.ops.categorify.Categorify object at 0x7f4aeb1f3b20>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1780, in _encode
    ).sort_values("order")["labels"]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 2214, in sort_values
    out = self._gather(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-24 06:32:38.378172: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-24 06:32:38.890665: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f484420e690 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-24 06:32:38.890814: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-24 06:32:39.071716: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-24 06:32:40.155114: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-24 06:32:40.483766: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.705243
Code block 'train epoch=0' took: 57953.43119 ms
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1780, in _encode
    ).sort_values("order")["labels"]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 2214, in sort_values
    out = self._gather(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home2/faculty/pwesolowski/praca-mgr/pipelines-repo/2_merlin/run_merlin.py", line 155, in <module>
    for batch, (examples, labels) in enumerate(train_tf_ds):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/tensorflow.py", line 97, in __next__
    converted_batch = self.convert_batch(super().__next__())
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 261, in __next__
    return self._get_next_batch()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 343, in _get_next_batch
    self._fetch_chunk()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 277, in _fetch_chunk
    raise chunks
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 791, in load_chunks
    self.chunk_logic(itr)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 759, in chunk_logic
    for chunks in self.batch(itr):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 745, in batch
    value = next(itr)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/io/dataframe_iter.py", line 44, in __iter__
    yield part.compute(scheduler="synchronous")
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/base.py", line 314, in compute
    (result,) = compute(self, traverse=False, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/base.py", line 599, in compute
    results = schedule(dsk, keys, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 557, in get_sync
    return get_async(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 500, in get_async
    for key, res_info, failed in queue_get(queue).result():
  File "/opt/conda/envs/rapids/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/opt/conda/envs/rapids/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 542, in submit
    fut.set_result(fn(*args, **kwargs))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 238, in batch_execute_tasks
    return [execute_task(*a) for a in it]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 238, in <listcomp>
    return [execute_task(*a) for a in it]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 229, in execute_task
    result = pack_exception(e, dumps)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 224, in execute_task
    result = _execute_task(task, data)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/optimization.py", line 990, in __call__
    return core.get(self.dsk, self.outkey, dict(zip(self.inkeys, args)))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 149, in get
    result = _execute_task(task, cache)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in <genexpr>
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/utils.py", line 72, in apply
    return func(*args, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 87, in transform
    transformed_data = self._execute_node(node, transformable, capture_dtypes, strict)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 101, in _execute_node
    upstream_outputs = self._run_upstream_transforms(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 114, in _run_upstream_transforms
    node_output = self._execute_node(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 107, in _execute_node
    transform_output = self._run_node_transform(node, transform_input, capture_dtypes, strict)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 227, in _run_node_transform
    raise exc
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
+ for CUFILE_THREAD_COUNT in 4 8 16 32 64
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --cufile-thread-count 16 --batch-size 16384 --epochs 5'
[WARN  tini (787874)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-24 06:33:26.942892: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-24 06:33:29.936300: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-24 06:33:52.578739: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-24 06:37:38.675542: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-24 06:37:39.000779: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fdd42b729f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-24 06:37:39.000847: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-24 06:37:39.147336: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-24 06:37:40.221511: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-24 06:37:40.552853: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 1.060866
Step #4000	Loss: 0.318791
Step #8000	Loss: 0.332157
Step #12000	Loss: 0.426191
Step #16000	Loss: 0.431250
Step #20000	Loss: 0.329444
Step #24000	Loss: 0.317800
Step #28000	Loss: 0.356166
Step #32000	Loss: 0.313378
Step #36000	Loss: 0.357103
Step #40000	Loss: 0.370261
Step #44000	Loss: 0.360831
Step #48000	Loss: 0.319680
Step #52000	Loss: 0.330380
Step #56000	Loss: 0.326857
Step #60000	Loss: 0.312443
Step #64000	Loss: 0.379948
Step #68000	Loss: 0.430013
Step #72000	Loss: 0.434849
Step #76000	Loss: 0.437558
Step #80000	Loss: 0.353373
Step #84000	Loss: 0.425667
Step #88000	Loss: 0.300230
Step #92000	Loss: 0.319885
Step #96000	Loss: 0.430141
Step #100000	Loss: 0.337849
Step #104000	Loss: 0.343432
Step #108000	Loss: 0.385235
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 975640.25627 ms
train loss 0.3615621030330658
Code block 'val epoch=0' took: 64363.65186 ms
validation loss 0.6021221280097961
Step #0	Loss: 0.478511
Step #4000	Loss: 0.302798
Step #8000	Loss: 0.314255
Step #12000	Loss: 0.355784
Step #16000	Loss: 0.347669
Step #20000	Loss: 0.330323
Step #24000	Loss: 0.305342
Step #28000	Loss: 0.319126
Step #32000	Loss: 0.304603
Step #36000	Loss: 0.331488
Step #40000	Loss: 0.320513
Step #44000	Loss: 0.317560
Step #48000	Loss: 0.296020
Step #52000	Loss: 0.317797
Step #56000	Loss: 0.302474
Step #60000	Loss: 0.308974
Step #64000	Loss: 0.338231
Step #68000	Loss: 0.364052
Step #72000	Loss: 0.343063
Step #76000	Loss: 0.349501
Step #80000	Loss: 0.311493
Step #84000	Loss: 0.359810
Step #88000	Loss: 0.280317
Step #92000	Loss: 0.297360
Step #96000	Loss: 0.350970
Step #100000	Loss: 0.314112
Step #104000	Loss: 0.319489
Step #108000	Loss: 0.341368
Code block 'train epoch=1' took: 950579.65655 ms
train loss 0.32420408725738525
Code block 'val epoch=1' took: 64096.84288 ms
validation loss 0.6635192036628723
Step #0	Loss: 0.330379
Step #4000	Loss: 0.300344
Step #8000	Loss: 0.298483
Step #12000	Loss: 0.323803
Step #16000	Loss: 0.322157
Step #20000	Loss: 0.317685
Step #24000	Loss: 0.292928
Step #28000	Loss: 0.304988
Step #32000	Loss: 0.293164
Step #36000	Loss: 0.297326
Step #40000	Loss: 0.311567
Step #44000	Loss: 0.310953
Step #48000	Loss: 0.298367
Step #52000	Loss: 0.317186
Step #56000	Loss: 0.310442
Step #60000	Loss: 0.298858
Step #64000	Loss: 0.322552
Step #68000	Loss: 0.331742
Step #72000	Loss: 0.313161
Step #76000	Loss: 0.318497
Step #80000	Loss: 0.293454
Step #84000	Loss: 0.327986
Step #88000	Loss: 0.273600
Step #92000	Loss: 0.292759
Step #96000	Loss: 0.329293
Step #100000	Loss: 0.313156
Step #104000	Loss: 0.307753
Step #108000	Loss: 0.322345
Code block 'train epoch=2' took: 952799.36331 ms
train loss 0.31047412753105164
Code block 'val epoch=2' took: 63975.00583 ms
validation loss 0.7104091048240662
Step #0	Loss: 0.299266
Step #4000	Loss: 0.293021
Step #8000	Loss: 0.297367
Step #12000	Loss: 0.316007
Step #16000	Loss: 0.304022
Step #20000	Loss: 0.302979
Step #24000	Loss: 0.284253
Step #28000	Loss: 0.302374
Step #32000	Loss: 0.298507
Step #36000	Loss: 0.296923
Step #40000	Loss: 0.299490
Step #44000	Loss: 0.306345
Step #48000	Loss: 0.298697
Step #52000	Loss: 0.304564
Step #56000	Loss: 0.306011
Step #60000	Loss: 0.299179
Step #64000	Loss: 0.303644
Step #68000	Loss: 0.323328
Step #72000	Loss: 0.307697
Step #76000	Loss: 0.317707
Step #80000	Loss: 0.282429
Step #84000	Loss: 0.318820
Step #88000	Loss: 0.278826
Step #92000	Loss: 0.285753
Step #96000	Loss: 0.320090
Step #100000	Loss: 0.311282
Step #104000	Loss: 0.304337
Step #108000	Loss: 0.323021
Code block 'train epoch=3' took: 950975.67751 ms
train loss 0.3048005700111389
Code block 'val epoch=3' took: 64673.12047 ms
validation loss 0.7288868427276611
Step #0	Loss: 0.302940
Step #4000	Loss: 0.285553
Step #8000	Loss: 0.289696
Step #12000	Loss: 0.313785
Step #16000	Loss: 0.308357
Step #20000	Loss: 0.305890
Step #24000	Loss: 0.292577
Step #28000	Loss: 0.296696
Step #32000	Loss: 0.284389
Step #36000	Loss: 0.295771
Step #40000	Loss: 0.295846
Step #44000	Loss: 0.298545
Step #48000	Loss: 0.292069
Step #52000	Loss: 0.299400
Step #56000	Loss: 0.297150
Step #60000	Loss: 0.290792
Step #64000	Loss: 0.313803
Step #68000	Loss: 0.308582
Step #72000	Loss: 0.300350
Step #76000	Loss: 0.308989
Step #80000	Loss: 0.285846
Step #84000	Loss: 0.311549
Step #88000	Loss: 0.274837
Step #92000	Loss: 0.289306
Step #96000	Loss: 0.310774
Step #100000	Loss: 0.305654
Step #104000	Loss: 0.308979
Step #108000	Loss: 0.312445
Code block 'train epoch=4' took: 950510.53903 ms
train loss 0.3020241856575012
Code block 'val epoch=4' took: 64182.12677 ms
validation loss 0.8052471280097961
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --cufile-thread-count 16 --batch-size 16384 --epochs 5'
[WARN  tini (868803)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-24 08:02:38.248967: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-24 08:02:41.664344: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-24 08:03:05.396504: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-24 08:06:52.065874: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-24 08:06:52.483184: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fa3780fc7b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-24 08:06:52.483262: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-24 08:06:52.636871: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-24 08:06:53.690857: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-24 08:06:54.036602: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.682035
Step #4000	Loss: 0.310896
Step #8000	Loss: 0.324675
Step #12000	Loss: 0.442969
Step #16000	Loss: 0.430285
Step #20000	Loss: 0.347727
Step #24000	Loss: 0.358260
Step #28000	Loss: 0.391894
Step #32000	Loss: 0.335066
Step #36000	Loss: 0.349021
Step #40000	Loss: 0.337622
Step #44000	Loss: 0.399661
Step #48000	Loss: 0.313792
Step #52000	Loss: 0.364721
Step #56000	Loss: 0.320224
Step #60000	Loss: 0.323171
Step #64000	Loss: 0.388111
Step #68000	Loss: 0.450514
Step #72000	Loss: 0.336765
Step #76000	Loss: 0.452201
Step #80000	Loss: 0.389418
Step #84000	Loss: 0.440626
Step #88000	Loss: 0.347395
Step #92000	Loss: 0.311764
Step #96000	Loss: 0.446999
Step #100000	Loss: 0.322890
Step #104000	Loss: 0.307988
Step #108000	Loss: 0.406394
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 967668.39279 ms
train loss 0.36003565788269043
Code block 'val epoch=0' took: 64453.36787 ms
validation loss 0.6023204326629639
Step #0	Loss: 0.452154
Step #4000	Loss: 0.296468
Step #8000	Loss: 0.305670
Step #12000	Loss: 0.358379
Step #16000	Loss: 0.348347
Step #20000	Loss: 0.331314
Step #24000	Loss: 0.321368
Step #28000	Loss: 0.335641
Step #32000	Loss: 0.302142
Step #36000	Loss: 0.314926
Step #40000	Loss: 0.315367
Step #44000	Loss: 0.338127
Step #48000	Loss: 0.312721
Step #52000	Loss: 0.332929
Step #56000	Loss: 0.303770
Step #60000	Loss: 0.301520
Step #64000	Loss: 0.330305
Step #68000	Loss: 0.358834
Step #72000	Loss: 0.312751
Step #76000	Loss: 0.356337
Step #80000	Loss: 0.312227
Step #84000	Loss: 0.354901
Step #88000	Loss: 0.300749
Step #92000	Loss: 0.302784
Step #96000	Loss: 0.362541
Step #100000	Loss: 0.314260
Step #104000	Loss: 0.306094
Step #108000	Loss: 0.342628
Code block 'train epoch=1' took: 944403.19804 ms
train loss 0.3222917914390564
Code block 'val epoch=1' took: 64546.93560 ms
validation loss 0.6541721820831299
Step #0	Loss: 0.350383
Step #4000	Loss: 0.297841
Step #8000	Loss: 0.297686
Step #12000	Loss: 0.330346
Step #16000	Loss: 0.314162
Step #20000	Loss: 0.313588
Step #24000	Loss: 0.306948
Step #28000	Loss: 0.313185
Step #32000	Loss: 0.294986
Step #36000	Loss: 0.305718
Step #40000	Loss: 0.300500
Step #44000	Loss: 0.309095
Step #48000	Loss: 0.304947
Step #52000	Loss: 0.318532
Step #56000	Loss: 0.306078
Step #60000	Loss: 0.308262
Step #64000	Loss: 0.314816
Step #68000	Loss: 0.339157
Step #72000	Loss: 0.301928
Step #76000	Loss: 0.321664
Step #80000	Loss: 0.293342
Step #84000	Loss: 0.337794
Step #88000	Loss: 0.296787
Step #92000	Loss: 0.300001
Step #96000	Loss: 0.337881
Step #100000	Loss: 0.307043
Step #104000	Loss: 0.291596
Step #108000	Loss: 0.324974
Code block 'train epoch=2' took: 942683.49546 ms
train loss 0.30982470512390137
Code block 'val epoch=2' took: 64195.61611 ms
validation loss 0.6868082880973816
Step #0	Loss: 0.312775
Step #4000	Loss: 0.292296
Step #8000	Loss: 0.294170
Step #12000	Loss: 0.318587
Step #16000	Loss: 0.295720
Step #20000	Loss: 0.311144
Step #24000	Loss: 0.299352
Step #28000	Loss: 0.306400
Step #32000	Loss: 0.292673
Step #36000	Loss: 0.300453
Step #40000	Loss: 0.299410
Step #44000	Loss: 0.311309
Step #48000	Loss: 0.297137
Step #52000	Loss: 0.310140
Step #56000	Loss: 0.305216
Step #60000	Loss: 0.298062
Step #64000	Loss: 0.314247
Step #68000	Loss: 0.326410
Step #72000	Loss: 0.302814
Step #76000	Loss: 0.314092
Step #80000	Loss: 0.286456
Step #84000	Loss: 0.321321
Step #88000	Loss: 0.289680
Step #92000	Loss: 0.287242
Step #96000	Loss: 0.322901
Step #100000	Loss: 0.301666
Step #104000	Loss: 0.291625
Step #108000	Loss: 0.324231
Code block 'train epoch=3' took: 943909.40098 ms
train loss 0.3046324551105499
Code block 'val epoch=3' took: 63845.93075 ms
validation loss 0.746789813041687
Step #0	Loss: 0.321348
Step #4000	Loss: 0.294229
Step #8000	Loss: 0.303333
Step #12000	Loss: 0.315571
Step #16000	Loss: 0.289456
Step #20000	Loss: 0.307805
Step #24000	Loss: 0.294476
Step #28000	Loss: 0.300903
Step #32000	Loss: 0.290847
Step #36000	Loss: 0.301877
Step #40000	Loss: 0.297700
Step #44000	Loss: 0.298681
Step #48000	Loss: 0.302056
Step #52000	Loss: 0.309529
Step #56000	Loss: 0.297632
Step #60000	Loss: 0.296107
Step #64000	Loss: 0.311417
Step #68000	Loss: 0.321866
Step #72000	Loss: 0.299765
Step #76000	Loss: 0.311605
Step #80000	Loss: 0.285893
Step #84000	Loss: 0.314104
Step #88000	Loss: 0.287879
Step #92000	Loss: 0.285560
Step #96000	Loss: 0.317718
Step #100000	Loss: 0.303778
Step #104000	Loss: 0.289944
Step #108000	Loss: 0.316486
Code block 'train epoch=4' took: 944890.61299 ms
train loss 0.3020087480545044
Code block 'val epoch=4' took: 64466.08020 ms
validation loss 0.775563657283783
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --cufile-thread-count 16 --batch-size 16384 --epochs 5'
[WARN  tini (948870)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-24 09:31:15.041284: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-24 09:31:18.410797: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-24 09:31:42.699537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-24 09:35:33.092932: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-24 09:35:33.492040: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f4eae4de2e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-24 09:35:33.492122: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-24 09:35:33.663629: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-24 09:35:34.681483: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-24 09:35:34.997934: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 2.911403
Step #4000	Loss: 0.372680
Step #8000	Loss: 0.329192
Step #12000	Loss: 0.366478
Step #16000	Loss: 0.431017
Step #20000	Loss: 0.328922
Step #24000	Loss: 0.383488
Step #28000	Loss: 0.326274
Step #32000	Loss: 0.324939
Step #36000	Loss: 0.351847
Step #40000	Loss: 0.329148
Step #44000	Loss: 0.340580
Step #48000	Loss: 0.325093
Step #52000	Loss: 0.320626
Step #56000	Loss: 0.311782
Step #60000	Loss: 0.336774
Step #64000	Loss: 0.340168
Step #68000	Loss: 0.458870
Step #72000	Loss: 0.447821
Step #76000	Loss: 0.464466
Step #80000	Loss: 0.349975
Step #84000	Loss: 0.446894
Step #88000	Loss: 0.336490
Step #92000	Loss: 0.314590
Step #96000	Loss: 0.386768
Step #100000	Loss: 0.327727
Step #104000	Loss: 0.407339
Step #108000	Loss: 0.407845
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 967631.27291 ms
train loss 0.36007219552993774
Code block 'val epoch=0' took: 63412.05371 ms
validation loss 0.6283431053161621
Step #0	Loss: 0.475397
Step #4000	Loss: 0.323270
Step #8000	Loss: 0.319108
Step #12000	Loss: 0.329380
Step #16000	Loss: 0.341348
Step #20000	Loss: 0.307138
Step #24000	Loss: 0.335854
Step #28000	Loss: 0.311346
Step #32000	Loss: 0.316799
Step #36000	Loss: 0.314828
Step #40000	Loss: 0.306852
Step #44000	Loss: 0.305716
Step #48000	Loss: 0.310307
Step #52000	Loss: 0.308871
Step #56000	Loss: 0.297984
Step #60000	Loss: 0.314018
Step #64000	Loss: 0.313567
Step #68000	Loss: 0.376778
Step #72000	Loss: 0.354076
Step #76000	Loss: 0.367786
Step #80000	Loss: 0.324556
Step #84000	Loss: 0.363421
Step #88000	Loss: 0.306556
Step #92000	Loss: 0.303026
Step #96000	Loss: 0.332432
Step #100000	Loss: 0.304813
Step #104000	Loss: 0.333831
Step #108000	Loss: 0.360160
Code block 'train epoch=1' took: 942843.11539 ms
train loss 0.3229404091835022
Code block 'val epoch=1' took: 63288.55426 ms
validation loss 0.6594324707984924
Step #0	Loss: 0.351247
Step #4000	Loss: 0.308668
Step #8000	Loss: 0.304633
Step #12000	Loss: 0.310683
Step #16000	Loss: 0.310488
Step #20000	Loss: 0.308991
Step #24000	Loss: 0.305225
Step #28000	Loss: 0.306838
Step #32000	Loss: 0.298136
Step #36000	Loss: 0.305172
Step #40000	Loss: 0.309664
Step #44000	Loss: 0.299177
Step #48000	Loss: 0.302194
Step #52000	Loss: 0.305273
Step #56000	Loss: 0.302797
Step #60000	Loss: 0.297456
Step #64000	Loss: 0.317724
Step #68000	Loss: 0.327744
Step #72000	Loss: 0.323517
Step #76000	Loss: 0.325769
Step #80000	Loss: 0.309730
Step #84000	Loss: 0.334105
Step #88000	Loss: 0.292183
Step #92000	Loss: 0.288349
Step #96000	Loss: 0.321202
Step #100000	Loss: 0.306533
Step #104000	Loss: 0.321333
Step #108000	Loss: 0.333226
Code block 'train epoch=2' took: 944666.05469 ms
train loss 0.3102412819862366
Code block 'val epoch=2' took: 62887.84122 ms
validation loss 0.7206889986991882
Step #0	Loss: 0.339617
Step #4000	Loss: 0.295793
Step #8000	Loss: 0.304923
Step #12000	Loss: 0.306402
Step #16000	Loss: 0.302071
Step #20000	Loss: 0.305888
Step #24000	Loss: 0.294010
Step #28000	Loss: 0.295446
Step #32000	Loss: 0.288419
Step #36000	Loss: 0.296726
Step #40000	Loss: 0.303006
Step #44000	Loss: 0.301142
Step #48000	Loss: 0.296993
Step #52000	Loss: 0.298415
Step #56000	Loss: 0.287213
Step #60000	Loss: 0.292519
Step #64000	Loss: 0.306332
Step #68000	Loss: 0.325507
Step #72000	Loss: 0.312051
Step #76000	Loss: 0.315522
Step #80000	Loss: 0.310122
Step #84000	Loss: 0.328110
Step #88000	Loss: 0.286496
Step #92000	Loss: 0.293753
Step #96000	Loss: 0.308527
Step #100000	Loss: 0.304581
Step #104000	Loss: 0.309048
Step #108000	Loss: 0.323445
Code block 'train epoch=3' took: 942945.06567 ms
train loss 0.3048115372657776
Code block 'val epoch=3' took: 63032.82388 ms
validation loss 0.7433848977088928
Step #0	Loss: 0.322321
Step #4000	Loss: 0.288535
Step #8000	Loss: 0.296544
Step #12000	Loss: 0.307846
Step #16000	Loss: 0.301302
Step #20000	Loss: 0.305133
Step #24000	Loss: 0.298312
Step #28000	Loss: 0.297421
Step #32000	Loss: 0.286469
Step #36000	Loss: 0.299302
Step #40000	Loss: 0.299930
Step #44000	Loss: 0.302642
Step #48000	Loss: 0.306549
Step #52000	Loss: 0.292301
Step #56000	Loss: 0.297192
Step #60000	Loss: 0.297714
Step #64000	Loss: 0.312074
Step #68000	Loss: 0.315476
Step #72000	Loss: 0.304654
Step #76000	Loss: 0.304621
Step #80000	Loss: 0.310494
Step #84000	Loss: 0.313417
Step #88000	Loss: 0.284485
Step #92000	Loss: 0.299204
Step #96000	Loss: 0.308728
Step #100000	Loss: 0.301701
Step #104000	Loss: 0.309584
Step #108000	Loss: 0.327179
Code block 'train epoch=4' took: 944337.12518 ms
train loss 0.30197903513908386
Code block 'val epoch=4' took: 62671.80297 ms
validation loss 0.8459916710853577
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --cufile-thread-count 16 --batch-size 16384 --epochs 5'
[WARN  tini (1028985)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-24 10:59:46.079945: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-24 10:59:49.947342: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-24 11:00:17.036200: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-24 11:03:59.066225: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-24 11:03:59.390694: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7ef3fbc828d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-24 11:03:59.390771: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-24 11:03:59.558585: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-24 11:04:00.553961: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-24 11:04:00.861729: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 1.479493
Step #4000	Loss: 0.365570
Step #8000	Loss: 0.320981
Step #12000	Loss: 0.439255
Step #16000	Loss: 0.442437
Step #20000	Loss: 0.355712
Step #24000	Loss: 0.356728
Step #28000	Loss: 0.398983
Step #32000	Loss: 0.333825
Step #36000	Loss: 0.434399
Step #40000	Loss: 0.505543
Step #44000	Loss: 0.504313
Step #48000	Loss: 0.477530
Step #52000	Loss: 0.472769
Step #56000	Loss: 0.514303
Step #60000	Loss: 0.492840
Step #64000	Loss: 0.495307
Step #68000	Loss: 0.506134
Step #72000	Loss: 0.499827
Step #76000	Loss: 0.521338
Step #80000	Loss: 0.467225
Step #84000	Loss: 0.506557
Step #88000	Loss: 0.468619
Step #92000	Loss: 0.464842
Step #96000	Loss: 0.524700
Step #100000	Loss: 0.511713
Step #104000	Loss: 0.465334
Step #108000	Loss: 0.511713
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 950982.52241 ms
train loss 0.4528009593486786
Code block 'val epoch=0' took: 60937.34588 ms
validation loss 0.49748533964157104
Step #0	Loss: 0.502867
Step #4000	Loss: 0.494354
Step #8000	Loss: 0.465137
Step #12000	Loss: 0.497054
Step #16000	Loss: 0.472413
Step #20000	Loss: 0.482130
Step #24000	Loss: 0.481972
Step #28000	Loss: 0.506827
Step #32000	Loss: 0.466106
Step #36000	Loss: 0.444252
Step #40000	Loss: 0.496540
Step #44000	Loss: 0.511548
Step #48000	Loss: 0.481030
Step #52000	Loss: 0.480923
Step #56000	Loss: 0.507777
Step #60000	Loss: 0.496191
Step #64000	Loss: 0.492463
Step #68000	Loss: 0.511392
Step #72000	Loss: 0.505072
Step #76000	Loss: 0.513436
Step #80000	Loss: 0.461078
Step #84000	Loss: 0.502322
Step #88000	Loss: 0.479200
Step #92000	Loss: 0.460016
Step #96000	Loss: 0.516668
Step #100000	Loss: 0.498331
Step #104000	Loss: 0.463897
Step #108000	Loss: 0.510661
Code block 'train epoch=1' took: 925877.71794 ms
train loss 0.49598029255867004
Code block 'val epoch=1' took: 60516.03532 ms
validation loss 0.497178852558136
Step #0	Loss: 0.509831
Step #4000	Loss: 0.497544
Step #8000	Loss: 0.461642
Step #12000	Loss: 0.501875
Step #16000	Loss: 0.480452
Step #20000	Loss: 0.480333
Step #24000	Loss: 0.480063
Step #28000	Loss: 0.513593
Step #32000	Loss: 0.465221
Step #36000	Loss: 0.445862
Step #40000	Loss: 0.505226
Step #44000	Loss: 0.510253
Step #48000	Loss: 0.481599
Step #52000	Loss: 0.467791
Step #56000	Loss: 0.502796
Step #60000	Loss: 0.496521
Step #64000	Loss: 0.502574
Step #68000	Loss: 0.515040
Step #72000	Loss: 0.498650
Step #76000	Loss: 0.510786
Step #80000	Loss: 0.462889
Step #84000	Loss: 0.513533
Step #88000	Loss: 0.470735
Step #92000	Loss: 0.463804
Step #96000	Loss: 0.508765
Step #100000	Loss: 0.508379
Step #104000	Loss: 0.455016
Step #108000	Loss: 0.510489
Code block 'train epoch=2' took: 926640.01795 ms
train loss 0.49598321318626404
Code block 'val epoch=2' took: 60678.28450 ms
validation loss 0.4971991777420044
Step #0	Loss: 0.504707
Step #4000	Loss: 0.493577
Step #8000	Loss: 0.462700
Step #12000	Loss: 0.496615
Step #16000	Loss: 0.470487
Step #20000	Loss: 0.482589
Step #24000	Loss: 0.476880
Step #28000	Loss: 0.505959
Step #32000	Loss: 0.461716
Step #36000	Loss: 0.435318
Step #40000	Loss: 0.491350
Step #44000	Loss: 0.508685
Step #48000	Loss: 0.479479
Step #52000	Loss: 0.476180
Step #56000	Loss: 0.506903
Step #60000	Loss: 0.501107
Step #64000	Loss: 0.496588
Step #68000	Loss: 0.508028
Step #72000	Loss: 0.495778
Step #76000	Loss: 0.517203
Step #80000	Loss: 0.464937
Step #84000	Loss: 0.510980
Step #88000	Loss: 0.477274
Step #92000	Loss: 0.468036
Step #96000	Loss: 0.522420
Step #100000	Loss: 0.518254
Step #104000	Loss: 0.465129
Step #108000	Loss: 0.506259
Code block 'train epoch=3' took: 926907.62025 ms
train loss 0.49597790837287903
Code block 'val epoch=3' took: 60841.23473 ms
validation loss 0.4972883462905884
Step #0	Loss: 0.503493
Step #4000	Loss: 0.502585
Step #8000	Loss: 0.468317
Step #12000	Loss: 0.509518
Step #16000	Loss: 0.476807
Step #20000	Loss: 0.475115
Step #24000	Loss: 0.479741
Step #28000	Loss: 0.510325
Step #32000	Loss: 0.471196
Step #36000	Loss: 0.443554
Step #40000	Loss: 0.505211
Step #44000	Loss: 0.509751
Step #48000	Loss: 0.488648
Step #52000	Loss: 0.470704
Step #56000	Loss: 0.509587
Step #60000	Loss: 0.493526
Step #64000	Loss: 0.490031
Step #68000	Loss: 0.506700
Step #72000	Loss: 0.508518
Step #76000	Loss: 0.516407
Step #80000	Loss: 0.469098
Step #84000	Loss: 0.511309
Step #88000	Loss: 0.472308
Step #92000	Loss: 0.467192
Step #96000	Loss: 0.509606
Step #100000	Loss: 0.510161
Step #104000	Loss: 0.468609
Step #108000	Loss: 0.507955
Code block 'train epoch=4' took: 927293.84340 ms
train loss 0.49598389863967896
Code block 'val epoch=4' took: 60738.56410 ms
validation loss 0.4972034990787506
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --cufile-thread-count 16 --batch-size 16384 --epochs 5'
[WARN  tini (1109903)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-24 12:26:37.809203: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-24 12:26:40.852196: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-24 12:27:03.803403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-24 12:30:46.058459: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-24 12:30:46.431002: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fb84b2c0c10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-24 12:30:46.431092: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-24 12:30:46.604102: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-24 12:30:47.667542: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-24 12:30:47.978362: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.818702
Step #4000	Loss: 0.318925
Step #8000	Loss: 0.354449
Step #12000	Loss: 0.354123
Step #16000	Loss: 0.345066
Step #20000	Loss: 0.331308
Step #24000	Loss: 0.312045
Step #28000	Loss: 0.341460
Step #32000	Loss: 0.320437
Step #36000	Loss: 0.396450
Step #40000	Loss: 0.345200
Step #44000	Loss: 0.428220
Step #48000	Loss: 0.404578
Step #52000	Loss: 0.345088
Step #56000	Loss: 0.314107
Step #60000	Loss: 0.322676
Step #64000	Loss: 0.343497
Step #68000	Loss: 0.452417
Step #72000	Loss: 0.385169
Step #76000	Loss: 0.320934
Step #80000	Loss: 0.410364
Step #84000	Loss: 0.337466
Step #88000	Loss: 0.401832
Step #92000	Loss: 0.341244
Step #96000	Loss: 0.350318
Step #100000	Loss: 0.371897
Step #104000	Loss: 0.357603
Step #108000	Loss: 0.347538
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 951779.29460 ms
train loss 0.3589397072792053
Code block 'val epoch=0' took: 60860.53735 ms
validation loss 0.6159384846687317
Step #0	Loss: 0.453117
Step #4000	Loss: 0.310508
Step #8000	Loss: 0.328782
Step #12000	Loss: 0.325397
Step #16000	Loss: 0.302312
Step #20000	Loss: 0.320466
Step #24000	Loss: 0.301008
Step #28000	Loss: 0.311768
Step #32000	Loss: 0.293015
Step #36000	Loss: 0.330239
Step #40000	Loss: 0.308141
Step #44000	Loss: 0.340706
Step #48000	Loss: 0.336720
Step #52000	Loss: 0.312000
Step #56000	Loss: 0.298965
Step #60000	Loss: 0.304855
Step #64000	Loss: 0.310833
Step #68000	Loss: 0.367917
Step #72000	Loss: 0.323100
Step #76000	Loss: 0.306105
Step #80000	Loss: 0.338908
Step #84000	Loss: 0.315997
Step #88000	Loss: 0.330771
Step #92000	Loss: 0.307864
Step #96000	Loss: 0.322258
Step #100000	Loss: 0.319803
Step #104000	Loss: 0.322427
Step #108000	Loss: 0.324428
Code block 'train epoch=1' took: 927672.64281 ms
train loss 0.3211957812309265
Code block 'val epoch=1' took: 60184.89961 ms
validation loss 0.6834421157836914
Step #0	Loss: 0.356896
Step #4000	Loss: 0.300119
Step #8000	Loss: 0.303288
Step #12000	Loss: 0.317006
Step #16000	Loss: 0.291669
Step #20000	Loss: 0.307394
Step #24000	Loss: 0.289980
Step #28000	Loss: 0.312702
Step #32000	Loss: 0.287691
Step #36000	Loss: 0.312701
Step #40000	Loss: 0.309494
Step #44000	Loss: 0.326295
Step #48000	Loss: 0.323485
Step #52000	Loss: 0.312693
Step #56000	Loss: 0.297231
Step #60000	Loss: 0.295233
Step #64000	Loss: 0.315726
Step #68000	Loss: 0.331244
Step #72000	Loss: 0.308276
Step #76000	Loss: 0.292053
Step #80000	Loss: 0.302721
Step #84000	Loss: 0.314187
Step #88000	Loss: 0.300883
Step #92000	Loss: 0.299479
Step #96000	Loss: 0.317665
Step #100000	Loss: 0.312854
Step #104000	Loss: 0.306443
Step #108000	Loss: 0.304392
Code block 'train epoch=2' took: 929074.72180 ms
train loss 0.309012770652771
Code block 'val epoch=2' took: 62423.73053 ms
validation loss 0.774218738079071
Step #0	Loss: 0.322483
Step #4000	Loss: 0.297039
Step #8000	Loss: 0.301459
Step #12000	Loss: 0.309054
Step #16000	Loss: 0.294246
Step #20000	Loss: 0.307844
Step #24000	Loss: 0.286226
Step #28000	Loss: 0.304257
Step #32000	Loss: 0.288372
Step #36000	Loss: 0.306860
Step #40000	Loss: 0.301158
Step #44000	Loss: 0.309543
Step #48000	Loss: 0.313792
Step #52000	Loss: 0.305080
Step #56000	Loss: 0.295003
Step #60000	Loss: 0.300719
Step #64000	Loss: 0.311995
Step #68000	Loss: 0.326030
Step #72000	Loss: 0.307521
Step #76000	Loss: 0.295460
Step #80000	Loss: 0.306100
Step #84000	Loss: 0.304141
Step #88000	Loss: 0.293793
Step #92000	Loss: 0.302415
Step #96000	Loss: 0.313202
Step #100000	Loss: 0.306357
Step #104000	Loss: 0.299184
Step #108000	Loss: 0.302963
Code block 'train epoch=3' took: 928205.24746 ms
train loss 0.30410492420196533
Code block 'val epoch=3' took: 60129.84222 ms
validation loss 0.781004786491394
Step #0	Loss: 0.313368
Step #4000	Loss: 0.294691
Step #8000	Loss: 0.301492
Step #12000	Loss: 0.309191
Step #16000	Loss: 0.284046
Step #20000	Loss: 0.309661
Step #24000	Loss: 0.294656
Step #28000	Loss: 0.302551
Step #32000	Loss: 0.291012
Step #36000	Loss: 0.302195
Step #40000	Loss: 0.296841
Step #44000	Loss: 0.303301
Step #48000	Loss: 0.308609
Step #52000	Loss: 0.292931
Step #56000	Loss: 0.304007
Step #60000	Loss: 0.302044
Step #64000	Loss: 0.314772
Step #68000	Loss: 0.328757
Step #72000	Loss: 0.301050
Step #76000	Loss: 0.299042
Step #80000	Loss: 0.290895
Step #84000	Loss: 0.307447
Step #88000	Loss: 0.303236
Step #92000	Loss: 0.301507
Step #96000	Loss: 0.313552
Step #100000	Loss: 0.305330
Step #104000	Loss: 0.298420
Step #108000	Loss: 0.307535
Code block 'train epoch=4' took: 928876.44384 ms
train loss 0.30167391896247864
Code block 'val epoch=4' took: 60204.70374 ms
validation loss 0.814099907875061
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --cufile-thread-count 16 --batch-size 16384 --epochs 5'
[WARN  tini (1190913)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-24 13:53:33.087762: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-24 13:53:36.481121: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-24 13:54:02.559895: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-24 13:57:48.497592: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-24 13:57:48.868947: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fa39e2bd9c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-24 13:57:48.869024: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-24 13:57:49.037437: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-24 13:57:50.079719: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-24 13:57:50.387732: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 1.340929
Step #4000	Loss: 0.319397
Step #8000	Loss: 0.324313
Step #12000	Loss: 0.438723
Step #16000	Loss: 0.352500
Step #20000	Loss: 0.329229
Step #24000	Loss: 0.309450
Step #28000	Loss: 0.426786
Step #32000	Loss: 0.347272
Step #36000	Loss: 0.394711
Step #40000	Loss: 0.327074
Step #44000	Loss: 0.377069
Step #48000	Loss: 0.371259
Step #52000	Loss: 0.313743
Step #56000	Loss: 0.339230
Step #60000	Loss: 0.344846
Step #64000	Loss: 0.361426
Step #68000	Loss: 0.445714
Step #72000	Loss: 0.333845
Step #76000	Loss: 0.412287
Step #80000	Loss: 0.341311
Step #84000	Loss: 0.363725
Step #88000	Loss: 0.335297
Step #92000	Loss: 0.355406
Step #96000	Loss: 0.345827
Step #100000	Loss: 0.334395
Step #104000	Loss: 0.318424
Step #108000	Loss: 0.367656
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 956221.67737 ms
train loss 0.35917890071868896
Code block 'val epoch=0' took: 60513.51350 ms
validation loss 0.6572058796882629
Step #0	Loss: 0.448418
Step #4000	Loss: 0.303258
Step #8000	Loss: 0.310985
Step #12000	Loss: 0.352513
Step #16000	Loss: 0.315045
Step #20000	Loss: 0.304643
Step #24000	Loss: 0.295217
Step #28000	Loss: 0.347031
Step #32000	Loss: 0.305502
Step #36000	Loss: 0.321475
Step #40000	Loss: 0.313935
Step #44000	Loss: 0.323172
Step #48000	Loss: 0.326499
Step #52000	Loss: 0.308618
Step #56000	Loss: 0.320196
Step #60000	Loss: 0.318528
Step #64000	Loss: 0.328030
Step #68000	Loss: 0.361688
Step #72000	Loss: 0.315795
Step #76000	Loss: 0.334778
Step #80000	Loss: 0.320233
Step #84000	Loss: 0.323516
Step #88000	Loss: 0.302169
Step #92000	Loss: 0.322968
Step #96000	Loss: 0.324398
Step #100000	Loss: 0.323289
Step #104000	Loss: 0.301780
Step #108000	Loss: 0.325258
Code block 'train epoch=1' took: 933895.31276 ms
train loss 0.32081544399261475
Code block 'val epoch=1' took: 60159.26781 ms
validation loss 0.695634126663208
Step #0	Loss: 0.346297
Step #4000	Loss: 0.290067
Step #8000	Loss: 0.305295
Step #12000	Loss: 0.320021
Step #16000	Loss: 0.298286
Step #20000	Loss: 0.304504
Step #24000	Loss: 0.288208
Step #28000	Loss: 0.320192
Step #32000	Loss: 0.298185
Step #36000	Loss: 0.302678
Step #40000	Loss: 0.305378
Step #44000	Loss: 0.311070
Step #48000	Loss: 0.319107
Step #52000	Loss: 0.298431
Step #56000	Loss: 0.306277
Step #60000	Loss: 0.304609
Step #64000	Loss: 0.319377
Step #68000	Loss: 0.329237
Step #72000	Loss: 0.299698
Step #76000	Loss: 0.316463
Step #80000	Loss: 0.308494
Step #84000	Loss: 0.322483
Step #88000	Loss: 0.292928
Step #92000	Loss: 0.303049
Step #96000	Loss: 0.328381
Step #100000	Loss: 0.307989
Step #104000	Loss: 0.299115
Step #108000	Loss: 0.322498
Code block 'train epoch=2' took: 932680.63915 ms
train loss 0.30873268842697144
Code block 'val epoch=2' took: 60017.50550 ms
validation loss 0.726556658744812
Step #0	Loss: 0.327182
Step #4000	Loss: 0.297931
Step #8000	Loss: 0.307312
Step #12000	Loss: 0.303625
Step #16000	Loss: 0.294790
Step #20000	Loss: 0.306339
Step #24000	Loss: 0.281107
Step #28000	Loss: 0.309809
Step #32000	Loss: 0.294272
Step #36000	Loss: 0.291963
Step #40000	Loss: 0.304172
Step #44000	Loss: 0.304604
Step #48000	Loss: 0.311586
Step #52000	Loss: 0.307836
Step #56000	Loss: 0.299253
Step #60000	Loss: 0.305480
Step #64000	Loss: 0.308097
Step #68000	Loss: 0.327464
Step #72000	Loss: 0.295841
Step #76000	Loss: 0.307861
Step #80000	Loss: 0.314877
Step #84000	Loss: 0.309967
Step #88000	Loss: 0.287228
Step #92000	Loss: 0.292699
Step #96000	Loss: 0.315762
Step #100000	Loss: 0.311036
Step #104000	Loss: 0.293326
Step #108000	Loss: 0.313707
Code block 'train epoch=3' took: 934317.12049 ms
train loss 0.3038749694824219
Code block 'val epoch=3' took: 60638.16955 ms
validation loss 0.7278942465782166
Step #0	Loss: 0.319314
Step #4000	Loss: 0.288317
Step #8000	Loss: 0.295520
Step #12000	Loss: 0.301687
Step #16000	Loss: 0.289517
Step #20000	Loss: 0.301960
Step #24000	Loss: 0.285862
Step #28000	Loss: 0.292964
Step #32000	Loss: 0.295788
Step #36000	Loss: 0.292905
Step #40000	Loss: 0.291121
Step #44000	Loss: 0.300489
Step #48000	Loss: 0.313611
Step #52000	Loss: 0.297958
Step #56000	Loss: 0.303620
Step #60000	Loss: 0.295842
Step #64000	Loss: 0.313019
Step #68000	Loss: 0.326277
Step #72000	Loss: 0.289928
Step #76000	Loss: 0.303852
Step #80000	Loss: 0.306208
Step #84000	Loss: 0.304565
Step #88000	Loss: 0.283582
Step #92000	Loss: 0.303882
Step #96000	Loss: 0.309813
Step #100000	Loss: 0.309753
Step #104000	Loss: 0.293664
Step #108000	Loss: 0.307654
Code block 'train epoch=4' took: 932504.60390 ms
train loss 0.30139854550361633
Code block 'val epoch=4' took: 62453.28292 ms
validation loss 0.7565780282020569
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --cufile-thread-count 16 --batch-size 16384 --epochs 5'
[WARN  tini (1272732)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-24 15:20:53.863059: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-24 15:20:57.252715: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-24 15:21:20.647538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-24 15:25:01.213425: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-24 15:25:01.548490: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f707445e720 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-24 15:25:01.548571: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-24 15:25:01.696568: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-24 15:25:02.796932: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-24 15:25:03.086357: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.819506
Step #4000	Loss: 0.365632
terminate called after throwing an instance of 'rmm::out_of_memory'
  what():  std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp
[dgx-2:1272759] *** Process received signal ***
[dgx-2:1272759] Signal: Aborted (6)
[dgx-2:1272759] Signal code:  (-6)
[dgx-2:1272759] [ 0] /lib/x86_64-linux-gnu/libc.so.6(+0x42520)[0x7f7aa721a520]
[dgx-2:1272759] [ 1] /lib/x86_64-linux-gnu/libc.so.6(pthread_kill+0x12c)[0x7f7aa726ea7c]
[dgx-2:1272759] [ 2] /lib/x86_64-linux-gnu/libc.so.6(raise+0x16)[0x7f7aa721a476]
[dgx-2:1272759] [ 3] /lib/x86_64-linux-gnu/libc.so.6(abort+0xd3)[0x7f7aa72007f3]
[dgx-2:1272759] [ 4] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(_ZN9__gnu_cxx27__verbose_terminate_handlerEv+0xc0)[0x7f7aa4388026]
[dgx-2:1272759] [ 5] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(+0xb0514)[0x7f7aa4386514]
[dgx-2:1272759] [ 6] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(+0xb0566)[0x7f7aa4386566]
[dgx-2:1272759] [ 7] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(__cxa_rethrow+0x0)[0x7f7aa4386758]
[dgx-2:1272759] [ 8] /opt/conda/envs/rapids/lib/python3.10/site-packages/rmm/_lib/device_buffer.cpython-310-x86_64-linux-gnu.so(+0x4b67d)[0x7f79781c467d]
[dgx-2:1272759] [ 9] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf19make_numeric_columnENS_9data_typeEiNS_10mask_stateEN3rmm16cuda_stream_viewEPNS2_2mr22device_memory_resourceE+0x126)[0x7f7863ae20c6]
[dgx-2:1272759] [10] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf7strings6detail25create_chars_child_columnEiN3rmm16cuda_stream_viewEPNS2_2mr22device_memory_resourceE+0x19)[0x7f78651ffa29]
[dgx-2:1272759] [11] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf7strings6detail19make_strings_columnIPKN6thrust4pairIPKciEEEESt10unique_ptrINS_6columnESt14default_deleteISB_EET_SF_N3rmm16cuda_stream_viewEPNSG_2mr22device_memory_resourceE+0x47a)[0x7f78651f937a]
[dgx-2:1272759] [12] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf19make_strings_columnENS_11device_spanIKN6thrust4pairIPKciEELm18446744073709551615EEEN3rmm16cuda_stream_viewEPNS8_2mr22device_memory_resourceE+0x83)[0x7f78651f4603]
[dgx-2:1272759] [13] /home2/faculty/pwesolowski/praca-mgr/parser-repo/build/libmeta-cudf-parser-1.so(_ZNK18ParserOutputDeviceI5JDictIN5boost4mp117mp_listIJNS3_IJNS3_IJSt17integral_constantIiLi117EES4_IiLi115EES4_IiLi101EES4_IiLi114EES4_IiLi95EES4_IiLi105EES4_IiLi100EEEEE17JStringStaticCopyIS4_IiLi21EESC_NS3_IJEEEEEEENS3_IJNS3_IJS4_IiLi103EES4_IiLi109EES4_IiLi97EES4_IiLi112EES9_SA_SB_EEESD_IS4_IiLi37EESM_SF_EEEENS3_IJNS3_IJS8_SK_S4_IiLi116EESA_S4_IiLi110EESI_EEE7JNumberIhSS_SF_EEEENS3_IJNS3_IJS4_IiLi99EESK_SQ_S7_SI_S4_IiLi111EES8_S4_IiLi121EEEEESD_IS4_IiLi470EESZ_SF_EEEENS3_IJNS3_IJS4_IiLi108EESK_SQ_SA_SQ_S5_SB_S7_EEE11JRealNumberIfS14_SF_EEEENS3_IJNS3_IJS13_SX_SR_SI_SA_SQ_S5_SB_S7_EEES15_IfS18_SF_EEEEEEESF_EE6ToCudfEN3rmm16cuda_stream_viewEPNS1E_2mr22device_memory_resourceE+0x82a)[0x7f77f21116ca]
[dgx-2:1272759] [14] /home2/faculty/pwesolowski/praca-mgr/parser-repo/build/libmeta-cudf-parser-1.so(_Z25generate_example_metadataPKcmmi11end_of_linebb+0x1cf)[0x7f77f2108bcf]
[dgx-2:1272759] [15] /home2/faculty/pwesolowski/praca-mgr/parser-repo/python_binding/metajsonparser/_lib/json_cudf.cpython-310-x86_64-linux-gnu.so(+0x4b344)[0x7f77f21e0344]
[dgx-2:1272759] [16] python(+0x13fb27)[0x564c5997eb27]
[dgx-2:1272759] [17] python(PyObject_Call+0x209)[0x564c5998b139]
[dgx-2:1272759] [18] python(_PyEval_EvalFrameDefault+0x5d8c)[0x564c59974b7c]
[dgx-2:1272759] [19] python(_PyFunction_Vectorcall+0x6f)[0x564c5997ef8f]
[dgx-2:1272759] [20] python(_PyEval_EvalFrameDefault+0x2ec2)[0x564c59971cb2]
[dgx-2:1272759] [21] python(_PyFunction_Vectorcall+0x6f)[0x564c5997ef8f]
[dgx-2:1272759] [22] python(_PyEval_EvalFrameDefault+0x332)[0x564c5996f122]
[dgx-2:1272759] [23] python(_PyFunction_Vectorcall+0x6f)[0x564c5997ef8f]
[dgx-2:1272759] [24] python(_PyEval_EvalFrameDefault+0x2ec2)[0x564c59971cb2]
[dgx-2:1272759] [25] python(_PyFunction_Vectorcall+0x6f)[0x564c5997ef8f]
[dgx-2:1272759] [26] python(_PyEval_EvalFrameDefault+0x332)[0x564c5996f122]
[dgx-2:1272759] [27] python(_PyFunction_Vectorcall+0x6f)[0x564c5997ef8f]
[dgx-2:1272759] [28] python(_PyEval_EvalFrameDefault+0x2ec2)[0x564c59971cb2]
[dgx-2:1272759] [29] python(+0x14b641)[0x564c5998a641]
[dgx-2:1272759] *** End of error message ***
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --cufile-thread-count 16 --batch-size 16384 --epochs 5'
[WARN  tini (1278664)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-24 15:25:59.339392: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-24 15:26:02.482168: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-24 15:26:25.569625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
terminate called after throwing an instance of 'rmm::out_of_memory'
  what():  std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp
[dgx-2:1278688] *** Process received signal ***
[dgx-2:1278688] Signal: Aborted (6)
[dgx-2:1278688] Signal code:  (-6)
[dgx-2:1278688] [ 0] /lib/x86_64-linux-gnu/libc.so.6(+0x42520)[0x7fc6b5253520]
[dgx-2:1278688] [ 1] /lib/x86_64-linux-gnu/libc.so.6(pthread_kill+0x12c)[0x7fc6b52a7a7c]
[dgx-2:1278688] [ 2] /lib/x86_64-linux-gnu/libc.so.6(raise+0x16)[0x7fc6b5253476]
[dgx-2:1278688] [ 3] /lib/x86_64-linux-gnu/libc.so.6(abort+0xd3)[0x7fc6b52397f3]
[dgx-2:1278688] [ 4] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(_ZN9__gnu_cxx27__verbose_terminate_handlerEv+0xc0)[0x7fc6b23c1026]
[dgx-2:1278688] [ 5] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(+0xb0514)[0x7fc6b23bf514]
[dgx-2:1278688] [ 6] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(+0xb0566)[0x7fc6b23bf566]
[dgx-2:1278688] [ 7] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(__cxa_rethrow+0x0)[0x7fc6b23bf758]
[dgx-2:1278688] [ 8] /opt/conda/envs/rapids/lib/python3.10/site-packages/rmm/_lib/device_buffer.cpython-310-x86_64-linux-gnu.so(+0x4b67d)[0x7fc5a01e267d]
[dgx-2:1278688] [ 9] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf6columnC2ERKS0_N3rmm16cuda_stream_viewEPNS3_2mr22device_memory_resourceE+0x6d)[0x7fc473ad6add]
[dgx-2:1278688] [10] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf6columnC2ERKS0_N3rmm16cuda_stream_viewEPNS3_2mr22device_memory_resourceE+0x20c)[0x7fc473ad6c7c]
[dgx-2:1278688] [11] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf5tableC1ERKS0_+0x263)[0x7fc475210ec3]
[dgx-2:1278688] [12] /home2/faculty/pwesolowski/praca-mgr/parser-repo/build/libmeta-cudf-parser-1.so(_Z25generate_example_metadataPKcmmi11end_of_linebb+0x87d)[0x7fbee08b627d]
[dgx-2:1278688] [13] /home2/faculty/pwesolowski/praca-mgr/parser-repo/python_binding/metajsonparser/_lib/json_cudf.cpython-310-x86_64-linux-gnu.so(+0x4b344)[0x7fbee098d344]
[dgx-2:1278688] [14] python(+0x13fb27)[0x55ef7b11eb27]
[dgx-2:1278688] [15] python(PyObject_Call+0x209)[0x55ef7b12b139]
[dgx-2:1278688] [16] python(_PyEval_EvalFrameDefault+0x5d8c)[0x55ef7b114b7c]
[dgx-2:1278688] [17] python(_PyFunction_Vectorcall+0x6f)[0x55ef7b11ef8f]
[dgx-2:1278688] [18] python(_PyEval_EvalFrameDefault+0x2ec2)[0x55ef7b111cb2]
[dgx-2:1278688] [19] python(_PyFunction_Vectorcall+0x6f)[0x55ef7b11ef8f]
[dgx-2:1278688] [20] python(_PyEval_EvalFrameDefault+0x332)[0x55ef7b10f122]
[dgx-2:1278688] [21] python(_PyFunction_Vectorcall+0x6f)[0x55ef7b11ef8f]
[dgx-2:1278688] [22] python(_PyEval_EvalFrameDefault+0x2ec2)[0x55ef7b111cb2]
[dgx-2:1278688] [23] python(_PyFunction_Vectorcall+0x6f)[0x55ef7b11ef8f]
[dgx-2:1278688] [24] python(_PyEval_EvalFrameDefault+0x332)[0x55ef7b10f122]
[dgx-2:1278688] [25] python(_PyFunction_Vectorcall+0x6f)[0x55ef7b11ef8f]
[dgx-2:1278688] [26] python(_PyEval_EvalFrameDefault+0x2ec2)[0x55ef7b111cb2]
[dgx-2:1278688] [27] python(+0x14b641)[0x55ef7b12a641]
[dgx-2:1278688] [28] python(_PyEval_EvalFrameDefault+0x332)[0x55ef7b10f122]
[dgx-2:1278688] [29] python(_PyFunction_Vectorcall+0x6f)[0x55ef7b11ef8f]
[dgx-2:1278688] *** End of error message ***
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --cufile-thread-count 16 --batch-size 16384 --epochs 5'
[WARN  tini (1283308)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-24 15:30:08.396072: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-24 15:30:11.563632: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-24 15:30:36.609919: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
Failed to transform operator <nvtabular.ops.categorify.Categorify object at 0x7fe48e37fb20>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1780, in _encode
    ).sort_values("order")["labels"]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 2214, in sort_values
    out = self._gather(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-24 15:34:21.549445: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-24 15:34:21.917708: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fdc642de5a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-24 15:34:21.917793: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-24 15:34:22.083447: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-24 15:34:23.146972: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-24 15:34:23.481433: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 3.638946
Code block 'train epoch=0' took: 56973.33445 ms
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1780, in _encode
    ).sort_values("order")["labels"]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 2214, in sort_values
    out = self._gather(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home2/faculty/pwesolowski/praca-mgr/pipelines-repo/2_merlin/run_merlin.py", line 155, in <module>
    for batch, (examples, labels) in enumerate(train_tf_ds):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/tensorflow.py", line 97, in __next__
    converted_batch = self.convert_batch(super().__next__())
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 261, in __next__
    return self._get_next_batch()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 343, in _get_next_batch
    self._fetch_chunk()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 277, in _fetch_chunk
    raise chunks
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 791, in load_chunks
    self.chunk_logic(itr)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 759, in chunk_logic
    for chunks in self.batch(itr):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 745, in batch
    value = next(itr)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/io/dataframe_iter.py", line 44, in __iter__
    yield part.compute(scheduler="synchronous")
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/base.py", line 314, in compute
    (result,) = compute(self, traverse=False, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/base.py", line 599, in compute
    results = schedule(dsk, keys, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 557, in get_sync
    return get_async(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 500, in get_async
    for key, res_info, failed in queue_get(queue).result():
  File "/opt/conda/envs/rapids/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/opt/conda/envs/rapids/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 542, in submit
    fut.set_result(fn(*args, **kwargs))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 238, in batch_execute_tasks
    return [execute_task(*a) for a in it]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 238, in <listcomp>
    return [execute_task(*a) for a in it]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 229, in execute_task
    result = pack_exception(e, dumps)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 224, in execute_task
    result = _execute_task(task, data)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/optimization.py", line 990, in __call__
    return core.get(self.dsk, self.outkey, dict(zip(self.inkeys, args)))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 149, in get
    result = _execute_task(task, cache)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in <genexpr>
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/utils.py", line 72, in apply
    return func(*args, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 87, in transform
    transformed_data = self._execute_node(node, transformable, capture_dtypes, strict)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 101, in _execute_node
    upstream_outputs = self._run_upstream_transforms(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 114, in _run_upstream_transforms
    node_output = self._execute_node(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 107, in _execute_node
    transform_output = self._run_node_transform(node, transform_input, capture_dtypes, strict)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 227, in _run_node_transform
    raise exc
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
+ for CUFILE_THREAD_COUNT in 4 8 16 32 64
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --cufile-thread-count 32 --batch-size 16384 --epochs 5'
[WARN  tini (1289073)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-24 15:35:09.493695: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-24 15:35:12.797161: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-24 15:35:37.333090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-24 15:39:24.529489: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-24 15:39:25.030147: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fa9e24b2530 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-24 15:39:25.030225: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-24 15:39:25.186246: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-24 15:39:26.231783: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-24 15:39:26.556483: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.514589
Step #4000	Loss: 0.323195
Step #8000	Loss: 0.342881
Step #12000	Loss: 0.427000
Step #16000	Loss: 0.429617
Step #20000	Loss: 0.341093
Step #24000	Loss: 0.323687
Step #28000	Loss: 0.350076
Step #32000	Loss: 0.306642
Step #36000	Loss: 0.368721
Step #40000	Loss: 0.374310
Step #44000	Loss: 0.361220
Step #48000	Loss: 0.317488
Step #52000	Loss: 0.319832
Step #56000	Loss: 0.326706
Step #60000	Loss: 0.308392
Step #64000	Loss: 0.372896
Step #68000	Loss: 0.424902
Step #72000	Loss: 0.437643
Step #76000	Loss: 0.435539
Step #80000	Loss: 0.343122
Step #84000	Loss: 0.430827
Step #88000	Loss: 0.307074
Step #92000	Loss: 0.316366
Step #96000	Loss: 0.428494
Step #100000	Loss: 0.341168
Step #104000	Loss: 0.330402
Step #108000	Loss: 0.393509
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 973612.03619 ms
train loss 0.3616446256637573
Code block 'val epoch=0' took: 65192.94715 ms
validation loss 0.589945375919342
Step #0	Loss: 0.438791
Step #4000	Loss: 0.299174
Step #8000	Loss: 0.312837
Step #12000	Loss: 0.354475
Step #16000	Loss: 0.355834
Step #20000	Loss: 0.324684
Step #24000	Loss: 0.307799
Step #28000	Loss: 0.318448
Step #32000	Loss: 0.299988
Step #36000	Loss: 0.331297
Step #40000	Loss: 0.328708
Step #44000	Loss: 0.327820
Step #48000	Loss: 0.302088
Step #52000	Loss: 0.321459
Step #56000	Loss: 0.315760
Step #60000	Loss: 0.306563
Step #64000	Loss: 0.326957
Step #68000	Loss: 0.364110
Step #72000	Loss: 0.337772
Step #76000	Loss: 0.346079
Step #80000	Loss: 0.298941
Step #84000	Loss: 0.358788
Step #88000	Loss: 0.283375
Step #92000	Loss: 0.302008
Step #96000	Loss: 0.351264
Step #100000	Loss: 0.319391
Step #104000	Loss: 0.317619
Step #108000	Loss: 0.337888
Code block 'train epoch=1' took: 949261.04197 ms
train loss 0.32406359910964966
Code block 'val epoch=1' took: 64454.50657 ms
validation loss 0.6262159943580627
Step #0	Loss: 0.325192
Step #4000	Loss: 0.293486
Step #8000	Loss: 0.303535
Step #12000	Loss: 0.329003
Step #16000	Loss: 0.319734
Step #20000	Loss: 0.319443
Step #24000	Loss: 0.301442
Step #28000	Loss: 0.315508
Step #32000	Loss: 0.296045
Step #36000	Loss: 0.309204
Step #40000	Loss: 0.306146
Step #44000	Loss: 0.302552
Step #48000	Loss: 0.301945
Step #52000	Loss: 0.314108
Step #56000	Loss: 0.310054
Step #60000	Loss: 0.293925
Step #64000	Loss: 0.318312
Step #68000	Loss: 0.340441
Step #72000	Loss: 0.314979
Step #76000	Loss: 0.323454
Step #80000	Loss: 0.297927
Step #84000	Loss: 0.331170
Step #88000	Loss: 0.274820
Step #92000	Loss: 0.296914
Step #96000	Loss: 0.325452
Step #100000	Loss: 0.308724
Step #104000	Loss: 0.301050
Step #108000	Loss: 0.326376
Code block 'train epoch=2' took: 950360.57804 ms
train loss 0.31111735105514526
Code block 'val epoch=2' took: 64254.10621 ms
validation loss 0.6725389361381531
Step #0	Loss: 0.307607
Step #4000	Loss: 0.291202
Step #8000	Loss: 0.299297
Step #12000	Loss: 0.316012
Step #16000	Loss: 0.307492
Step #20000	Loss: 0.305549
Step #24000	Loss: 0.293334
Step #28000	Loss: 0.300682
Step #32000	Loss: 0.298725
Step #36000	Loss: 0.295915
Step #40000	Loss: 0.296769
Step #44000	Loss: 0.299381
Step #48000	Loss: 0.297964
Step #52000	Loss: 0.306460
Step #56000	Loss: 0.306199
Step #60000	Loss: 0.287036
Step #64000	Loss: 0.312235
Step #68000	Loss: 0.316959
Step #72000	Loss: 0.305686
Step #76000	Loss: 0.314889
Step #80000	Loss: 0.287969
Step #84000	Loss: 0.318647
Step #88000	Loss: 0.276492
Step #92000	Loss: 0.289746
Step #96000	Loss: 0.320108
Step #100000	Loss: 0.301816
Step #104000	Loss: 0.301646
Step #108000	Loss: 0.316631
Code block 'train epoch=3' took: 949550.39602 ms
train loss 0.30553075671195984
Code block 'val epoch=3' took: 64689.43057 ms
validation loss 0.7089222073554993
Step #0	Loss: 0.304470
Step #4000	Loss: 0.292537
Step #8000	Loss: 0.304411
Step #12000	Loss: 0.299991
Step #16000	Loss: 0.299634
Step #20000	Loss: 0.308407
Step #24000	Loss: 0.290641
Step #28000	Loss: 0.295316
Step #32000	Loss: 0.288163
Step #36000	Loss: 0.293181
Step #40000	Loss: 0.297777
Step #44000	Loss: 0.300144
Step #48000	Loss: 0.281193
Step #52000	Loss: 0.304166
Step #56000	Loss: 0.292826
Step #60000	Loss: 0.296316
Step #64000	Loss: 0.310293
Step #68000	Loss: 0.318267
Step #72000	Loss: 0.303800
Step #76000	Loss: 0.305114
Step #80000	Loss: 0.283467
Step #84000	Loss: 0.313763
Step #88000	Loss: 0.275528
Step #92000	Loss: 0.295841
Step #96000	Loss: 0.309486
Step #100000	Loss: 0.310701
Step #104000	Loss: 0.303724
Step #108000	Loss: 0.311664
Code block 'train epoch=4' took: 947877.68293 ms
train loss 0.3028487265110016
Code block 'val epoch=4' took: 64581.89141 ms
validation loss 0.7446344494819641
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --cufile-thread-count 32 --batch-size 16384 --epochs 5'
[WARN  tini (1369840)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-24 17:04:23.208305: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-24 17:04:27.075360: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-24 17:04:55.610999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-24 17:08:46.257269: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-24 17:08:46.738726: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fe312aa9900 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-24 17:08:46.738803: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-24 17:08:46.891271: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-24 17:08:47.867154: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-24 17:08:48.176104: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.516516
Step #4000	Loss: 0.309566
Step #8000	Loss: 0.320799
Step #12000	Loss: 0.442432
Step #16000	Loss: 0.436997
Step #20000	Loss: 0.345421
Step #24000	Loss: 0.368007
Step #28000	Loss: 0.407617
Step #32000	Loss: 0.330940
Step #36000	Loss: 0.349321
Step #40000	Loss: 0.332558
Step #44000	Loss: 0.394974
Step #48000	Loss: 0.318040
Step #52000	Loss: 0.360621
Step #56000	Loss: 0.319380
Step #60000	Loss: 0.323820
Step #64000	Loss: 0.395850
Step #68000	Loss: 0.439513
Step #72000	Loss: 0.337091
Step #76000	Loss: 0.453874
Step #80000	Loss: 0.380462
Step #84000	Loss: 0.450633
Step #88000	Loss: 0.352519
Step #92000	Loss: 0.312544
Step #96000	Loss: 0.450910
Step #100000	Loss: 0.320013
Step #104000	Loss: 0.314857
Step #108000	Loss: 0.401303
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 969986.05415 ms
train loss 0.3605564832687378
Code block 'val epoch=0' took: 64503.73787 ms
validation loss 0.6073033809661865
Step #0	Loss: 0.483844
Step #4000	Loss: 0.301966
Step #8000	Loss: 0.308647
Step #12000	Loss: 0.368140
Step #16000	Loss: 0.356631
Step #20000	Loss: 0.325109
Step #24000	Loss: 0.329829
Step #28000	Loss: 0.333542
Step #32000	Loss: 0.316103
Step #36000	Loss: 0.318338
Step #40000	Loss: 0.311475
Step #44000	Loss: 0.341266
Step #48000	Loss: 0.301110
Step #52000	Loss: 0.331593
Step #56000	Loss: 0.300989
Step #60000	Loss: 0.312680
Step #64000	Loss: 0.333927
Step #68000	Loss: 0.374002
Step #72000	Loss: 0.312530
Step #76000	Loss: 0.360746
Step #80000	Loss: 0.321203
Step #84000	Loss: 0.364728
Step #88000	Loss: 0.307134
Step #92000	Loss: 0.301476
Step #96000	Loss: 0.372396
Step #100000	Loss: 0.316523
Step #104000	Loss: 0.299849
Step #108000	Loss: 0.350299
Code block 'train epoch=1' took: 943037.94533 ms
train loss 0.3234896957874298
Code block 'val epoch=1' took: 64579.99965 ms
validation loss 0.6982980966567993
Step #0	Loss: 0.348789
Step #4000	Loss: 0.292580
Step #8000	Loss: 0.302011
Step #12000	Loss: 0.325661
Step #16000	Loss: 0.322591
Step #20000	Loss: 0.312379
Step #24000	Loss: 0.300077
Step #28000	Loss: 0.323079
Step #32000	Loss: 0.295909
Step #36000	Loss: 0.311607
Step #40000	Loss: 0.299840
Step #44000	Loss: 0.311691
Step #48000	Loss: 0.298847
Step #52000	Loss: 0.307653
Step #56000	Loss: 0.294327
Step #60000	Loss: 0.300727
Step #64000	Loss: 0.314891
Step #68000	Loss: 0.334002
Step #72000	Loss: 0.299763
Step #76000	Loss: 0.318127
Step #80000	Loss: 0.300179
Step #84000	Loss: 0.338310
Step #88000	Loss: 0.292979
Step #92000	Loss: 0.292225
Step #96000	Loss: 0.329579
Step #100000	Loss: 0.315771
Step #104000	Loss: 0.295364
Step #108000	Loss: 0.328298
Code block 'train epoch=2' took: 945220.31442 ms
train loss 0.31022319197654724
Code block 'val epoch=2' took: 64375.25903 ms
validation loss 0.7123379111289978
Step #0	Loss: 0.315046
Step #4000	Loss: 0.293783
Step #8000	Loss: 0.296716
Step #12000	Loss: 0.315437
Step #16000	Loss: 0.304753
Step #20000	Loss: 0.305669
Step #24000	Loss: 0.290600
Step #28000	Loss: 0.311927
Step #32000	Loss: 0.291233
Step #36000	Loss: 0.309167
Step #40000	Loss: 0.308024
Step #44000	Loss: 0.307025
Step #48000	Loss: 0.291969
Step #52000	Loss: 0.313065
Step #56000	Loss: 0.296574
Step #60000	Loss: 0.295518
Step #64000	Loss: 0.307303
Step #68000	Loss: 0.328152
Step #72000	Loss: 0.302334
Step #76000	Loss: 0.317380
Step #80000	Loss: 0.292254
Step #84000	Loss: 0.323018
Step #88000	Loss: 0.291890
Step #92000	Loss: 0.290857
Step #96000	Loss: 0.327476
Step #100000	Loss: 0.306121
Step #104000	Loss: 0.287557
Step #108000	Loss: 0.326736
Code block 'train epoch=3' took: 950752.53314 ms
train loss 0.3048509657382965
Code block 'val epoch=3' took: 64353.41678 ms
validation loss 0.7497942447662354
Step #0	Loss: 0.313471
Step #4000	Loss: 0.289753
Step #8000	Loss: 0.299238
Step #12000	Loss: 0.300196
Step #16000	Loss: 0.292850
Step #20000	Loss: 0.316924
Step #24000	Loss: 0.291796
Step #28000	Loss: 0.315099
Step #32000	Loss: 0.291953
Step #36000	Loss: 0.292384
Step #40000	Loss: 0.296916
Step #44000	Loss: 0.303457
Step #48000	Loss: 0.292961
Step #52000	Loss: 0.306638
Step #56000	Loss: 0.297672
Step #60000	Loss: 0.301636
Step #64000	Loss: 0.308963
Step #68000	Loss: 0.316964
Step #72000	Loss: 0.297277
Step #76000	Loss: 0.314030
Step #80000	Loss: 0.292129
Step #84000	Loss: 0.311756
Step #88000	Loss: 0.285138
Step #92000	Loss: 0.291048
Step #96000	Loss: 0.323412
Step #100000	Loss: 0.302352
Step #104000	Loss: 0.293439
Step #108000	Loss: 0.311762
Code block 'train epoch=4' took: 947595.69378 ms
train loss 0.30212435126304626
Code block 'val epoch=4' took: 63861.89614 ms
validation loss 0.7762855887413025
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --cufile-thread-count 32 --batch-size 16384 --epochs 5'
[WARN  tini (1453467)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-24 18:33:21.420369: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-24 18:33:24.456334: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-24 18:33:48.529080: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-24 18:37:38.308796: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-24 18:37:38.645412: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f4443576c30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-24 18:37:38.645482: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-24 18:37:38.807420: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-24 18:37:39.823737: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-24 18:37:40.116640: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 1.602618
Step #4000	Loss: 0.379373
Step #8000	Loss: 0.331186
Step #12000	Loss: 0.373358
Step #16000	Loss: 0.429533
Step #20000	Loss: 0.321901
Step #24000	Loss: 0.392629
Step #28000	Loss: 0.320448
Step #32000	Loss: 0.328331
Step #36000	Loss: 0.351369
Step #40000	Loss: 0.333270
Step #44000	Loss: 0.339556
Step #48000	Loss: 0.329207
Step #52000	Loss: 0.320138
Step #56000	Loss: 0.310740
Step #60000	Loss: 0.347775
Step #64000	Loss: 0.341206
Step #68000	Loss: 0.449300
Step #72000	Loss: 0.446823
Step #76000	Loss: 0.462288
Step #80000	Loss: 0.340941
Step #84000	Loss: 0.442829
Step #88000	Loss: 0.330405
Step #92000	Loss: 0.321236
Step #96000	Loss: 0.382170
Step #100000	Loss: 0.330867
Step #104000	Loss: 0.405446
Step #108000	Loss: 0.420353
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 966041.64216 ms
train loss 0.35980042815208435
Code block 'val epoch=0' took: 63890.55609 ms
validation loss 0.6101997494697571
Step #0	Loss: 0.436916
Step #4000	Loss: 0.308763
Step #8000	Loss: 0.313874
Step #12000	Loss: 0.326665
Step #16000	Loss: 0.350624
Step #20000	Loss: 0.311434
Step #24000	Loss: 0.334798
Step #28000	Loss: 0.310915
Step #32000	Loss: 0.305058
Step #36000	Loss: 0.315750
Step #40000	Loss: 0.309706
Step #44000	Loss: 0.312167
Step #48000	Loss: 0.317836
Step #52000	Loss: 0.304742
Step #56000	Loss: 0.295379
Step #60000	Loss: 0.311211
Step #64000	Loss: 0.312715
Step #68000	Loss: 0.359717
Step #72000	Loss: 0.346289
Step #76000	Loss: 0.365236
Step #80000	Loss: 0.322102
Step #84000	Loss: 0.355471
Step #88000	Loss: 0.302030
Step #92000	Loss: 0.295473
Step #96000	Loss: 0.330454
Step #100000	Loss: 0.311355
Step #104000	Loss: 0.342904
Step #108000	Loss: 0.353040
Code block 'train epoch=1' took: 940695.30334 ms
train loss 0.3218134939670563
Code block 'val epoch=1' took: 63427.95466 ms
validation loss 0.6363641619682312
Step #0	Loss: 0.337925
Step #4000	Loss: 0.297465
Step #8000	Loss: 0.301459
Step #12000	Loss: 0.313889
Step #16000	Loss: 0.309900
Step #20000	Loss: 0.307811
Step #24000	Loss: 0.307946
Step #28000	Loss: 0.308082
Step #32000	Loss: 0.302375
Step #36000	Loss: 0.308942
Step #40000	Loss: 0.308441
Step #44000	Loss: 0.304293
Step #48000	Loss: 0.297680
Step #52000	Loss: 0.302004
Step #56000	Loss: 0.301724
Step #60000	Loss: 0.303375
Step #64000	Loss: 0.314919
Step #68000	Loss: 0.335149
Step #72000	Loss: 0.317629
Step #76000	Loss: 0.327064
Step #80000	Loss: 0.311365
Step #84000	Loss: 0.329127
Step #88000	Loss: 0.297136
Step #92000	Loss: 0.297674
Step #96000	Loss: 0.321655
Step #100000	Loss: 0.301506
Step #104000	Loss: 0.314336
Step #108000	Loss: 0.331379
Code block 'train epoch=2' took: 942363.44516 ms
train loss 0.3093186616897583
Code block 'val epoch=2' took: 63856.82853 ms
validation loss 0.6745457053184509
Step #0	Loss: 0.325422
Step #4000	Loss: 0.299620
Step #8000	Loss: 0.302906
Step #12000	Loss: 0.306406
Step #16000	Loss: 0.296266
Step #20000	Loss: 0.305797
Step #24000	Loss: 0.297382
Step #28000	Loss: 0.300988
Step #32000	Loss: 0.291139
Step #36000	Loss: 0.297738
Step #40000	Loss: 0.304131
Step #44000	Loss: 0.303412
Step #48000	Loss: 0.301231
Step #52000	Loss: 0.302377
Step #56000	Loss: 0.293930
Step #60000	Loss: 0.299167
Step #64000	Loss: 0.301240
Step #68000	Loss: 0.319456
Step #72000	Loss: 0.304954
Step #76000	Loss: 0.319397
Step #80000	Loss: 0.306584
Step #84000	Loss: 0.318382
Step #88000	Loss: 0.292448
Step #92000	Loss: 0.289244
Step #96000	Loss: 0.307680
Step #100000	Loss: 0.303283
Step #104000	Loss: 0.311385
Step #108000	Loss: 0.323627
Code block 'train epoch=3' took: 943273.59333 ms
train loss 0.3041759133338928
Code block 'val epoch=3' took: 63345.49213 ms
validation loss 0.7281957864761353
Step #0	Loss: 0.321021
Step #4000	Loss: 0.293346
Step #8000	Loss: 0.299428
Step #12000	Loss: 0.301607
Step #16000	Loss: 0.287031
Step #20000	Loss: 0.308200
Step #24000	Loss: 0.286950
Step #28000	Loss: 0.293264
Step #32000	Loss: 0.291305
Step #36000	Loss: 0.298644
Step #40000	Loss: 0.302589
Step #44000	Loss: 0.298842
Step #48000	Loss: 0.311186
Step #52000	Loss: 0.296164
Step #56000	Loss: 0.287190
Step #60000	Loss: 0.294319
Step #64000	Loss: 0.311396
Step #68000	Loss: 0.322128
Step #72000	Loss: 0.302505
Step #76000	Loss: 0.318352
Step #80000	Loss: 0.305097
Step #84000	Loss: 0.310591
Step #88000	Loss: 0.290603
Step #92000	Loss: 0.292689
Step #96000	Loss: 0.311104
Step #100000	Loss: 0.301195
Step #104000	Loss: 0.308836
Step #108000	Loss: 0.321321
Code block 'train epoch=4' took: 942540.13419 ms
train loss 0.3017515242099762
Code block 'val epoch=4' took: 63461.96667 ms
validation loss 0.811886191368103
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --cufile-thread-count 32 --batch-size 16384 --epochs 5'
[WARN  tini (1559544)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-24 20:01:47.982914: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-24 20:01:51.332325: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-24 20:02:17.644073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-24 20:05:59.948411: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-24 20:06:00.419970: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f5c9adbbb90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-24 20:06:00.420054: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-24 20:06:00.572158: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-24 20:06:01.543822: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-24 20:06:01.848015: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 4.005999
Step #4000	Loss: 0.367532
Step #8000	Loss: 0.321623
Step #12000	Loss: 0.434025
Step #16000	Loss: 0.428363
Step #20000	Loss: 0.346225
Step #24000	Loss: 0.365752
Step #28000	Loss: 0.386772
Step #32000	Loss: 0.328701
Step #36000	Loss: 0.354219
Step #40000	Loss: 0.409433
Step #44000	Loss: 0.400839
Step #48000	Loss: 0.353641
Step #52000	Loss: 0.314916
Step #56000	Loss: 0.332985
Step #60000	Loss: 0.313867
Step #64000	Loss: 0.398984
Step #68000	Loss: 0.449288
Step #72000	Loss: 0.339586
Step #76000	Loss: 0.340234
Step #80000	Loss: 0.387666
Step #84000	Loss: 0.358347
Step #88000	Loss: 0.350222
Step #92000	Loss: 0.301165
Step #96000	Loss: 0.445638
Step #100000	Loss: 0.325804
Step #104000	Loss: 0.313150
Step #108000	Loss: 0.406933
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 953101.08476 ms
train loss 0.3605622351169586
Code block 'val epoch=0' took: 60853.40365 ms
validation loss 0.5757282972335815
Step #0	Loss: 0.482777
Step #4000	Loss: 0.315429
Step #8000	Loss: 0.307883
Step #12000	Loss: 0.358545
Step #16000	Loss: 0.348836
Step #20000	Loss: 0.326384
Step #24000	Loss: 0.325886
Step #28000	Loss: 0.330464
Step #32000	Loss: 0.303998
Step #36000	Loss: 0.321738
Step #40000	Loss: 0.339299
Step #44000	Loss: 0.334982
Step #48000	Loss: 0.330254
Step #52000	Loss: 0.301078
Step #56000	Loss: 0.310341
Step #60000	Loss: 0.303134
Step #64000	Loss: 0.333994
Step #68000	Loss: 0.365010
Step #72000	Loss: 0.312654
Step #76000	Loss: 0.317530
Step #80000	Loss: 0.313743
Step #84000	Loss: 0.322178
Step #88000	Loss: 0.309927
Step #92000	Loss: 0.302024
Step #96000	Loss: 0.366350
Step #100000	Loss: 0.309833
Step #104000	Loss: 0.304301
Step #108000	Loss: 0.350323
Code block 'train epoch=1' took: 927652.86322 ms
train loss 0.3229110538959503
Code block 'val epoch=1' took: 60841.86257 ms
validation loss 0.6218689680099487
Step #0	Loss: 0.340473
Step #4000	Loss: 0.296151
Step #8000	Loss: 0.300561
Step #12000	Loss: 0.324202
Step #16000	Loss: 0.317815
Step #20000	Loss: 0.308549
Step #24000	Loss: 0.304372
Step #28000	Loss: 0.316096
Step #32000	Loss: 0.288687
Step #36000	Loss: 0.301910
Step #40000	Loss: 0.315461
Step #44000	Loss: 0.309584
Step #48000	Loss: 0.316057
Step #52000	Loss: 0.303468
Step #56000	Loss: 0.299884
Step #60000	Loss: 0.303843
Step #64000	Loss: 0.318449
Step #68000	Loss: 0.341388
Step #72000	Loss: 0.301896
Step #76000	Loss: 0.307532
Step #80000	Loss: 0.299216
Step #84000	Loss: 0.315650
Step #88000	Loss: 0.294450
Step #92000	Loss: 0.297327
Step #96000	Loss: 0.329421
Step #100000	Loss: 0.305607
Step #104000	Loss: 0.296417
Step #108000	Loss: 0.325312
Code block 'train epoch=2' took: 930217.91757 ms
train loss 0.30989155173301697
Code block 'val epoch=2' took: 60105.50557 ms
validation loss 0.701537013053894
Step #0	Loss: 0.316438
Step #4000	Loss: 0.294620
Step #8000	Loss: 0.298257
Step #12000	Loss: 0.315257
Step #16000	Loss: 0.307074
Step #20000	Loss: 0.308472
Step #24000	Loss: 0.302398
Step #28000	Loss: 0.304583
Step #32000	Loss: 0.285402
Step #36000	Loss: 0.300834
Step #40000	Loss: 0.305884
Step #44000	Loss: 0.306529
Step #48000	Loss: 0.311095
Step #52000	Loss: 0.295874
Step #56000	Loss: 0.308554
Step #60000	Loss: 0.302097
Step #64000	Loss: 0.306438
Step #68000	Loss: 0.327889
Step #72000	Loss: 0.301155
Step #76000	Loss: 0.309423
Step #80000	Loss: 0.297249
Step #84000	Loss: 0.305421
Step #88000	Loss: 0.282889
Step #92000	Loss: 0.294257
Step #96000	Loss: 0.326563
Step #100000	Loss: 0.304068
Step #104000	Loss: 0.288625
Step #108000	Loss: 0.309106
Code block 'train epoch=3' took: 928919.55303 ms
train loss 0.3046017289161682
Code block 'val epoch=3' took: 60501.11912 ms
validation loss 0.7469866871833801
Step #0	Loss: 0.312516
Step #4000	Loss: 0.288688
Step #8000	Loss: 0.292064
Step #12000	Loss: 0.304501
Step #16000	Loss: 0.299241
Step #20000	Loss: 0.308882
Step #24000	Loss: 0.293115
Step #28000	Loss: 0.302245
Step #32000	Loss: 0.283288
Step #36000	Loss: 0.294749
Step #40000	Loss: 0.297428
Step #44000	Loss: 0.307352
Step #48000	Loss: 0.312474
Step #52000	Loss: 0.291382
Step #56000	Loss: 0.292600
Step #60000	Loss: 0.294338
Step #64000	Loss: 0.299461
Step #68000	Loss: 0.319820
Step #72000	Loss: 0.297507
Step #76000	Loss: 0.302224
Step #80000	Loss: 0.295957
Step #84000	Loss: 0.305403
Step #88000	Loss: 0.287487
Step #92000	Loss: 0.288711
Step #96000	Loss: 0.313174
Step #100000	Loss: 0.303904
Step #104000	Loss: 0.296316
Step #108000	Loss: 0.313425
Code block 'train epoch=4' took: 928145.93554 ms
train loss 0.30199968814849854
Code block 'val epoch=4' took: 61068.45770 ms
validation loss 0.775793731212616
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --cufile-thread-count 32 --batch-size 16384 --epochs 5'
[WARN  tini (1637584)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-24 21:28:50.277698: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-24 21:28:53.710520: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-24 21:29:19.779173: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-24 21:33:04.692188: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-24 21:33:05.254797: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7ef5c26de720 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-24 21:33:05.254883: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-24 21:33:05.437748: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-24 21:33:06.459444: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-24 21:33:06.801447: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.513617
Step #4000	Loss: 0.324933
Step #8000	Loss: 0.355055
Step #12000	Loss: 0.357644
Step #16000	Loss: 0.342840
Step #20000	Loss: 0.327771
Step #24000	Loss: 0.320504
Step #28000	Loss: 0.328820
Step #32000	Loss: 0.316022
Step #36000	Loss: 0.394114
Step #40000	Loss: 0.347185
Step #44000	Loss: 0.430996
Step #48000	Loss: 0.399292
Step #52000	Loss: 0.344684
Step #56000	Loss: 0.319274
Step #60000	Loss: 0.321101
Step #64000	Loss: 0.340069
Step #68000	Loss: 0.454950
Step #72000	Loss: 0.378978
Step #76000	Loss: 0.322340
Step #80000	Loss: 0.404456
Step #84000	Loss: 0.338392
Step #88000	Loss: 0.401653
Step #92000	Loss: 0.343738
Step #96000	Loss: 0.363139
Step #100000	Loss: 0.367315
Step #104000	Loss: 0.355435
Step #108000	Loss: 0.355897
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 954662.02143 ms
train loss 0.3592507839202881
Code block 'val epoch=0' took: 59994.87460 ms
validation loss 0.6007973551750183
Step #0	Loss: 0.499588
Step #4000	Loss: 0.307157
Step #8000	Loss: 0.315318
Step #12000	Loss: 0.327499
Step #16000	Loss: 0.306089
Step #20000	Loss: 0.316734
Step #24000	Loss: 0.296835
Step #28000	Loss: 0.313080
Step #32000	Loss: 0.303967
Step #36000	Loss: 0.333473
Step #40000	Loss: 0.318586
Step #44000	Loss: 0.350503
Step #48000	Loss: 0.343644
Step #52000	Loss: 0.313904
Step #56000	Loss: 0.303183
Step #60000	Loss: 0.306852
Step #64000	Loss: 0.327065
Step #68000	Loss: 0.373999
Step #72000	Loss: 0.327235
Step #76000	Loss: 0.313282
Step #80000	Loss: 0.331840
Step #84000	Loss: 0.321432
Step #88000	Loss: 0.323821
Step #92000	Loss: 0.310678
Step #96000	Loss: 0.324655
Step #100000	Loss: 0.322759
Step #104000	Loss: 0.314909
Step #108000	Loss: 0.324115
Code block 'train epoch=1' took: 928267.73881 ms
train loss 0.32226675748825073
Code block 'val epoch=1' took: 59934.60930 ms
validation loss 0.6964713931083679
Step #0	Loss: 0.387156
Step #4000	Loss: 0.290983
Step #8000	Loss: 0.305096
Step #12000	Loss: 0.317531
Step #16000	Loss: 0.302152
Step #20000	Loss: 0.308896
Step #24000	Loss: 0.289921
Step #28000	Loss: 0.299939
Step #32000	Loss: 0.294698
Step #36000	Loss: 0.305780
Step #40000	Loss: 0.295713
Step #44000	Loss: 0.321463
Step #48000	Loss: 0.324682
Step #52000	Loss: 0.307031
Step #56000	Loss: 0.293677
Step #60000	Loss: 0.297342
Step #64000	Loss: 0.314836
Step #68000	Loss: 0.328487
Step #72000	Loss: 0.305150
Step #76000	Loss: 0.301964
Step #80000	Loss: 0.308337
Step #84000	Loss: 0.310876
Step #88000	Loss: 0.307420
Step #92000	Loss: 0.298344
Step #96000	Loss: 0.320819
Step #100000	Loss: 0.324650
Step #104000	Loss: 0.311744
Step #108000	Loss: 0.312353
Code block 'train epoch=2' took: 928638.91886 ms
train loss 0.3097034990787506
Code block 'val epoch=2' took: 62919.77713 ms
validation loss 0.6978868246078491
Step #0	Loss: 0.354283
Step #4000	Loss: 0.291591
Step #8000	Loss: 0.305613
Step #12000	Loss: 0.303798
Step #16000	Loss: 0.290874
Step #20000	Loss: 0.307812
Step #24000	Loss: 0.294228
Step #28000	Loss: 0.293869
Step #32000	Loss: 0.289609
Step #36000	Loss: 0.302638
Step #40000	Loss: 0.300793
Step #44000	Loss: 0.310994
Step #48000	Loss: 0.319427
Step #52000	Loss: 0.299408
Step #56000	Loss: 0.294114
Step #60000	Loss: 0.304786
Step #64000	Loss: 0.304471
Step #68000	Loss: 0.327268
Step #72000	Loss: 0.303461
Step #76000	Loss: 0.298402
Step #80000	Loss: 0.296702
Step #84000	Loss: 0.310077
Step #88000	Loss: 0.300515
Step #92000	Loss: 0.301958
Step #96000	Loss: 0.310705
Step #100000	Loss: 0.314400
Step #104000	Loss: 0.305852
Step #108000	Loss: 0.309142
Code block 'train epoch=3' took: 927907.70232 ms
train loss 0.3044748604297638
Code block 'val epoch=3' took: 60244.72396 ms
validation loss 0.7573431134223938
Step #0	Loss: 0.341260
Step #4000	Loss: 0.290898
Step #8000	Loss: 0.300692
Step #12000	Loss: 0.301483
Step #16000	Loss: 0.289130
Step #20000	Loss: 0.298831
Step #24000	Loss: 0.292046
Step #28000	Loss: 0.303466
Step #32000	Loss: 0.285485
Step #36000	Loss: 0.296833
Step #40000	Loss: 0.299131
Step #44000	Loss: 0.303068
Step #48000	Loss: 0.316335
Step #52000	Loss: 0.300935
Step #56000	Loss: 0.285858
Step #60000	Loss: 0.299894
Step #64000	Loss: 0.309859
Step #68000	Loss: 0.320159
Step #72000	Loss: 0.304362
Step #76000	Loss: 0.294837
Step #80000	Loss: 0.298504
Step #84000	Loss: 0.307646
Step #88000	Loss: 0.296091
Step #92000	Loss: 0.290551
Step #96000	Loss: 0.305450
Step #100000	Loss: 0.309749
Step #104000	Loss: 0.305558
Step #108000	Loss: 0.304838
Code block 'train epoch=4' took: 929231.46635 ms
train loss 0.3019677698612213
Code block 'val epoch=4' took: 59821.06983 ms
validation loss 0.7501133680343628
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --cufile-thread-count 32 --batch-size 16384 --epochs 5'
[WARN  tini (1716799)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-24 22:55:50.298675: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-24 22:55:53.514422: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-24 22:56:18.106469: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-24 23:00:02.668137: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-24 23:00:03.042401: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f1008dfcf20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-24 23:00:03.042473: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-24 23:00:03.180548: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-24 23:00:04.198428: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-24 23:00:04.500506: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.602529
Step #4000	Loss: 0.322803
Step #8000	Loss: 0.330024
Step #12000	Loss: 0.448672
Step #16000	Loss: 0.355777
Step #20000	Loss: 0.327822
Step #24000	Loss: 0.318229
Step #28000	Loss: 0.426177
Step #32000	Loss: 0.342379
Step #36000	Loss: 0.400937
Step #40000	Loss: 0.338358
Step #44000	Loss: 0.364381
Step #48000	Loss: 0.373449
Step #52000	Loss: 0.313880
Step #56000	Loss: 0.340443
Step #60000	Loss: 0.337709
Step #64000	Loss: 0.365405
Step #68000	Loss: 0.442632
Step #72000	Loss: 0.333434
Step #76000	Loss: 0.415188
Step #80000	Loss: 0.342845
Step #84000	Loss: 0.356186
Step #88000	Loss: 0.341807
Step #92000	Loss: 0.361042
Step #96000	Loss: 0.341476
Step #100000	Loss: 0.338937
Step #104000	Loss: 0.314447
Step #108000	Loss: 0.363095
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 957254.04798 ms
train loss 0.35912296175956726
Code block 'val epoch=0' took: 60275.18241 ms
validation loss 0.6219611763954163
Step #0	Loss: 0.446187
Step #4000	Loss: 0.305259
Step #8000	Loss: 0.311268
Step #12000	Loss: 0.368035
Step #16000	Loss: 0.307246
Step #20000	Loss: 0.310270
Step #24000	Loss: 0.298894
Step #28000	Loss: 0.348028
Step #32000	Loss: 0.309507
Step #36000	Loss: 0.330416
Step #40000	Loss: 0.313333
Step #44000	Loss: 0.314978
Step #48000	Loss: 0.332635
Step #52000	Loss: 0.309362
Step #56000	Loss: 0.318840
Step #60000	Loss: 0.317664
Step #64000	Loss: 0.331029
Step #68000	Loss: 0.362387
Step #72000	Loss: 0.309156
Step #76000	Loss: 0.342611
Step #80000	Loss: 0.324606
Step #84000	Loss: 0.323843
Step #88000	Loss: 0.302557
Step #92000	Loss: 0.317519
Step #96000	Loss: 0.326142
Step #100000	Loss: 0.309162
Step #104000	Loss: 0.303428
Step #108000	Loss: 0.327738
Code block 'train epoch=1' took: 933819.39755 ms
train loss 0.3207722306251526
Code block 'val epoch=1' took: 60102.65480 ms
validation loss 0.6994522213935852
Step #0	Loss: 0.341906
Step #4000	Loss: 0.299211
Step #8000	Loss: 0.302799
Step #12000	Loss: 0.323170
Step #16000	Loss: 0.297613
Step #20000	Loss: 0.310000
Step #24000	Loss: 0.291759
Step #28000	Loss: 0.316787
Step #32000	Loss: 0.310666
Step #36000	Loss: 0.305642
Step #40000	Loss: 0.301669
Step #44000	Loss: 0.308538
Step #48000	Loss: 0.319869
Step #52000	Loss: 0.298719
Step #56000	Loss: 0.305933
Step #60000	Loss: 0.308376
Step #64000	Loss: 0.325712
Step #68000	Loss: 0.328553
Step #72000	Loss: 0.296234
Step #76000	Loss: 0.322496
Step #80000	Loss: 0.314552
Step #84000	Loss: 0.314148
Step #88000	Loss: 0.298707
Step #92000	Loss: 0.311823
Step #96000	Loss: 0.320611
Step #100000	Loss: 0.310062
Step #104000	Loss: 0.291339
Step #108000	Loss: 0.317445
Code block 'train epoch=2' took: 932937.35852 ms
train loss 0.30877164006233215
Code block 'val epoch=2' took: 60305.01121 ms
validation loss 0.6875428557395935
Step #0	Loss: 0.329507
Step #4000	Loss: 0.296108
Step #8000	Loss: 0.298309
Step #12000	Loss: 0.317876
Step #16000	Loss: 0.296039
Step #20000	Loss: 0.306349
Step #24000	Loss: 0.284157
Step #28000	Loss: 0.298145
Step #32000	Loss: 0.295124
Step #36000	Loss: 0.296113
Step #40000	Loss: 0.300002
Step #44000	Loss: 0.302424
Step #48000	Loss: 0.306779
Step #52000	Loss: 0.300141
Step #56000	Loss: 0.301584
Step #60000	Loss: 0.310778
Step #64000	Loss: 0.319859
Step #68000	Loss: 0.322509
Step #72000	Loss: 0.295644
Step #76000	Loss: 0.313891
Step #80000	Loss: 0.306843
Step #84000	Loss: 0.313627
Step #88000	Loss: 0.298837
Step #92000	Loss: 0.304464
Step #96000	Loss: 0.311823
Step #100000	Loss: 0.307302
Step #104000	Loss: 0.299231
Step #108000	Loss: 0.314612
Code block 'train epoch=3' took: 933640.18732 ms
train loss 0.30395594239234924
Code block 'val epoch=3' took: 60250.05033 ms
validation loss 0.7274557948112488
Step #0	Loss: 0.320535
Step #4000	Loss: 0.284389
Step #8000	Loss: 0.304136
Step #12000	Loss: 0.298816
Step #16000	Loss: 0.291529
Step #20000	Loss: 0.306816
Step #24000	Loss: 0.283405
Step #28000	Loss: 0.303653
Step #32000	Loss: 0.293905
Step #36000	Loss: 0.295843
Step #40000	Loss: 0.300292
Step #44000	Loss: 0.310539
Step #48000	Loss: 0.303836
Step #52000	Loss: 0.296268
Step #56000	Loss: 0.300115
Step #60000	Loss: 0.302946
Step #64000	Loss: 0.311416
Step #68000	Loss: 0.315395
Step #72000	Loss: 0.289536
Step #76000	Loss: 0.302864
Step #80000	Loss: 0.298282
Step #84000	Loss: 0.311086
Step #88000	Loss: 0.281042
Step #92000	Loss: 0.299260
Step #96000	Loss: 0.312568
Step #100000	Loss: 0.305587
Step #104000	Loss: 0.297832
Step #108000	Loss: 0.311653
Code block 'train epoch=4' took: 933439.79954 ms
train loss 0.30152586102485657
Code block 'val epoch=4' took: 62294.11796 ms
validation loss 0.7421383261680603
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --cufile-thread-count 32 --batch-size 16384 --epochs 5'
[WARN  tini (1795965)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-25 00:23:11.175510: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-25 00:23:14.375844: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-25 00:23:39.103133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-25 00:27:19.301487: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-25 00:27:19.776549: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f55e8f9e4f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-25 00:27:19.776630: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-25 00:27:19.933464: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-25 00:27:21.007200: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-25 00:27:21.488334: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.691622
Step #4000	Loss: 0.384451
terminate called after throwing an instance of 'rmm::out_of_memory'
  what():  std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp
[dgx-2:1795990] *** Process received signal ***
[dgx-2:1795990] Signal: Aborted (6)
[dgx-2:1795990] Signal code:  (-6)
[dgx-2:1795990] [ 0] /lib/x86_64-linux-gnu/libc.so.6(+0x42520)[0x7f603359a520]
[dgx-2:1795990] [ 1] /lib/x86_64-linux-gnu/libc.so.6(pthread_kill+0x12c)[0x7f60335eea7c]
[dgx-2:1795990] [ 2] /lib/x86_64-linux-gnu/libc.so.6(raise+0x16)[0x7f603359a476]
[dgx-2:1795990] [ 3] /lib/x86_64-linux-gnu/libc.so.6(abort+0xd3)[0x7f60335807f3]
[dgx-2:1795990] [ 4] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(_ZN9__gnu_cxx27__verbose_terminate_handlerEv+0xc0)[0x7f6030708026]
[dgx-2:1795990] [ 5] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(+0xb0514)[0x7f6030706514]
[dgx-2:1795990] [ 6] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(+0xb0566)[0x7f6030706566]
[dgx-2:1795990] [ 7] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(__cxa_rethrow+0x0)[0x7f6030706758]
[dgx-2:1795990] [ 8] /opt/conda/envs/rapids/lib/python3.10/site-packages/rmm/_lib/device_buffer.cpython-310-x86_64-linux-gnu.so(+0x4b67d)[0x7f5f0011c67d]
[dgx-2:1795990] [ 9] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf19make_numeric_columnENS_9data_typeEiNS_10mask_stateEN3rmm16cuda_stream_viewEPNS2_2mr22device_memory_resourceE+0x126)[0x7f5df3ae20c6]
[dgx-2:1795990] [10] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf7strings6detail25create_chars_child_columnEiN3rmm16cuda_stream_viewEPNS2_2mr22device_memory_resourceE+0x19)[0x7f5df51ffa29]
[dgx-2:1795990] [11] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf7strings6detail19make_strings_columnIPKN6thrust4pairIPKciEEEESt10unique_ptrINS_6columnESt14default_deleteISB_EET_SF_N3rmm16cuda_stream_viewEPNSG_2mr22device_memory_resourceE+0x47a)[0x7f5df51f937a]
[dgx-2:1795990] [12] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf19make_strings_columnENS_11device_spanIKN6thrust4pairIPKciEELm18446744073709551615EEEN3rmm16cuda_stream_viewEPNS8_2mr22device_memory_resourceE+0x83)[0x7f5df51f4603]
[dgx-2:1795990] [13] /home2/faculty/pwesolowski/praca-mgr/parser-repo/build/libmeta-cudf-parser-1.so(_ZNK18ParserOutputDeviceI5JDictIN5boost4mp117mp_listIJNS3_IJNS3_IJSt17integral_constantIiLi117EES4_IiLi115EES4_IiLi101EES4_IiLi114EES4_IiLi95EES4_IiLi105EES4_IiLi100EEEEE17JStringStaticCopyIS4_IiLi21EESC_NS3_IJEEEEEEENS3_IJNS3_IJS4_IiLi103EES4_IiLi109EES4_IiLi97EES4_IiLi112EES9_SA_SB_EEESD_IS4_IiLi37EESM_SF_EEEENS3_IJNS3_IJS8_SK_S4_IiLi116EESA_S4_IiLi110EESI_EEE7JNumberIhSS_SF_EEEENS3_IJNS3_IJS4_IiLi99EESK_SQ_S7_SI_S4_IiLi111EES8_S4_IiLi121EEEEESD_IS4_IiLi470EESZ_SF_EEEENS3_IJNS3_IJS4_IiLi108EESK_SQ_SA_SQ_S5_SB_S7_EEE11JRealNumberIfS14_SF_EEEENS3_IJNS3_IJS13_SX_SR_SI_SA_SQ_S5_SB_S7_EEES15_IfS18_SF_EEEEEEESF_EE6ToCudfEN3rmm16cuda_stream_viewEPNS1E_2mr22device_memory_resourceE+0x505)[0x7f585e3bf3a5]
[dgx-2:1795990] [14] /home2/faculty/pwesolowski/praca-mgr/parser-repo/build/libmeta-cudf-parser-1.so(_Z25generate_example_metadataPKcmmi11end_of_linebb+0x1cf)[0x7f585e3b6bcf]
[dgx-2:1795990] [15] /home2/faculty/pwesolowski/praca-mgr/parser-repo/python_binding/metajsonparser/_lib/json_cudf.cpython-310-x86_64-linux-gnu.so(+0x4b344)[0x7f585e48e344]
[dgx-2:1795990] [16] python(+0x13fb27)[0x561602e1db27]
[dgx-2:1795990] [17] python(PyObject_Call+0x209)[0x561602e2a139]
[dgx-2:1795990] [18] python(_PyEval_EvalFrameDefault+0x5d8c)[0x561602e13b7c]
[dgx-2:1795990] [19] python(_PyFunction_Vectorcall+0x6f)[0x561602e1df8f]
[dgx-2:1795990] [20] python(_PyEval_EvalFrameDefault+0x2ec2)[0x561602e10cb2]
[dgx-2:1795990] [21] python(_PyFunction_Vectorcall+0x6f)[0x561602e1df8f]
[dgx-2:1795990] [22] python(_PyEval_EvalFrameDefault+0x332)[0x561602e0e122]
[dgx-2:1795990] [23] python(_PyFunction_Vectorcall+0x6f)[0x561602e1df8f]
[dgx-2:1795990] [24] python(_PyEval_EvalFrameDefault+0x2ec2)[0x561602e10cb2]
[dgx-2:1795990] [25] python(_PyFunction_Vectorcall+0x6f)[0x561602e1df8f]
[dgx-2:1795990] [26] python(_PyEval_EvalFrameDefault+0x332)[0x561602e0e122]
[dgx-2:1795990] [27] python(_PyFunction_Vectorcall+0x6f)[0x561602e1df8f]
[dgx-2:1795990] [28] python(_PyEval_EvalFrameDefault+0x2ec2)[0x561602e10cb2]
[dgx-2:1795990] [29] python(+0x14b641)[0x561602e29641]
[dgx-2:1795990] *** End of error message ***
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --cufile-thread-count 32 --batch-size 16384 --epochs 5'
[WARN  tini (1801703)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-25 00:28:20.193964: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-25 00:28:23.938299: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-25 00:28:50.966957: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
Failed to transform operator <nvtabular.ops.categorify.Categorify object at 0x7f06ac55bac0>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1780, in _encode
    ).sort_values("order")["labels"]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 2214, in sort_values
    out = self._gather(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-25 00:32:35.048436: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-25 00:32:35.443200: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7efec6bf96b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-25 00:32:35.443267: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-25 00:32:35.579072: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-25 00:32:36.571977: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-25 00:32:36.875787: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.884977
Code block 'train epoch=0' took: 43521.81932 ms
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 332, in _get_next_batch
    batch = next(self._batch_itr)
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home2/faculty/pwesolowski/praca-mgr/pipelines-repo/2_merlin/run_merlin.py", line 155, in <module>
    for batch, (examples, labels) in enumerate(train_tf_ds):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/tensorflow.py", line 97, in __next__
    converted_batch = self.convert_batch(super().__next__())
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 261, in __next__
    return self._get_next_batch()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 344, in _get_next_batch
    batch = next(self._batch_itr)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 369, in make_tensors
    tensors_by_name = self._convert_df_to_tensors(gdf)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 520, in _convert_df_to_tensors
    tensors_by_name[column_name] = self._to_tensor(gdf_i[[column_name]])
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 450, in _to_tensor
    tensor = df_or_series.to_cupy()
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/single_column_frame.py", line 131, in to_cupy
    return super().to_cupy(dtype, copy, na_value).flatten()
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 533, in to_cupy
    return self._to_array(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 498, in _to_array
    matrix[:, i] = get_column_values_na(col)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 477, in get_column_values_na
    return get_column_values(col)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 534, in <lambda>
    (lambda col: col.values.copy())
  File "cupy/_core/core.pyx", line 590, in cupy._core.core._ndarray_base.copy
  File "cupy/_core/core.pyx", line 616, in cupy._core.core._ndarray_base.copy
  File "cupy/_core/core.pyx", line 575, in cupy._core.core._ndarray_base.astype
  File "cupy/_core/core.pyx", line 136, in cupy._core.core.ndarray.__new__
  File "cupy/_core/core.pyx", line 224, in cupy._core.core._ndarray_base._init
  File "cupy/cuda/memory.pyx", line 742, in cupy.cuda.memory.alloc
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/rmm/rmm.py", line 230, in rmm_cupy_allocator
    buf = librmm.device_buffer.DeviceBuffer(size=nbytes, stream=stream)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --cufile-thread-count 32 --batch-size 16384 --epochs 5'
[WARN  tini (1807540)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-25 00:33:11.696367: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-25 00:33:15.265149: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-25 00:33:42.156726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
Failed to transform operator <nvtabular.ops.categorify.Categorify object at 0x7fe4de9b7b50>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1780, in _encode
    ).sort_values("order")["labels"]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 2214, in sort_values
    out = self._gather(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-25 00:37:26.683466: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-25 00:37:27.045073: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fdc51b4ad00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-25 00:37:27.045143: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-25 00:37:27.196261: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-25 00:37:28.193042: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-25 00:37:28.495300: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.498758
Code block 'train epoch=0' took: 57483.90292 ms
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1780, in _encode
    ).sort_values("order")["labels"]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 2214, in sort_values
    out = self._gather(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home2/faculty/pwesolowski/praca-mgr/pipelines-repo/2_merlin/run_merlin.py", line 155, in <module>
    for batch, (examples, labels) in enumerate(train_tf_ds):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/tensorflow.py", line 97, in __next__
    converted_batch = self.convert_batch(super().__next__())
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 261, in __next__
    return self._get_next_batch()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 343, in _get_next_batch
    self._fetch_chunk()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 277, in _fetch_chunk
    raise chunks
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 791, in load_chunks
    self.chunk_logic(itr)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 759, in chunk_logic
    for chunks in self.batch(itr):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 745, in batch
    value = next(itr)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/io/dataframe_iter.py", line 44, in __iter__
    yield part.compute(scheduler="synchronous")
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/base.py", line 314, in compute
    (result,) = compute(self, traverse=False, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/base.py", line 599, in compute
    results = schedule(dsk, keys, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 557, in get_sync
    return get_async(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 500, in get_async
    for key, res_info, failed in queue_get(queue).result():
  File "/opt/conda/envs/rapids/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/opt/conda/envs/rapids/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 542, in submit
    fut.set_result(fn(*args, **kwargs))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 238, in batch_execute_tasks
    return [execute_task(*a) for a in it]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 238, in <listcomp>
    return [execute_task(*a) for a in it]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 229, in execute_task
    result = pack_exception(e, dumps)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 224, in execute_task
    result = _execute_task(task, data)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/optimization.py", line 990, in __call__
    return core.get(self.dsk, self.outkey, dict(zip(self.inkeys, args)))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 149, in get
    result = _execute_task(task, cache)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in <genexpr>
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/utils.py", line 72, in apply
    return func(*args, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 87, in transform
    transformed_data = self._execute_node(node, transformable, capture_dtypes, strict)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 101, in _execute_node
    upstream_outputs = self._run_upstream_transforms(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 114, in _run_upstream_transforms
    node_output = self._execute_node(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 107, in _execute_node
    transform_output = self._run_node_transform(node, transform_input, capture_dtypes, strict)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 227, in _run_node_transform
    raise exc
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
+ for CUFILE_THREAD_COUNT in 4 8 16 32 64
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --cufile-thread-count 64 --batch-size 16384 --epochs 5'
[WARN  tini (1813288)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-25 00:38:16.801168: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-25 00:38:20.276301: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-25 00:38:46.412113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-25 00:42:33.519004: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-25 00:42:33.929138: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f3b34846260 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-25 00:42:33.929201: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-25 00:42:34.081125: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-25 00:42:35.129104: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-25 00:42:35.450075: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.542545
Step #4000	Loss: 0.318916
Step #8000	Loss: 0.337055
Step #12000	Loss: 0.431492
Step #16000	Loss: 0.432022
Step #20000	Loss: 0.333275
Step #24000	Loss: 0.328271
Step #28000	Loss: 0.348332
Step #32000	Loss: 0.306715
Step #36000	Loss: 0.393607
Step #40000	Loss: 0.381799
Step #44000	Loss: 0.368067
Step #48000	Loss: 0.316383
Step #52000	Loss: 0.332184
Step #56000	Loss: 0.334992
Step #60000	Loss: 0.317064
Step #64000	Loss: 0.372854
Step #68000	Loss: 0.436850
Step #72000	Loss: 0.429494
Step #76000	Loss: 0.421874
Step #80000	Loss: 0.356426
Step #84000	Loss: 0.426212
Step #88000	Loss: 0.303044
Step #92000	Loss: 0.314073
Step #96000	Loss: 0.422706
Step #100000	Loss: 0.335626
Step #104000	Loss: 0.348813
Step #108000	Loss: 0.398920
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 974835.78482 ms
train loss 0.36267420649528503
Code block 'val epoch=0' took: 64435.15273 ms
validation loss 0.6787850856781006
Step #0	Loss: 0.716143
Step #4000	Loss: 0.305904
Step #8000	Loss: 0.308686
Step #12000	Loss: 0.360956
Step #16000	Loss: 0.357935
Step #20000	Loss: 0.316654
Step #24000	Loss: 0.306141
Step #28000	Loss: 0.324301
Step #32000	Loss: 0.299911
Step #36000	Loss: 0.356624
Step #40000	Loss: 0.323963
Step #44000	Loss: 0.324459
Step #48000	Loss: 0.306632
Step #52000	Loss: 0.315802
Step #56000	Loss: 0.308842
Step #60000	Loss: 0.305933
Step #64000	Loss: 0.337470
Step #68000	Loss: 0.358490
Step #72000	Loss: 0.338787
Step #76000	Loss: 0.347797
Step #80000	Loss: 0.302751
Step #84000	Loss: 0.351011
Step #88000	Loss: 0.284783
Step #92000	Loss: 0.290959
Step #96000	Loss: 0.351666
Step #100000	Loss: 0.325964
Step #104000	Loss: 0.317706
Step #108000	Loss: 0.345655
Code block 'train epoch=1' took: 948198.66340 ms
train loss 0.32619908452033997
Code block 'val epoch=1' took: 64245.85294 ms
validation loss 0.7091097831726074
Step #0	Loss: 0.543149
Step #4000	Loss: 0.302022
Step #8000	Loss: 0.305967
Step #12000	Loss: 0.327078
Step #16000	Loss: 0.325775
Step #20000	Loss: 0.317590
Step #24000	Loss: 0.294856
Step #28000	Loss: 0.302878
Step #32000	Loss: 0.293925
Step #36000	Loss: 0.323996
Step #40000	Loss: 0.312877
Step #44000	Loss: 0.306398
Step #48000	Loss: 0.301500
Step #52000	Loss: 0.308830
Step #56000	Loss: 0.305669
Step #60000	Loss: 0.298380
Step #64000	Loss: 0.318012
Step #68000	Loss: 0.327177
Step #72000	Loss: 0.313602
Step #76000	Loss: 0.324477
Step #80000	Loss: 0.292931
Step #84000	Loss: 0.333841
Step #88000	Loss: 0.276132
Step #92000	Loss: 0.292976
Step #96000	Loss: 0.333985
Step #100000	Loss: 0.314481
Step #104000	Loss: 0.306582
Step #108000	Loss: 0.328778
Code block 'train epoch=2' took: 950470.31957 ms
train loss 0.3116315007209778
Code block 'val epoch=2' took: 64372.62454 ms
validation loss 0.7926790118217468
Step #0	Loss: 0.460675
Step #4000	Loss: 0.297980
Step #8000	Loss: 0.302985
Step #12000	Loss: 0.313845
Step #16000	Loss: 0.307418
Step #20000	Loss: 0.316245
Step #24000	Loss: 0.292503
Step #28000	Loss: 0.302643
Step #32000	Loss: 0.293888
Step #36000	Loss: 0.303536
Step #40000	Loss: 0.298358
Step #44000	Loss: 0.310452
Step #48000	Loss: 0.294242
Step #52000	Loss: 0.309663
Step #56000	Loss: 0.300916
Step #60000	Loss: 0.298085
Step #64000	Loss: 0.309933
Step #68000	Loss: 0.326322
Step #72000	Loss: 0.302342
Step #76000	Loss: 0.315344
Step #80000	Loss: 0.284816
Step #84000	Loss: 0.322603
Step #88000	Loss: 0.271790
Step #92000	Loss: 0.289588
Step #96000	Loss: 0.313127
Step #100000	Loss: 0.313597
Step #104000	Loss: 0.307687
Step #108000	Loss: 0.318293
Code block 'train epoch=3' took: 950840.76134 ms
train loss 0.305571585893631
Code block 'val epoch=3' took: 64455.55937 ms
validation loss 0.8082624673843384
Step #0	Loss: 0.422128
Step #4000	Loss: 0.291070
Step #8000	Loss: 0.293211
Step #12000	Loss: 0.313366
Step #16000	Loss: 0.299681
Step #20000	Loss: 0.319858
Step #24000	Loss: 0.297671
Step #28000	Loss: 0.304975
Step #32000	Loss: 0.286599
Step #36000	Loss: 0.295039
Step #40000	Loss: 0.295171
Step #44000	Loss: 0.298322
Step #48000	Loss: 0.299509
Step #52000	Loss: 0.299835
Step #56000	Loss: 0.293018
Step #60000	Loss: 0.292800
Step #64000	Loss: 0.305953
Step #68000	Loss: 0.316612
Step #72000	Loss: 0.301868
Step #76000	Loss: 0.311439
Step #80000	Loss: 0.279646
Step #84000	Loss: 0.305743
Step #88000	Loss: 0.269235
Step #92000	Loss: 0.291514
Step #96000	Loss: 0.300243
Step #100000	Loss: 0.301508
Step #104000	Loss: 0.304801
Step #108000	Loss: 0.320710
Code block 'train epoch=4' took: 948415.63889 ms
train loss 0.3026236593723297
Code block 'val epoch=4' took: 64526.51995 ms
validation loss 0.8903341293334961
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --cufile-thread-count 64 --batch-size 16384 --epochs 5'
[WARN  tini (1898281)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-25 02:07:27.358348: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-25 02:07:30.752450: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-25 02:07:56.930421: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-25 02:11:44.525893: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-25 02:11:45.057117: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f2b6ad997e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-25 02:11:45.057197: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-25 02:11:45.230869: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-25 02:11:46.266242: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-25 02:11:46.609433: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.842710
Step #4000	Loss: 0.315990
Step #8000	Loss: 0.321500
Step #12000	Loss: 0.442790
Step #16000	Loss: 0.436598
Step #20000	Loss: 0.344635
Step #24000	Loss: 0.366661
Step #28000	Loss: 0.401191
Step #32000	Loss: 0.336548
Step #36000	Loss: 0.359855
Step #40000	Loss: 0.339698
Step #44000	Loss: 0.388071
Step #48000	Loss: 0.313779
Step #52000	Loss: 0.368941
Step #56000	Loss: 0.318196
Step #60000	Loss: 0.312747
Step #64000	Loss: 0.392096
Step #68000	Loss: 0.444750
Step #72000	Loss: 0.339095
Step #76000	Loss: 0.450900
Step #80000	Loss: 0.382848
Step #84000	Loss: 0.442374
Step #88000	Loss: 0.354864
Step #92000	Loss: 0.302626
Step #96000	Loss: 0.449730
Step #100000	Loss: 0.329152
Step #104000	Loss: 0.319524
Step #108000	Loss: 0.405638
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 969628.90378 ms
train loss 0.36062920093536377
Code block 'val epoch=0' took: 63771.27760 ms
validation loss 0.5696421265602112
Step #0	Loss: 0.447789
Step #4000	Loss: 0.304760
Step #8000	Loss: 0.309931
Step #12000	Loss: 0.368144
Step #16000	Loss: 0.352422
Step #20000	Loss: 0.330883
Step #24000	Loss: 0.317696
Step #28000	Loss: 0.338666
Step #32000	Loss: 0.304995
Step #36000	Loss: 0.320078
Step #40000	Loss: 0.312398
Step #44000	Loss: 0.336547
Step #48000	Loss: 0.312018
Step #52000	Loss: 0.331400
Step #56000	Loss: 0.298663
Step #60000	Loss: 0.304467
Step #64000	Loss: 0.340278
Step #68000	Loss: 0.377083
Step #72000	Loss: 0.315116
Step #76000	Loss: 0.359315
Step #80000	Loss: 0.317872
Step #84000	Loss: 0.364955
Step #88000	Loss: 0.308090
Step #92000	Loss: 0.297496
Step #96000	Loss: 0.370764
Step #100000	Loss: 0.308150
Step #104000	Loss: 0.305482
Step #108000	Loss: 0.345204
Code block 'train epoch=1' took: 945604.89947 ms
train loss 0.3233024477958679
Code block 'val epoch=1' took: 63315.71287 ms
validation loss 0.6392940282821655
Step #0	Loss: 0.338340
Step #4000	Loss: 0.301964
Step #8000	Loss: 0.306428
Step #12000	Loss: 0.325699
Step #16000	Loss: 0.315975
Step #20000	Loss: 0.324728
Step #24000	Loss: 0.303779
Step #28000	Loss: 0.319189
Step #32000	Loss: 0.293966
Step #36000	Loss: 0.301650
Step #40000	Loss: 0.305755
Step #44000	Loss: 0.316603
Step #48000	Loss: 0.304702
Step #52000	Loss: 0.316686
Step #56000	Loss: 0.300055
Step #60000	Loss: 0.307644
Step #64000	Loss: 0.313918
Step #68000	Loss: 0.341950
Step #72000	Loss: 0.299205
Step #76000	Loss: 0.327265
Step #80000	Loss: 0.299217
Step #84000	Loss: 0.330718
Step #88000	Loss: 0.289265
Step #92000	Loss: 0.296441
Step #96000	Loss: 0.332489
Step #100000	Loss: 0.308755
Step #104000	Loss: 0.295275
Step #108000	Loss: 0.327761
Code block 'train epoch=2' took: 943538.98380 ms
train loss 0.3105284571647644
Code block 'val epoch=2' took: 63077.22702 ms
validation loss 0.6803662180900574
Step #0	Loss: 0.317180
Step #4000	Loss: 0.296922
Step #8000	Loss: 0.305362
Step #12000	Loss: 0.313901
Step #16000	Loss: 0.302919
Step #20000	Loss: 0.315984
Step #24000	Loss: 0.291089
Step #28000	Loss: 0.311884
Step #32000	Loss: 0.293203
Step #36000	Loss: 0.309283
Step #40000	Loss: 0.299833
Step #44000	Loss: 0.304924
Step #48000	Loss: 0.305203
Step #52000	Loss: 0.312719
Step #56000	Loss: 0.296644
Step #60000	Loss: 0.302438
Step #64000	Loss: 0.307714
Step #68000	Loss: 0.331961
Step #72000	Loss: 0.301186
Step #76000	Loss: 0.317648
Step #80000	Loss: 0.291991
Step #84000	Loss: 0.316236
Step #88000	Loss: 0.287254
Step #92000	Loss: 0.289665
Step #96000	Loss: 0.326946
Step #100000	Loss: 0.308096
Step #104000	Loss: 0.294123
Step #108000	Loss: 0.319480
Code block 'train epoch=3' took: 942841.65380 ms
train loss 0.3051105737686157
Code block 'val epoch=3' took: 63655.15425 ms
validation loss 0.7262691259384155
Step #0	Loss: 0.318589
Step #4000	Loss: 0.299249
Step #8000	Loss: 0.295406
Step #12000	Loss: 0.307504
Step #16000	Loss: 0.298044
Step #20000	Loss: 0.308637
Step #24000	Loss: 0.298712
Step #28000	Loss: 0.305623
Step #32000	Loss: 0.281608
Step #36000	Loss: 0.302520
Step #40000	Loss: 0.304448
Step #44000	Loss: 0.299450
Step #48000	Loss: 0.297402
Step #52000	Loss: 0.301721
Step #56000	Loss: 0.293322
Step #60000	Loss: 0.298658
Step #64000	Loss: 0.312299
Step #68000	Loss: 0.326389
Step #72000	Loss: 0.303037
Step #76000	Loss: 0.316202
Step #80000	Loss: 0.288327
Step #84000	Loss: 0.320432
Step #88000	Loss: 0.286771
Step #92000	Loss: 0.293172
Step #96000	Loss: 0.319377
Step #100000	Loss: 0.307729
Step #104000	Loss: 0.288469
Step #108000	Loss: 0.318560
Code block 'train epoch=4' took: 945572.83854 ms
train loss 0.30231934785842896
Code block 'val epoch=4' took: 63658.20317 ms
validation loss 0.7809844017028809
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --cufile-thread-count 64 --batch-size 16384 --epochs 5'
[WARN  tini (1979347)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-25 03:36:08.453751: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-25 03:36:11.975041: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-25 03:36:39.535270: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-25 03:40:30.312750: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-25 03:40:30.720292: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fd909688060 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-25 03:40:30.720362: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-25 03:40:30.876737: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-25 03:40:31.913070: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-25 03:40:32.219305: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 1.882428
Step #4000	Loss: 0.379182
Step #8000	Loss: 0.336456
Step #12000	Loss: 0.377235
Step #16000	Loss: 0.429209
Step #20000	Loss: 0.328321
Step #24000	Loss: 0.386300
Step #28000	Loss: 0.323189
Step #32000	Loss: 0.325177
Step #36000	Loss: 0.349602
Step #40000	Loss: 0.331642
Step #44000	Loss: 0.323128
Step #48000	Loss: 0.322045
Step #52000	Loss: 0.316585
Step #56000	Loss: 0.320949
Step #60000	Loss: 0.346521
Step #64000	Loss: 0.336956
Step #68000	Loss: 0.448678
Step #72000	Loss: 0.456222
Step #76000	Loss: 0.465187
Step #80000	Loss: 0.339570
Step #84000	Loss: 0.441096
Step #88000	Loss: 0.338316
Step #92000	Loss: 0.317026
Step #96000	Loss: 0.378399
Step #100000	Loss: 0.328345
Step #104000	Loss: 0.408009
Step #108000	Loss: 0.433224
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 967107.01708 ms
train loss 0.3599407374858856
Code block 'val epoch=0' took: 63089.20626 ms
validation loss 0.5643540024757385
Step #0	Loss: 0.443144
Step #4000	Loss: 0.321148
Step #8000	Loss: 0.324790
Step #12000	Loss: 0.321407
Step #16000	Loss: 0.340886
Step #20000	Loss: 0.309214
Step #24000	Loss: 0.326418
Step #28000	Loss: 0.306921
Step #32000	Loss: 0.292874
Step #36000	Loss: 0.327493
Step #40000	Loss: 0.311125
Step #44000	Loss: 0.313621
Step #48000	Loss: 0.316317
Step #52000	Loss: 0.306514
Step #56000	Loss: 0.297925
Step #60000	Loss: 0.307373
Step #64000	Loss: 0.321610
Step #68000	Loss: 0.369215
Step #72000	Loss: 0.348481
Step #76000	Loss: 0.364591
Step #80000	Loss: 0.323382
Step #84000	Loss: 0.369780
Step #88000	Loss: 0.297016
Step #92000	Loss: 0.301325
Step #96000	Loss: 0.331038
Step #100000	Loss: 0.314524
Step #104000	Loss: 0.334104
Step #108000	Loss: 0.351676
Code block 'train epoch=1' took: 941105.16986 ms
train loss 0.3220437169075012
Code block 'val epoch=1' took: 63906.66864 ms
validation loss 0.6344875693321228
Step #0	Loss: 0.344739
Step #4000	Loss: 0.300618
Step #8000	Loss: 0.305989
Step #12000	Loss: 0.316207
Step #16000	Loss: 0.309883
Step #20000	Loss: 0.303478
Step #24000	Loss: 0.299459
Step #28000	Loss: 0.304714
Step #32000	Loss: 0.300352
Step #36000	Loss: 0.307689
Step #40000	Loss: 0.306160
Step #44000	Loss: 0.303030
Step #48000	Loss: 0.306171
Step #52000	Loss: 0.301790
Step #56000	Loss: 0.293061
Step #60000	Loss: 0.302766
Step #64000	Loss: 0.316447
Step #68000	Loss: 0.332628
Step #72000	Loss: 0.325562
Step #76000	Loss: 0.328753
Step #80000	Loss: 0.314075
Step #84000	Loss: 0.328529
Step #88000	Loss: 0.294420
Step #92000	Loss: 0.290518
Step #96000	Loss: 0.316088
Step #100000	Loss: 0.310884
Step #104000	Loss: 0.315193
Step #108000	Loss: 0.336104
Code block 'train epoch=2' took: 944704.41524 ms
train loss 0.3093298077583313
Code block 'val epoch=2' took: 63259.67947 ms
validation loss 0.6547294855117798
Step #0	Loss: 0.322841
Step #4000	Loss: 0.292170
Step #8000	Loss: 0.307667
Step #12000	Loss: 0.311704
Step #16000	Loss: 0.301520
Step #20000	Loss: 0.308914
Step #24000	Loss: 0.289378
Step #28000	Loss: 0.303190
Step #32000	Loss: 0.294204
Step #36000	Loss: 0.297708
Step #40000	Loss: 0.311445
Step #44000	Loss: 0.305748
Step #48000	Loss: 0.296962
Step #52000	Loss: 0.294670
Step #56000	Loss: 0.293203
Step #60000	Loss: 0.292533
Step #64000	Loss: 0.308751
Step #68000	Loss: 0.325452
Step #72000	Loss: 0.316253
Step #76000	Loss: 0.316868
Step #80000	Loss: 0.310516
Step #84000	Loss: 0.312524
Step #88000	Loss: 0.286377
Step #92000	Loss: 0.296205
Step #96000	Loss: 0.320622
Step #100000	Loss: 0.304193
Step #104000	Loss: 0.311190
Step #108000	Loss: 0.321835
Code block 'train epoch=3' took: 941911.57442 ms
train loss 0.30417293310165405
Code block 'val epoch=3' took: 63411.48705 ms
validation loss 0.7147495150566101
Step #0	Loss: 0.310557
Step #4000	Loss: 0.290475
Step #8000	Loss: 0.300952
Step #12000	Loss: 0.301815
Step #16000	Loss: 0.300119
Step #20000	Loss: 0.304152
Step #24000	Loss: 0.291627
Step #28000	Loss: 0.298611
Step #32000	Loss: 0.276323
Step #36000	Loss: 0.302921
Step #40000	Loss: 0.307277
Step #44000	Loss: 0.304984
Step #48000	Loss: 0.297223
Step #52000	Loss: 0.301486
Step #56000	Loss: 0.291585
Step #60000	Loss: 0.299611
Step #64000	Loss: 0.306615
Step #68000	Loss: 0.312552
Step #72000	Loss: 0.300365
Step #76000	Loss: 0.319532
Step #80000	Loss: 0.313061
Step #84000	Loss: 0.304124
Step #88000	Loss: 0.288736
Step #92000	Loss: 0.299138
Step #96000	Loss: 0.313628
Step #100000	Loss: 0.304982
Step #104000	Loss: 0.307076
Step #108000	Loss: 0.312661
Code block 'train epoch=4' took: 938523.67306 ms
train loss 0.30163949728012085
Code block 'val epoch=4' took: 63858.28903 ms
validation loss 0.7648988366127014
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --cufile-thread-count 64 --batch-size 16384 --epochs 5'
[WARN  tini (2058072)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-25 05:04:37.450794: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-25 05:04:41.068202: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-25 05:05:08.159250: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-25 05:08:51.046883: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-25 05:08:51.527163: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f6e20057ee0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-25 05:08:51.527235: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-25 05:08:51.687088: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-25 05:08:52.813486: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-25 05:08:53.177122: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 2.111421
Step #4000	Loss: 0.366791
Step #8000	Loss: 0.318659
Step #12000	Loss: 0.443132
Step #16000	Loss: 0.429113
Step #20000	Loss: 0.347666
Step #24000	Loss: 0.360268
Step #28000	Loss: 0.393242
Step #32000	Loss: 0.336839
Step #36000	Loss: 0.364204
Step #40000	Loss: 0.409097
Step #44000	Loss: 0.395032
Step #48000	Loss: 0.363872
Step #52000	Loss: 0.316692
Step #56000	Loss: 0.339189
Step #60000	Loss: 0.322619
Step #64000	Loss: 0.401587
Step #68000	Loss: 0.454733
Step #72000	Loss: 0.338314
Step #76000	Loss: 0.349346
Step #80000	Loss: 0.381239
Step #84000	Loss: 0.348470
Step #88000	Loss: 0.349968
Step #92000	Loss: 0.296962
Step #96000	Loss: 0.449856
Step #100000	Loss: 0.325601
Step #104000	Loss: 0.318918
Step #108000	Loss: 0.408995
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 952767.50546 ms
train loss 0.3605632781982422
Code block 'val epoch=0' took: 61367.19902 ms
validation loss 0.573896050453186
Step #0	Loss: 0.440820
Step #4000	Loss: 0.312730
Step #8000	Loss: 0.314052
Step #12000	Loss: 0.363115
Step #16000	Loss: 0.359287
Step #20000	Loss: 0.322357
Step #24000	Loss: 0.328499
Step #28000	Loss: 0.333827
Step #32000	Loss: 0.303667
Step #36000	Loss: 0.323319
Step #40000	Loss: 0.331251
Step #44000	Loss: 0.334989
Step #48000	Loss: 0.321235
Step #52000	Loss: 0.308244
Step #56000	Loss: 0.317915
Step #60000	Loss: 0.309084
Step #64000	Loss: 0.333388
Step #68000	Loss: 0.379583
Step #72000	Loss: 0.315525
Step #76000	Loss: 0.316753
Step #80000	Loss: 0.319381
Step #84000	Loss: 0.320979
Step #88000	Loss: 0.308814
Step #92000	Loss: 0.305526
Step #96000	Loss: 0.366942
Step #100000	Loss: 0.308931
Step #104000	Loss: 0.304281
Step #108000	Loss: 0.344326
Code block 'train epoch=1' took: 926270.83271 ms
train loss 0.32292190194129944
Code block 'val epoch=1' took: 60614.90599 ms
validation loss 0.6261496543884277
Step #0	Loss: 0.334405
Step #4000	Loss: 0.300786
Step #8000	Loss: 0.299996
Step #12000	Loss: 0.324625
Step #16000	Loss: 0.317566
Step #20000	Loss: 0.315197
Step #24000	Loss: 0.308216
Step #28000	Loss: 0.312749
Step #32000	Loss: 0.286022
Step #36000	Loss: 0.307897
Step #40000	Loss: 0.323573
Step #44000	Loss: 0.312391
Step #48000	Loss: 0.311526
Step #52000	Loss: 0.305055
Step #56000	Loss: 0.309190
Step #60000	Loss: 0.300958
Step #64000	Loss: 0.319442
Step #68000	Loss: 0.340314
Step #72000	Loss: 0.303055
Step #76000	Loss: 0.311117
Step #80000	Loss: 0.302459
Step #84000	Loss: 0.308434
Step #88000	Loss: 0.297708
Step #92000	Loss: 0.294501
Step #96000	Loss: 0.338359
Step #100000	Loss: 0.306488
Step #104000	Loss: 0.302510
Step #108000	Loss: 0.328204
Code block 'train epoch=2' took: 929105.33273 ms
train loss 0.31027480959892273
Code block 'val epoch=2' took: 60920.71237 ms
validation loss 0.6797626614570618
Step #0	Loss: 0.317753
Step #4000	Loss: 0.291459
Step #8000	Loss: 0.299822
Step #12000	Loss: 0.309100
Step #16000	Loss: 0.300087
Step #20000	Loss: 0.307414
Step #24000	Loss: 0.296887
Step #28000	Loss: 0.314430
Step #32000	Loss: 0.287440
Step #36000	Loss: 0.304031
Step #40000	Loss: 0.305587
Step #44000	Loss: 0.303192
Step #48000	Loss: 0.312088
Step #52000	Loss: 0.294781
Step #56000	Loss: 0.306645
Step #60000	Loss: 0.296037
Step #64000	Loss: 0.314076
Step #68000	Loss: 0.326671
Step #72000	Loss: 0.303029
Step #76000	Loss: 0.302910
Step #80000	Loss: 0.297108
Step #84000	Loss: 0.311235
Step #88000	Loss: 0.296415
Step #92000	Loss: 0.299067
Step #96000	Loss: 0.316148
Step #100000	Loss: 0.306571
Step #104000	Loss: 0.292952
Step #108000	Loss: 0.317930
Code block 'train epoch=3' took: 925723.15228 ms
train loss 0.30482569336891174
Code block 'val epoch=3' took: 60891.75321 ms
validation loss 0.7226235270500183
Step #0	Loss: 0.319117
Step #4000	Loss: 0.292981
Step #8000	Loss: 0.295273
Step #12000	Loss: 0.307066
Step #16000	Loss: 0.296095
Step #20000	Loss: 0.309161
Step #24000	Loss: 0.300073
Step #28000	Loss: 0.300294
Step #32000	Loss: 0.282149
Step #36000	Loss: 0.292066
Step #40000	Loss: 0.297160
Step #44000	Loss: 0.291015
Step #48000	Loss: 0.303853
Step #52000	Loss: 0.294966
Step #56000	Loss: 0.298179
Step #60000	Loss: 0.296586
Step #64000	Loss: 0.312858
Step #68000	Loss: 0.334702
Step #72000	Loss: 0.302229
Step #76000	Loss: 0.303495
Step #80000	Loss: 0.284264
Step #84000	Loss: 0.304669
Step #88000	Loss: 0.289700
Step #92000	Loss: 0.295241
Step #96000	Loss: 0.312476
Step #100000	Loss: 0.310632
Step #104000	Loss: 0.294042
Step #108000	Loss: 0.311612
Code block 'train epoch=4' took: 929064.59858 ms
train loss 0.30198416113853455
Code block 'val epoch=4' took: 60694.98836 ms
validation loss 0.7715972661972046
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --cufile-thread-count 64 --batch-size 16384 --epochs 5'
[WARN  tini (2136278)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-25 06:31:35.715128: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-25 06:31:38.800882: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-25 06:32:02.775281: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-25 06:35:45.169688: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-25 06:35:45.534212: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f089423d050 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-25 06:35:45.534325: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-25 06:35:45.680011: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-25 06:35:46.694745: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-25 06:35:46.991623: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 2.105171
Step #4000	Loss: 0.318696
Step #8000	Loss: 0.349646
Step #12000	Loss: 0.349798
Step #16000	Loss: 0.337857
Step #20000	Loss: 0.330399
Step #24000	Loss: 0.317718
Step #28000	Loss: 0.335273
Step #32000	Loss: 0.312916
Step #36000	Loss: 0.393907
Step #40000	Loss: 0.346446
Step #44000	Loss: 0.436249
Step #48000	Loss: 0.410256
Step #52000	Loss: 0.350870
Step #56000	Loss: 0.315085
Step #60000	Loss: 0.319877
Step #64000	Loss: 0.348585
Step #68000	Loss: 0.453399
Step #72000	Loss: 0.381368
Step #76000	Loss: 0.322002
Step #80000	Loss: 0.415373
Step #84000	Loss: 0.331297
Step #88000	Loss: 0.400433
Step #92000	Loss: 0.338269
Step #96000	Loss: 0.352745
Step #100000	Loss: 0.365664
Step #104000	Loss: 0.357728
Step #108000	Loss: 0.344841
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 951033.44257 ms
train loss 0.35933494567871094
Code block 'val epoch=0' took: 60449.59766 ms
validation loss 0.6078183054924011
Step #0	Loss: 0.517971
Step #4000	Loss: 0.301984
Step #8000	Loss: 0.315757
Step #12000	Loss: 0.328215
Step #16000	Loss: 0.314329
Step #20000	Loss: 0.307169
Step #24000	Loss: 0.308400
Step #28000	Loss: 0.306894
Step #32000	Loss: 0.296090
Step #36000	Loss: 0.340765
Step #40000	Loss: 0.312464
Step #44000	Loss: 0.348721
Step #48000	Loss: 0.347542
Step #52000	Loss: 0.312421
Step #56000	Loss: 0.297956
Step #60000	Loss: 0.309403
Step #64000	Loss: 0.316571
Step #68000	Loss: 0.365972
Step #72000	Loss: 0.328769
Step #76000	Loss: 0.312820
Step #80000	Loss: 0.339564
Step #84000	Loss: 0.315609
Step #88000	Loss: 0.335064
Step #92000	Loss: 0.315977
Step #96000	Loss: 0.327723
Step #100000	Loss: 0.324206
Step #104000	Loss: 0.322005
Step #108000	Loss: 0.323768
Code block 'train epoch=1' took: 928160.84457 ms
train loss 0.32135361433029175
Code block 'val epoch=1' took: 60344.42610 ms
validation loss 0.7255690693855286
Step #0	Loss: 0.403406
Step #4000	Loss: 0.294479
Step #8000	Loss: 0.308719
Step #12000	Loss: 0.312081
Step #16000	Loss: 0.295639
Step #20000	Loss: 0.309951
Step #24000	Loss: 0.294891
Step #28000	Loss: 0.307356
Step #32000	Loss: 0.289598
Step #36000	Loss: 0.312645
Step #40000	Loss: 0.301626
Step #44000	Loss: 0.318906
Step #48000	Loss: 0.326684
Step #52000	Loss: 0.310553
Step #56000	Loss: 0.295604
Step #60000	Loss: 0.306817
Step #64000	Loss: 0.308665
Step #68000	Loss: 0.329432
Step #72000	Loss: 0.308091
Step #76000	Loss: 0.304781
Step #80000	Loss: 0.301803
Step #84000	Loss: 0.306170
Step #88000	Loss: 0.299573
Step #92000	Loss: 0.298549
Step #96000	Loss: 0.315731
Step #100000	Loss: 0.308379
Step #104000	Loss: 0.304231
Step #108000	Loss: 0.312592
Code block 'train epoch=2' took: 927420.85383 ms
train loss 0.3092171847820282
Code block 'val epoch=2' took: 62894.79547 ms
validation loss 0.7633190155029297
Step #0	Loss: 0.360298
Step #4000	Loss: 0.291727
Step #8000	Loss: 0.302646
Step #12000	Loss: 0.309397
Step #16000	Loss: 0.293690
Step #20000	Loss: 0.306883
Step #24000	Loss: 0.283136
Step #28000	Loss: 0.299971
Step #32000	Loss: 0.296804
Step #36000	Loss: 0.298680
Step #40000	Loss: 0.303427
Step #44000	Loss: 0.308200
Step #48000	Loss: 0.317910
Step #52000	Loss: 0.308022
Step #56000	Loss: 0.286701
Step #60000	Loss: 0.305180
Step #64000	Loss: 0.311057
Step #68000	Loss: 0.323553
Step #72000	Loss: 0.301810
Step #76000	Loss: 0.302038
Step #80000	Loss: 0.298204
Step #84000	Loss: 0.312926
Step #88000	Loss: 0.305354
Step #92000	Loss: 0.299064
Step #96000	Loss: 0.316967
Step #100000	Loss: 0.312162
Step #104000	Loss: 0.305419
Step #108000	Loss: 0.311402
Code block 'train epoch=3' took: 928702.85619 ms
train loss 0.30418241024017334
Code block 'val epoch=3' took: 60713.29947 ms
validation loss 0.8002842664718628
Step #0	Loss: 0.355186
Step #4000	Loss: 0.283335
Step #8000	Loss: 0.303244
Step #12000	Loss: 0.310048
Step #16000	Loss: 0.299407
Step #20000	Loss: 0.310231
Step #24000	Loss: 0.288620
Step #28000	Loss: 0.296347
Step #32000	Loss: 0.291006
Step #36000	Loss: 0.295821
Step #40000	Loss: 0.293653
Step #44000	Loss: 0.302448
Step #48000	Loss: 0.311653
Step #52000	Loss: 0.296015
Step #56000	Loss: 0.290728
Step #60000	Loss: 0.305278
Step #64000	Loss: 0.308707
Step #68000	Loss: 0.323614
Step #72000	Loss: 0.292004
Step #76000	Loss: 0.295034
Step #80000	Loss: 0.288065
Step #84000	Loss: 0.307886
Step #88000	Loss: 0.296887
Step #92000	Loss: 0.299496
Step #96000	Loss: 0.308621
Step #100000	Loss: 0.310376
Step #104000	Loss: 0.299755
Step #108000	Loss: 0.306467
Code block 'train epoch=4' took: 929219.38024 ms
train loss 0.30162233114242554
Code block 'val epoch=4' took: 59937.80612 ms
validation loss 0.7929872274398804
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --cufile-thread-count 64 --batch-size 16384 --epochs 5'
[WARN  tini (2213412)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-25 07:58:30.778978: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-25 07:58:34.118259: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-25 07:59:00.180840: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-25 08:02:44.612475: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-25 08:02:44.944690: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f7c1744a0c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-25 08:02:44.944765: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-25 08:02:45.099933: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-25 08:02:46.164031: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-25 08:02:46.464548: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.527104
Step #4000	Loss: 0.315912
Step #8000	Loss: 0.327908
Step #12000	Loss: 0.450058
Step #16000	Loss: 0.353686
Step #20000	Loss: 0.331701
Step #24000	Loss: 0.302962
Step #28000	Loss: 0.422920
Step #32000	Loss: 0.344077
Step #36000	Loss: 0.386641
Step #40000	Loss: 0.325014
Step #44000	Loss: 0.363755
Step #48000	Loss: 0.368315
Step #52000	Loss: 0.318543
Step #56000	Loss: 0.342310
Step #60000	Loss: 0.350185
Step #64000	Loss: 0.364131
Step #68000	Loss: 0.458517
Step #72000	Loss: 0.329921
Step #76000	Loss: 0.422510
Step #80000	Loss: 0.340581
Step #84000	Loss: 0.349120
Step #88000	Loss: 0.335209
Step #92000	Loss: 0.365409
Step #96000	Loss: 0.352484
Step #100000	Loss: 0.323268
Step #104000	Loss: 0.326861
Step #108000	Loss: 0.362746
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 959244.02826 ms
train loss 0.3580966293811798
Code block 'val epoch=0' took: 60556.45116 ms
validation loss 0.6479390263557434
Step #0	Loss: 0.463827
Step #4000	Loss: 0.295768
Step #8000	Loss: 0.308870
Step #12000	Loss: 0.369597
Step #16000	Loss: 0.324002
Step #20000	Loss: 0.318997
Step #24000	Loss: 0.293585
Step #28000	Loss: 0.346571
Step #32000	Loss: 0.310715
Step #36000	Loss: 0.324731
Step #40000	Loss: 0.306497
Step #44000	Loss: 0.326850
Step #48000	Loss: 0.328481
Step #52000	Loss: 0.309871
Step #56000	Loss: 0.316976
Step #60000	Loss: 0.312381
Step #64000	Loss: 0.320722
Step #68000	Loss: 0.360061
Step #72000	Loss: 0.303291
Step #76000	Loss: 0.338309
Step #80000	Loss: 0.316977
Step #84000	Loss: 0.315866
Step #88000	Loss: 0.306139
Step #92000	Loss: 0.324665
Step #96000	Loss: 0.328630
Step #100000	Loss: 0.312714
Step #104000	Loss: 0.300358
Step #108000	Loss: 0.321713
Code block 'train epoch=1' took: 935220.17859 ms
train loss 0.3195747435092926
Code block 'val epoch=1' took: 59923.16567 ms
validation loss 0.7161186933517456
Step #0	Loss: 0.341762
Step #4000	Loss: 0.295062
Step #8000	Loss: 0.298140
Step #12000	Loss: 0.328320
Step #16000	Loss: 0.297119
Step #20000	Loss: 0.303376
Step #24000	Loss: 0.290459
Step #28000	Loss: 0.318587
Step #32000	Loss: 0.304164
Step #36000	Loss: 0.304756
Step #40000	Loss: 0.303141
Step #44000	Loss: 0.299276
Step #48000	Loss: 0.318132
Step #52000	Loss: 0.304512
Step #56000	Loss: 0.306932
Step #60000	Loss: 0.307657
Step #64000	Loss: 0.319358
Step #68000	Loss: 0.338588
Step #72000	Loss: 0.299154
Step #76000	Loss: 0.316857
Step #80000	Loss: 0.311614
Step #84000	Loss: 0.316809
Step #88000	Loss: 0.285062
Step #92000	Loss: 0.304579
Step #96000	Loss: 0.314584
Step #100000	Loss: 0.301289
Step #104000	Loss: 0.295574
Step #108000	Loss: 0.304449
Code block 'train epoch=2' took: 933709.49812 ms
train loss 0.30796393752098083
Code block 'val epoch=2' took: 59754.64256 ms
validation loss 0.7441509962081909
Step #0	Loss: 0.327753
Step #4000	Loss: 0.290386
Step #8000	Loss: 0.303058
Step #12000	Loss: 0.319970
Step #16000	Loss: 0.296497
Step #20000	Loss: 0.306760
Step #24000	Loss: 0.282228
Step #28000	Loss: 0.303595
Step #32000	Loss: 0.295058
Step #36000	Loss: 0.294018
Step #40000	Loss: 0.302693
Step #44000	Loss: 0.307367
Step #48000	Loss: 0.316167
Step #52000	Loss: 0.294039
Step #56000	Loss: 0.305770
Step #60000	Loss: 0.303984
Step #64000	Loss: 0.316400
Step #68000	Loss: 0.325747
Step #72000	Loss: 0.295922
Step #76000	Loss: 0.318681
Step #80000	Loss: 0.304926
Step #84000	Loss: 0.299716
Step #88000	Loss: 0.288462
Step #92000	Loss: 0.299721
Step #96000	Loss: 0.316275
Step #100000	Loss: 0.308872
Step #104000	Loss: 0.304875
Step #108000	Loss: 0.303755
Code block 'train epoch=3' took: 932656.23598 ms
train loss 0.30338039994239807
Code block 'val epoch=3' took: 59771.88802 ms
validation loss 0.7617323398590088
Step #0	Loss: 0.312962
Step #4000	Loss: 0.290154
Step #8000	Loss: 0.298603
Step #12000	Loss: 0.312764
Step #16000	Loss: 0.288361
Step #20000	Loss: 0.303370
Step #24000	Loss: 0.282429
Step #28000	Loss: 0.305778
Step #32000	Loss: 0.304583
Step #36000	Loss: 0.292497
Step #40000	Loss: 0.302529
Step #44000	Loss: 0.303428
Step #48000	Loss: 0.315633
Step #52000	Loss: 0.291927
Step #56000	Loss: 0.307704
Step #60000	Loss: 0.304137
Step #64000	Loss: 0.311701
Step #68000	Loss: 0.315709
Step #72000	Loss: 0.292451
Step #76000	Loss: 0.313598
Step #80000	Loss: 0.301709
Step #84000	Loss: 0.310654
Step #88000	Loss: 0.289590
Step #92000	Loss: 0.304150
Step #96000	Loss: 0.311522
Step #100000	Loss: 0.306955
Step #104000	Loss: 0.294803
Step #108000	Loss: 0.314934
Code block 'train epoch=4' took: 933687.93938 ms
train loss 0.30120742321014404
Code block 'val epoch=4' took: 62666.95247 ms
validation loss 0.8217570781707764
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --cufile-thread-count 64 --batch-size 16384 --epochs 5'
[WARN  tini (2291514)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-25 09:25:56.926418: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-25 09:26:00.087138: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-25 09:26:26.901801: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-25 09:30:07.839921: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-25 09:30:08.194896: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f473048ad60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-25 09:30:08.194963: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-25 09:30:08.358165: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-25 09:30:09.426276: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-25 09:30:09.728748: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.929227
Step #4000	Loss: 0.373666
terminate called after throwing an instance of 'rmm::out_of_memory'
  what():  std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp
[dgx-2:2291538] *** Process received signal ***
[dgx-2:2291538] Signal: Aborted (6)
[dgx-2:2291538] Signal code:  (-6)
[dgx-2:2291538] [ 0] /lib/x86_64-linux-gnu/libc.so.6(+0x42520)[0x7f5157fcd520]
[dgx-2:2291538] [ 1] /lib/x86_64-linux-gnu/libc.so.6(pthread_kill+0x12c)[0x7f5158021a7c]
[dgx-2:2291538] [ 2] /lib/x86_64-linux-gnu/libc.so.6(raise+0x16)[0x7f5157fcd476]
[dgx-2:2291538] [ 3] /lib/x86_64-linux-gnu/libc.so.6(abort+0xd3)[0x7f5157fb37f3]
[dgx-2:2291538] [ 4] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(_ZN9__gnu_cxx27__verbose_terminate_handlerEv+0xc0)[0x7f515513b026]
[dgx-2:2291538] [ 5] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(+0xb0514)[0x7f5155139514]
[dgx-2:2291538] [ 6] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(+0xb0566)[0x7f5155139566]
[dgx-2:2291538] [ 7] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(__cxa_rethrow+0x0)[0x7f5155139758]
[dgx-2:2291538] [ 8] /opt/conda/envs/rapids/lib/python3.10/site-packages/rmm/_lib/device_buffer.cpython-310-x86_64-linux-gnu.so(+0x4b67d)[0x7f502408167d]
[dgx-2:2291538] [ 9] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf19make_numeric_columnENS_9data_typeEiNS_10mask_stateEN3rmm16cuda_stream_viewEPNS2_2mr22device_memory_resourceE+0x126)[0x7f4f23ae20c6]
[dgx-2:2291538] [10] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf7strings6detail25create_chars_child_columnEiN3rmm16cuda_stream_viewEPNS2_2mr22device_memory_resourceE+0x19)[0x7f4f251ffa29]
[dgx-2:2291538] [11] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf7strings6detail19make_strings_columnIPKN6thrust4pairIPKciEEEESt10unique_ptrINS_6columnESt14default_deleteISB_EET_SF_N3rmm16cuda_stream_viewEPNSG_2mr22device_memory_resourceE+0x47a)[0x7f4f251f937a]
[dgx-2:2291538] [12] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf19make_strings_columnENS_11device_spanIKN6thrust4pairIPKciEELm18446744073709551615EEEN3rmm16cuda_stream_viewEPNS8_2mr22device_memory_resourceE+0x83)[0x7f4f251f4603]
[dgx-2:2291538] [13] /home2/faculty/pwesolowski/praca-mgr/parser-repo/build/libmeta-cudf-parser-1.so(_ZNK18ParserOutputDeviceI5JDictIN5boost4mp117mp_listIJNS3_IJNS3_IJSt17integral_constantIiLi117EES4_IiLi115EES4_IiLi101EES4_IiLi114EES4_IiLi95EES4_IiLi105EES4_IiLi100EEEEE17JStringStaticCopyIS4_IiLi21EESC_NS3_IJEEEEEEENS3_IJNS3_IJS4_IiLi103EES4_IiLi109EES4_IiLi97EES4_IiLi112EES9_SA_SB_EEESD_IS4_IiLi37EESM_SF_EEEENS3_IJNS3_IJS8_SK_S4_IiLi116EESA_S4_IiLi110EESI_EEE7JNumberIhSS_SF_EEEENS3_IJNS3_IJS4_IiLi99EESK_SQ_S7_SI_S4_IiLi111EES8_S4_IiLi121EEEEESD_IS4_IiLi470EESZ_SF_EEEENS3_IJNS3_IJS4_IiLi108EESK_SQ_SA_SQ_S5_SB_S7_EEE11JRealNumberIfS14_SF_EEEENS3_IJNS3_IJS13_SX_SR_SI_SA_SQ_S5_SB_S7_EEES15_IfS18_SF_EEEEEEESF_EE6ToCudfEN3rmm16cuda_stream_viewEPNS1E_2mr22device_memory_resourceE+0x505)[0x7f4e962903a5]
[dgx-2:2291538] [14] /home2/faculty/pwesolowski/praca-mgr/parser-repo/build/libmeta-cudf-parser-1.so(_Z25generate_example_metadataPKcmmi11end_of_linebb+0x1cf)[0x7f4e96287bcf]
[dgx-2:2291538] [15] /home2/faculty/pwesolowski/praca-mgr/parser-repo/python_binding/metajsonparser/_lib/json_cudf.cpython-310-x86_64-linux-gnu.so(+0x4b344)[0x7f4e9635f344]
[dgx-2:2291538] [16] python(+0x13fb27)[0x55565e6e5b27]
[dgx-2:2291538] [17] python(PyObject_Call+0x209)[0x55565e6f2139]
[dgx-2:2291538] [18] python(_PyEval_EvalFrameDefault+0x5d8c)[0x55565e6dbb7c]
[dgx-2:2291538] [19] python(_PyFunction_Vectorcall+0x6f)[0x55565e6e5f8f]
[dgx-2:2291538] [20] python(_PyEval_EvalFrameDefault+0x2ec2)[0x55565e6d8cb2]
[dgx-2:2291538] [21] python(_PyFunction_Vectorcall+0x6f)[0x55565e6e5f8f]
[dgx-2:2291538] [22] python(_PyEval_EvalFrameDefault+0x332)[0x55565e6d6122]
[dgx-2:2291538] [23] python(_PyFunction_Vectorcall+0x6f)[0x55565e6e5f8f]
[dgx-2:2291538] [24] python(_PyEval_EvalFrameDefault+0x2ec2)[0x55565e6d8cb2]
[dgx-2:2291538] [25] python(_PyFunction_Vectorcall+0x6f)[0x55565e6e5f8f]
[dgx-2:2291538] [26] python(_PyEval_EvalFrameDefault+0x332)[0x55565e6d6122]
[dgx-2:2291538] [27] python(_PyFunction_Vectorcall+0x6f)[0x55565e6e5f8f]
[dgx-2:2291538] [28] python(_PyEval_EvalFrameDefault+0x2ec2)[0x55565e6d8cb2]
[dgx-2:2291538] [29] python(+0x14b641)[0x55565e6f1641]
[dgx-2:2291538] *** End of error message ***
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --cufile-thread-count 64 --batch-size 16384 --epochs 5'
[WARN  tini (2297533)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-25 09:31:06.319621: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-25 09:31:09.292407: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-25 09:31:32.975566: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
Failed to transform operator <nvtabular.ops.categorify.Categorify object at 0x7f32de2dbac0>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1780, in _encode
    ).sort_values("order")["labels"]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 2214, in sort_values
    out = self._gather(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-25 09:35:17.264181: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-25 09:35:17.587376: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f299e3c01d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-25 09:35:17.587443: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-25 09:35:17.733654: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-25 09:35:18.810014: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-25 09:35:19.142746: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 3.427050
Code block 'train epoch=0' took: 43100.32128 ms
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 332, in _get_next_batch
    batch = next(self._batch_itr)
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home2/faculty/pwesolowski/praca-mgr/pipelines-repo/2_merlin/run_merlin.py", line 155, in <module>
    for batch, (examples, labels) in enumerate(train_tf_ds):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/tensorflow.py", line 97, in __next__
    converted_batch = self.convert_batch(super().__next__())
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 261, in __next__
    return self._get_next_batch()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 344, in _get_next_batch
    batch = next(self._batch_itr)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 369, in make_tensors
    tensors_by_name = self._convert_df_to_tensors(gdf)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 520, in _convert_df_to_tensors
    tensors_by_name[column_name] = self._to_tensor(gdf_i[[column_name]])
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 450, in _to_tensor
    tensor = df_or_series.to_cupy()
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/single_column_frame.py", line 131, in to_cupy
    return super().to_cupy(dtype, copy, na_value).flatten()
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 533, in to_cupy
    return self._to_array(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 498, in _to_array
    matrix[:, i] = get_column_values_na(col)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 477, in get_column_values_na
    return get_column_values(col)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 534, in <lambda>
    (lambda col: col.values.copy())
  File "cupy/_core/core.pyx", line 590, in cupy._core.core._ndarray_base.copy
  File "cupy/_core/core.pyx", line 616, in cupy._core.core._ndarray_base.copy
  File "cupy/_core/core.pyx", line 575, in cupy._core.core._ndarray_base.astype
  File "cupy/_core/core.pyx", line 136, in cupy._core.core.ndarray.__new__
  File "cupy/_core/core.pyx", line 224, in cupy._core.core._ndarray_base._init
  File "cupy/cuda/memory.pyx", line 742, in cupy.cuda.memory.alloc
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/rmm/rmm.py", line 230, in rmm_cupy_allocator
    buf = librmm.device_buffer.DeviceBuffer(size=nbytes, stream=stream)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --cufile-thread-count 64 --batch-size 16384 --epochs 5'
[WARN  tini (2302734)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-25 09:35:51.476086: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-25 09:35:54.403318: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-25 09:36:18.058326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
Failed to transform operator <nvtabular.ops.categorify.Categorify object at 0x7f8251d37a90>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1780, in _encode
    ).sort_values("order")["labels"]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 2214, in sort_values
    out = self._gather(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-25 09:40:02.281509: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-25 09:40:02.666460: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f7f559ddae0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-25 09:40:02.666528: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-25 09:40:02.803584: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-25 09:40:03.806637: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-25 09:40:04.095950: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.691543
Code block 'train epoch=0' took: 57435.14865 ms
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1780, in _encode
    ).sort_values("order")["labels"]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 2214, in sort_values
    out = self._gather(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home2/faculty/pwesolowski/praca-mgr/pipelines-repo/2_merlin/run_merlin.py", line 155, in <module>
    for batch, (examples, labels) in enumerate(train_tf_ds):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/tensorflow.py", line 97, in __next__
    converted_batch = self.convert_batch(super().__next__())
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 261, in __next__
    return self._get_next_batch()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 343, in _get_next_batch
    self._fetch_chunk()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 277, in _fetch_chunk
    raise chunks
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 791, in load_chunks
    self.chunk_logic(itr)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 759, in chunk_logic
    for chunks in self.batch(itr):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 745, in batch
    value = next(itr)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/io/dataframe_iter.py", line 44, in __iter__
    yield part.compute(scheduler="synchronous")
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/base.py", line 314, in compute
    (result,) = compute(self, traverse=False, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/base.py", line 599, in compute
    results = schedule(dsk, keys, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 557, in get_sync
    return get_async(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 500, in get_async
    for key, res_info, failed in queue_get(queue).result():
  File "/opt/conda/envs/rapids/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/opt/conda/envs/rapids/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 542, in submit
    fut.set_result(fn(*args, **kwargs))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 238, in batch_execute_tasks
    return [execute_task(*a) for a in it]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 238, in <listcomp>
    return [execute_task(*a) for a in it]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 229, in execute_task
    result = pack_exception(e, dumps)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 224, in execute_task
    result = _execute_task(task, data)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/optimization.py", line 990, in __call__
    return core.get(self.dsk, self.outkey, dict(zip(self.inkeys, args)))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 149, in get
    result = _execute_task(task, cache)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in <genexpr>
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/utils.py", line 72, in apply
    return func(*args, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 87, in transform
    transformed_data = self._execute_node(node, transformable, capture_dtypes, strict)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 101, in _execute_node
    upstream_outputs = self._run_upstream_transforms(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 114, in _run_upstream_transforms
    node_output = self._execute_node(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 107, in _execute_node
    transform_output = self._run_node_transform(node, transform_input, capture_dtypes, strict)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 227, in _run_node_transform
    raise exc
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
+ for BATCH_SIZE in 8192 16384 32768
+ for CUFILE_THREAD_COUNT in 4 8 16 32 64
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --cufile-thread-count 4 --batch-size 32768 --epochs 5'
[WARN  tini (2308337)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-25 09:40:51.754962: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-25 09:40:54.982064: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-25 09:41:19.734052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-25 09:45:08.061108: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-25 09:45:08.384743: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f7a176915e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-25 09:45:08.384819: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-25 09:45:08.531636: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-25 09:45:09.682230: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-25 09:45:09.994739: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.491080
Step #4000	Loss: 0.330970
Step #8000	Loss: 0.438725
Step #12000	Loss: 0.324741
Step #16000	Loss: 0.305763
Step #20000	Loss: 0.380343
Step #24000	Loss: 0.315427
Step #28000	Loss: 0.327681
Step #32000	Loss: 0.379571
Step #36000	Loss: 0.428710
Step #40000	Loss: 0.351787
Step #44000	Loss: 0.306881
Step #48000	Loss: 0.433130
Step #52000	Loss: 0.348071
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 613113.03698 ms
train loss 0.36457088589668274
Code block 'val epoch=0' took: 51983.46148 ms
validation loss 0.5943543910980225
Step #0	Loss: 0.460602
Step #4000	Loss: 0.310017
Step #8000	Loss: 0.348165
Step #12000	Loss: 0.305858
Step #16000	Loss: 0.300794
Step #20000	Loss: 0.321038
Step #24000	Loss: 0.303994
Step #28000	Loss: 0.304880
Step #32000	Loss: 0.329719
Step #36000	Loss: 0.345099
Step #40000	Loss: 0.304578
Step #44000	Loss: 0.278603
Step #48000	Loss: 0.356808
Step #52000	Loss: 0.308909
Code block 'train epoch=1' took: 589285.24556 ms
train loss 0.3236822485923767
Code block 'val epoch=1' took: 52240.72400 ms
validation loss 0.6665411591529846
Step #0	Loss: 0.324465
Step #4000	Loss: 0.302484
Step #8000	Loss: 0.315035
Step #12000	Loss: 0.291487
Step #16000	Loss: 0.295832
Step #20000	Loss: 0.312377
Step #24000	Loss: 0.297110
Step #28000	Loss: 0.302144
Step #32000	Loss: 0.320696
Step #36000	Loss: 0.312889
Step #40000	Loss: 0.289553
Step #44000	Loss: 0.284716
Step #48000	Loss: 0.323841
Step #52000	Loss: 0.304181
Code block 'train epoch=2' took: 588545.71605 ms
train loss 0.3099547326564789
Code block 'val epoch=2' took: 52042.87403 ms
validation loss 0.7486822605133057
Step #0	Loss: 0.307425
Step #4000	Loss: 0.296496
Step #8000	Loss: 0.297544
Step #12000	Loss: 0.291531
Step #16000	Loss: 0.286130
Step #20000	Loss: 0.301820
Step #24000	Loss: 0.294751
Step #28000	Loss: 0.298231
Step #32000	Loss: 0.310636
Step #36000	Loss: 0.306978
Step #40000	Loss: 0.285167
Step #44000	Loss: 0.271475
Step #48000	Loss: 0.320125
Step #52000	Loss: 0.301485
Code block 'train epoch=3' took: 590976.99971 ms
train loss 0.30459603667259216
Code block 'val epoch=3' took: 52115.07283 ms
validation loss 0.7827563285827637
Step #0	Loss: 0.296423
Step #4000	Loss: 0.294094
Step #8000	Loss: 0.289715
Step #12000	Loss: 0.291063
Step #16000	Loss: 0.284516
Step #20000	Loss: 0.294528
Step #24000	Loss: 0.294859
Step #28000	Loss: 0.299329
Step #32000	Loss: 0.304518
Step #36000	Loss: 0.298076
Step #40000	Loss: 0.282151
Step #44000	Loss: 0.269387
Step #48000	Loss: 0.308634
Step #52000	Loss: 0.304852
Code block 'train epoch=4' took: 588359.56469 ms
train loss 0.3019370138645172
Code block 'val epoch=4' took: 51438.21145 ms
validation loss 0.8617345094680786
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --cufile-thread-count 4 --batch-size 32768 --epochs 5'
[WARN  tini (2360161)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-25 10:38:53.966406: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-25 10:38:56.926337: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-25 10:39:20.254698: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-25 10:43:09.009744: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-25 10:43:09.449236: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f017fe33830 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-25 10:43:09.449302: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-25 10:43:09.598756: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-25 10:43:10.650702: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-25 10:43:10.956725: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.552684
Step #4000	Loss: 0.321083
Step #8000	Loss: 0.441666
Step #12000	Loss: 0.360066
Step #16000	Loss: 0.333649
Step #20000	Loss: 0.333916
Step #24000	Loss: 0.320631
Step #28000	Loss: 0.319372
Step #32000	Loss: 0.405277
Step #36000	Loss: 0.344748
Step #40000	Loss: 0.387843
Step #44000	Loss: 0.357902
Step #48000	Loss: 0.452144
Step #52000	Loss: 0.321243
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 606882.32672 ms
train loss 0.3622141182422638
Code block 'val epoch=0' took: 51079.95491 ms
validation loss 0.5865461230278015
Step #0	Loss: 0.467724
Step #4000	Loss: 0.312306
Step #8000	Loss: 0.357282
Step #12000	Loss: 0.318960
Step #16000	Loss: 0.304869
Step #20000	Loss: 0.317865
Step #24000	Loss: 0.305075
Step #28000	Loss: 0.305023
Step #32000	Loss: 0.339864
Step #36000	Loss: 0.314212
Step #40000	Loss: 0.315582
Step #44000	Loss: 0.310394
Step #48000	Loss: 0.364467
Step #52000	Loss: 0.302863
Code block 'train epoch=1' took: 582242.23106 ms
train loss 0.32261964678764343
Code block 'val epoch=1' took: 50721.63018 ms
validation loss 0.6312184929847717
Step #0	Loss: 0.347807
Step #4000	Loss: 0.294417
Step #8000	Loss: 0.325585
Step #12000	Loss: 0.302628
Step #16000	Loss: 0.290055
Step #20000	Loss: 0.310788
Step #24000	Loss: 0.303831
Step #28000	Loss: 0.292071
Step #32000	Loss: 0.317751
Step #36000	Loss: 0.304936
Step #40000	Loss: 0.302780
Step #44000	Loss: 0.294544
Step #48000	Loss: 0.337018
Step #52000	Loss: 0.295974
Code block 'train epoch=2' took: 582578.75604 ms
train loss 0.30954331159591675
Code block 'val epoch=2' took: 50726.26329 ms
validation loss 0.6839250326156616
Step #0	Loss: 0.330373
Step #4000	Loss: 0.302587
Step #8000	Loss: 0.305838
Step #12000	Loss: 0.298950
Step #16000	Loss: 0.295180
Step #20000	Loss: 0.301647
Step #24000	Loss: 0.298026
Step #28000	Loss: 0.295321
Step #32000	Loss: 0.311728
Step #36000	Loss: 0.297039
Step #40000	Loss: 0.293205
Step #44000	Loss: 0.290078
Step #48000	Loss: 0.318094
Step #52000	Loss: 0.297817
Code block 'train epoch=3' took: 583770.51889 ms
train loss 0.3044029474258423
Code block 'val epoch=3' took: 50633.07881 ms
validation loss 0.7249836921691895
Step #0	Loss: 0.323383
Step #4000	Loss: 0.298531
Step #8000	Loss: 0.298302
Step #12000	Loss: 0.293897
Step #16000	Loss: 0.289148
Step #20000	Loss: 0.302090
Step #24000	Loss: 0.293867
Step #28000	Loss: 0.293849
Step #32000	Loss: 0.308195
Step #36000	Loss: 0.298752
Step #40000	Loss: 0.289372
Step #44000	Loss: 0.284385
Step #48000	Loss: 0.317469
Step #52000	Loss: 0.297106
Code block 'train epoch=4' took: 582303.75571 ms
train loss 0.30184367299079895
Code block 'val epoch=4' took: 50701.50978 ms
validation loss 0.7735737562179565
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --cufile-thread-count 4 --batch-size 32768 --epochs 5'
[WARN  tini (2412377)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-25 11:36:16.533347: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-25 11:36:19.587774: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-25 11:36:42.833081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-25 11:40:30.870620: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-25 11:40:31.187768: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f73bc99b490 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-25 11:40:31.187833: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-25 11:40:31.338781: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-25 11:40:32.331398: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-25 11:40:32.627465: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.990055
Step #4000	Loss: 0.337082
Step #8000	Loss: 0.435205
Step #12000	Loss: 0.384471
Step #16000	Loss: 0.326292
Step #20000	Loss: 0.330507
Step #24000	Loss: 0.324664
Step #28000	Loss: 0.314920
Step #32000	Loss: 0.330487
Step #36000	Loss: 0.449198
Step #40000	Loss: 0.343286
Step #44000	Loss: 0.333476
Step #48000	Loss: 0.374562
Step #52000	Loss: 0.404902
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 604893.21047 ms
train loss 0.4838466942310333
Code block 'val epoch=0' took: 51217.68294 ms
validation loss 0.62264084815979
Step #0	Loss: 0.522296
Step #4000	Loss: 0.312845
Step #8000	Loss: 0.354782
Step #12000	Loss: 0.321054
Step #16000	Loss: 0.298254
Step #20000	Loss: 0.314965
Step #24000	Loss: 0.310536
Step #28000	Loss: 0.301848
Step #32000	Loss: 0.313952
Step #36000	Loss: 0.349256
Step #40000	Loss: 0.321855
Step #44000	Loss: 0.298857
Step #48000	Loss: 0.333722
Step #52000	Loss: 0.333345
Code block 'train epoch=1' took: 580689.25657 ms
train loss 0.32306039333343506
Code block 'val epoch=1' took: 50931.66219 ms
validation loss 0.6981921792030334
Step #0	Loss: 0.341317
Step #4000	Loss: 0.305696
Step #8000	Loss: 0.313569
Step #12000	Loss: 0.298191
Step #16000	Loss: 0.289153
Step #20000	Loss: 0.306037
Step #24000	Loss: 0.306141
Step #28000	Loss: 0.293601
Step #32000	Loss: 0.313532
Step #36000	Loss: 0.315905
Step #40000	Loss: 0.317348
Step #44000	Loss: 0.294150
Step #48000	Loss: 0.319372
Step #52000	Loss: 0.315005
Code block 'train epoch=2' took: 581070.91719 ms
train loss 0.3094528913497925
Code block 'val epoch=2' took: 50784.05243 ms
validation loss 0.7588696479797363
Step #0	Loss: 0.316071
Step #4000	Loss: 0.297755
Step #8000	Loss: 0.308054
Step #12000	Loss: 0.296411
Step #16000	Loss: 0.289035
Step #20000	Loss: 0.307689
Step #24000	Loss: 0.303762
Step #28000	Loss: 0.294130
Step #32000	Loss: 0.307438
Step #36000	Loss: 0.308244
Step #40000	Loss: 0.309976
Step #44000	Loss: 0.293427
Step #48000	Loss: 0.318930
Step #52000	Loss: 0.312576
Code block 'train epoch=3' took: 581879.34668 ms
train loss 0.30435794591903687
Code block 'val epoch=3' took: 50699.68374 ms
validation loss 0.8133041262626648
Step #0	Loss: 0.315084
Step #4000	Loss: 0.297472
Step #8000	Loss: 0.293839
Step #12000	Loss: 0.297778
Step #16000	Loss: 0.289775
Step #20000	Loss: 0.301378
Step #24000	Loss: 0.299838
Step #28000	Loss: 0.293187
Step #32000	Loss: 0.310363
Step #36000	Loss: 0.300777
Step #40000	Loss: 0.309542
Step #44000	Loss: 0.286474
Step #48000	Loss: 0.317185
Step #52000	Loss: 0.304842
Code block 'train epoch=4' took: 584193.76795 ms
train loss 0.3018469512462616
Code block 'val epoch=4' took: 50896.93303 ms
validation loss 0.8819992542266846
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --cufile-thread-count 4 --batch-size 32768 --epochs 5'
[WARN  tini (2465940)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-25 12:33:33.750802: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-25 12:33:37.705077: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-25 12:34:03.132924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-25 12:37:44.818355: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-25 12:37:45.160199: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f1ecb25e2d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-25 12:37:45.160267: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-25 12:37:45.338774: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-25 12:37:46.341022: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-25 12:37:46.656618: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.880846
Step #4000	Loss: 0.325589
Step #8000	Loss: 0.447177
Step #12000	Loss: 0.368161
Step #16000	Loss: 0.335162
Step #20000	Loss: 0.407825
Step #24000	Loss: 0.365305
Step #28000	Loss: 0.336561
Step #32000	Loss: 0.393876
Step #36000	Loss: 0.336068
Step #40000	Loss: 0.391687
Step #44000	Loss: 0.352037
Step #48000	Loss: 0.448727
Step #52000	Loss: 0.316630
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 592777.43219 ms
train loss 0.3631301820278168
Code block 'val epoch=0' took: 48810.91383 ms
validation loss 0.6283689141273499
Step #0	Loss: 0.455690
Step #4000	Loss: 0.310912
Step #8000	Loss: 0.365258
Step #12000	Loss: 0.319443
Step #16000	Loss: 0.303786
Step #20000	Loss: 0.357788
Step #24000	Loss: 0.325979
Step #28000	Loss: 0.307972
Step #32000	Loss: 0.329336
Step #36000	Loss: 0.313548
Step #40000	Loss: 0.317138
Step #44000	Loss: 0.308945
Step #48000	Loss: 0.366033
Step #52000	Loss: 0.298779
Code block 'train epoch=1' took: 568671.86861 ms
train loss 0.32389840483665466
Code block 'val epoch=1' took: 48086.66092 ms
validation loss 0.6961729526519775
Step #0	Loss: 0.332262
Step #4000	Loss: 0.298974
Step #8000	Loss: 0.323482
Step #12000	Loss: 0.303622
Step #16000	Loss: 0.291718
Step #20000	Loss: 0.314777
Step #24000	Loss: 0.318436
Step #28000	Loss: 0.305146
Step #32000	Loss: 0.318020
Step #36000	Loss: 0.302197
Step #40000	Loss: 0.302210
Step #44000	Loss: 0.292247
Step #48000	Loss: 0.333224
Step #52000	Loss: 0.297571
Code block 'train epoch=2' took: 567354.66066 ms
train loss 0.3102828562259674
Code block 'val epoch=2' took: 48305.48031 ms
validation loss 0.7612641453742981
Step #0	Loss: 0.316904
Step #4000	Loss: 0.298788
Step #8000	Loss: 0.307220
Step #12000	Loss: 0.296331
Step #16000	Loss: 0.295613
Step #20000	Loss: 0.304544
Step #24000	Loss: 0.310379
Step #28000	Loss: 0.299312
Step #32000	Loss: 0.311498
Step #36000	Loss: 0.297547
Step #40000	Loss: 0.294275
Step #44000	Loss: 0.287657
Step #48000	Loss: 0.316702
Step #52000	Loss: 0.293891
Code block 'train epoch=3' took: 568015.01160 ms
train loss 0.3048757314682007
Code block 'val epoch=3' took: 47941.81756 ms
validation loss 0.8243945240974426
Step #0	Loss: 0.311307
Step #4000	Loss: 0.296862
Step #8000	Loss: 0.297680
Step #12000	Loss: 0.297645
Step #16000	Loss: 0.287592
Step #20000	Loss: 0.297333
Step #24000	Loss: 0.304357
Step #28000	Loss: 0.298568
Step #32000	Loss: 0.303450
Step #36000	Loss: 0.293035
Step #40000	Loss: 0.290301
Step #44000	Loss: 0.282608
Step #48000	Loss: 0.317386
Step #52000	Loss: 0.292026
Code block 'train epoch=4' took: 570083.39291 ms
train loss 0.3021187484264374
Code block 'val epoch=4' took: 48077.91843 ms
validation loss 0.8892915844917297
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --cufile-thread-count 4 --batch-size 32768 --epochs 5'
[WARN  tini (2516347)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-25 13:29:31.438134: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-25 13:29:34.847012: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-25 13:29:58.756734: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-25 13:33:44.558852: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-25 13:33:44.976521: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f3d14637770 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-25 13:33:44.976593: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-25 13:33:45.124764: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-25 13:33:46.209201: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-25 13:33:46.519902: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.813710
Step #4000	Loss: 0.351436
Step #8000	Loss: 0.342282
Step #12000	Loss: 0.313758
Step #16000	Loss: 0.320215
Step #20000	Loss: 0.347695
Step #24000	Loss: 0.401731
Step #28000	Loss: 0.316383
Step #32000	Loss: 0.347920
Step #36000	Loss: 0.380227
Step #40000	Loss: 0.416772
Step #44000	Loss: 0.402779
Step #48000	Loss: 0.367675
Step #52000	Loss: 0.359645
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 594124.35746 ms
train loss 0.3609832525253296
Code block 'val epoch=0' took: 48152.31271 ms
validation loss 0.5866478681564331
Step #0	Loss: 0.469604
Step #4000	Loss: 0.320698
Step #8000	Loss: 0.312781
Step #12000	Loss: 0.298238
Step #16000	Loss: 0.297151
Step #20000	Loss: 0.309898
Step #24000	Loss: 0.344581
Step #28000	Loss: 0.300846
Step #32000	Loss: 0.321870
Step #36000	Loss: 0.325346
Step #40000	Loss: 0.321420
Step #44000	Loss: 0.322868
Step #48000	Loss: 0.326822
Step #52000	Loss: 0.320325
Code block 'train epoch=1' took: 567115.33222 ms
train loss 0.32115161418914795
Code block 'val epoch=1' took: 47429.65011 ms
validation loss 0.6522656083106995
Step #0	Loss: 0.353783
Step #4000	Loss: 0.303507
Step #8000	Loss: 0.296646
Step #12000	Loss: 0.292995
Step #16000	Loss: 0.293177
Step #20000	Loss: 0.312029
Step #24000	Loss: 0.317741
Step #28000	Loss: 0.291352
Step #32000	Loss: 0.306674
Step #36000	Loss: 0.316441
Step #40000	Loss: 0.300504
Step #44000	Loss: 0.306756
Step #48000	Loss: 0.316677
Step #52000	Loss: 0.310127
Code block 'train epoch=2' took: 568342.77304 ms
train loss 0.3087383508682251
Code block 'val epoch=2' took: 47583.72002 ms
validation loss 0.6887208819389343
Step #0	Loss: 0.324998
Step #4000	Loss: 0.297585
Step #8000	Loss: 0.291244
Step #12000	Loss: 0.295966
Step #16000	Loss: 0.290560
Step #20000	Loss: 0.298321
Step #24000	Loss: 0.315582
Step #28000	Loss: 0.293430
Step #32000	Loss: 0.309123
Step #36000	Loss: 0.304199
Step #40000	Loss: 0.295256
Step #44000	Loss: 0.297950
Step #48000	Loss: 0.318045
Step #52000	Loss: 0.308562
Code block 'train epoch=3' took: 567397.13086 ms
train loss 0.30395734310150146
Code block 'val epoch=3' took: 47577.51330 ms
validation loss 0.7277215719223022
Step #0	Loss: 0.319519
Step #4000	Loss: 0.304379
Step #8000	Loss: 0.290178
Step #12000	Loss: 0.292126
Step #16000	Loss: 0.289454
Step #20000	Loss: 0.299386
Step #24000	Loss: 0.307873
Step #28000	Loss: 0.288087
Step #32000	Loss: 0.304210
Step #36000	Loss: 0.297882
Step #40000	Loss: 0.291208
Step #44000	Loss: 0.295313
Step #48000	Loss: 0.316316
Step #52000	Loss: 0.300124
Code block 'train epoch=4' took: 567662.39931 ms
train loss 0.3016020953655243
Code block 'val epoch=4' took: 47691.77053 ms
validation loss 0.7797359824180603
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --cufile-thread-count 4 --batch-size 32768 --epochs 5'
[WARN  tini (2570689)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-25 14:25:20.927604: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-25 14:25:23.825829: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-25 14:25:46.312191: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-25 14:29:31.874893: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-25 14:29:32.178889: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f5c658adf20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-25 14:29:32.178961: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-25 14:29:32.311603: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-25 14:29:33.351355: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-25 14:29:33.669213: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 6.391749
Step #4000	Loss: 0.328133
Step #8000	Loss: 0.360991
Step #12000	Loss: 0.306149
Step #16000	Loss: 0.344147
Step #20000	Loss: 0.329761
Step #24000	Loss: 0.382876
Step #28000	Loss: 0.345311
Step #32000	Loss: 0.361599
Step #36000	Loss: 0.330129
Step #40000	Loss: 0.339476
Step #44000	Loss: 0.332203
Step #48000	Loss: 0.348143
Step #52000	Loss: 0.315556
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 598225.99859 ms
train loss 0.36003461480140686
Code block 'val epoch=0' took: 48139.39315 ms
validation loss 0.6207600235939026
Step #0	Loss: 0.479503
Step #4000	Loss: 0.315286
Step #8000	Loss: 0.319169
Step #12000	Loss: 0.292835
Step #16000	Loss: 0.313463
Step #20000	Loss: 0.305127
Step #24000	Loss: 0.334577
Step #28000	Loss: 0.315020
Step #32000	Loss: 0.328699
Step #36000	Loss: 0.309610
Step #40000	Loss: 0.317970
Step #44000	Loss: 0.302109
Step #48000	Loss: 0.320371
Step #52000	Loss: 0.304990
Code block 'train epoch=1' took: 574477.31510 ms
train loss 0.320708304643631
Code block 'val epoch=1' took: 47934.64920 ms
validation loss 0.6651885509490967
Step #0	Loss: 0.351503
Step #4000	Loss: 0.301777
Step #8000	Loss: 0.300222
Step #12000	Loss: 0.290713
Step #16000	Loss: 0.305650
Step #20000	Loss: 0.304231
Step #24000	Loss: 0.321077
Step #28000	Loss: 0.305654
Step #32000	Loss: 0.313806
Step #36000	Loss: 0.295984
Step #40000	Loss: 0.313143
Step #44000	Loss: 0.291622
Step #48000	Loss: 0.314024
Step #52000	Loss: 0.298556
Code block 'train epoch=2' took: 576587.26373 ms
train loss 0.3087990880012512
Code block 'val epoch=2' took: 47567.34195 ms
validation loss 0.7104527950286865
Step #0	Loss: 0.332797
Step #4000	Loss: 0.295316
Step #8000	Loss: 0.294852
Step #12000	Loss: 0.289616
Step #16000	Loss: 0.298351
Step #20000	Loss: 0.300434
Step #24000	Loss: 0.310369
Step #28000	Loss: 0.303788
Step #32000	Loss: 0.312629
Step #36000	Loss: 0.291283
Step #40000	Loss: 0.307213
Step #44000	Loss: 0.286236
Step #48000	Loss: 0.316362
Step #52000	Loss: 0.289352
Code block 'train epoch=3' took: 576039.32852 ms
train loss 0.30387043952941895
Code block 'val epoch=3' took: 47986.02789 ms
validation loss 0.7412915229797363
Step #0	Loss: 0.321477
Step #4000	Loss: 0.303644
Step #8000	Loss: 0.296243
Step #12000	Loss: 0.291637
Step #16000	Loss: 0.296515
Step #20000	Loss: 0.298540
Step #24000	Loss: 0.314115
Step #28000	Loss: 0.305292
Step #32000	Loss: 0.310063
Step #36000	Loss: 0.294652
Step #40000	Loss: 0.307733
Step #44000	Loss: 0.291480
Step #48000	Loss: 0.315595
Step #52000	Loss: 0.290552
Code block 'train epoch=4' took: 572652.59644 ms
train loss 0.3015275001525879
Code block 'val epoch=4' took: 48034.92100 ms
validation loss 0.767387866973877
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --cufile-thread-count 4 --batch-size 32768 --epochs 5'
[WARN  tini (2636347)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-25 15:21:46.346761: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-25 15:21:49.963315: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-25 15:22:17.184509: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-25 15:25:59.496408: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-25 15:25:59.907802: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f8c4aba5fe0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-25 15:25:59.907877: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-25 15:26:00.046758: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-25 15:26:01.121700: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-25 15:26:01.438162: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 1.390068
Failed to transform operator <nvtabular.ops.categorify.Categorify object at 0x7f8e6c8cbb20>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1778, in _encode
    labels = codes.merge(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/dataframe.py", line 4004, in merge
    ).perform_merge()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/join/join.py", line 203, in perform_merge
    self.rhs._gather(gather_map=right_rows, **gather_kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
Code block 'train epoch=0' took: 55954.89473 ms
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 332, in _get_next_batch
    batch = next(self._batch_itr)
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home2/faculty/pwesolowski/praca-mgr/pipelines-repo/2_merlin/run_merlin.py", line 155, in <module>
    for batch, (examples, labels) in enumerate(train_tf_ds):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/tensorflow.py", line 97, in __next__
    converted_batch = self.convert_batch(super().__next__())
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 261, in __next__
    return self._get_next_batch()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 344, in _get_next_batch
    batch = next(self._batch_itr)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 369, in make_tensors
    tensors_by_name = self._convert_df_to_tensors(gdf)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 520, in _convert_df_to_tensors
    tensors_by_name[column_name] = self._to_tensor(gdf_i[[column_name]])
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 450, in _to_tensor
    tensor = df_or_series.to_cupy()
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/single_column_frame.py", line 131, in to_cupy
    return super().to_cupy(dtype, copy, na_value).flatten()
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 533, in to_cupy
    return self._to_array(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 498, in _to_array
    matrix[:, i] = get_column_values_na(col)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 477, in get_column_values_na
    return get_column_values(col)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 534, in <lambda>
    (lambda col: col.values.copy())
  File "cupy/_core/core.pyx", line 590, in cupy._core.core._ndarray_base.copy
  File "cupy/_core/core.pyx", line 616, in cupy._core.core._ndarray_base.copy
  File "cupy/_core/core.pyx", line 575, in cupy._core.core._ndarray_base.astype
  File "cupy/_core/core.pyx", line 136, in cupy._core.core.ndarray.__new__
  File "cupy/_core/core.pyx", line 224, in cupy._core.core._ndarray_base._init
  File "cupy/cuda/memory.pyx", line 742, in cupy.cuda.memory.alloc
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/rmm/rmm.py", line 230, in rmm_cupy_allocator
    buf = librmm.device_buffer.DeviceBuffer(size=nbytes, stream=stream)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --cufile-thread-count 4 --batch-size 32768 --epochs 5'
[WARN  tini (2642008)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-25 15:26:50.556514: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-25 15:26:53.611847: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-25 15:27:17.261615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
Failed to transform operator <nvtabular.ops.categorify.Categorify object at 0x7f1c7224ba90>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1780, in _encode
    ).sort_values("order")["labels"]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 2214, in sort_values
    out = self._gather(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-25 15:31:01.635230: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-25 15:31:01.980018: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f13c1471bf0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-25 15:31:01.980120: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-25 15:31:02.122966: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-25 15:31:03.222582: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-25 15:31:03.525365: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.589888
Code block 'train epoch=0' took: 37464.34727 ms
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 332, in _get_next_batch
    batch = next(self._batch_itr)
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home2/faculty/pwesolowski/praca-mgr/pipelines-repo/2_merlin/run_merlin.py", line 155, in <module>
    for batch, (examples, labels) in enumerate(train_tf_ds):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/tensorflow.py", line 97, in __next__
    converted_batch = self.convert_batch(super().__next__())
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 261, in __next__
    return self._get_next_batch()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 344, in _get_next_batch
    batch = next(self._batch_itr)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 369, in make_tensors
    tensors_by_name = self._convert_df_to_tensors(gdf)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 520, in _convert_df_to_tensors
    tensors_by_name[column_name] = self._to_tensor(gdf_i[[column_name]])
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 450, in _to_tensor
    tensor = df_or_series.to_cupy()
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/single_column_frame.py", line 131, in to_cupy
    return super().to_cupy(dtype, copy, na_value).flatten()
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 533, in to_cupy
    return self._to_array(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 498, in _to_array
    matrix[:, i] = get_column_values_na(col)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 477, in get_column_values_na
    return get_column_values(col)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 534, in <lambda>
    (lambda col: col.values.copy())
  File "cupy/_core/core.pyx", line 590, in cupy._core.core._ndarray_base.copy
  File "cupy/_core/core.pyx", line 616, in cupy._core.core._ndarray_base.copy
  File "cupy/_core/core.pyx", line 575, in cupy._core.core._ndarray_base.astype
  File "cupy/_core/core.pyx", line 136, in cupy._core.core.ndarray.__new__
  File "cupy/_core/core.pyx", line 224, in cupy._core.core._ndarray_base._init
  File "cupy/cuda/memory.pyx", line 742, in cupy.cuda.memory.alloc
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/rmm/rmm.py", line 230, in rmm_cupy_allocator
    buf = librmm.device_buffer.DeviceBuffer(size=nbytes, stream=stream)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --cufile-thread-count 4 --batch-size 32768 --epochs 5'
[WARN  tini (2658981)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-25 15:31:31.057306: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-25 15:31:34.180359: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-25 15:32:00.107647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
Failed to transform operator <nvtabular.ops.categorify.Categorify object at 0x7ff23c20fac0>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1780, in _encode
    ).sort_values("order")["labels"]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 2214, in sort_values
    out = self._gather(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-25 15:35:45.227708: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-25 15:35:45.594124: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fea5e8f6520 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-25 15:35:45.594196: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-25 15:35:45.755260: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-25 15:35:46.863529: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-25 15:35:47.173154: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.500781
Code block 'train epoch=0' took: 45975.79377 ms
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1780, in _encode
    ).sort_values("order")["labels"]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 2214, in sort_values
    out = self._gather(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home2/faculty/pwesolowski/praca-mgr/pipelines-repo/2_merlin/run_merlin.py", line 155, in <module>
    for batch, (examples, labels) in enumerate(train_tf_ds):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/tensorflow.py", line 97, in __next__
    converted_batch = self.convert_batch(super().__next__())
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 261, in __next__
    return self._get_next_batch()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 343, in _get_next_batch
    self._fetch_chunk()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 277, in _fetch_chunk
    raise chunks
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 791, in load_chunks
    self.chunk_logic(itr)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 759, in chunk_logic
    for chunks in self.batch(itr):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 745, in batch
    value = next(itr)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/io/dataframe_iter.py", line 44, in __iter__
    yield part.compute(scheduler="synchronous")
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/base.py", line 314, in compute
    (result,) = compute(self, traverse=False, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/base.py", line 599, in compute
    results = schedule(dsk, keys, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 557, in get_sync
    return get_async(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 500, in get_async
    for key, res_info, failed in queue_get(queue).result():
  File "/opt/conda/envs/rapids/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/opt/conda/envs/rapids/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 542, in submit
    fut.set_result(fn(*args, **kwargs))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 238, in batch_execute_tasks
    return [execute_task(*a) for a in it]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 238, in <listcomp>
    return [execute_task(*a) for a in it]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 229, in execute_task
    result = pack_exception(e, dumps)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 224, in execute_task
    result = _execute_task(task, data)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/optimization.py", line 990, in __call__
    return core.get(self.dsk, self.outkey, dict(zip(self.inkeys, args)))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 149, in get
    result = _execute_task(task, cache)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in <genexpr>
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/utils.py", line 72, in apply
    return func(*args, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 87, in transform
    transformed_data = self._execute_node(node, transformable, capture_dtypes, strict)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 101, in _execute_node
    upstream_outputs = self._run_upstream_transforms(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 114, in _run_upstream_transforms
    node_output = self._execute_node(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 107, in _execute_node
    transform_output = self._run_node_transform(node, transform_input, capture_dtypes, strict)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 227, in _run_node_transform
    raise exc
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
+ for CUFILE_THREAD_COUNT in 4 8 16 32 64
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --cufile-thread-count 8 --batch-size 32768 --epochs 5'
[WARN  tini (2672406)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-25 15:36:21.364088: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-25 15:36:24.316566: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-25 15:36:46.834420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-25 15:40:33.451456: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-25 15:40:33.787665: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fea0f449630 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-25 15:40:33.787743: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-25 15:40:33.933004: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-25 15:40:34.956953: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-25 15:40:35.266118: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.654562
Step #4000	Loss: 0.336884
Step #8000	Loss: 0.439642
Step #12000	Loss: 0.324503
Step #16000	Loss: 0.311913
Step #20000	Loss: 0.378449
Step #24000	Loss: 0.322682
Step #28000	Loss: 0.329000
Step #32000	Loss: 0.383357
Step #36000	Loss: 0.436635
Step #40000	Loss: 0.348857
Step #44000	Loss: 0.310058
Step #48000	Loss: 0.437915
Step #52000	Loss: 0.342461
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 613516.07538 ms
train loss 0.3668472468852997
Code block 'val epoch=0' took: 52299.06249 ms
validation loss 0.5580522418022156
Step #0	Loss: 0.474447
Step #4000	Loss: 0.312865
Step #8000	Loss: 0.338629
Step #12000	Loss: 0.301210
Step #16000	Loss: 0.292443
Step #20000	Loss: 0.325623
Step #24000	Loss: 0.304337
Step #28000	Loss: 0.312804
Step #32000	Loss: 0.329700
Step #36000	Loss: 0.342775
Step #40000	Loss: 0.299968
Step #44000	Loss: 0.280746
Step #48000	Loss: 0.356933
Step #52000	Loss: 0.315710
Code block 'train epoch=1' took: 588189.32357 ms
train loss 0.32403692603111267
Code block 'val epoch=1' took: 52274.46805 ms
validation loss 0.6317435503005981
Step #0	Loss: 0.331154
Step #4000	Loss: 0.301442
Step #8000	Loss: 0.307885
Step #12000	Loss: 0.295987
Step #16000	Loss: 0.294395
Step #20000	Loss: 0.305298
Step #24000	Loss: 0.304785
Step #28000	Loss: 0.305085
Step #32000	Loss: 0.325302
Step #36000	Loss: 0.314047
Step #40000	Loss: 0.288679
Step #44000	Loss: 0.280157
Step #48000	Loss: 0.327901
Step #52000	Loss: 0.311280
Code block 'train epoch=2' took: 588003.78630 ms
train loss 0.30961111187934875
Code block 'val epoch=2' took: 51639.32801 ms
validation loss 0.7021710276603699
Step #0	Loss: 0.296049
Step #4000	Loss: 0.295617
Step #8000	Loss: 0.291822
Step #12000	Loss: 0.286076
Step #16000	Loss: 0.295909
Step #20000	Loss: 0.296103
Step #24000	Loss: 0.295287
Step #28000	Loss: 0.300065
Step #32000	Loss: 0.306917
Step #36000	Loss: 0.312456
Step #40000	Loss: 0.283711
Step #44000	Loss: 0.277438
Step #48000	Loss: 0.314788
Step #52000	Loss: 0.304267
Code block 'train epoch=3' took: 587552.46234 ms
train loss 0.3041713535785675
Code block 'val epoch=3' took: 51854.04690 ms
validation loss 0.7729051113128662
Step #0	Loss: 0.299921
Step #4000	Loss: 0.292182
Step #8000	Loss: 0.296939
Step #12000	Loss: 0.291076
Step #16000	Loss: 0.287574
Step #20000	Loss: 0.293196
Step #24000	Loss: 0.297489
Step #28000	Loss: 0.300487
Step #32000	Loss: 0.311617
Step #36000	Loss: 0.302941
Step #40000	Loss: 0.283548
Step #44000	Loss: 0.274760
Step #48000	Loss: 0.313094
Step #52000	Loss: 0.302127
Code block 'train epoch=4' took: 591358.01663 ms
train loss 0.30161505937576294
Code block 'val epoch=4' took: 52080.74737 ms
validation loss 0.8054875731468201
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --cufile-thread-count 8 --batch-size 32768 --epochs 5'
[WARN  tini (2741671)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-25 16:34:19.799714: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-25 16:34:22.966215: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-25 16:34:45.466122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-25 16:38:32.080854: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-25 16:38:32.365255: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fdd9b118710 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-25 16:38:32.365323: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-25 16:38:32.505556: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-25 16:38:33.504169: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-25 16:38:33.810336: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.534719
Step #4000	Loss: 0.318534
Step #8000	Loss: 0.453044
Step #12000	Loss: 0.365561
Step #16000	Loss: 0.342662
Step #20000	Loss: 0.340671
Step #24000	Loss: 0.326389
Step #28000	Loss: 0.321189
Step #32000	Loss: 0.395275
Step #36000	Loss: 0.336811
Step #40000	Loss: 0.390370
Step #44000	Loss: 0.356437
Step #48000	Loss: 0.449535
Step #52000	Loss: 0.314613
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 609058.08180 ms
train loss 0.3627976179122925
Code block 'val epoch=0' took: 51322.64182 ms
validation loss 0.5831499099731445
Step #0	Loss: 0.456228
Step #4000	Loss: 0.307601
Step #8000	Loss: 0.354484
Step #12000	Loss: 0.319002
Step #16000	Loss: 0.306550
Step #20000	Loss: 0.316015
Step #24000	Loss: 0.308117
Step #28000	Loss: 0.308456
Step #32000	Loss: 0.340788
Step #36000	Loss: 0.310818
Step #40000	Loss: 0.315707
Step #44000	Loss: 0.304772
Step #48000	Loss: 0.366743
Step #52000	Loss: 0.303880
Code block 'train epoch=1' took: 584091.56035 ms
train loss 0.322776734828949
Code block 'val epoch=1' took: 50617.87812 ms
validation loss 0.6537056565284729
Step #0	Loss: 0.348271
Step #4000	Loss: 0.305655
Step #8000	Loss: 0.317511
Step #12000	Loss: 0.304029
Step #16000	Loss: 0.298020
Step #20000	Loss: 0.312452
Step #24000	Loss: 0.304115
Step #28000	Loss: 0.297041
Step #32000	Loss: 0.316087
Step #36000	Loss: 0.301204
Step #40000	Loss: 0.299482
Step #44000	Loss: 0.289068
Step #48000	Loss: 0.334680
Step #52000	Loss: 0.294918
Code block 'train epoch=2' took: 591838.01428 ms
train loss 0.30963703989982605
Code block 'val epoch=2' took: 51415.66852 ms
validation loss 0.7060757279396057
Step #0	Loss: 0.322633
Step #4000	Loss: 0.298111
Step #8000	Loss: 0.301713
Step #12000	Loss: 0.293297
Step #16000	Loss: 0.291949
Step #20000	Loss: 0.302843
Step #24000	Loss: 0.295441
Step #28000	Loss: 0.300802
Step #32000	Loss: 0.311446
Step #36000	Loss: 0.305333
Step #40000	Loss: 0.291394
Step #44000	Loss: 0.290736
Step #48000	Loss: 0.316352
Step #52000	Loss: 0.296941
Code block 'train epoch=3' took: 585914.65017 ms
train loss 0.3044168949127197
Code block 'val epoch=3' took: 51303.98183 ms
validation loss 0.7631194591522217
Step #0	Loss: 0.314404
Step #4000	Loss: 0.298587
Step #8000	Loss: 0.295228
Step #12000	Loss: 0.294747
Step #16000	Loss: 0.289780
Step #20000	Loss: 0.303182
Step #24000	Loss: 0.299622
Step #28000	Loss: 0.295958
Step #32000	Loss: 0.308253
Step #36000	Loss: 0.297318
Step #40000	Loss: 0.290933
Step #44000	Loss: 0.291529
Step #48000	Loss: 0.321197
Step #52000	Loss: 0.291214
Code block 'train epoch=4' took: 585365.57962 ms
train loss 0.3017829656600952
Code block 'val epoch=4' took: 50993.01018 ms
validation loss 0.8004752397537231
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --cufile-thread-count 8 --batch-size 32768 --epochs 5'
[WARN  tini (2794022)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-25 17:32:01.636941: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-25 17:32:04.660349: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-25 17:32:30.231460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-25 17:36:19.857304: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-25 17:36:20.170665: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f11f3d75f40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-25 17:36:20.170732: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-25 17:36:20.311305: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-25 17:36:21.277374: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-25 17:36:21.558213: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.558154
Step #4000	Loss: 0.341644
Step #8000	Loss: 0.440073
Step #12000	Loss: 0.384263
Step #16000	Loss: 0.338196
Step #20000	Loss: 0.342434
Step #24000	Loss: 0.322916
Step #28000	Loss: 0.312256
Step #32000	Loss: 0.330219
Step #36000	Loss: 0.448008
Step #40000	Loss: 0.344451
Step #44000	Loss: 0.337778
Step #48000	Loss: 0.377425
Step #52000	Loss: 0.401103
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 605632.78373 ms
train loss 0.36156705021858215
Code block 'val epoch=0' took: 51589.41384 ms
validation loss 0.5783390402793884
Step #0	Loss: 0.484817
Step #4000	Loss: 0.317029
Step #8000	Loss: 0.360300
Step #12000	Loss: 0.330079
Step #16000	Loss: 0.305345
Step #20000	Loss: 0.322196
Step #24000	Loss: 0.314982
Step #28000	Loss: 0.304852
Step #32000	Loss: 0.323404
Step #36000	Loss: 0.348637
Step #40000	Loss: 0.324569
Step #44000	Loss: 0.302255
Step #48000	Loss: 0.331760
Step #52000	Loss: 0.338415
Code block 'train epoch=1' took: 582608.32381 ms
train loss 0.32283180952072144
Code block 'val epoch=1' took: 51131.76023 ms
validation loss 0.6185072660446167
Step #0	Loss: 0.346395
Step #4000	Loss: 0.306927
Step #8000	Loss: 0.316286
Step #12000	Loss: 0.303227
Step #16000	Loss: 0.293995
Step #20000	Loss: 0.308838
Step #24000	Loss: 0.306561
Step #28000	Loss: 0.302150
Step #32000	Loss: 0.306998
Step #36000	Loss: 0.313990
Step #40000	Loss: 0.316838
Step #44000	Loss: 0.290253
Step #48000	Loss: 0.318980
Step #52000	Loss: 0.316778
Code block 'train epoch=2' took: 581285.13469 ms
train loss 0.3095800280570984
Code block 'val epoch=2' took: 50820.97063 ms
validation loss 0.6830362677574158
Step #0	Loss: 0.329905
Step #4000	Loss: 0.304886
Step #8000	Loss: 0.297952
Step #12000	Loss: 0.298627
Step #16000	Loss: 0.294786
Step #20000	Loss: 0.303254
Step #24000	Loss: 0.305258
Step #28000	Loss: 0.293609
Step #32000	Loss: 0.311615
Step #36000	Loss: 0.305173
Step #40000	Loss: 0.309942
Step #44000	Loss: 0.290298
Step #48000	Loss: 0.315303
Step #52000	Loss: 0.313230
Code block 'train epoch=3' took: 581144.79425 ms
train loss 0.3044528365135193
Code block 'val epoch=3' took: 50909.34736 ms
validation loss 0.710935115814209
Step #0	Loss: 0.320264
Step #4000	Loss: 0.307585
Step #8000	Loss: 0.293796
Step #12000	Loss: 0.293645
Step #16000	Loss: 0.291628
Step #20000	Loss: 0.304922
Step #24000	Loss: 0.300180
Step #28000	Loss: 0.292746
Step #32000	Loss: 0.309815
Step #36000	Loss: 0.302339
Step #40000	Loss: 0.306455
Step #44000	Loss: 0.288546
Step #48000	Loss: 0.312303
Step #52000	Loss: 0.312654
Code block 'train epoch=4' took: 583516.39469 ms
train loss 0.30191171169281006
Code block 'val epoch=4' took: 50973.78662 ms
validation loss 0.7708961963653564
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --cufile-thread-count 8 --batch-size 32768 --epochs 5'
[WARN  tini (2845257)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-25 18:29:23.429501: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-25 18:29:26.233664: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-25 18:29:48.315727: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-25 18:33:28.180429: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-25 18:33:28.554462: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fa0c8769c90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-25 18:33:28.554524: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-25 18:33:28.691065: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-25 18:33:29.698254: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-25 18:33:30.008426: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.709340
Step #4000	Loss: 0.315441
Step #8000	Loss: 0.440426
Step #12000	Loss: 0.362873
Step #16000	Loss: 0.338138
Step #20000	Loss: 0.412367
Step #24000	Loss: 0.362983
Step #28000	Loss: 0.333365
Step #32000	Loss: 0.407434
Step #36000	Loss: 0.336885
Step #40000	Loss: 0.388856
Step #44000	Loss: 0.363505
Step #48000	Loss: 0.451167
Step #52000	Loss: 0.322540
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 603983.81165 ms
train loss 0.36289775371551514
Code block 'val epoch=0' took: 48340.32674 ms
validation loss 0.5795547962188721
Step #0	Loss: 0.473200
Step #4000	Loss: 0.304192
Step #8000	Loss: 0.359614
Step #12000	Loss: 0.324842
Step #16000	Loss: 0.304355
Step #20000	Loss: 0.338395
Step #24000	Loss: 0.326144
Step #28000	Loss: 0.305590
Step #32000	Loss: 0.339662
Step #36000	Loss: 0.314080
Step #40000	Loss: 0.322622
Step #44000	Loss: 0.310267
Step #48000	Loss: 0.365452
Step #52000	Loss: 0.302183
Code block 'train epoch=1' took: 568886.92582 ms
train loss 0.3228939473628998
Code block 'val epoch=1' took: 47813.33042 ms
validation loss 0.6198638677597046
Step #0	Loss: 0.370965
Step #4000	Loss: 0.301625
Step #8000	Loss: 0.316262
Step #12000	Loss: 0.302099
Step #16000	Loss: 0.293012
Step #20000	Loss: 0.312263
Step #24000	Loss: 0.309213
Step #28000	Loss: 0.300447
Step #32000	Loss: 0.316207
Step #36000	Loss: 0.304263
Step #40000	Loss: 0.301631
Step #44000	Loss: 0.289677
Step #48000	Loss: 0.334683
Step #52000	Loss: 0.295184
Code block 'train epoch=2' took: 566783.81664 ms
train loss 0.3095856308937073
Code block 'val epoch=2' took: 48416.33323 ms
validation loss 0.6866291165351868
Step #0	Loss: 0.351703
Step #4000	Loss: 0.304102
Step #8000	Loss: 0.298771
Step #12000	Loss: 0.295294
Step #16000	Loss: 0.293028
Step #20000	Loss: 0.307293
Step #24000	Loss: 0.307115
Step #28000	Loss: 0.298193
Step #32000	Loss: 0.312481
Step #36000	Loss: 0.299374
Step #40000	Loss: 0.292627
Step #44000	Loss: 0.286794
Step #48000	Loss: 0.326083
Step #52000	Loss: 0.297734
Code block 'train epoch=3' took: 568121.58226 ms
train loss 0.30436447262763977
Code block 'val epoch=3' took: 48366.53664 ms
validation loss 0.7426916360855103
Step #0	Loss: 0.349398
Step #4000	Loss: 0.301111
Step #8000	Loss: 0.297528
Step #12000	Loss: 0.296016
Step #16000	Loss: 0.291810
Step #20000	Loss: 0.297205
Step #24000	Loss: 0.304607
Step #28000	Loss: 0.296583
Step #32000	Loss: 0.306094
Step #36000	Loss: 0.303329
Step #40000	Loss: 0.284435
Step #44000	Loss: 0.284742
Step #48000	Loss: 0.314071
Step #52000	Loss: 0.292404
Code block 'train epoch=4' took: 568121.87085 ms
train loss 0.3017390966415405
Code block 'val epoch=4' took: 48070.12958 ms
validation loss 0.7911916971206665
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --cufile-thread-count 8 --batch-size 32768 --epochs 5'
[WARN  tini (2898900)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-25 19:25:22.261071: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-25 19:25:25.313184: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-25 19:25:47.702421: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-25 19:29:31.478550: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-25 19:29:31.795207: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f9f18cf7930 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-25 19:29:31.795282: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-25 19:29:31.929850: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-25 19:29:32.929996: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-25 19:29:33.217460: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.778440
Step #4000	Loss: 0.353359
Step #8000	Loss: 0.343008
Step #12000	Loss: 0.323567
Step #16000	Loss: 0.315850
Step #20000	Loss: 0.343567
Step #24000	Loss: 0.409698
Step #28000	Loss: 0.320813
Step #32000	Loss: 0.343837
Step #36000	Loss: 0.385475
Step #40000	Loss: 0.414791
Step #44000	Loss: 0.406490
Step #48000	Loss: 0.365722
Step #52000	Loss: 0.358385
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 591272.23280 ms
train loss 0.3614199459552765
Code block 'val epoch=0' took: 47499.29877 ms
validation loss 0.6079365611076355
Step #0	Loss: 0.473466
Step #4000	Loss: 0.317629
Step #8000	Loss: 0.308394
Step #12000	Loss: 0.301737
Step #16000	Loss: 0.300171
Step #20000	Loss: 0.318058
Step #24000	Loss: 0.341067
Step #28000	Loss: 0.304720
Step #32000	Loss: 0.316020
Step #36000	Loss: 0.335327
Step #40000	Loss: 0.329265
Step #44000	Loss: 0.325543
Step #48000	Loss: 0.321540
Step #52000	Loss: 0.324161
Code block 'train epoch=1' took: 568142.96093 ms
train loss 0.32257330417633057
Code block 'val epoch=1' took: 47166.73079 ms
validation loss 0.6268970370292664
Step #0	Loss: 0.347911
Step #4000	Loss: 0.305009
Step #8000	Loss: 0.305220
Step #12000	Loss: 0.290021
Step #16000	Loss: 0.289754
Step #20000	Loss: 0.304677
Step #24000	Loss: 0.325471
Step #28000	Loss: 0.302143
Step #32000	Loss: 0.312117
Step #36000	Loss: 0.311334
Step #40000	Loss: 0.304214
Step #44000	Loss: 0.306473
Step #48000	Loss: 0.321170
Step #52000	Loss: 0.309578
Code block 'train epoch=2' took: 566076.23328 ms
train loss 0.3100093901157379
Code block 'val epoch=2' took: 47250.66359 ms
validation loss 0.6662713885307312
Step #0	Loss: 0.324476
Step #4000	Loss: 0.303564
Step #8000	Loss: 0.296439
Step #12000	Loss: 0.295298
Step #16000	Loss: 0.290370
Step #20000	Loss: 0.299347
Step #24000	Loss: 0.321779
Step #28000	Loss: 0.295539
Step #32000	Loss: 0.310611
Step #36000	Loss: 0.308202
Step #40000	Loss: 0.295520
Step #44000	Loss: 0.299699
Step #48000	Loss: 0.316969
Step #52000	Loss: 0.305461
Code block 'train epoch=3' took: 567348.16801 ms
train loss 0.30460962653160095
Code block 'val epoch=3' took: 47646.58811 ms
validation loss 0.7385669946670532
Step #0	Loss: 0.319433
Step #4000	Loss: 0.303677
Step #8000	Loss: 0.292482
Step #12000	Loss: 0.290990
Step #16000	Loss: 0.287760
Step #20000	Loss: 0.299102
Step #24000	Loss: 0.308630
Step #28000	Loss: 0.291648
Step #32000	Loss: 0.309803
Step #36000	Loss: 0.301237
Step #40000	Loss: 0.294472
Step #44000	Loss: 0.293932
Step #48000	Loss: 0.313963
Step #52000	Loss: 0.307578
Code block 'train epoch=4' took: 567557.10482 ms
train loss 0.301846981048584
Code block 'val epoch=4' took: 47255.81739 ms
validation loss 0.7609308958053589
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --cufile-thread-count 8 --batch-size 32768 --epochs 5'
[WARN  tini (2948144)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-25 20:21:04.614167: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-25 20:21:07.743895: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-25 20:21:30.656483: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-25 20:25:17.764160: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-25 20:25:18.099336: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f4ff15c95e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-25 20:25:18.099395: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-25 20:25:18.259940: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-25 20:25:19.391871: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-25 20:25:19.807127: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 3.202695
Step #4000	Loss: 0.329522
Step #8000	Loss: 0.358371
Step #12000	Loss: 0.304299
Step #16000	Loss: 0.349450
Step #20000	Loss: 0.329329
Step #24000	Loss: 0.375300
Step #28000	Loss: 0.339412
Step #32000	Loss: 0.362379
Step #36000	Loss: 0.336587
Step #40000	Loss: 0.344505
Step #44000	Loss: 0.334621
Step #48000	Loss: 0.353479
Step #52000	Loss: 0.323055
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 599139.10474 ms
train loss 0.3603352904319763
Code block 'val epoch=0' took: 47732.53810 ms
validation loss 0.614997386932373
Step #0	Loss: 0.443384
Step #4000	Loss: 0.312141
Step #8000	Loss: 0.310189
Step #12000	Loss: 0.294817
Step #16000	Loss: 0.314887
Step #20000	Loss: 0.316943
Step #24000	Loss: 0.325618
Step #28000	Loss: 0.316542
Step #32000	Loss: 0.326085
Step #36000	Loss: 0.308118
Step #40000	Loss: 0.316119
Step #44000	Loss: 0.304415
Step #48000	Loss: 0.330796
Step #52000	Loss: 0.299728
Code block 'train epoch=1' took: 574958.77051 ms
train loss 0.3203134536743164
Code block 'val epoch=1' took: 47432.59839 ms
validation loss 0.6520447731018066
Step #0	Loss: 0.338918
Step #4000	Loss: 0.299533
Step #8000	Loss: 0.300728
Step #12000	Loss: 0.286163
Step #16000	Loss: 0.305946
Step #20000	Loss: 0.303201
Step #24000	Loss: 0.318390
Step #28000	Loss: 0.314048
Step #32000	Loss: 0.316969
Step #36000	Loss: 0.297324
Step #40000	Loss: 0.311166
Step #44000	Loss: 0.289833
Step #48000	Loss: 0.323576
Step #52000	Loss: 0.302924
Code block 'train epoch=2' took: 573727.43253 ms
train loss 0.3084898293018341
Code block 'val epoch=2' took: 47316.76778 ms
validation loss 0.686219334602356
Step #0	Loss: 0.323447
Step #4000	Loss: 0.296204
Step #8000	Loss: 0.292304
Step #12000	Loss: 0.282937
Step #16000	Loss: 0.296682
Step #20000	Loss: 0.300001
Step #24000	Loss: 0.309791
Step #28000	Loss: 0.306874
Step #32000	Loss: 0.315578
Step #36000	Loss: 0.295943
Step #40000	Loss: 0.306963
Step #44000	Loss: 0.288135
Step #48000	Loss: 0.314215
Step #52000	Loss: 0.296963
Code block 'train epoch=3' took: 571962.13055 ms
train loss 0.30369192361831665
Code block 'val epoch=3' took: 47313.45725 ms
validation loss 0.7619292140007019
Step #0	Loss: 0.315624
Step #4000	Loss: 0.292216
Step #8000	Loss: 0.292261
Step #12000	Loss: 0.285015
Step #16000	Loss: 0.291800
Step #20000	Loss: 0.299183
Step #24000	Loss: 0.304724
Step #28000	Loss: 0.302136
Step #32000	Loss: 0.310844
Step #36000	Loss: 0.300400
Step #40000	Loss: 0.305964
Step #44000	Loss: 0.287737
Step #48000	Loss: 0.315090
Step #52000	Loss: 0.294422
Code block 'train epoch=4' took: 573218.47940 ms
train loss 0.30117127299308777
Code block 'val epoch=4' took: 47052.11678 ms
validation loss 0.769457995891571
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --cufile-thread-count 8 --batch-size 32768 --epochs 5'
[WARN  tini (3014691)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-25 21:17:23.938505: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-25 21:17:27.679763: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-25 21:17:55.053160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-25 21:21:36.637279: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-25 21:21:36.994457: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fee7c2f7bf0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-25 21:21:36.994518: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-25 21:21:37.131309: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-25 21:21:38.125331: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-25 21:21:38.434233: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.531533
Failed to transform operator <nvtabular.ops.categorify.Categorify object at 0x7ff0efdcfa90>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1778, in _encode
    labels = codes.merge(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/dataframe.py", line 4004, in merge
    ).perform_merge()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/join/join.py", line 203, in perform_merge
    self.rhs._gather(gather_map=right_rows, **gather_kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
Code block 'train epoch=0' took: 56013.75726 ms
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 332, in _get_next_batch
    batch = next(self._batch_itr)
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home2/faculty/pwesolowski/praca-mgr/pipelines-repo/2_merlin/run_merlin.py", line 155, in <module>
    for batch, (examples, labels) in enumerate(train_tf_ds):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/tensorflow.py", line 97, in __next__
    converted_batch = self.convert_batch(super().__next__())
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 261, in __next__
    return self._get_next_batch()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 344, in _get_next_batch
    batch = next(self._batch_itr)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 369, in make_tensors
    tensors_by_name = self._convert_df_to_tensors(gdf)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 520, in _convert_df_to_tensors
    tensors_by_name[column_name] = self._to_tensor(gdf_i[[column_name]])
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 450, in _to_tensor
    tensor = df_or_series.to_cupy()
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/single_column_frame.py", line 131, in to_cupy
    return super().to_cupy(dtype, copy, na_value).flatten()
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 533, in to_cupy
    return self._to_array(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 498, in _to_array
    matrix[:, i] = get_column_values_na(col)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 477, in get_column_values_na
    return get_column_values(col)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 534, in <lambda>
    (lambda col: col.values.copy())
  File "cupy/_core/core.pyx", line 590, in cupy._core.core._ndarray_base.copy
  File "cupy/_core/core.pyx", line 616, in cupy._core.core._ndarray_base.copy
  File "cupy/_core/core.pyx", line 575, in cupy._core.core._ndarray_base.astype
  File "cupy/_core/core.pyx", line 136, in cupy._core.core.ndarray.__new__
  File "cupy/_core/core.pyx", line 224, in cupy._core.core._ndarray_base._init
  File "cupy/cuda/memory.pyx", line 742, in cupy.cuda.memory.alloc
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/rmm/rmm.py", line 230, in rmm_cupy_allocator
    buf = librmm.device_buffer.DeviceBuffer(size=nbytes, stream=stream)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --cufile-thread-count 8 --batch-size 32768 --epochs 5'
[WARN  tini (3021471)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-25 21:22:28.884849: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-25 21:22:31.802414: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-25 21:22:54.365660: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
Failed to transform operator <nvtabular.ops.categorify.Categorify object at 0x7f3513b1bb50>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1780, in _encode
    ).sort_values("order")["labels"]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 2214, in sort_values
    out = self._gather(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-25 21:26:38.535403: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-25 21:26:38.906162: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f3287123d90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-25 21:26:38.906223: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-25 21:26:39.081588: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-25 21:26:40.107436: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-25 21:26:40.425102: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.649008
Code block 'train epoch=0' took: 37087.53362 ms
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 332, in _get_next_batch
    batch = next(self._batch_itr)
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home2/faculty/pwesolowski/praca-mgr/pipelines-repo/2_merlin/run_merlin.py", line 155, in <module>
    for batch, (examples, labels) in enumerate(train_tf_ds):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/tensorflow.py", line 97, in __next__
    converted_batch = self.convert_batch(super().__next__())
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 261, in __next__
    return self._get_next_batch()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 344, in _get_next_batch
    batch = next(self._batch_itr)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 369, in make_tensors
    tensors_by_name = self._convert_df_to_tensors(gdf)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 520, in _convert_df_to_tensors
    tensors_by_name[column_name] = self._to_tensor(gdf_i[[column_name]])
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 450, in _to_tensor
    tensor = df_or_series.to_cupy()
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/single_column_frame.py", line 131, in to_cupy
    return super().to_cupy(dtype, copy, na_value).flatten()
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 533, in to_cupy
    return self._to_array(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 498, in _to_array
    matrix[:, i] = get_column_values_na(col)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 477, in get_column_values_na
    return get_column_values(col)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 534, in <lambda>
    (lambda col: col.values.copy())
  File "cupy/_core/core.pyx", line 590, in cupy._core.core._ndarray_base.copy
  File "cupy/_core/core.pyx", line 616, in cupy._core.core._ndarray_base.copy
  File "cupy/_core/core.pyx", line 575, in cupy._core.core._ndarray_base.astype
  File "cupy/_core/core.pyx", line 136, in cupy._core.core.ndarray.__new__
  File "cupy/_core/core.pyx", line 224, in cupy._core.core._ndarray_base._init
  File "cupy/cuda/memory.pyx", line 742, in cupy.cuda.memory.alloc
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/rmm/rmm.py", line 230, in rmm_cupy_allocator
    buf = librmm.device_buffer.DeviceBuffer(size=nbytes, stream=stream)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --cufile-thread-count 8 --batch-size 32768 --epochs 5'
[WARN  tini (3028659)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-25 21:27:09.177826: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-25 21:27:12.955521: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-25 21:27:36.320224: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
terminate called after throwing an instance of 'rmm::out_of_memory'
  what():  std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp
[dgx-2:3028685] *** Process received signal ***
[dgx-2:3028685] Signal: Aborted (6)
[dgx-2:3028685] Signal code:  (-6)
[dgx-2:3028685] [ 0] /lib/x86_64-linux-gnu/libc.so.6(+0x42520)[0x7f4232112520]
[dgx-2:3028685] [ 1] /lib/x86_64-linux-gnu/libc.so.6(pthread_kill+0x12c)[0x7f4232166a7c]
[dgx-2:3028685] [ 2] /lib/x86_64-linux-gnu/libc.so.6(raise+0x16)[0x7f4232112476]
[dgx-2:3028685] [ 3] /lib/x86_64-linux-gnu/libc.so.6(abort+0xd3)[0x7f42320f87f3]
[dgx-2:3028685] [ 4] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(_ZN9__gnu_cxx27__verbose_terminate_handlerEv+0xc0)[0x7f422f280026]
[dgx-2:3028685] [ 5] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(+0xb0514)[0x7f422f27e514]
[dgx-2:3028685] [ 6] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(+0xb0566)[0x7f422f27e566]
[dgx-2:3028685] [ 7] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(__cxa_rethrow+0x0)[0x7f422f27e758]
[dgx-2:3028685] [ 8] /opt/conda/envs/rapids/lib/python3.10/site-packages/rmm/_lib/device_buffer.cpython-310-x86_64-linux-gnu.so(+0x4b67d)[0x7f410c08167d]
[dgx-2:3028685] [ 9] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf6columnC2ERKS0_N3rmm16cuda_stream_viewEPNS3_2mr22device_memory_resourceE+0x6d)[0x7f3ff3ad6add]
[dgx-2:3028685] [10] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf6columnC2ERKS0_N3rmm16cuda_stream_viewEPNS3_2mr22device_memory_resourceE+0x20c)[0x7f3ff3ad6c7c]
[dgx-2:3028685] [11] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf5tableC1ERKS0_+0x263)[0x7f3ff5210ec3]
[dgx-2:3028685] [12] /home2/faculty/pwesolowski/praca-mgr/parser-repo/build/libmeta-cudf-parser-1.so(_Z25generate_example_metadataPKcmmi11end_of_linebb+0x87d)[0x7f3f9229127d]
[dgx-2:3028685] [13] /home2/faculty/pwesolowski/praca-mgr/parser-repo/python_binding/metajsonparser/_lib/json_cudf.cpython-310-x86_64-linux-gnu.so(+0x4b344)[0x7f3f92368344]
[dgx-2:3028685] [14] python(+0x13fb27)[0x55a73e705b27]
[dgx-2:3028685] [15] python(PyObject_Call+0x209)[0x55a73e712139]
[dgx-2:3028685] [16] python(_PyEval_EvalFrameDefault+0x5d8c)[0x55a73e6fbb7c]
[dgx-2:3028685] [17] python(_PyFunction_Vectorcall+0x6f)[0x55a73e705f8f]
[dgx-2:3028685] [18] python(_PyEval_EvalFrameDefault+0x2ec2)[0x55a73e6f8cb2]
[dgx-2:3028685] [19] python(_PyFunction_Vectorcall+0x6f)[0x55a73e705f8f]
[dgx-2:3028685] [20] python(_PyEval_EvalFrameDefault+0x332)[0x55a73e6f6122]
[dgx-2:3028685] [21] python(_PyFunction_Vectorcall+0x6f)[0x55a73e705f8f]
[dgx-2:3028685] [22] python(_PyEval_EvalFrameDefault+0x2ec2)[0x55a73e6f8cb2]
[dgx-2:3028685] [23] python(_PyFunction_Vectorcall+0x6f)[0x55a73e705f8f]
[dgx-2:3028685] [24] python(_PyEval_EvalFrameDefault+0x332)[0x55a73e6f6122]
[dgx-2:3028685] [25] python(_PyFunction_Vectorcall+0x6f)[0x55a73e705f8f]
[dgx-2:3028685] [26] python(_PyEval_EvalFrameDefault+0x2ec2)[0x55a73e6f8cb2]
[dgx-2:3028685] [27] python(+0x14b641)[0x55a73e711641]
[dgx-2:3028685] [28] python(_PyEval_EvalFrameDefault+0x332)[0x55a73e6f6122]
[dgx-2:3028685] [29] python(_PyFunction_Vectorcall+0x6f)[0x55a73e705f8f]
[dgx-2:3028685] *** End of error message ***
+ for CUFILE_THREAD_COUNT in 4 8 16 32 64
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --cufile-thread-count 16 --batch-size 32768 --epochs 5'
[WARN  tini (3034671)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-25 21:31:21.770335: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-25 21:31:25.167214: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-25 21:31:51.783354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-25 21:35:39.414348: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-25 21:35:39.785280: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fc435363110 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-25 21:35:39.785334: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-25 21:35:39.927483: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-25 21:35:41.010572: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-25 21:35:41.340027: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 2.220649
Step #4000	Loss: 0.338303
Step #8000	Loss: 0.440517
Step #12000	Loss: 0.324872
Step #16000	Loss: 0.309893
Step #20000	Loss: 0.381600
Step #24000	Loss: 0.319373
Step #28000	Loss: 0.333425
Step #32000	Loss: 0.384467
Step #36000	Loss: 0.438680
Step #40000	Loss: 0.351666
Step #44000	Loss: 0.311117
Step #48000	Loss: 0.435502
Step #52000	Loss: 0.349141
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 613759.00989 ms
train loss 0.3662869334220886
Code block 'val epoch=0' took: 51937.41557 ms
validation loss 0.5778011083602905
Step #0	Loss: 0.468902
Step #4000	Loss: 0.314296
Step #8000	Loss: 0.345218
Step #12000	Loss: 0.306697
Step #16000	Loss: 0.297016
Step #20000	Loss: 0.324578
Step #24000	Loss: 0.302204
Step #28000	Loss: 0.313576
Step #32000	Loss: 0.331638
Step #36000	Loss: 0.341005
Step #40000	Loss: 0.305184
Step #44000	Loss: 0.286086
Step #48000	Loss: 0.353734
Step #52000	Loss: 0.321559
Code block 'train epoch=1' took: 588027.14988 ms
train loss 0.3249209225177765
Code block 'val epoch=1' took: 51565.95764 ms
validation loss 0.6254138350486755
Step #0	Loss: 0.332327
Step #4000	Loss: 0.298910
Step #8000	Loss: 0.314458
Step #12000	Loss: 0.294551
Step #16000	Loss: 0.288210
Step #20000	Loss: 0.303546
Step #24000	Loss: 0.287280
Step #28000	Loss: 0.304356
Step #32000	Loss: 0.309737
Step #36000	Loss: 0.314745
Step #40000	Loss: 0.289167
Step #44000	Loss: 0.271177
Step #48000	Loss: 0.329885
Step #52000	Loss: 0.303748
Code block 'train epoch=2' took: 587673.26933 ms
train loss 0.3106078803539276
Code block 'val epoch=2' took: 51377.79533 ms
validation loss 0.6996495127677917
Step #0	Loss: 0.304336
Step #4000	Loss: 0.300726
Step #8000	Loss: 0.302037
Step #12000	Loss: 0.287943
Step #16000	Loss: 0.283989
Step #20000	Loss: 0.295717
Step #24000	Loss: 0.289847
Step #28000	Loss: 0.299321
Step #32000	Loss: 0.307717
Step #36000	Loss: 0.309365
Step #40000	Loss: 0.288282
Step #44000	Loss: 0.278656
Step #48000	Loss: 0.321407
Step #52000	Loss: 0.309603
Code block 'train epoch=3' took: 587818.56291 ms
train loss 0.30494463443756104
Code block 'val epoch=3' took: 51094.19065 ms
validation loss 0.7359980940818787
Step #0	Loss: 0.299700
Step #4000	Loss: 0.294582
Step #8000	Loss: 0.297670
Step #12000	Loss: 0.292111
Step #16000	Loss: 0.286733
Step #20000	Loss: 0.292157
Step #24000	Loss: 0.293358
Step #28000	Loss: 0.299060
Step #32000	Loss: 0.304059
Step #36000	Loss: 0.301639
Step #40000	Loss: 0.282968
Step #44000	Loss: 0.276869
Step #48000	Loss: 0.311051
Step #52000	Loss: 0.305007
Code block 'train epoch=4' took: 588025.39023 ms
train loss 0.3021109700202942
Code block 'val epoch=4' took: 51596.33171 ms
validation loss 0.8063528537750244
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --cufile-thread-count 16 --batch-size 32768 --epochs 5'
[WARN  tini (3103865)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-25 22:29:20.247449: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-25 22:29:23.297773: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-25 22:29:46.392664: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-25 22:33:34.177027: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-25 22:33:34.510027: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f1f1fd26370 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-25 22:33:34.510087: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-25 22:33:34.640782: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-25 22:33:35.619095: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-25 22:33:35.893445: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 1.268039
Step #4000	Loss: 2.713572
Step #8000	Loss: 2.828518
Step #12000	Loss: 2.878312
Step #16000	Loss: 2.681461
Step #20000	Loss: 3.112393
Step #24000	Loss: 2.671688
Step #28000	Loss: 3.017458
Step #32000	Loss: 2.978832
Step #36000	Loss: 3.058410
Step #40000	Loss: 2.685184
Step #44000	Loss: 2.748940
Step #48000	Loss: 3.127751
Step #52000	Loss: 2.693095
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 604704.93608 ms
train loss 3.0125601291656494
Code block 'val epoch=0' took: 50907.34338 ms
validation loss 3.013399362564087
Step #0	Loss: 3.085867
Step #4000	Loss: 2.709849
Step #8000	Loss: 2.821072
Step #12000	Loss: 2.887154
Step #16000	Loss: 2.647023
Step #20000	Loss: 3.158930
Step #24000	Loss: 2.651212
Step #28000	Loss: 3.060738
Step #32000	Loss: 2.935088
Step #36000	Loss: 3.031884
Step #40000	Loss: 2.689372
Step #44000	Loss: 2.773139
Step #48000	Loss: 3.176615
Step #52000	Loss: 2.699145
Code block 'train epoch=1' took: 581798.75850 ms
train loss 3.0126051902770996
Code block 'val epoch=1' took: 50738.27726 ms
validation loss 3.013399362564087
Step #0	Loss: 2.997447
Step #4000	Loss: 2.689372
Step #8000	Loss: 2.739632
Step #12000	Loss: 2.867609
Step #16000	Loss: 2.636320
Step #20000	Loss: 3.129612
Step #24000	Loss: 2.668896
Step #28000	Loss: 3.011408
Step #32000	Loss: 3.049103
Step #36000	Loss: 2.995586
Step #40000	Loss: 2.652608
Step #44000	Loss: 2.651677
Step #48000	Loss: 3.217102
Step #52000	Loss: 2.688442
Code block 'train epoch=2' took: 582112.93003 ms
train loss 3.0125832557678223
Code block 'val epoch=2' took: 50500.50646 ms
validation loss 3.013399362564087
Step #0	Loss: 3.077491
Step #4000	Loss: 2.700541
Step #8000	Loss: 2.707522
Step #12000	Loss: 2.889947
Step #16000	Loss: 2.690768
Step #20000	Loss: 3.125889
Step #24000	Loss: 2.723810
Step #28000	Loss: 3.033746
Step #32000	Loss: 2.991863
Step #36000	Loss: 3.016993
Step #40000	Loss: 2.640508
Step #44000	Loss: 2.768485
Step #48000	Loss: 3.204071
Step #52000	Loss: 2.715899
Code block 'train epoch=3' took: 582769.58404 ms
train loss 3.0125746726989746
Code block 'val epoch=3' took: 51272.80212 ms
validation loss 3.013399362564087
Step #0	Loss: 3.124028
Step #4000	Loss: 2.733117
Step #8000	Loss: 2.770347
Step #12000	Loss: 2.779654
Step #16000	Loss: 2.671223
Step #20000	Loss: 3.099363
Step #24000	Loss: 2.742424
Step #28000	Loss: 3.084937
Step #32000	Loss: 2.976971
Step #36000	Loss: 3.000239
Step #40000	Loss: 2.734048
Step #44000	Loss: 2.772674
Step #48000	Loss: 3.115186
Step #52000	Loss: 2.707522
Code block 'train epoch=4' took: 582474.70573 ms
train loss 3.0125908851623535
Code block 'val epoch=4' took: 50841.57867 ms
validation loss 3.013399362564087
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --cufile-thread-count 16 --batch-size 32768 --epochs 5'
[WARN  tini (3173550)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-25 23:26:41.299093: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-25 23:26:44.644256: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-25 23:27:10.581692: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-25 23:31:01.162403: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-25 23:31:01.480844: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f0767f642e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-25 23:31:01.480906: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-25 23:31:01.619861: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-25 23:31:02.646729: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-25 23:31:02.924495: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.608239
Step #4000	Loss: 0.342351
Step #8000	Loss: 0.447325
Step #12000	Loss: 0.385213
Step #16000	Loss: 0.328289
Step #20000	Loss: 0.333141
Step #24000	Loss: 0.325450
Step #28000	Loss: 0.312403
Step #32000	Loss: 0.335685
Step #36000	Loss: 0.446754
Step #40000	Loss: 0.341000
Step #44000	Loss: 0.342220
Step #48000	Loss: 0.376877
Step #52000	Loss: 0.399379
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 606199.30784 ms
train loss 0.361061155796051
Code block 'val epoch=0' took: 51319.94670 ms
validation loss 0.5791676044464111
Step #0	Loss: 0.446405
Step #4000	Loss: 0.308970
Step #8000	Loss: 0.342450
Step #12000	Loss: 0.325617
Step #16000	Loss: 0.305764
Step #20000	Loss: 0.318672
Step #24000	Loss: 0.310306
Step #28000	Loss: 0.304359
Step #32000	Loss: 0.323062
Step #36000	Loss: 0.350651
Step #40000	Loss: 0.326882
Step #44000	Loss: 0.304641
Step #48000	Loss: 0.327504
Step #52000	Loss: 0.338254
Code block 'train epoch=1' took: 582051.81006 ms
train loss 0.3226091265678406
Code block 'val epoch=1' took: 50719.22448 ms
validation loss 0.6302340626716614
Step #0	Loss: 0.336646
Step #4000	Loss: 0.308242
Step #8000	Loss: 0.309472
Step #12000	Loss: 0.308095
Step #16000	Loss: 0.296862
Step #20000	Loss: 0.306721
Step #24000	Loss: 0.300854
Step #28000	Loss: 0.292961
Step #32000	Loss: 0.307323
Step #36000	Loss: 0.315939
Step #40000	Loss: 0.313504
Step #44000	Loss: 0.292855
Step #48000	Loss: 0.316892
Step #52000	Loss: 0.317613
Code block 'train epoch=2' took: 580353.84096 ms
train loss 0.3097556233406067
Code block 'val epoch=2' took: 50809.90555 ms
validation loss 0.6910440325737
Step #0	Loss: 0.322684
Step #4000	Loss: 0.300975
Step #8000	Loss: 0.300148
Step #12000	Loss: 0.298743
Step #16000	Loss: 0.287079
Step #20000	Loss: 0.303919
Step #24000	Loss: 0.304044
Step #28000	Loss: 0.297338
Step #32000	Loss: 0.303760
Step #36000	Loss: 0.303772
Step #40000	Loss: 0.310832
Step #44000	Loss: 0.288243
Step #48000	Loss: 0.315010
Step #52000	Loss: 0.314707
Code block 'train epoch=3' took: 580919.76512 ms
train loss 0.3045057952404022
Code block 'val epoch=3' took: 50836.24510 ms
validation loss 0.7017238140106201
Step #0	Loss: 0.318050
Step #4000	Loss: 0.299968
Step #8000	Loss: 0.290615
Step #12000	Loss: 0.296362
Step #16000	Loss: 0.284956
Step #20000	Loss: 0.304153
Step #24000	Loss: 0.297528
Step #28000	Loss: 0.293785
Step #32000	Loss: 0.308527
Step #36000	Loss: 0.304856
Step #40000	Loss: 0.312127
Step #44000	Loss: 0.288787
Step #48000	Loss: 0.315452
Step #52000	Loss: 0.308722
Code block 'train epoch=4' took: 580572.74533 ms
train loss 0.30187252163887024
Code block 'val epoch=4' took: 50698.90717 ms
validation loss 0.7623802423477173
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --cufile-thread-count 16 --batch-size 32768 --epochs 5'
[WARN  tini (3242397)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-26 00:24:02.317304: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-26 00:24:05.861439: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-26 00:24:31.622035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-26 00:28:13.499550: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-26 00:28:13.915173: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f77cff54e50 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-26 00:28:13.915229: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-26 00:28:14.062920: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-26 00:28:15.059915: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-26 00:28:15.366484: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.967377
Step #4000	Loss: 0.318371
Step #8000	Loss: 0.452578
Step #12000	Loss: 0.367620
Step #16000	Loss: 0.333492
Step #20000	Loss: 0.420949
Step #24000	Loss: 0.365845
Step #28000	Loss: 0.341042
Step #32000	Loss: 0.397222
Step #36000	Loss: 0.344108
Step #40000	Loss: 0.387390
Step #44000	Loss: 0.350752
Step #48000	Loss: 0.452385
Step #52000	Loss: 0.314811
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 593270.00439 ms
train loss 0.36329948902130127
Code block 'val epoch=0' took: 48953.68666 ms
validation loss 0.5561051964759827
Step #0	Loss: 0.478988
Step #4000	Loss: 0.311607
Step #8000	Loss: 0.353902
Step #12000	Loss: 0.325522
Step #16000	Loss: 0.306233
Step #20000	Loss: 0.337965
Step #24000	Loss: 0.322202
Step #28000	Loss: 0.314083
Step #32000	Loss: 0.332732
Step #36000	Loss: 0.312323
Step #40000	Loss: 0.318849
Step #44000	Loss: 0.306429
Step #48000	Loss: 0.364961
Step #52000	Loss: 0.304902
Code block 'train epoch=1' took: 567727.82575 ms
train loss 0.32336026430130005
Code block 'val epoch=1' took: 48277.47668 ms
validation loss 0.6349415183067322
Step #0	Loss: 0.334639
Step #4000	Loss: 0.299665
Step #8000	Loss: 0.319209
Step #12000	Loss: 0.303377
Step #16000	Loss: 0.291257
Step #20000	Loss: 0.308943
Step #24000	Loss: 0.312568
Step #28000	Loss: 0.306448
Step #32000	Loss: 0.322124
Step #36000	Loss: 0.305573
Step #40000	Loss: 0.294138
Step #44000	Loss: 0.294881
Step #48000	Loss: 0.329425
Step #52000	Loss: 0.300391
Code block 'train epoch=2' took: 566818.30327 ms
train loss 0.30977776646614075
Code block 'val epoch=2' took: 48506.32075 ms
validation loss 0.7239953875541687
Step #0	Loss: 0.320318
Step #4000	Loss: 0.298791
Step #8000	Loss: 0.301867
Step #12000	Loss: 0.298619
Step #16000	Loss: 0.290809
Step #20000	Loss: 0.303371
Step #24000	Loss: 0.311800
Step #28000	Loss: 0.306314
Step #32000	Loss: 0.312452
Step #36000	Loss: 0.308123
Step #40000	Loss: 0.288263
Step #44000	Loss: 0.286214
Step #48000	Loss: 0.318128
Step #52000	Loss: 0.296435
Code block 'train epoch=3' took: 567056.89328 ms
train loss 0.30444344878196716
Code block 'val epoch=3' took: 48138.27093 ms
validation loss 0.779598593711853
Step #0	Loss: 0.308186
Step #4000	Loss: 0.301042
Step #8000	Loss: 0.298430
Step #12000	Loss: 0.299526
Step #16000	Loss: 0.291209
Step #20000	Loss: 0.297759
Step #24000	Loss: 0.304344
Step #28000	Loss: 0.299442
Step #32000	Loss: 0.305906
Step #36000	Loss: 0.297402
Step #40000	Loss: 0.286816
Step #44000	Loss: 0.282598
Step #48000	Loss: 0.312170
Step #52000	Loss: 0.299227
Code block 'train epoch=4' took: 567406.19438 ms
train loss 0.3018566370010376
Code block 'val epoch=4' took: 48653.03151 ms
validation loss 0.807409405708313
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --cufile-thread-count 16 --batch-size 32768 --epochs 5'
[WARN  tini (3309054)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-26 01:19:56.231442: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-26 01:19:59.710725: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-26 01:20:24.599560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-26 01:24:10.788523: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-26 01:24:11.245400: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f3b700a9fe0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-26 01:24:11.245462: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-26 01:24:11.402771: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-26 01:24:12.541307: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-26 01:24:12.871752: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.546973
Step #4000	Loss: 0.345533
Step #8000	Loss: 0.349158
Step #12000	Loss: 0.317543
Step #16000	Loss: 0.314711
Step #20000	Loss: 0.345612
Step #24000	Loss: 0.398763
Step #28000	Loss: 0.321045
Step #32000	Loss: 0.337678
Step #36000	Loss: 0.384332
Step #40000	Loss: 0.417847
Step #44000	Loss: 0.407594
Step #48000	Loss: 0.367130
Step #52000	Loss: 0.355409
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 594979.07904 ms
train loss 0.36105650663375854
Code block 'val epoch=0' took: 47891.47259 ms
validation loss 0.6204820871353149
Step #0	Loss: 0.453728
Step #4000	Loss: 0.321630
Step #8000	Loss: 0.321507
Step #12000	Loss: 0.302505
Step #16000	Loss: 0.293739
Step #20000	Loss: 0.324762
Step #24000	Loss: 0.349145
Step #28000	Loss: 0.306629
Step #32000	Loss: 0.321485
Step #36000	Loss: 0.326640
Step #40000	Loss: 0.323852
Step #44000	Loss: 0.329668
Step #48000	Loss: 0.329220
Step #52000	Loss: 0.317159
Code block 'train epoch=1' took: 567622.43975 ms
train loss 0.32210659980773926
Code block 'val epoch=1' took: 47576.97657 ms
validation loss 0.6900553703308105
Step #0	Loss: 0.337336
Step #4000	Loss: 0.307120
Step #8000	Loss: 0.300326
Step #12000	Loss: 0.296305
Step #16000	Loss: 0.288488
Step #20000	Loss: 0.305614
Step #24000	Loss: 0.321942
Step #28000	Loss: 0.295465
Step #32000	Loss: 0.319381
Step #36000	Loss: 0.313846
Step #40000	Loss: 0.302559
Step #44000	Loss: 0.305156
Step #48000	Loss: 0.322078
Step #52000	Loss: 0.305738
Code block 'train epoch=2' took: 567507.37802 ms
train loss 0.3093286454677582
Code block 'val epoch=2' took: 47468.54995 ms
validation loss 0.7338921427726746
Step #0	Loss: 0.313439
Step #4000	Loss: 0.297451
Step #8000	Loss: 0.298516
Step #12000	Loss: 0.294004
Step #16000	Loss: 0.287120
Step #20000	Loss: 0.300153
Step #24000	Loss: 0.314209
Step #28000	Loss: 0.295304
Step #32000	Loss: 0.307316
Step #36000	Loss: 0.310644
Step #40000	Loss: 0.291170
Step #44000	Loss: 0.297297
Step #48000	Loss: 0.312762
Step #52000	Loss: 0.307133
Code block 'train epoch=3' took: 567988.89075 ms
train loss 0.3043358027935028
Code block 'val epoch=3' took: 47942.79211 ms
validation loss 0.7975218892097473
Step #0	Loss: 0.307756
Step #4000	Loss: 0.296977
Step #8000	Loss: 0.295375
Step #12000	Loss: 0.290912
Step #16000	Loss: 0.286751
Step #20000	Loss: 0.300550
Step #24000	Loss: 0.313974
Step #28000	Loss: 0.293036
Step #32000	Loss: 0.305289
Step #36000	Loss: 0.304956
Step #40000	Loss: 0.289722
Step #44000	Loss: 0.292988
Step #48000	Loss: 0.314444
Step #52000	Loss: 0.303065
Code block 'train epoch=4' took: 568511.46671 ms
train loss 0.3018970489501953
Code block 'val epoch=4' took: 47459.34921 ms
validation loss 0.801131546497345
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --cufile-thread-count 16 --batch-size 32768 --epochs 5'
[WARN  tini (3381007)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-26 02:15:48.882591: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-26 02:15:51.813367: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-26 02:16:14.873069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-26 02:20:02.038118: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-26 02:20:02.467482: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f27a0730340 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-26 02:20:02.467544: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-26 02:20:02.618549: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-26 02:20:03.608237: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-26 02:20:03.884459: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.523652
Step #4000	Loss: 0.328885
Step #8000	Loss: 0.357509
Step #12000	Loss: 0.306793
Step #16000	Loss: 0.344588
Step #20000	Loss: 0.331826
Step #24000	Loss: 0.376620
Step #28000	Loss: 0.346121
Step #32000	Loss: 0.359700
Step #36000	Loss: 0.334718
Step #40000	Loss: 0.340260
Step #44000	Loss: 0.334471
Step #48000	Loss: 0.349272
Step #52000	Loss: 0.314905
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 598670.12107 ms
train loss 0.36030107736587524
Code block 'val epoch=0' took: 48929.08921 ms
validation loss 0.587914228439331
Step #0	Loss: 0.444270
Step #4000	Loss: 0.308942
Step #8000	Loss: 0.316117
Step #12000	Loss: 0.299071
Step #16000	Loss: 0.315256
Step #20000	Loss: 0.310994
Step #24000	Loss: 0.324843
Step #28000	Loss: 0.317765
Step #32000	Loss: 0.327988
Step #36000	Loss: 0.303809
Step #40000	Loss: 0.320496
Step #44000	Loss: 0.301658
Step #48000	Loss: 0.325552
Step #52000	Loss: 0.305367
Code block 'train epoch=1' took: 575071.05155 ms
train loss 0.32082197070121765
Code block 'val epoch=1' took: 47191.15130 ms
validation loss 0.6633200645446777
Step #0	Loss: 0.339437
Step #4000	Loss: 0.302321
Step #8000	Loss: 0.298664
Step #12000	Loss: 0.288368
Step #16000	Loss: 0.302886
Step #20000	Loss: 0.300377
Step #24000	Loss: 0.314055
Step #28000	Loss: 0.310241
Step #32000	Loss: 0.316902
Step #36000	Loss: 0.301510
Step #40000	Loss: 0.310995
Step #44000	Loss: 0.289217
Step #48000	Loss: 0.320674
Step #52000	Loss: 0.292342
Code block 'train epoch=2' took: 575309.48694 ms
train loss 0.3084428012371063
Code block 'val epoch=2' took: 47426.22840 ms
validation loss 0.7069610953330994
Step #0	Loss: 0.322508
Step #4000	Loss: 0.297184
Step #8000	Loss: 0.297048
Step #12000	Loss: 0.289866
Step #16000	Loss: 0.291784
Step #20000	Loss: 0.297629
Step #24000	Loss: 0.313574
Step #28000	Loss: 0.300533
Step #32000	Loss: 0.317099
Step #36000	Loss: 0.292145
Step #40000	Loss: 0.309880
Step #44000	Loss: 0.286285
Step #48000	Loss: 0.315409
Step #52000	Loss: 0.292681
Code block 'train epoch=3' took: 573347.93817 ms
train loss 0.3037079870700836
Code block 'val epoch=3' took: 47401.48437 ms
validation loss 0.7241233587265015
Step #0	Loss: 0.319202
Step #4000	Loss: 0.295551
Step #8000	Loss: 0.292755
Step #12000	Loss: 0.282975
Step #16000	Loss: 0.287832
Step #20000	Loss: 0.298115
Step #24000	Loss: 0.309900
Step #28000	Loss: 0.303841
Step #32000	Loss: 0.313108
Step #36000	Loss: 0.291193
Step #40000	Loss: 0.308120
Step #44000	Loss: 0.282095
Step #48000	Loss: 0.317517
Step #52000	Loss: 0.297672
Code block 'train epoch=4' took: 575404.47784 ms
train loss 0.3013686537742615
Code block 'val epoch=4' took: 47517.68601 ms
validation loss 0.7535011172294617
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --cufile-thread-count 16 --batch-size 32768 --epochs 5'
[WARN  tini (3449045)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-26 03:12:10.511278: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-26 03:12:13.935963: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-26 03:12:39.072482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-26 03:16:20.503946: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-26 03:16:20.965827: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f462ae81330 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-26 03:16:20.965883: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-26 03:16:21.138498: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-26 03:16:22.201011: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-26 03:16:22.537422: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.669295
Failed to transform operator <nvtabular.ops.categorify.Categorify object at 0x7f4d4a40bb50>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1778, in _encode
    labels = codes.merge(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/dataframe.py", line 4004, in merge
    ).perform_merge()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/join/join.py", line 203, in perform_merge
    self.rhs._gather(gather_map=right_rows, **gather_kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
Code block 'train epoch=0' took: 56272.84445 ms
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 332, in _get_next_batch
    batch = next(self._batch_itr)
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home2/faculty/pwesolowski/praca-mgr/pipelines-repo/2_merlin/run_merlin.py", line 155, in <module>
    for batch, (examples, labels) in enumerate(train_tf_ds):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/tensorflow.py", line 97, in __next__
    converted_batch = self.convert_batch(super().__next__())
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 261, in __next__
    return self._get_next_batch()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 344, in _get_next_batch
    batch = next(self._batch_itr)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 369, in make_tensors
    tensors_by_name = self._convert_df_to_tensors(gdf)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 520, in _convert_df_to_tensors
    tensors_by_name[column_name] = self._to_tensor(gdf_i[[column_name]])
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 450, in _to_tensor
    tensor = df_or_series.to_cupy()
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/single_column_frame.py", line 131, in to_cupy
    return super().to_cupy(dtype, copy, na_value).flatten()
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 533, in to_cupy
    return self._to_array(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 498, in _to_array
    matrix[:, i] = get_column_values_na(col)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 477, in get_column_values_na
    return get_column_values(col)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 534, in <lambda>
    (lambda col: col.values.copy())
  File "cupy/_core/core.pyx", line 590, in cupy._core.core._ndarray_base.copy
  File "cupy/_core/core.pyx", line 616, in cupy._core.core._ndarray_base.copy
  File "cupy/_core/core.pyx", line 575, in cupy._core.core._ndarray_base.astype
  File "cupy/_core/core.pyx", line 136, in cupy._core.core.ndarray.__new__
  File "cupy/_core/core.pyx", line 224, in cupy._core.core._ndarray_base._init
  File "cupy/cuda/memory.pyx", line 742, in cupy.cuda.memory.alloc
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/rmm/rmm.py", line 230, in rmm_cupy_allocator
    buf = librmm.device_buffer.DeviceBuffer(size=nbytes, stream=stream)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --cufile-thread-count 16 --batch-size 32768 --epochs 5'
[WARN  tini (3456021)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-26 03:17:12.174102: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-26 03:17:15.513935: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-26 03:17:40.060735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
Failed to transform operator <nvtabular.ops.categorify.Categorify object at 0x7f4ed424fb50>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1778, in _encode
    labels = codes.merge(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/dataframe.py", line 4004, in merge
    ).perform_merge()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/join/join.py", line 203, in perform_merge
    self.rhs._gather(gather_map=right_rows, **gather_kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-26 03:21:23.119933: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-26 03:21:23.471672: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f461b2167d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-26 03:21:23.471735: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-26 03:21:23.622181: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-26 03:21:24.733005: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-26 03:21:25.090501: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 5.466664
Code block 'train epoch=0' took: 36963.33989 ms
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 332, in _get_next_batch
    batch = next(self._batch_itr)
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home2/faculty/pwesolowski/praca-mgr/pipelines-repo/2_merlin/run_merlin.py", line 155, in <module>
    for batch, (examples, labels) in enumerate(train_tf_ds):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/tensorflow.py", line 97, in __next__
    converted_batch = self.convert_batch(super().__next__())
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 261, in __next__
    return self._get_next_batch()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 344, in _get_next_batch
    batch = next(self._batch_itr)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 369, in make_tensors
    tensors_by_name = self._convert_df_to_tensors(gdf)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 520, in _convert_df_to_tensors
    tensors_by_name[column_name] = self._to_tensor(gdf_i[[column_name]])
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 450, in _to_tensor
    tensor = df_or_series.to_cupy()
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/single_column_frame.py", line 131, in to_cupy
    return super().to_cupy(dtype, copy, na_value).flatten()
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 533, in to_cupy
    return self._to_array(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 498, in _to_array
    matrix[:, i] = get_column_values_na(col)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 477, in get_column_values_na
    return get_column_values(col)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 534, in <lambda>
    (lambda col: col.values.copy())
  File "cupy/_core/core.pyx", line 590, in cupy._core.core._ndarray_base.copy
  File "cupy/_core/core.pyx", line 616, in cupy._core.core._ndarray_base.copy
  File "cupy/_core/core.pyx", line 575, in cupy._core.core._ndarray_base.astype
  File "cupy/_core/core.pyx", line 136, in cupy._core.core.ndarray.__new__
  File "cupy/_core/core.pyx", line 224, in cupy._core.core._ndarray_base._init
  File "cupy/cuda/memory.pyx", line 742, in cupy.cuda.memory.alloc
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/rmm/rmm.py", line 230, in rmm_cupy_allocator
    buf = librmm.device_buffer.DeviceBuffer(size=nbytes, stream=stream)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --cufile-thread-count 16 --batch-size 32768 --epochs 5'
[WARN  tini (3462824)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-26 03:21:51.225009: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-26 03:21:54.054758: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-26 03:22:16.677294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
Failed to transform operator <nvtabular.ops.categorify.Categorify object at 0x7fa05c533b50>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1780, in _encode
    ).sort_values("order")["labels"]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 2214, in sort_values
    out = self._gather(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-26 03:26:01.242167: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-26 03:26:01.645629: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f9d43997760 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-26 03:26:01.645690: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-26 03:26:01.794981: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-26 03:26:02.825323: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-26 03:26:03.151174: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 5.347536
Code block 'train epoch=0' took: 45687.65239 ms
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1780, in _encode
    ).sort_values("order")["labels"]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 2214, in sort_values
    out = self._gather(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home2/faculty/pwesolowski/praca-mgr/pipelines-repo/2_merlin/run_merlin.py", line 155, in <module>
    for batch, (examples, labels) in enumerate(train_tf_ds):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/tensorflow.py", line 97, in __next__
    converted_batch = self.convert_batch(super().__next__())
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 261, in __next__
    return self._get_next_batch()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 343, in _get_next_batch
    self._fetch_chunk()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 277, in _fetch_chunk
    raise chunks
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 791, in load_chunks
    self.chunk_logic(itr)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 759, in chunk_logic
    for chunks in self.batch(itr):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 745, in batch
    value = next(itr)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/io/dataframe_iter.py", line 44, in __iter__
    yield part.compute(scheduler="synchronous")
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/base.py", line 314, in compute
    (result,) = compute(self, traverse=False, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/base.py", line 599, in compute
    results = schedule(dsk, keys, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 557, in get_sync
    return get_async(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 500, in get_async
    for key, res_info, failed in queue_get(queue).result():
  File "/opt/conda/envs/rapids/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/opt/conda/envs/rapids/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 542, in submit
    fut.set_result(fn(*args, **kwargs))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 238, in batch_execute_tasks
    return [execute_task(*a) for a in it]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 238, in <listcomp>
    return [execute_task(*a) for a in it]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 229, in execute_task
    result = pack_exception(e, dumps)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 224, in execute_task
    result = _execute_task(task, data)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/optimization.py", line 990, in __call__
    return core.get(self.dsk, self.outkey, dict(zip(self.inkeys, args)))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 149, in get
    result = _execute_task(task, cache)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in <genexpr>
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/utils.py", line 72, in apply
    return func(*args, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 87, in transform
    transformed_data = self._execute_node(node, transformable, capture_dtypes, strict)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 101, in _execute_node
    upstream_outputs = self._run_upstream_transforms(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 114, in _run_upstream_transforms
    node_output = self._execute_node(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 107, in _execute_node
    transform_output = self._run_node_transform(node, transform_input, capture_dtypes, strict)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 227, in _run_node_transform
    raise exc
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
+ for CUFILE_THREAD_COUNT in 4 8 16 32 64
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --cufile-thread-count 32 --batch-size 32768 --epochs 5'
[WARN  tini (3469718)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-26 03:26:37.973111: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-26 03:26:40.854990: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-26 03:27:03.245482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-26 03:30:49.795786: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-26 03:30:50.075027: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f4d92bf4830 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-26 03:30:50.075088: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-26 03:30:50.212268: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-26 03:30:51.184291: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-26 03:30:51.465130: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 1.850666
Step #4000	Loss: 0.336576
Step #8000	Loss: 0.439142
Step #12000	Loss: 0.331090
Step #16000	Loss: 0.308683
Step #20000	Loss: 0.379544
Step #24000	Loss: 0.321129
Step #28000	Loss: 0.334789
Step #32000	Loss: 0.382762
Step #36000	Loss: 0.429873
Step #40000	Loss: 0.343996
Step #44000	Loss: 0.305642
Step #48000	Loss: 0.431946
Step #52000	Loss: 0.342338
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 610034.49313 ms
train loss 0.3656235933303833
Code block 'val epoch=0' took: 52205.75895 ms
validation loss 0.5893827676773071
Step #0	Loss: 0.497391
Step #4000	Loss: 0.306087
Step #8000	Loss: 0.362208
Step #12000	Loss: 0.304149
Step #16000	Loss: 0.298519
Step #20000	Loss: 0.323823
Step #24000	Loss: 0.300375
Step #28000	Loss: 0.312800
Step #32000	Loss: 0.340483
Step #36000	Loss: 0.343197
Step #40000	Loss: 0.302337
Step #44000	Loss: 0.289119
Step #48000	Loss: 0.351281
Step #52000	Loss: 0.317223
Code block 'train epoch=1' took: 590636.12223 ms
train loss 0.3250706195831299
Code block 'val epoch=1' took: 51858.51208 ms
validation loss 0.6477123498916626
Step #0	Loss: 0.319213
Step #4000	Loss: 0.297158
Step #8000	Loss: 0.320617
Step #12000	Loss: 0.292328
Step #16000	Loss: 0.290208
Step #20000	Loss: 0.307600
Step #24000	Loss: 0.299797
Step #28000	Loss: 0.303354
Step #32000	Loss: 0.317347
Step #36000	Loss: 0.313459
Step #40000	Loss: 0.290106
Step #44000	Loss: 0.279735
Step #48000	Loss: 0.326799
Step #52000	Loss: 0.308283
Code block 'train epoch=2' took: 589570.79890 ms
train loss 0.31038302183151245
Code block 'val epoch=2' took: 51508.29361 ms
validation loss 0.7160090804100037
Step #0	Loss: 0.304588
Step #4000	Loss: 0.300156
Step #8000	Loss: 0.301521
Step #12000	Loss: 0.292385
Step #16000	Loss: 0.292780
Step #20000	Loss: 0.298889
Step #24000	Loss: 0.291761
Step #28000	Loss: 0.302256
Step #32000	Loss: 0.304975
Step #36000	Loss: 0.303393
Step #40000	Loss: 0.282573
Step #44000	Loss: 0.272822
Step #48000	Loss: 0.317983
Step #52000	Loss: 0.303509
Code block 'train epoch=3' took: 588387.56068 ms
train loss 0.30486705899238586
Code block 'val epoch=3' took: 51492.18659 ms
validation loss 0.7662526965141296
Step #0	Loss: 0.297505
Step #4000	Loss: 0.301021
Step #8000	Loss: 0.294671
Step #12000	Loss: 0.289179
Step #16000	Loss: 0.291241
Step #20000	Loss: 0.295815
Step #24000	Loss: 0.302577
Step #28000	Loss: 0.298928
Step #32000	Loss: 0.302874
Step #36000	Loss: 0.303203
Step #40000	Loss: 0.281844
Step #44000	Loss: 0.273909
Step #48000	Loss: 0.310046
Step #52000	Loss: 0.308540
Code block 'train epoch=4' took: 588834.93294 ms
train loss 0.30223655700683594
Code block 'val epoch=4' took: 51554.55165 ms
validation loss 0.758205771446228
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --cufile-thread-count 32 --batch-size 32768 --epochs 5'
[WARN  tini (3538645)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-26 04:24:32.378448: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-26 04:24:35.450839: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-26 04:24:57.299502: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-26 04:28:44.100566: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-26 04:28:44.398704: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f6806b7cbe0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-26 04:28:44.398764: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-26 04:28:44.533118: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-26 04:28:45.523432: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-26 04:28:45.802704: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 1.114336
Step #4000	Loss: 0.324173
Step #8000	Loss: 0.452883
Step #12000	Loss: 0.366417
Step #16000	Loss: 0.343833
Step #20000	Loss: 0.358881
Step #24000	Loss: 0.323691
Step #28000	Loss: 0.320975
Step #32000	Loss: 0.394950
Step #36000	Loss: 0.341533
Step #40000	Loss: 0.387284
Step #44000	Loss: 0.358596
Step #48000	Loss: 0.444680
Step #52000	Loss: 0.314376
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 606755.99637 ms
train loss 0.36288630962371826
Code block 'val epoch=0' took: 50734.96662 ms
validation loss 0.6001325249671936
Step #0	Loss: 0.487572
Step #4000	Loss: 0.313693
Step #8000	Loss: 0.355549
Step #12000	Loss: 0.322214
Step #16000	Loss: 0.308248
Step #20000	Loss: 0.318694
Step #24000	Loss: 0.307486
Step #28000	Loss: 0.306633
Step #32000	Loss: 0.334855
Step #36000	Loss: 0.307800
Step #40000	Loss: 0.320838
Step #44000	Loss: 0.301373
Step #48000	Loss: 0.370987
Step #52000	Loss: 0.299290
Code block 'train epoch=1' took: 581894.24677 ms
train loss 0.32364070415496826
Code block 'val epoch=1' took: 50402.92475 ms
validation loss 0.6441409587860107
Step #0	Loss: 0.350744
Step #4000	Loss: 0.300064
Step #8000	Loss: 0.313803
Step #12000	Loss: 0.305597
Step #16000	Loss: 0.295622
Step #20000	Loss: 0.307541
Step #24000	Loss: 0.302475
Step #28000	Loss: 0.297381
Step #32000	Loss: 0.321611
Step #36000	Loss: 0.302065
Step #40000	Loss: 0.301616
Step #44000	Loss: 0.296949
Step #48000	Loss: 0.333898
Step #52000	Loss: 0.299655
Code block 'train epoch=2' took: 581524.09316 ms
train loss 0.3101062476634979
Code block 'val epoch=2' took: 50600.58556 ms
validation loss 0.7073241472244263
Step #0	Loss: 0.321009
Step #4000	Loss: 0.293208
Step #8000	Loss: 0.301972
Step #12000	Loss: 0.297788
Step #16000	Loss: 0.292206
Step #20000	Loss: 0.301466
Step #24000	Loss: 0.302061
Step #28000	Loss: 0.297412
Step #32000	Loss: 0.309744
Step #36000	Loss: 0.299026
Step #40000	Loss: 0.291103
Step #44000	Loss: 0.289938
Step #48000	Loss: 0.318779
Step #52000	Loss: 0.295929
Code block 'train epoch=3' took: 581794.77397 ms
train loss 0.3047342896461487
Code block 'val epoch=3' took: 50635.10811 ms
validation loss 0.7611730098724365
Step #0	Loss: 0.317161
Step #4000	Loss: 0.292614
Step #8000	Loss: 0.293023
Step #12000	Loss: 0.298492
Step #16000	Loss: 0.292730
Step #20000	Loss: 0.302608
Step #24000	Loss: 0.299770
Step #28000	Loss: 0.296309
Step #32000	Loss: 0.309689
Step #36000	Loss: 0.301560
Step #40000	Loss: 0.291786
Step #44000	Loss: 0.289323
Step #48000	Loss: 0.316897
Step #52000	Loss: 0.292451
Code block 'train epoch=4' took: 582371.47499 ms
train loss 0.3020738661289215
Code block 'val epoch=4' took: 50744.49928 ms
validation loss 0.8282204866409302
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --cufile-thread-count 32 --batch-size 32768 --epochs 5'
[WARN  tini (3607425)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-26 05:21:47.663335: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-26 05:21:50.673458: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-26 05:22:13.139180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-26 05:26:04.319939: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-26 05:26:04.776853: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f5e5aa03850 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-26 05:26:04.776913: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-26 05:26:04.922360: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-26 05:26:05.967629: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-26 05:26:06.257132: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.521557
Step #4000	Loss: 12.638685
Step #8000	Loss: 12.722005
Step #12000	Loss: 12.579838
Step #16000	Loss: 12.712590
Step #20000	Loss: 12.216438
Step #24000	Loss: 12.573254
Step #28000	Loss: 12.468752
Step #32000	Loss: 12.399553
Step #36000	Loss: 12.259275
Step #40000	Loss: 12.159950
Step #44000	Loss: 12.552071
Step #48000	Loss: 12.184900
Step #52000	Loss: 12.292227
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 607116.97556 ms
train loss 12.376763343811035
Code block 'val epoch=0' took: 50987.69725 ms
validation loss 12.37680721282959
Step #0	Loss: 12.127000
Step #4000	Loss: 12.631624
Step #8000	Loss: 12.684346
Step #12000	Loss: 12.530417
Step #16000	Loss: 12.641510
Step #20000	Loss: 12.192902
Step #24000	Loss: 12.564310
Step #28000	Loss: 12.462161
Step #32000	Loss: 12.449451
Step #36000	Loss: 12.265865
Step #40000	Loss: 12.175486
Step #44000	Loss: 12.655161
Step #48000	Loss: 12.215027
Step #52000	Loss: 12.279987
Code block 'train epoch=1' took: 580872.70758 ms
train loss 12.377535820007324
Code block 'val epoch=1' took: 50676.30422 ms
validation loss 12.37680721282959
Step #0	Loss: 12.114290
Step #4000	Loss: 12.667871
Step #8000	Loss: 12.644335
Step #12000	Loss: 12.576078
Step #16000	Loss: 12.688583
Step #20000	Loss: 12.223029
Step #24000	Loss: 12.484756
Step #28000	Loss: 12.455571
Step #32000	Loss: 12.393434
Step #36000	Loss: 12.262100
Step #40000	Loss: 12.228207
Step #44000	Loss: 12.632565
Step #48000	Loss: 12.176897
Step #52000	Loss: 12.285166
Code block 'train epoch=2' took: 580086.12320 ms
train loss 12.377642631530762
Code block 'val epoch=2' took: 50654.44844 ms
validation loss 12.37680721282959
Step #0	Loss: 12.101110
Step #4000	Loss: 12.647159
Step #8000	Loss: 12.667871
Step #12000	Loss: 12.503586
Step #16000	Loss: 12.693762
Step #20000	Loss: 12.176427
Step #24000	Loss: 12.518648
Step #28000	Loss: 12.431092
Step #32000	Loss: 12.374605
Step #36000	Loss: 12.261158
Step #40000	Loss: 12.184429
Step #44000	Loss: 12.623622
Step #48000	Loss: 12.139709
Step #52000	Loss: 12.320942
Code block 'train epoch=3' took: 581044.85231 ms
train loss 12.377701759338379
Code block 'val epoch=3' took: 50463.66591 ms
validation loss 12.37680721282959
Step #0	Loss: 12.118998
Step #4000	Loss: 12.669283
Step #8000	Loss: 12.644334
Step #12000	Loss: 12.578902
Step #16000	Loss: 12.643864
Step #20000	Loss: 12.222088
Step #24000	Loss: 12.523827
Step #28000	Loss: 12.509706
Step #32000	Loss: 12.465927
Step #36000	Loss: 12.292227
Step #40000	Loss: 12.178308
Step #44000	Loss: 12.657515
Step #48000	Loss: 12.180193
Step #52000	Loss: 12.265395
Code block 'train epoch=4' took: 579931.45125 ms
train loss 12.377631187438965
Code block 'val epoch=4' took: 50491.87270 ms
validation loss 12.37680721282959
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --cufile-thread-count 32 --batch-size 32768 --epochs 5'
[WARN  tini (3676154)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-26 06:19:01.418650: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-26 06:19:04.525037: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-26 06:19:29.293729: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-26 06:23:10.685820: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-26 06:23:11.010652: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f5ecc87bc00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-26 06:23:11.010713: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-26 06:23:11.142063: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-26 06:23:12.118553: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-26 06:23:12.408070: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 1.323986
Step #4000	Loss: 0.312934
Step #8000	Loss: 0.443008
Step #12000	Loss: 0.365654
Step #16000	Loss: 0.340769
Step #20000	Loss: 0.410222
Step #24000	Loss: 0.358276
Step #28000	Loss: 0.339463
Step #32000	Loss: 0.392527
Step #36000	Loss: 0.339213
Step #40000	Loss: 0.391249
Step #44000	Loss: 0.354495
Step #48000	Loss: 0.446220
Step #52000	Loss: 0.309809
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 594800.23990 ms
train loss 0.3614957630634308
Code block 'val epoch=0' took: 48192.99044 ms
validation loss 0.5808914303779602
Step #0	Loss: 0.496004
Step #4000	Loss: 0.313256
Step #8000	Loss: 0.362396
Step #12000	Loss: 0.318178
Step #16000	Loss: 0.303809
Step #20000	Loss: 0.338374
Step #24000	Loss: 0.324584
Step #28000	Loss: 0.309406
Step #32000	Loss: 0.338483
Step #36000	Loss: 0.310795
Step #40000	Loss: 0.323772
Step #44000	Loss: 0.307056
Step #48000	Loss: 0.360006
Step #52000	Loss: 0.300848
Code block 'train epoch=1' took: 569434.70348 ms
train loss 0.3231208920478821
Code block 'val epoch=1' took: 47819.17050 ms
validation loss 0.6494814157485962
Step #0	Loss: 0.340101
Step #4000	Loss: 0.302763
Step #8000	Loss: 0.316470
Step #12000	Loss: 0.303315
Step #16000	Loss: 0.294944
Step #20000	Loss: 0.315218
Step #24000	Loss: 0.311946
Step #28000	Loss: 0.300892
Step #32000	Loss: 0.313328
Step #36000	Loss: 0.303448
Step #40000	Loss: 0.303457
Step #44000	Loss: 0.292300
Step #48000	Loss: 0.331050
Step #52000	Loss: 0.299309
Code block 'train epoch=2' took: 568038.12897 ms
train loss 0.309611439704895
Code block 'val epoch=2' took: 48078.20944 ms
validation loss 0.6995311975479126
Step #0	Loss: 0.317664
Step #4000	Loss: 0.298623
Step #8000	Loss: 0.303692
Step #12000	Loss: 0.294740
Step #16000	Loss: 0.287680
Step #20000	Loss: 0.303948
Step #24000	Loss: 0.308520
Step #28000	Loss: 0.298197
Step #32000	Loss: 0.309360
Step #36000	Loss: 0.303075
Step #40000	Loss: 0.290654
Step #44000	Loss: 0.289216
Step #48000	Loss: 0.318599
Step #52000	Loss: 0.290508
Code block 'train epoch=3' took: 567858.17179 ms
train loss 0.3043503761291504
Code block 'val epoch=3' took: 47882.82778 ms
validation loss 0.7581634521484375
Step #0	Loss: 0.309627
Step #4000	Loss: 0.298850
Step #8000	Loss: 0.295407
Step #12000	Loss: 0.292759
Step #16000	Loss: 0.288064
Step #20000	Loss: 0.300806
Step #24000	Loss: 0.307258
Step #28000	Loss: 0.293894
Step #32000	Loss: 0.306325
Step #36000	Loss: 0.296683
Step #40000	Loss: 0.291913
Step #44000	Loss: 0.285714
Step #48000	Loss: 0.312649
Step #52000	Loss: 0.294581
Code block 'train epoch=4' took: 568075.46865 ms
train loss 0.30173566937446594
Code block 'val epoch=4' took: 48186.16121 ms
validation loss 0.8077914118766785
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --cufile-thread-count 32 --batch-size 32768 --epochs 5'
[WARN  tini (3743026)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-26 07:14:57.220398: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-26 07:15:00.453725: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-26 07:15:24.485871: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-26 07:19:10.697071: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-26 07:19:11.114494: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f28b4661d80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-26 07:19:11.114551: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-26 07:19:11.268687: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-26 07:19:12.342157: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-26 07:19:12.679683: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.581408
Step #4000	Loss: 0.353108
Step #8000	Loss: 0.344765
Step #12000	Loss: 0.318842
Step #16000	Loss: 0.313298
Step #20000	Loss: 0.343195
Step #24000	Loss: 0.404822
Step #28000	Loss: 0.314817
Step #32000	Loss: 0.338309
Step #36000	Loss: 0.380427
Step #40000	Loss: 0.412052
Step #44000	Loss: 0.405428
Step #48000	Loss: 0.357933
Step #52000	Loss: 0.362212
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 592289.89576 ms
train loss 0.3597441613674164
Code block 'val epoch=0' took: 47783.20159 ms
validation loss 0.6921569108963013
Step #0	Loss: 0.477364
Step #4000	Loss: 0.318631
Step #8000	Loss: 0.308701
Step #12000	Loss: 0.296844
Step #16000	Loss: 0.298153
Step #20000	Loss: 0.314713
Step #24000	Loss: 0.335449
Step #28000	Loss: 0.300397
Step #32000	Loss: 0.326564
Step #36000	Loss: 0.333479
Step #40000	Loss: 0.325625
Step #44000	Loss: 0.330727
Step #48000	Loss: 0.325931
Step #52000	Loss: 0.321097
Code block 'train epoch=1' took: 568082.59168 ms
train loss 0.32088950276374817
Code block 'val epoch=1' took: 47567.22748 ms
validation loss 0.7915812134742737
Step #0	Loss: 0.358350
Step #4000	Loss: 0.301187
Step #8000	Loss: 0.294121
Step #12000	Loss: 0.300177
Step #16000	Loss: 0.287647
Step #20000	Loss: 0.306791
Step #24000	Loss: 0.318989
Step #28000	Loss: 0.300344
Step #32000	Loss: 0.312242
Step #36000	Loss: 0.308389
Step #40000	Loss: 0.311501
Step #44000	Loss: 0.310532
Step #48000	Loss: 0.316720
Step #52000	Loss: 0.306750
Code block 'train epoch=2' took: 566548.37323 ms
train loss 0.3086506426334381
Code block 'val epoch=2' took: 47082.97799 ms
validation loss 0.8239634037017822
Step #0	Loss: 0.330843
Step #4000	Loss: 0.299779
Step #8000	Loss: 0.293630
Step #12000	Loss: 0.293296
Step #16000	Loss: 0.284488
Step #20000	Loss: 0.302274
Step #24000	Loss: 0.311933
Step #28000	Loss: 0.295069
Step #32000	Loss: 0.315761
Step #36000	Loss: 0.305850
Step #40000	Loss: 0.298364
Step #44000	Loss: 0.299864
Step #48000	Loss: 0.316618
Step #52000	Loss: 0.304148
Code block 'train epoch=3' took: 565850.19955 ms
train loss 0.30375319719314575
Code block 'val epoch=3' took: 47831.10164 ms
validation loss 0.882688045501709
Step #0	Loss: 0.327436
Step #4000	Loss: 0.301205
Step #8000	Loss: 0.286978
Step #12000	Loss: 0.288848
Step #16000	Loss: 0.285715
Step #20000	Loss: 0.299413
Step #24000	Loss: 0.312162
Step #28000	Loss: 0.296578
Step #32000	Loss: 0.302948
Step #36000	Loss: 0.301377
Step #40000	Loss: 0.288722
Step #44000	Loss: 0.298705
Step #48000	Loss: 0.312625
Step #52000	Loss: 0.307523
Code block 'train epoch=4' took: 566947.52101 ms
train loss 0.3012997806072235
Code block 'val epoch=4' took: 47362.42232 ms
validation loss 0.8903981447219849
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --cufile-thread-count 32 --batch-size 32768 --epochs 5'
[WARN  tini (3810033)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-26 08:10:40.758355: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-26 08:10:43.654367: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-26 08:11:06.095097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-26 08:14:52.093172: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-26 08:14:52.502581: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f32571c5c60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-26 08:14:52.502638: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-26 08:14:52.642176: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-26 08:14:53.632006: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-26 08:14:53.934895: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.537883
Step #4000	Loss: 2.746613
Step #8000	Loss: 2.763366
Step #12000	Loss: 2.673550
Step #16000	Loss: 2.942999
Step #20000	Loss: 3.045846
Step #24000	Loss: 2.988605
Step #28000	Loss: 3.095640
Step #32000	Loss: 3.133801
Step #36000	Loss: 3.011408
Step #40000	Loss: 3.017923
Step #44000	Loss: 0.331273
Step #48000	Loss: 0.344920
Step #52000	Loss: 0.313955
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 596255.59736 ms
train loss 2.2878801822662354
Code block 'val epoch=0' took: 48311.69335 ms
validation loss 0.5189324021339417
Step #0	Loss: 0.503501
Step #4000	Loss: 0.330595
Step #8000	Loss: 0.356386
Step #12000	Loss: 0.304275
Step #16000	Loss: 0.350439
Step #20000	Loss: 0.329271
Step #24000	Loss: 0.379662
Step #28000	Loss: 0.343639
Step #32000	Loss: 0.369208
Step #36000	Loss: 0.342665
Step #40000	Loss: 0.339993
Step #44000	Loss: 0.304435
Step #48000	Loss: 0.331644
Step #52000	Loss: 0.304897
Code block 'train epoch=1' took: 573148.27715 ms
train loss 0.348631352186203
Code block 'val epoch=1' took: 47231.82979 ms
validation loss 0.6069523096084595
Step #0	Loss: 0.358340
Step #4000	Loss: 0.309581
Step #8000	Loss: 0.310974
Step #12000	Loss: 0.291772
Step #16000	Loss: 0.309085
Step #20000	Loss: 0.305380
Step #24000	Loss: 0.333047
Step #28000	Loss: 0.315341
Step #32000	Loss: 0.329819
Step #36000	Loss: 0.306314
Step #40000	Loss: 0.316702
Step #44000	Loss: 0.291881
Step #48000	Loss: 0.320149
Step #52000	Loss: 0.298650
Code block 'train epoch=2' took: 572681.74981 ms
train loss 0.3169765770435333
Code block 'val epoch=2' took: 47954.03736 ms
validation loss 0.7065842747688293
Step #0	Loss: 0.323244
Step #4000	Loss: 0.304650
Step #8000	Loss: 0.298145
Step #12000	Loss: 0.284774
Step #16000	Loss: 0.300354
Step #20000	Loss: 0.309197
Step #24000	Loss: 0.315038
Step #28000	Loss: 0.315646
Step #32000	Loss: 0.316033
Step #36000	Loss: 0.305707
Step #40000	Loss: 0.313555
Step #44000	Loss: 0.289319
Step #48000	Loss: 0.309406
Step #52000	Loss: 0.298598
Code block 'train epoch=3' took: 572056.23223 ms
train loss 0.30735811591148376
Code block 'val epoch=3' took: 47349.85439 ms
validation loss 0.7755804061889648
Step #0	Loss: 0.315813
Step #4000	Loss: 0.296742
Step #8000	Loss: 0.299920
Step #12000	Loss: 0.287058
Step #16000	Loss: 0.296878
Step #20000	Loss: 0.303064
Step #24000	Loss: 0.313880
Step #28000	Loss: 0.307992
Step #32000	Loss: 0.316061
Step #36000	Loss: 0.298290
Step #40000	Loss: 0.306097
Step #44000	Loss: 0.287449
Step #48000	Loss: 0.318989
Step #52000	Loss: 0.296378
Code block 'train epoch=4' took: 571881.75315 ms
train loss 0.30325573682785034
Code block 'val epoch=4' took: 47555.37700 ms
validation loss 0.8377618193626404
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --cufile-thread-count 32 --batch-size 32768 --epochs 5'
[WARN  tini (3877216)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-26 09:06:48.945163: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-26 09:06:51.850809: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-26 09:07:14.388624: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-26 09:10:55.483214: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-26 09:10:55.765133: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fa114e973d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-26 09:10:55.765195: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-26 09:10:55.896364: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-26 09:10:56.876020: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-26 09:10:57.186394: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 3.680135
Failed to transform operator <nvtabular.ops.categorify.Categorify object at 0x7fa8711b3b80>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1778, in _encode
    labels = codes.merge(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/dataframe.py", line 4004, in merge
    ).perform_merge()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/join/join.py", line 203, in perform_merge
    self.rhs._gather(gather_map=right_rows, **gather_kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
Code block 'train epoch=0' took: 55028.14068 ms
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 332, in _get_next_batch
    batch = next(self._batch_itr)
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home2/faculty/pwesolowski/praca-mgr/pipelines-repo/2_merlin/run_merlin.py", line 155, in <module>
    for batch, (examples, labels) in enumerate(train_tf_ds):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/tensorflow.py", line 97, in __next__
    converted_batch = self.convert_batch(super().__next__())
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 261, in __next__
    return self._get_next_batch()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 344, in _get_next_batch
    batch = next(self._batch_itr)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 369, in make_tensors
    tensors_by_name = self._convert_df_to_tensors(gdf)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 520, in _convert_df_to_tensors
    tensors_by_name[column_name] = self._to_tensor(gdf_i[[column_name]])
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 450, in _to_tensor
    tensor = df_or_series.to_cupy()
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/single_column_frame.py", line 131, in to_cupy
    return super().to_cupy(dtype, copy, na_value).flatten()
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 533, in to_cupy
    return self._to_array(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 498, in _to_array
    matrix[:, i] = get_column_values_na(col)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 477, in get_column_values_na
    return get_column_values(col)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 534, in <lambda>
    (lambda col: col.values.copy())
  File "cupy/_core/core.pyx", line 590, in cupy._core.core._ndarray_base.copy
  File "cupy/_core/core.pyx", line 616, in cupy._core.core._ndarray_base.copy
  File "cupy/_core/core.pyx", line 575, in cupy._core.core._ndarray_base.astype
  File "cupy/_core/core.pyx", line 136, in cupy._core.core.ndarray.__new__
  File "cupy/_core/core.pyx", line 224, in cupy._core.core._ndarray_base._init
  File "cupy/cuda/memory.pyx", line 742, in cupy.cuda.memory.alloc
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/rmm/rmm.py", line 230, in rmm_cupy_allocator
    buf = librmm.device_buffer.DeviceBuffer(size=nbytes, stream=stream)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --cufile-thread-count 32 --batch-size 32768 --epochs 5'
[WARN  tini (3884755)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-26 09:11:49.504841: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-26 09:11:53.111665: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-26 09:12:21.697740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
Failed to transform operator <nvtabular.ops.categorify.Categorify object at 0x7fd340283b80>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1780, in _encode
    ).sort_values("order")["labels"]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 2214, in sort_values
    out = self._gather(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-26 09:16:07.978758: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-26 09:16:08.378329: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fd0850668f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-26 09:16:08.378390: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-26 09:16:08.567722: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-26 09:16:09.756750: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-26 09:16:10.114142: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 1.027499
Code block 'train epoch=0' took: 38356.17020 ms
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 332, in _get_next_batch
    batch = next(self._batch_itr)
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home2/faculty/pwesolowski/praca-mgr/pipelines-repo/2_merlin/run_merlin.py", line 155, in <module>
    for batch, (examples, labels) in enumerate(train_tf_ds):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/tensorflow.py", line 97, in __next__
    converted_batch = self.convert_batch(super().__next__())
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 261, in __next__
    return self._get_next_batch()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 344, in _get_next_batch
    batch = next(self._batch_itr)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 369, in make_tensors
    tensors_by_name = self._convert_df_to_tensors(gdf)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 520, in _convert_df_to_tensors
    tensors_by_name[column_name] = self._to_tensor(gdf_i[[column_name]])
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 450, in _to_tensor
    tensor = df_or_series.to_cupy()
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/single_column_frame.py", line 131, in to_cupy
    return super().to_cupy(dtype, copy, na_value).flatten()
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 533, in to_cupy
    return self._to_array(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 498, in _to_array
    matrix[:, i] = get_column_values_na(col)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 477, in get_column_values_na
    return get_column_values(col)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 534, in <lambda>
    (lambda col: col.values.copy())
  File "cupy/_core/core.pyx", line 590, in cupy._core.core._ndarray_base.copy
  File "cupy/_core/core.pyx", line 616, in cupy._core.core._ndarray_base.copy
  File "cupy/_core/core.pyx", line 575, in cupy._core.core._ndarray_base.astype
  File "cupy/_core/core.pyx", line 136, in cupy._core.core.ndarray.__new__
  File "cupy/_core/core.pyx", line 224, in cupy._core.core._ndarray_base._init
  File "cupy/cuda/memory.pyx", line 742, in cupy.cuda.memory.alloc
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/rmm/rmm.py", line 230, in rmm_cupy_allocator
    buf = librmm.device_buffer.DeviceBuffer(size=nbytes, stream=stream)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --cufile-thread-count 32 --batch-size 32768 --epochs 5'
[WARN  tini (3891202)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-26 09:16:39.233897: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-26 09:16:42.565197: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-26 09:17:08.120974: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
terminate called after throwing an instance of 'rmm::out_of_memory'
  what():  std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp
[dgx-2:3891227] *** Process received signal ***
[dgx-2:3891227] Signal: Aborted (6)
[dgx-2:3891227] Signal code:  (-6)
[dgx-2:3891227] [ 0] /lib/x86_64-linux-gnu/libc.so.6(+0x42520)[0x7f1f9b93f520]
[dgx-2:3891227] [ 1] /lib/x86_64-linux-gnu/libc.so.6(pthread_kill+0x12c)[0x7f1f9b993a7c]
[dgx-2:3891227] [ 2] /lib/x86_64-linux-gnu/libc.so.6(raise+0x16)[0x7f1f9b93f476]
[dgx-2:3891227] [ 3] /lib/x86_64-linux-gnu/libc.so.6(abort+0xd3)[0x7f1f9b9257f3]
[dgx-2:3891227] [ 4] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(_ZN9__gnu_cxx27__verbose_terminate_handlerEv+0xc0)[0x7f1f98aad026]
[dgx-2:3891227] [ 5] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(+0xb0514)[0x7f1f98aab514]
[dgx-2:3891227] [ 6] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(+0xb0566)[0x7f1f98aab566]
[dgx-2:3891227] [ 7] /opt/conda/envs/rapids/lib/python3.10/site-packages/cupy/_core/../../../../libstdc++.so.6(__cxa_rethrow+0x0)[0x7f1f98aab758]
[dgx-2:3891227] [ 8] /opt/conda/envs/rapids/lib/python3.10/site-packages/rmm/_lib/device_buffer.cpython-310-x86_64-linux-gnu.so(+0x4b67d)[0x7f1e8008167d]
[dgx-2:3891227] [ 9] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf6columnC2ERKS0_N3rmm16cuda_stream_viewEPNS3_2mr22device_memory_resourceE+0x6d)[0x7f1d63ad6add]
[dgx-2:3891227] [10] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf6columnC2ERKS0_N3rmm16cuda_stream_viewEPNS3_2mr22device_memory_resourceE+0x20c)[0x7f1d63ad6c7c]
[dgx-2:3891227] [11] /opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/_lib/../../../../libcudf.so(_ZN4cudf5tableC1ERKS0_+0x263)[0x7f1d65210ec3]
[dgx-2:3891227] [12] /home2/faculty/pwesolowski/praca-mgr/parser-repo/build/libmeta-cudf-parser-1.so(_Z25generate_example_metadataPKcmmi11end_of_linebb+0x87d)[0x7f1cdc16027d]
[dgx-2:3891227] [13] /home2/faculty/pwesolowski/praca-mgr/parser-repo/python_binding/metajsonparser/_lib/json_cudf.cpython-310-x86_64-linux-gnu.so(+0x4b344)[0x7f1cdc237344]
[dgx-2:3891227] [14] python(+0x13fb27)[0x5589bbd4db27]
[dgx-2:3891227] [15] python(PyObject_Call+0x209)[0x5589bbd5a139]
[dgx-2:3891227] [16] python(_PyEval_EvalFrameDefault+0x5d8c)[0x5589bbd43b7c]
[dgx-2:3891227] [17] python(_PyFunction_Vectorcall+0x6f)[0x5589bbd4df8f]
[dgx-2:3891227] [18] python(_PyEval_EvalFrameDefault+0x2ec2)[0x5589bbd40cb2]
[dgx-2:3891227] [19] python(_PyFunction_Vectorcall+0x6f)[0x5589bbd4df8f]
[dgx-2:3891227] [20] python(_PyEval_EvalFrameDefault+0x332)[0x5589bbd3e122]
[dgx-2:3891227] [21] python(_PyFunction_Vectorcall+0x6f)[0x5589bbd4df8f]
[dgx-2:3891227] [22] python(_PyEval_EvalFrameDefault+0x2ec2)[0x5589bbd40cb2]
[dgx-2:3891227] [23] python(_PyFunction_Vectorcall+0x6f)[0x5589bbd4df8f]
[dgx-2:3891227] [24] python(_PyEval_EvalFrameDefault+0x332)[0x5589bbd3e122]
[dgx-2:3891227] [25] python(_PyFunction_Vectorcall+0x6f)[0x5589bbd4df8f]
[dgx-2:3891227] [26] python(_PyEval_EvalFrameDefault+0x2ec2)[0x5589bbd40cb2]
[dgx-2:3891227] [27] python(+0x14b641)[0x5589bbd59641]
[dgx-2:3891227] [28] python(_PyEval_EvalFrameDefault+0x332)[0x5589bbd3e122]
[dgx-2:3891227] [29] python(_PyFunction_Vectorcall+0x6f)[0x5589bbd4df8f]
[dgx-2:3891227] *** End of error message ***
+ for CUFILE_THREAD_COUNT in 4 8 16 32 64
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --cufile-thread-count 64 --batch-size 32768 --epochs 5'
[WARN  tini (3897714)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-26 09:20:53.896791: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-26 09:20:57.248311: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-26 09:21:22.604728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-26 09:25:10.310220: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-26 09:25:10.626620: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f2ce09175d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-26 09:25:10.626679: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-26 09:25:10.776946: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-26 09:25:11.759453: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-26 09:25:12.072473: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.797595
Step #4000	Loss: 0.339685
Step #8000	Loss: 0.432934
Step #12000	Loss: 0.327628
Step #16000	Loss: 0.306985
Step #20000	Loss: 0.381462
Step #24000	Loss: 0.319010
Step #28000	Loss: 0.329463
Step #32000	Loss: 0.385659
Step #36000	Loss: 0.434925
Step #40000	Loss: 0.345287
Step #44000	Loss: 0.307396
Step #48000	Loss: 0.433742
Step #52000	Loss: 0.347410
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 614864.56965 ms
train loss 0.36547616124153137
Code block 'val epoch=0' took: 51930.29881 ms
validation loss 0.5690341591835022
Step #0	Loss: 0.447531
Step #4000	Loss: 0.308492
Step #8000	Loss: 0.357719
Step #12000	Loss: 0.299240
Step #16000	Loss: 0.302142
Step #20000	Loss: 0.326688
Step #24000	Loss: 0.302364
Step #28000	Loss: 0.308700
Step #32000	Loss: 0.332439
Step #36000	Loss: 0.340325
Step #40000	Loss: 0.297089
Step #44000	Loss: 0.287316
Step #48000	Loss: 0.355346
Step #52000	Loss: 0.318210
Code block 'train epoch=1' took: 589861.30355 ms
train loss 0.3240131437778473
Code block 'val epoch=1' took: 51839.04973 ms
validation loss 0.6266406774520874
Step #0	Loss: 0.331475
Step #4000	Loss: 0.298064
Step #8000	Loss: 0.306053
Step #12000	Loss: 0.291328
Step #16000	Loss: 0.293513
Step #20000	Loss: 0.307311
Step #24000	Loss: 0.295327
Step #28000	Loss: 0.304091
Step #32000	Loss: 0.315639
Step #36000	Loss: 0.316464
Step #40000	Loss: 0.288658
Step #44000	Loss: 0.275485
Step #48000	Loss: 0.328187
Step #52000	Loss: 0.309355
Code block 'train epoch=2' took: 589883.21624 ms
train loss 0.3102110028266907
Code block 'val epoch=2' took: 52311.75884 ms
validation loss 0.6898675560951233
Step #0	Loss: 0.311569
Step #4000	Loss: 0.298332
Step #8000	Loss: 0.302799
Step #12000	Loss: 0.293286
Step #16000	Loss: 0.289697
Step #20000	Loss: 0.295361
Step #24000	Loss: 0.291961
Step #28000	Loss: 0.302379
Step #32000	Loss: 0.309595
Step #36000	Loss: 0.303766
Step #40000	Loss: 0.283395
Step #44000	Loss: 0.277772
Step #48000	Loss: 0.312426
Step #52000	Loss: 0.305047
Code block 'train epoch=3' took: 589213.66625 ms
train loss 0.30478668212890625
Code block 'val epoch=3' took: 51650.37974 ms
validation loss 0.7233518362045288
Step #0	Loss: 0.305866
Step #4000	Loss: 0.291085
Step #8000	Loss: 0.298184
Step #12000	Loss: 0.291938
Step #16000	Loss: 0.287427
Step #20000	Loss: 0.295949
Step #24000	Loss: 0.295779
Step #28000	Loss: 0.297645
Step #32000	Loss: 0.308987
Step #36000	Loss: 0.293703
Step #40000	Loss: 0.287707
Step #44000	Loss: 0.273996
Step #48000	Loss: 0.307252
Step #52000	Loss: 0.300897
Code block 'train epoch=4' took: 589670.23996 ms
train loss 0.30209892988204956
Code block 'val epoch=4' took: 51597.18335 ms
validation loss 0.779951274394989
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --cufile-thread-count 64 --batch-size 32768 --epochs 5'
[WARN  tini (3969723)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-26 10:19:01.258306: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-26 10:19:04.624218: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-26 10:19:30.881756: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-26 10:23:20.131319: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-26 10:23:20.505029: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f9fdaef8870 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-26 10:23:20.505094: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-26 10:23:20.654271: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-26 10:23:21.632483: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-26 10:23:21.938553: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.521319
Step #4000	Loss: 0.321561
Step #8000	Loss: 0.444785
Step #12000	Loss: 0.364912
Step #16000	Loss: 0.347687
Step #20000	Loss: 0.344761
Step #24000	Loss: 0.318596
Step #28000	Loss: 0.319729
Step #32000	Loss: 0.392272
Step #36000	Loss: 0.340466
Step #40000	Loss: 0.387244
Step #44000	Loss: 0.356480
Step #48000	Loss: 0.446536
Step #52000	Loss: 0.315529
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 610998.07643 ms
train loss 0.36123067140579224
Code block 'val epoch=0' took: 50898.13485 ms
validation loss 0.5911967754364014
Step #0	Loss: 0.467616
Step #4000	Loss: 0.313571
Step #8000	Loss: 0.357867
Step #12000	Loss: 0.322037
Step #16000	Loss: 0.307096
Step #20000	Loss: 0.319272
Step #24000	Loss: 0.306243
Step #28000	Loss: 0.301620
Step #32000	Loss: 0.343327
Step #36000	Loss: 0.319290
Step #40000	Loss: 0.315751
Step #44000	Loss: 0.305163
Step #48000	Loss: 0.362963
Step #52000	Loss: 0.300979
Code block 'train epoch=1' took: 585617.26695 ms
train loss 0.3223491907119751
Code block 'val epoch=1' took: 50994.79348 ms
validation loss 0.6432466506958008
Step #0	Loss: 0.334751
Step #4000	Loss: 0.302825
Step #8000	Loss: 0.313957
Step #12000	Loss: 0.304073
Step #16000	Loss: 0.299577
Step #20000	Loss: 0.307693
Step #24000	Loss: 0.303171
Step #28000	Loss: 0.296579
Step #32000	Loss: 0.318389
Step #36000	Loss: 0.308610
Step #40000	Loss: 0.296995
Step #44000	Loss: 0.297101
Step #48000	Loss: 0.332173
Step #52000	Loss: 0.295041
Code block 'train epoch=2' took: 582750.50913 ms
train loss 0.3093533515930176
Code block 'val epoch=2' took: 51021.18410 ms
validation loss 0.6968754529953003
Step #0	Loss: 0.313314
Step #4000	Loss: 0.297746
Step #8000	Loss: 0.302702
Step #12000	Loss: 0.295113
Step #16000	Loss: 0.287940
Step #20000	Loss: 0.303374
Step #24000	Loss: 0.301048
Step #28000	Loss: 0.300669
Step #32000	Loss: 0.311622
Step #36000	Loss: 0.301344
Step #40000	Loss: 0.292016
Step #44000	Loss: 0.288613
Step #48000	Loss: 0.320054
Step #52000	Loss: 0.291509
Code block 'train epoch=3' took: 582696.50929 ms
train loss 0.3042888939380646
Code block 'val epoch=3' took: 51203.25392 ms
validation loss 0.7439833283424377
Step #0	Loss: 0.307660
Step #4000	Loss: 0.296736
Step #8000	Loss: 0.295164
Step #12000	Loss: 0.297085
Step #16000	Loss: 0.289199
Step #20000	Loss: 0.301194
Step #24000	Loss: 0.298277
Step #28000	Loss: 0.294156
Step #32000	Loss: 0.303447
Step #36000	Loss: 0.298476
Step #40000	Loss: 0.286146
Step #44000	Loss: 0.285158
Step #48000	Loss: 0.315577
Step #52000	Loss: 0.290341
Code block 'train epoch=4' took: 583867.28978 ms
train loss 0.3017704486846924
Code block 'val epoch=4' took: 51085.19179 ms
validation loss 0.7932121157646179
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 512MiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --cufile-thread-count 64 --batch-size 32768 --epochs 5'
[WARN  tini (4043782)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-26 11:16:36.813436: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-26 11:16:39.822086: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-26 11:17:03.909573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-26 11:20:55.612838: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-26 11:20:56.053432: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7ef856a11bd0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-26 11:20:56.053505: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-26 11:20:56.248387: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-26 11:20:57.307021: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-26 11:20:57.649317: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.691522
Step #4000	Loss: 0.339106
Step #8000	Loss: 0.435937
Step #12000	Loss: 0.383399
Step #16000	Loss: 0.330158
Step #20000	Loss: 0.324960
Step #24000	Loss: 0.320592
Step #28000	Loss: 0.310298
Step #32000	Loss: 0.330267
Step #36000	Loss: 0.449802
Step #40000	Loss: 0.337834
Step #44000	Loss: 0.337251
Step #48000	Loss: 0.382378
Step #52000	Loss: 0.403553
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 608937.52771 ms
train loss 0.3613041937351227
Code block 'val epoch=0' took: 50811.43727 ms
validation loss 0.5599802732467651
Step #0	Loss: 0.490880
Step #4000	Loss: 0.318502
Step #8000	Loss: 0.350735
Step #12000	Loss: 0.322908
Step #16000	Loss: 0.302843
Step #20000	Loss: 0.307454
Step #24000	Loss: 0.309200
Step #28000	Loss: 0.305279
Step #32000	Loss: 0.316073
Step #36000	Loss: 0.349448
Step #40000	Loss: 0.319211
Step #44000	Loss: 0.305012
Step #48000	Loss: 0.330836
Step #52000	Loss: 0.337941
Code block 'train epoch=1' took: 584664.34557 ms
train loss 0.32182577252388
Code block 'val epoch=1' took: 49893.27923 ms
validation loss 0.6224856972694397
Step #0	Loss: 0.354558
Step #4000	Loss: 0.302860
Step #8000	Loss: 0.311891
Step #12000	Loss: 0.306132
Step #16000	Loss: 0.290567
Step #20000	Loss: 0.311443
Step #24000	Loss: 0.303017
Step #28000	Loss: 0.294198
Step #32000	Loss: 0.307655
Step #36000	Loss: 0.315685
Step #40000	Loss: 0.321074
Step #44000	Loss: 0.287698
Step #48000	Loss: 0.319979
Step #52000	Loss: 0.324256
Code block 'train epoch=2' took: 580472.92437 ms
train loss 0.3092034161090851
Code block 'val epoch=2' took: 50157.46848 ms
validation loss 0.6474097967147827
Step #0	Loss: 0.327596
Step #4000	Loss: 0.302246
Step #8000	Loss: 0.300790
Step #12000	Loss: 0.293123
Step #16000	Loss: 0.291387
Step #20000	Loss: 0.304431
Step #24000	Loss: 0.299413
Step #28000	Loss: 0.292905
Step #32000	Loss: 0.311782
Step #36000	Loss: 0.305362
Step #40000	Loss: 0.312004
Step #44000	Loss: 0.286012
Step #48000	Loss: 0.315436
Step #52000	Loss: 0.306448
Code block 'train epoch=3' took: 579709.48820 ms
train loss 0.30428141355514526
Code block 'val epoch=3' took: 50224.40179 ms
validation loss 0.7039085030555725
Step #0	Loss: 0.324809
Step #4000	Loss: 0.305377
Step #8000	Loss: 0.298728
Step #12000	Loss: 0.289939
Step #16000	Loss: 0.286903
Step #20000	Loss: 0.305376
Step #24000	Loss: 0.300107
Step #28000	Loss: 0.293787
Step #32000	Loss: 0.308782
Step #36000	Loss: 0.296020
Step #40000	Loss: 0.307533
Step #44000	Loss: 0.288392
Step #48000	Loss: 0.318268
Step #52000	Loss: 0.305047
Code block 'train epoch=4' took: 579697.23797 ms
train loss 0.3019096851348877
Code block 'val epoch=4' took: 50388.29466 ms
validation loss 0.7469446659088135
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --cufile-thread-count 64 --batch-size 32768 --epochs 5'
[WARN  tini (4103954)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-26 12:13:56.500206: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-26 12:13:59.887223: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-26 12:14:25.594603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-26 12:18:17.416011: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-26 12:18:18.268289: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f0fcffb98c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-26 12:18:18.268367: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-26 12:18:18.432098: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-26 12:18:20.029466: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-26 12:18:20.353842: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.790568
Step #4000	Loss: 0.320797
Step #8000	Loss: 0.430581
Step #12000	Loss: 0.368130
Step #16000	Loss: 0.334177
Step #20000	Loss: 0.411082
Step #24000	Loss: 0.364763
Step #28000	Loss: 0.342660
Step #32000	Loss: 0.401227
Step #36000	Loss: 0.337243
Step #40000	Loss: 0.394254
Step #44000	Loss: 0.360190
Step #48000	Loss: 0.449633
Step #52000	Loss: 0.318083
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 631447.10956 ms
train loss 0.36357465386390686
Code block 'val epoch=0' took: 50431.93139 ms
validation loss 0.5732027888298035
Step #0	Loss: 0.441738
Step #4000	Loss: 0.307199
Step #8000	Loss: 0.369210
Step #12000	Loss: 0.319901
Step #16000	Loss: 0.302571
Step #20000	Loss: 0.339087
Step #24000	Loss: 0.328091
Step #28000	Loss: 0.312228
Step #32000	Loss: 0.335637
Step #36000	Loss: 0.315525
Step #40000	Loss: 0.325510
Step #44000	Loss: 0.307353
Step #48000	Loss: 0.367454
Step #52000	Loss: 0.305520
Code block 'train epoch=1' took: 582270.81556 ms
train loss 0.32358279824256897
Code block 'val epoch=1' took: 51199.57864 ms
validation loss 0.6628518104553223
Step #0	Loss: 0.356868
Step #4000	Loss: 0.296371
Step #8000	Loss: 0.325289
Step #12000	Loss: 0.301232
Step #16000	Loss: 0.288685
Step #20000	Loss: 0.314476
Step #24000	Loss: 0.307106
Step #28000	Loss: 0.302226
Step #32000	Loss: 0.321428
Step #36000	Loss: 0.307948
Step #40000	Loss: 0.298969
Step #44000	Loss: 0.299572
Step #48000	Loss: 0.337696
Step #52000	Loss: 0.301237
Code block 'train epoch=2' took: 577811.79503 ms
train loss 0.31020206212997437
Code block 'val epoch=2' took: 50663.60413 ms
validation loss 0.7493687272071838
Step #0	Loss: 0.336512
Step #4000	Loss: 0.293245
Step #8000	Loss: 0.305357
Step #12000	Loss: 0.298523
Step #16000	Loss: 0.290140
Step #20000	Loss: 0.302880
Step #24000	Loss: 0.308339
Step #28000	Loss: 0.298120
Step #32000	Loss: 0.308312
Step #36000	Loss: 0.299111
Step #40000	Loss: 0.292124
Step #44000	Loss: 0.284603
Step #48000	Loss: 0.321611
Step #52000	Loss: 0.298534
Code block 'train epoch=3' took: 579770.64349 ms
train loss 0.30495816469192505
Code block 'val epoch=3' took: 50445.56518 ms
validation loss 0.807090163230896
Step #0	Loss: 0.332489
Step #4000	Loss: 0.297727
Step #8000	Loss: 0.301265
Step #12000	Loss: 0.295461
Step #16000	Loss: 0.290179
Step #20000	Loss: 0.289873
Step #24000	Loss: 0.306183
Step #28000	Loss: 0.296881
Step #32000	Loss: 0.310174
Step #36000	Loss: 0.299766
Step #40000	Loss: 0.292474
Step #44000	Loss: 0.285594
Step #48000	Loss: 0.320785
Step #52000	Loss: 0.293182
Code block 'train epoch=4' took: 576890.72606 ms
train loss 0.30210041999816895
Code block 'val epoch=4' took: 50861.45370 ms
validation loss 0.845993161201477
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --cufile-thread-count 64 --batch-size 32768 --epochs 5'
[WARN  tini (34549)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-26 13:11:29.106020: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-26 13:11:32.426006: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-26 13:11:57.642478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-26 13:15:42.450692: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-26 13:15:42.872998: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7ef9d7805fa0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-26 13:15:42.873069: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-26 13:15:43.024940: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-26 13:15:44.038683: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-26 13:15:44.378168: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 2.515428
Step #4000	Loss: 0.353196
Step #8000	Loss: 0.341028
Step #12000	Loss: 0.314696
Step #16000	Loss: 0.318311
Step #20000	Loss: 0.349970
Step #24000	Loss: 0.403079
Step #28000	Loss: 0.318027
Step #32000	Loss: 0.334877
Step #36000	Loss: 0.383486
Step #40000	Loss: 0.417086
Step #44000	Loss: 0.406788
Step #48000	Loss: 0.358786
Step #52000	Loss: 0.350362
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 602087.83389 ms
train loss 0.3609931468963623
Code block 'val epoch=0' took: 50618.55925 ms
validation loss 0.5986302495002747
Step #0	Loss: 0.445878
Step #4000	Loss: 0.322727
Step #8000	Loss: 0.305435
Step #12000	Loss: 0.305774
Step #16000	Loss: 0.301381
Step #20000	Loss: 0.316578
Step #24000	Loss: 0.342586
Step #28000	Loss: 0.303178
Step #32000	Loss: 0.323690
Step #36000	Loss: 0.325587
Step #40000	Loss: 0.328008
Step #44000	Loss: 0.328594
Step #48000	Loss: 0.330782
Step #52000	Loss: 0.321478
Code block 'train epoch=1' took: 578524.62263 ms
train loss 0.32258567214012146
Code block 'val epoch=1' took: 51304.81847 ms
validation loss 0.6513691544532776
Step #0	Loss: 0.334915
Step #4000	Loss: 0.306432
Step #8000	Loss: 0.296727
Step #12000	Loss: 0.299355
Step #16000	Loss: 0.294744
Step #20000	Loss: 0.314309
Step #24000	Loss: 0.327911
Step #28000	Loss: 0.297817
Step #32000	Loss: 0.310678
Step #36000	Loss: 0.309912
Step #40000	Loss: 0.302618
Step #44000	Loss: 0.311246
Step #48000	Loss: 0.323239
Step #52000	Loss: 0.315314
Code block 'train epoch=2' took: 576833.92935 ms
train loss 0.31032782793045044
Code block 'val epoch=2' took: 50673.55419 ms
validation loss 0.7027502655982971
Step #0	Loss: 0.318184
Step #4000	Loss: 0.302377
Step #8000	Loss: 0.292599
Step #12000	Loss: 0.289907
Step #16000	Loss: 0.288050
Step #20000	Loss: 0.306487
Step #24000	Loss: 0.318123
Step #28000	Loss: 0.292336
Step #32000	Loss: 0.306891
Step #36000	Loss: 0.304287
Step #40000	Loss: 0.291579
Step #44000	Loss: 0.298852
Step #48000	Loss: 0.315432
Step #52000	Loss: 0.308431
Code block 'train epoch=3' took: 578362.45896 ms
train loss 0.30483829975128174
Code block 'val epoch=3' took: 50077.18704 ms
validation loss 0.7257567048072815
Step #0	Loss: 0.316323
Step #4000	Loss: 0.302064
Step #8000	Loss: 0.294544
Step #12000	Loss: 0.292828
Step #16000	Loss: 0.288881
Step #20000	Loss: 0.296420
Step #24000	Loss: 0.314668
Step #28000	Loss: 0.289919
Step #32000	Loss: 0.306556
Step #36000	Loss: 0.302300
Step #40000	Loss: 0.290113
Step #44000	Loss: 0.298383
Step #48000	Loss: 0.313070
Step #52000	Loss: 0.300372
Code block 'train epoch=4' took: 575295.98161 ms
train loss 0.30195996165275574
Code block 'val epoch=4' took: 50061.61654 ms
validation loss 0.7487040162086487
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_block_8 (Sequent  multiple                 256320160 
 ialBlock)                                                       
                                                                 
 rating_binary/binary_output  multiple                 33        
  (BinaryOutput)                                                 
                                                                 
 model_context (ModelContext  multiple                 0         
 )                                                               
                                                                 
 prepare_features (PrepareFe  multiple                 0         
 atures)                                                         
                                                                 
=================================================================
Total params: 256,320,194
Trainable params: 256,320,193
Non-trainable params: 1
_________________________________________________________________
None
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 1GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --cufile-thread-count 64 --batch-size 32768 --epochs 5'
[WARN  tini (140772)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-26 14:08:24.330534: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-26 14:08:28.279501: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-26 14:08:55.730590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-26 14:12:43.685790: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-26 14:12:44.237665: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f0af681b580 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-26 14:12:44.237735: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-26 14:12:44.396224: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-26 14:12:45.420247: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-26 14:12:45.762846: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 3.524110
Step #4000	Loss: 0.325502
Step #8000	Loss: 0.350409
Step #12000	Loss: 0.307885
Step #16000	Loss: 0.345754
Step #20000	Loss: 0.330634
Step #24000	Loss: 0.372236
Step #28000	Loss: 0.336670
Step #32000	Loss: 0.357697
Step #36000	Loss: 0.332540
Step #40000	Loss: 0.339834
Step #44000	Loss: 0.340434
Step #48000	Loss: 0.350256
Step #52000	Loss: 0.325981
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
Code block 'train epoch=0' took: 607832.57816 ms
train loss 0.3595527410507202
Code block 'val epoch=0' took: 50398.05824 ms
validation loss 0.6245836615562439
Step #0	Loss: 0.480989
Step #4000	Loss: 0.308759
Step #8000	Loss: 0.312641
Step #12000	Loss: 0.297437
Step #16000	Loss: 0.314968
Step #20000	Loss: 0.307511
Step #24000	Loss: 0.328427
Step #28000	Loss: 0.314951
Step #32000	Loss: 0.323723
Step #36000	Loss: 0.301454
Step #40000	Loss: 0.319544
Step #44000	Loss: 0.303682
Step #48000	Loss: 0.328057
Step #52000	Loss: 0.298947
Code block 'train epoch=1' took: 583647.97793 ms
train loss 0.32003259658813477
Code block 'val epoch=1' took: 49941.91374 ms
validation loss 0.6908830404281616
Step #0	Loss: 0.384716
Step #4000	Loss: 0.301356
Step #8000	Loss: 0.300018
Step #12000	Loss: 0.295053
Step #16000	Loss: 0.302635
Step #20000	Loss: 0.307467
Step #24000	Loss: 0.314610
Step #28000	Loss: 0.306315
Step #32000	Loss: 0.320641
Step #36000	Loss: 0.299700
Step #40000	Loss: 0.310067
Step #44000	Loss: 0.293696
Step #48000	Loss: 0.319482
Step #52000	Loss: 0.298392
Code block 'train epoch=2' took: 588624.04927 ms
train loss 0.3082194924354553
Code block 'val epoch=2' took: 49936.42843 ms
validation loss 0.7525240182876587
Step #0	Loss: 0.352358
Step #4000	Loss: 0.295486
Step #8000	Loss: 0.300763
Step #12000	Loss: 0.289452
Step #16000	Loss: 0.296159
Step #20000	Loss: 0.299803
Step #24000	Loss: 0.311841
Step #28000	Loss: 0.303573
Step #32000	Loss: 0.314503
Step #36000	Loss: 0.292143
Step #40000	Loss: 0.310892
Step #44000	Loss: 0.294807
Step #48000	Loss: 0.320183
Step #52000	Loss: 0.294541
Code block 'train epoch=3' took: 584681.63763 ms
train loss 0.30357712507247925
Code block 'val epoch=3' took: 51299.88240 ms
validation loss 0.7782257795333862
Step #0	Loss: 0.342959
Step #4000	Loss: 0.300020
Step #8000	Loss: 0.296088
Step #12000	Loss: 0.277151
Step #16000	Loss: 0.294084
Step #20000	Loss: 0.299139
Step #24000	Loss: 0.307273
Step #28000	Loss: 0.305688
Step #32000	Loss: 0.311057
Step #36000	Loss: 0.293739
Step #40000	Loss: 0.309844
Step #44000	Loss: 0.282202
Step #48000	Loss: 0.312522
Code block 'train epoch=4' took: 525551.41318 ms
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 332, in _get_next_batch
    batch = next(self._batch_itr)
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home2/faculty/pwesolowski/praca-mgr/pipelines-repo/2_merlin/run_merlin.py", line 155, in <module>
    for batch, (examples, labels) in enumerate(train_tf_ds):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/tensorflow.py", line 97, in __next__
    converted_batch = self.convert_batch(super().__next__())
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 261, in __next__
    return self._get_next_batch()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 343, in _get_next_batch
    self._fetch_chunk()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 277, in _fetch_chunk
    raise chunks
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 791, in load_chunks
    self.chunk_logic(itr)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 759, in chunk_logic
    for chunks in self.batch(itr):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 745, in batch
    value = next(itr)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/io/dataframe_iter.py", line 44, in __iter__
    yield part.compute(scheduler="synchronous")
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/base.py", line 314, in compute
    (result,) = compute(self, traverse=False, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/base.py", line 599, in compute
    results = schedule(dsk, keys, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 557, in get_sync
    return get_async(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 500, in get_async
    for key, res_info, failed in queue_get(queue).result():
  File "/opt/conda/envs/rapids/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/opt/conda/envs/rapids/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 542, in submit
    fut.set_result(fn(*args, **kwargs))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 238, in batch_execute_tasks
    return [execute_task(*a) for a in it]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 238, in <listcomp>
    return [execute_task(*a) for a in it]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 229, in execute_task
    result = pack_exception(e, dumps)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 224, in execute_task
    result = _execute_task(task, data)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/optimization.py", line 990, in __call__
    return core.get(self.dsk, self.outkey, dict(zip(self.inkeys, args)))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 149, in get
    result = _execute_task(task, cache)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in <genexpr>
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in <genexpr>
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 113, in _execute_task
    return [_execute_task(a, cache) for a in arg]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 113, in <listcomp>
    return [_execute_task(a, cache) for a in arg]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in <genexpr>
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/utils.py", line 1104, in __call__
    return getattr(__obj, self.method)(*args, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/dataframe.py", line 6841, in explode
    return super()._explode(column, ignore_index)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 3791, in _explode
    exploded = libcudf.lists.explode_outer(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "lists.pyx", line 67, in cudf._lib.lists.explode_outer
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp
+ for BLOCKSIZE in "512MiB" "1GiB" "2GiB"
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 1 --cufile-thread-count 64 --batch-size 32768 --epochs 5'
[WARN  tini (242554)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-26 15:04:11.685171: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-26 15:04:15.747424: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-26 15:04:43.071868: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-26 15:08:25.646741: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-26 15:08:26.177682: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f4f3fce6720 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-26 15:08:26.177756: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-26 15:08:26.337641: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-26 15:08:27.410681: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-26 15:08:27.755822: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.809713
Failed to transform operator <nvtabular.ops.categorify.Categorify object at 0x7f5189593af0>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1778, in _encode
    labels = codes.merge(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/dataframe.py", line 4004, in merge
    ).perform_merge()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/join/join.py", line 203, in perform_merge
    self.rhs._gather(gather_map=right_rows, **gather_kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
Code block 'train epoch=0' took: 57084.81869 ms
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 332, in _get_next_batch
    batch = next(self._batch_itr)
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home2/faculty/pwesolowski/praca-mgr/pipelines-repo/2_merlin/run_merlin.py", line 155, in <module>
    for batch, (examples, labels) in enumerate(train_tf_ds):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/tensorflow.py", line 97, in __next__
    converted_batch = self.convert_batch(super().__next__())
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 261, in __next__
    return self._get_next_batch()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 344, in _get_next_batch
    batch = next(self._batch_itr)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 369, in make_tensors
    tensors_by_name = self._convert_df_to_tensors(gdf)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 520, in _convert_df_to_tensors
    tensors_by_name[column_name] = self._to_tensor(gdf_i[[column_name]])
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 450, in _to_tensor
    tensor = df_or_series.to_cupy()
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/single_column_frame.py", line 131, in to_cupy
    return super().to_cupy(dtype, copy, na_value).flatten()
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 533, in to_cupy
    return self._to_array(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 498, in _to_array
    matrix[:, i] = get_column_values_na(col)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 477, in get_column_values_na
    return get_column_values(col)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 534, in <lambda>
    (lambda col: col.values.copy())
  File "cupy/_core/core.pyx", line 590, in cupy._core.core._ndarray_base.copy
  File "cupy/_core/core.pyx", line 616, in cupy._core.core._ndarray_base.copy
  File "cupy/_core/core.pyx", line 575, in cupy._core.core._ndarray_base.astype
  File "cupy/_core/core.pyx", line 136, in cupy._core.core.ndarray.__new__
  File "cupy/_core/core.pyx", line 224, in cupy._core.core._ndarray_base._init
  File "cupy/cuda/memory.pyx", line 742, in cupy.cuda.memory.alloc
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/rmm/rmm.py", line 230, in rmm_cupy_allocator
    buf = librmm.device_buffer.DeviceBuffer(size=nbytes, stream=stream)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 2 --cufile-thread-count 64 --batch-size 32768 --epochs 5'
[WARN  tini (252969)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-26 15:09:22.077194: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-26 15:09:25.653222: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-26 15:09:51.916848: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
Failed to transform operator <nvtabular.ops.categorify.Categorify object at 0x7f4c80157b80>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1780, in _encode
    ).sort_values("order")["labels"]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 2214, in sort_values
    out = self._gather(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-26 15:13:38.314927: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-26 15:13:38.831105: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f44038062c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-26 15:13:38.831180: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-26 15:13:38.980783: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-26 15:13:40.319858: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-26 15:13:40.647937: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 1.083123
Code block 'train epoch=0' took: 39363.85233 ms
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 332, in _get_next_batch
    batch = next(self._batch_itr)
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home2/faculty/pwesolowski/praca-mgr/pipelines-repo/2_merlin/run_merlin.py", line 155, in <module>
    for batch, (examples, labels) in enumerate(train_tf_ds):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/tensorflow.py", line 97, in __next__
    converted_batch = self.convert_batch(super().__next__())
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 261, in __next__
    return self._get_next_batch()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 344, in _get_next_batch
    batch = next(self._batch_itr)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 369, in make_tensors
    tensors_by_name = self._convert_df_to_tensors(gdf)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 520, in _convert_df_to_tensors
    tensors_by_name[column_name] = self._to_tensor(gdf_i[[column_name]])
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 450, in _to_tensor
    tensor = df_or_series.to_cupy()
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/single_column_frame.py", line 131, in to_cupy
    return super().to_cupy(dtype, copy, na_value).flatten()
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 533, in to_cupy
    return self._to_array(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 498, in _to_array
    matrix[:, i] = get_column_values_na(col)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 477, in get_column_values_na
    return get_column_values(col)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/frame.py", line 534, in <lambda>
    (lambda col: col.values.copy())
  File "cupy/_core/core.pyx", line 590, in cupy._core.core._ndarray_base.copy
  File "cupy/_core/core.pyx", line 616, in cupy._core.core._ndarray_base.copy
  File "cupy/_core/core.pyx", line 575, in cupy._core.core._ndarray_base.astype
  File "cupy/_core/core.pyx", line 136, in cupy._core.core.ndarray.__new__
  File "cupy/_core/core.pyx", line 224, in cupy._core.core._ndarray_base._init
  File "cupy/cuda/memory.pyx", line 742, in cupy.cuda.memory.alloc
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/rmm/rmm.py", line 230, in rmm_cupy_allocator
    buf = librmm.device_buffer.DeviceBuffer(size=nbytes, stream=stream)
  File "device_buffer.pyx", line 85, in rmm._lib.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp
+ for PARTS_PER_CHUNK in 1 2 3
+ singularity run --nv -B /scratch/shared/pwesolowski,/run/udev:/run/udev:ro /home2/faculty/pwesolowski/containers/merlin-prod.sif /bin/bash --rcfile /home2/faculty/pwesolowski/containers/singularity_rc -ci 'cd ~/praca-mgr/pipelines-repo/2_merlin && export PMIX_MCA_gds=^ds12 && ./hvd_wrapper.sh python -u run_merlin.py --workflow-dir /scratch/shared/pwesolowski/mgr-pipeline/merlin/ --blocksize 2GiB --data-path /scratch/shared/pwesolowski/mgr-pipeline/joined-recommender --parts-per-chunk 3 --cufile-thread-count 64 --batch-size 32768 --epochs 5'
[WARN  tini (262972)] Tini is not running as PID 1 .
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, run Tini as PID 1.
This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.download.nvidia.com/licenses/NVIDIA_Deep_Learning_Container_License.pdf

bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2023-07-26 15:14:11.999916: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-26 15:14:15.785632: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'
  warn(f"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}")
/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'
  warn(f"Triton dtype mappings did not load successfully due to an error: {exc.msg}")
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
2023-07-26 15:14:43.241510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20169 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0
hvd.local_rank()=0
hvd.rank()=0
hvd.size()=1
nvt.ops.get_embedding_sizes(workflow)={'user_id': (2000000, 512), 'gmap_id': (2000000, 512), 'category': (4564, 179)}
Failed to transform operator <nvtabular.ops.categorify.Categorify object at 0x7f846cddfa90>
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1780, in _encode
    ).sort_values("order")["labels"]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 2214, in sort_values
    out = self._gather(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:459: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128000000 elements. This may consume a large amount of memory.
  warnings.warn(
2023-07-26 15:18:29.816959: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-07-26 15:18:30.217591: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f7bbcc04be0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-26 15:18:30.217670: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
2023-07-26 15:18:30.354234: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-07-26 15:18:31.412269: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-26 15:18:31.731720: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Step #0	Loss: 0.685773
Code block 'train epoch=0' took: 46192.26196 ms
Traceback (most recent call last):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 510, in transform
    encoded = _encode(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 1780, in _encode
    ).sort_values("order")["labels"]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 2214, in sort_values
    out = self._gather(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/cudf/core/indexed_frame.py", line 1718, in _gather
    libcudf.copying.gather(
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "copying.pyx", line 186, in cudf._lib.copying.gather
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home2/faculty/pwesolowski/praca-mgr/pipelines-repo/2_merlin/run_merlin.py", line 155, in <module>
    for batch, (examples, labels) in enumerate(train_tf_ds):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/tensorflow.py", line 97, in __next__
    converted_batch = self.convert_batch(super().__next__())
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 261, in __next__
    return self._get_next_batch()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 343, in _get_next_batch
    self._fetch_chunk()
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 277, in _fetch_chunk
    raise chunks
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 791, in load_chunks
    self.chunk_logic(itr)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 759, in chunk_logic
    for chunks in self.batch(itr):
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dataloader/loader_base.py", line 745, in batch
    value = next(itr)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/io/dataframe_iter.py", line 44, in __iter__
    yield part.compute(scheduler="synchronous")
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/base.py", line 314, in compute
    (result,) = compute(self, traverse=False, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/base.py", line 599, in compute
    results = schedule(dsk, keys, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 557, in get_sync
    return get_async(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 500, in get_async
    for key, res_info, failed in queue_get(queue).result():
  File "/opt/conda/envs/rapids/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/opt/conda/envs/rapids/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 542, in submit
    fut.set_result(fn(*args, **kwargs))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 238, in batch_execute_tasks
    return [execute_task(*a) for a in it]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 238, in <listcomp>
    return [execute_task(*a) for a in it]
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 229, in execute_task
    result = pack_exception(e, dumps)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/local.py", line 224, in execute_task
    result = _execute_task(task, data)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/optimization.py", line 990, in __call__
    return core.get(self.dsk, self.outkey, dict(zip(self.inkeys, args)))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 149, in get
    result = _execute_task(task, cache)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in <genexpr>
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/core.py", line 119, in _execute_task
    return func(*(_execute_task(a, cache) for a in args))
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/dask/utils.py", line 72, in apply
    return func(*args, **kwargs)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 87, in transform
    transformed_data = self._execute_node(node, transformable, capture_dtypes, strict)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 101, in _execute_node
    upstream_outputs = self._run_upstream_transforms(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 114, in _run_upstream_transforms
    node_output = self._execute_node(
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 107, in _execute_node
    transform_output = self._run_node_transform(node, transform_input, capture_dtypes, strict)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 227, in _run_node_transform
    raise exc
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/merlin/dag/executors.py", line 214, in _run_node_transform
    transformed_data = node.op.transform(selection, input_data)
  File "/opt/conda/envs/rapids/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/opt/conda/envs/rapids/lib/python3.10/site-packages/nvtabular/ops/categorify.py", line 534, in transform
    raise RuntimeError(f"Failed to categorical encode column {name}") from e
RuntimeError: Failed to categorical encode column gmap_id
